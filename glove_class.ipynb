{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cfe0dae-33c9-4cf0-8a4e-490c292400c4",
   "metadata": {},
   "source": [
    "# 1. Get the images\n",
    "\n",
    "## Glove Images Samples\n",
    "\n",
    "![](https://github.com/fdh0/files/blob/master/0_0_5_20210909_094256082_0_85.bmp?raw=true)\n",
    "\n",
    "## Folders Images Examples\n",
    "\n",
    "-- 001_Folder\n",
    "\n",
    "    -- left\n",
    "    \n",
    "        -- 00001.bmp\n",
    "        \n",
    "        -- 00002.bmp\n",
    "        \n",
    "    -- right\n",
    "    \n",
    "        -- 00001.bmp\n",
    "        \n",
    "        -- 00002.bmp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0687fa6-bc55-48fd-8f8c-06eb8531411d",
   "metadata": {},
   "source": [
    "# 2. Preprocess the Images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723f9086-fa8a-4bf0-9b04-5b345a05daab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e48823c-13e0-41fb-b1b1-14b855338b7f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from collections import OrderedDict\n",
      "from functools import partial\n",
      "from typing import Callable, Optional\n",
      "\n",
      "import torch.nn as nn\n",
      "import torch\n",
      "from torch import Tensor\n",
      "\n",
      "\n",
      "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
      "    \"\"\"\n",
      "    Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
      "    \"Deep Networks with Stochastic Depth\", https://arxiv.org/pdf/1603.09382.pdf\n",
      "\n",
      "    This function is taken from the rwightman.\n",
      "    It can be seen here:\n",
      "    https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/layers/drop.py#L140\n",
      "    \"\"\"\n",
      "    if drop_prob == 0. or not training:\n",
      "        return x\n",
      "    keep_prob = 1 - drop_prob\n",
      "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
      "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
      "    random_tensor.floor_()  # binarize\n",
      "    output = x.div(keep_prob) * random_tensor\n",
      "    return output\n",
      "\n",
      "\n",
      "class DropPath(nn.Module):\n",
      "    \"\"\"\n",
      "    Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
      "    \"Deep Networks with Stochastic Depth\", https://arxiv.org/pdf/1603.09382.pdf\n",
      "    \"\"\"\n",
      "    def __init__(self, drop_prob=None):\n",
      "        super(DropPath, self).__init__()\n",
      "        self.drop_prob = drop_prob\n",
      "\n",
      "    def forward(self, x):\n",
      "        return drop_path(x, self.drop_prob, self.training)\n",
      "\n",
      "\n",
      "class ConvBNAct(nn.Module):\n",
      "    def __init__(self,\n",
      "                 in_planes: int,\n",
      "                 out_planes: int,\n",
      "                 kernel_size: int = 3,\n",
      "                 stride: int = 1,\n",
      "                 groups: int = 1,\n",
      "                 norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
      "                 activation_layer: Optional[Callable[..., nn.Module]] = None):\n",
      "        super(ConvBNAct, self).__init__()\n",
      "\n",
      "        padding = (kernel_size - 1) // 2\n",
      "        if norm_layer is None:\n",
      "            norm_layer = nn.BatchNorm2d\n",
      "        if activation_layer is None:\n",
      "            activation_layer = nn.SiLU  # alias Swish  (torch>=1.7)\n",
      "\n",
      "        self.conv = nn.Conv2d(in_channels=in_planes,\n",
      "                              out_channels=out_planes,\n",
      "                              kernel_size=kernel_size,\n",
      "                              stride=stride,\n",
      "                              padding=padding,\n",
      "                              groups=groups,\n",
      "                              bias=False)\n",
      "\n",
      "        self.bn = norm_layer(out_planes)\n",
      "        self.act = activation_layer()\n",
      "\n",
      "    def forward(self, x):\n",
      "        result = self.conv(x)\n",
      "        result = self.bn(result)\n",
      "        result = self.act(result)\n",
      "\n",
      "        return result\n",
      "\n",
      "\n",
      "class SqueezeExcite(nn.Module):\n",
      "    def __init__(self,\n",
      "                 input_c: int,   # block input channel\n",
      "                 expand_c: int,  # block expand channel\n",
      "                 se_ratio: float = 0.25):\n",
      "        super(SqueezeExcite, self).__init__()\n",
      "        squeeze_c = int(input_c * se_ratio)\n",
      "        self.conv_reduce = nn.Conv2d(expand_c, squeeze_c, 1)\n",
      "        self.act1 = nn.SiLU()  # alias Swish\n",
      "        self.conv_expand = nn.Conv2d(squeeze_c, expand_c, 1)\n",
      "        self.act2 = nn.Sigmoid()\n",
      "\n",
      "    def forward(self, x: Tensor) -> Tensor:\n",
      "        scale = x.mean((2, 3), keepdim=True)\n",
      "        scale = self.conv_reduce(scale)\n",
      "        scale = self.act1(scale)\n",
      "        scale = self.conv_expand(scale)\n",
      "        scale = self.act2(scale)\n",
      "        return scale * x\n",
      "\n",
      "\n",
      "class MBConv(nn.Module):\n",
      "    def __init__(self,\n",
      "                 kernel_size: int,\n",
      "                 input_c: int,\n",
      "                 out_c: int,\n",
      "                 expand_ratio: int,\n",
      "                 stride: int,\n",
      "                 se_ratio: float,\n",
      "                 drop_rate: float,\n",
      "                 norm_layer: Callable[..., nn.Module]):\n",
      "        super(MBConv, self).__init__()\n",
      "\n",
      "        if stride not in [1, 2]:\n",
      "            raise ValueError(\"illegal stride value.\")\n",
      "\n",
      "        self.has_shortcut = (stride == 1 and input_c == out_c)\n",
      "\n",
      "        activation_layer = nn.SiLU  # alias Swish\n",
      "        expanded_c = input_c * expand_ratio\n",
      "\n",
      "        # 在EfficientNetV2中，MBConv中不存在expansion=1的情况所以conv_pw肯定存在\n",
      "        assert expand_ratio != 1\n",
      "        # Point-wise expansion\n",
      "        self.expand_conv = ConvBNAct(input_c,\n",
      "                                     expanded_c,\n",
      "                                     kernel_size=1,\n",
      "                                     norm_layer=norm_layer,\n",
      "                                     activation_layer=activation_layer)\n",
      "\n",
      "        # Depth-wise convolution\n",
      "        self.dwconv = ConvBNAct(expanded_c,\n",
      "                                expanded_c,\n",
      "                                kernel_size=kernel_size,\n",
      "                                stride=stride,\n",
      "                                groups=expanded_c,\n",
      "                                norm_layer=norm_layer,\n",
      "                                activation_layer=activation_layer)\n",
      "\n",
      "        self.se = SqueezeExcite(input_c, expanded_c, se_ratio) if se_ratio > 0 else nn.Identity()\n",
      "\n",
      "        # Point-wise linear projection\n",
      "        self.project_conv = ConvBNAct(expanded_c,\n",
      "                                      out_planes=out_c,\n",
      "                                      kernel_size=1,\n",
      "                                      norm_layer=norm_layer,\n",
      "                                      activation_layer=nn.Identity)  # 注意这里没有激活函数，所有传入Identity\n",
      "\n",
      "        self.out_channels = out_c\n",
      "\n",
      "        # 只有在使用shortcut连接时才使用dropout层\n",
      "        self.drop_rate = drop_rate\n",
      "        if self.has_shortcut and drop_rate > 0:\n",
      "            self.dropout = DropPath(drop_rate)\n",
      "\n",
      "    def forward(self, x: Tensor) -> Tensor:\n",
      "        result = self.expand_conv(x)\n",
      "        result = self.dwconv(result)\n",
      "        result = self.se(result)\n",
      "        result = self.project_conv(result)\n",
      "\n",
      "        if self.has_shortcut:\n",
      "            if self.drop_rate > 0:\n",
      "                result = self.dropout(result)\n",
      "            result += x\n",
      "\n",
      "        return result\n",
      "\n",
      "\n",
      "class FusedMBConv(nn.Module):\n",
      "    def __init__(self,\n",
      "                 kernel_size: int,\n",
      "                 input_c: int,\n",
      "                 out_c: int,\n",
      "                 expand_ratio: int,\n",
      "                 stride: int,\n",
      "                 se_ratio: float,\n",
      "                 drop_rate: float,\n",
      "                 norm_layer: Callable[..., nn.Module]):\n",
      "        super(FusedMBConv, self).__init__()\n",
      "\n",
      "        assert stride in [1, 2]\n",
      "        assert se_ratio == 0\n",
      "\n",
      "        self.has_shortcut = stride == 1 and input_c == out_c\n",
      "        self.drop_rate = drop_rate\n",
      "\n",
      "        self.has_expansion = expand_ratio != 1\n",
      "\n",
      "        activation_layer = nn.SiLU  # alias Swish\n",
      "        expanded_c = input_c * expand_ratio\n",
      "\n",
      "        # 只有当expand ratio不等于1时才有expand conv\n",
      "        if self.has_expansion:\n",
      "            # Expansion convolution\n",
      "            self.expand_conv = ConvBNAct(input_c,\n",
      "                                         expanded_c,\n",
      "                                         kernel_size=kernel_size,\n",
      "                                         stride=stride,\n",
      "                                         norm_layer=norm_layer,\n",
      "                                         activation_layer=activation_layer)\n",
      "\n",
      "            self.project_conv = ConvBNAct(expanded_c,\n",
      "                                          out_c,\n",
      "                                          kernel_size=1,\n",
      "                                          norm_layer=norm_layer,\n",
      "                                          activation_layer=nn.Identity)  # 注意没有激活函数\n",
      "        else:\n",
      "            # 当只有project_conv时的情况\n",
      "            self.project_conv = ConvBNAct(input_c,\n",
      "                                          out_c,\n",
      "                                          kernel_size=kernel_size,\n",
      "                                          stride=stride,\n",
      "                                          norm_layer=norm_layer,\n",
      "                                          activation_layer=activation_layer)  # 注意有激活函数\n",
      "\n",
      "        self.out_channels = out_c\n",
      "\n",
      "        # 只有在使用shortcut连接时才使用dropout层\n",
      "        self.drop_rate = drop_rate\n",
      "        if self.has_shortcut and drop_rate > 0:\n",
      "            self.dropout = DropPath(drop_rate)\n",
      "\n",
      "    def forward(self, x: Tensor) -> Tensor:\n",
      "        if self.has_expansion:\n",
      "            result = self.expand_conv(x)\n",
      "            result = self.project_conv(result)\n",
      "        else:\n",
      "            result = self.project_conv(x)\n",
      "\n",
      "        if self.has_shortcut:\n",
      "            if self.drop_rate > 0:\n",
      "                result = self.dropout(result)\n",
      "\n",
      "            result += x\n",
      "\n",
      "        return result\n",
      "\n",
      "\n",
      "class EfficientNetV2(nn.Module):\n",
      "    def __init__(self,\n",
      "                 model_cnf: list,\n",
      "                 num_classes: int = 1000,\n",
      "                 num_features: int = 1280,\n",
      "                 dropout_rate: float = 0.2,\n",
      "                 drop_connect_rate: float = 0.2):\n",
      "        super(EfficientNetV2, self).__init__()\n",
      "\n",
      "        for cnf in model_cnf:\n",
      "            assert len(cnf) == 8\n",
      "\n",
      "        norm_layer = partial(nn.BatchNorm2d, eps=1e-3, momentum=0.1)\n",
      "\n",
      "        stem_filter_num = model_cnf[0][4]\n",
      "\n",
      "        self.stem = ConvBNAct(3,\n",
      "                              stem_filter_num,\n",
      "                              kernel_size=3,\n",
      "                              stride=2,\n",
      "                              norm_layer=norm_layer)  # 激活函数默认是SiLU\n",
      "\n",
      "        total_blocks = sum([i[0] for i in model_cnf])\n",
      "        block_id = 0\n",
      "        blocks = []\n",
      "        for cnf in model_cnf:\n",
      "            repeats = cnf[0]\n",
      "            op = FusedMBConv if cnf[-2] == 0 else MBConv\n",
      "            for i in range(repeats):\n",
      "                blocks.append(op(kernel_size=cnf[1],\n",
      "                                 input_c=cnf[4] if i == 0 else cnf[5],\n",
      "                                 out_c=cnf[5],\n",
      "                                 expand_ratio=cnf[3],\n",
      "                                 stride=cnf[2] if i == 0 else 1,\n",
      "                                 se_ratio=cnf[-1],\n",
      "                                 drop_rate=drop_connect_rate * block_id / total_blocks,\n",
      "                                 norm_layer=norm_layer))\n",
      "                block_id += 1\n",
      "        self.blocks = nn.Sequential(*blocks)\n",
      "\n",
      "        head_input_c = model_cnf[-1][-3]\n",
      "        head = OrderedDict()\n",
      "\n",
      "        head.update({\"project_conv\": ConvBNAct(head_input_c,\n",
      "                                               num_features,\n",
      "                                               kernel_size=1,\n",
      "                                               norm_layer=norm_layer)})  # 激活函数默认是SiLU\n",
      "\n",
      "        head.update({\"avgpool\": nn.AdaptiveAvgPool2d(1)})\n",
      "        head.update({\"flatten\": nn.Flatten()})\n",
      "\n",
      "        if dropout_rate > 0:\n",
      "            head.update({\"dropout\": nn.Dropout(p=dropout_rate, inplace=True)})\n",
      "        head.update({\"classifier\": nn.Linear(num_features, num_classes)})\n",
      "\n",
      "        self.head = nn.Sequential(head)\n",
      "\n",
      "        # initial weights\n",
      "        for m in self.modules():\n",
      "            if isinstance(m, nn.Conv2d):\n",
      "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
      "                if m.bias is not None:\n",
      "                    nn.init.zeros_(m.bias)\n",
      "            elif isinstance(m, nn.BatchNorm2d):\n",
      "                nn.init.ones_(m.weight)\n",
      "                nn.init.zeros_(m.bias)\n",
      "            elif isinstance(m, nn.Linear):\n",
      "                nn.init.normal_(m.weight, 0, 0.01)\n",
      "                nn.init.zeros_(m.bias)\n",
      "\n",
      "    def forward(self, x: Tensor) -> Tensor:\n",
      "        x = self.stem(x)\n",
      "        x = self.blocks(x)\n",
      "        x = self.head(x)\n",
      "\n",
      "        return x\n",
      "\n",
      "\n",
      "def efficientnetv2_s(num_classes: int = 1000):\n",
      "    \"\"\"\n",
      "    EfficientNetV2\n",
      "    https://arxiv.org/abs/2104.00298\n",
      "    \"\"\"\n",
      "    # train_size: 300, eval_size: 384\n",
      "\n",
      "    # repeat, kernel, stride, expansion, in_c, out_c, operator, se_ratio\n",
      "    model_config = [[2, 3, 1, 1, 24, 24, 0, 0],\n",
      "                    [4, 3, 2, 4, 24, 48, 0, 0],\n",
      "                    [4, 3, 2, 4, 48, 64, 0, 0],\n",
      "                    [6, 3, 2, 4, 64, 128, 1, 0.25],\n",
      "                    [9, 3, 1, 6, 128, 160, 1, 0.25],\n",
      "                    [15, 3, 2, 6, 160, 256, 1, 0.25]]\n",
      "\n",
      "    model = EfficientNetV2(model_cnf=model_config,\n",
      "                           num_classes=num_classes,\n",
      "                           dropout_rate=0.2)\n",
      "    return model\n",
      "\n",
      "\n",
      "def efficientnetv2_m(num_classes: int = 1000):\n",
      "    \"\"\"\n",
      "    EfficientNetV2\n",
      "    https://arxiv.org/abs/2104.00298\n",
      "    \"\"\"\n",
      "    # train_size: 384, eval_size: 480\n",
      "\n",
      "    # repeat, kernel, stride, expansion, in_c, out_c, operator, se_ratio\n",
      "    model_config = [[3, 3, 1, 1, 24, 24, 0, 0],\n",
      "                    [5, 3, 2, 4, 24, 48, 0, 0],\n",
      "                    [5, 3, 2, 4, 48, 80, 0, 0],\n",
      "                    [7, 3, 2, 4, 80, 160, 1, 0.25],\n",
      "                    [14, 3, 1, 6, 160, 176, 1, 0.25],\n",
      "                    [18, 3, 2, 6, 176, 304, 1, 0.25],\n",
      "                    [5, 3, 1, 6, 304, 512, 1, 0.25]]\n",
      "\n",
      "    model = EfficientNetV2(model_cnf=model_config,\n",
      "                           num_classes=num_classes,\n",
      "                           dropout_rate=0.3)\n",
      "    return model\n",
      "\n",
      "\n",
      "def efficientnetv2_l(num_classes: int = 1000):\n",
      "    \"\"\"\n",
      "    EfficientNetV2\n",
      "    https://arxiv.org/abs/2104.00298\n",
      "    \"\"\"\n",
      "    # train_size: 384, eval_size: 480\n",
      "\n",
      "    # repeat, kernel, stride, expansion, in_c, out_c, operator, se_ratio\n",
      "    model_config = [[4, 3, 1, 1, 32, 32, 0, 0],\n",
      "                    [7, 3, 2, 4, 32, 64, 0, 0],\n",
      "                    [7, 3, 2, 4, 64, 96, 0, 0],\n",
      "                    [10, 3, 2, 4, 96, 192, 1, 0.25],\n",
      "                    [19, 3, 1, 6, 192, 224, 1, 0.25],\n",
      "                    [25, 3, 2, 6, 224, 384, 1, 0.25],\n",
      "                    [7, 3, 1, 6, 384, 640, 1, 0.25]]\n",
      "\n",
      "    model = EfficientNetV2(model_cnf=model_config,\n",
      "                           num_classes=num_classes,\n",
      "                           dropout_rate=0.4)\n",
      "    return model\n"
     ]
    }
   ],
   "source": [
    "# 3. Design or Select the model\n",
    "!cat model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d7e139-ff0a-4d4c-8544-fcb74441b0fc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from PIL import Image\n",
      "import torch\n",
      "from torch.utils.data import Dataset\n",
      "\n",
      "\n",
      "class MyDataSet(Dataset):\n",
      "    \"\"\"自定义数据集\"\"\"\n",
      "\n",
      "    def __init__(self, images_path: list, images_class: list, transform=None):\n",
      "        self.images_path = images_path\n",
      "        self.images_class = images_class\n",
      "        self.transform = transform\n",
      "\n",
      "    def __len__(self):\n",
      "        return len(self.images_path)\n",
      "\n",
      "    def __getitem__(self, item):\n",
      "        img = Image.open(self.images_path[item])\n",
      "        # RGB为彩色图片，L为灰度图片\n",
      "        if img.mode != 'RGB':\n",
      "            raise ValueError(\"image: {} isn't RGB mode.\".format(self.images_path[item]))\n",
      "        label = self.images_class[item]\n",
      "\n",
      "        if self.transform is not None:\n",
      "            img = self.transform(img)\n",
      "\n",
      "        return img, label\n",
      "\n",
      "    @staticmethod\n",
      "    def collate_fn(batch):\n",
      "        # 官方实现的default_collate可以参考\n",
      "        # https://github.com/pytorch/pytorch/blob/67b7e751e6b5931a9f45274653f4f653a4e6cdf6/torch/utils/data/_utils/collate.py\n",
      "        images, labels = tuple(zip(*batch))\n",
      "\n",
      "        images = torch.stack(images, dim=0)\n",
      "        labels = torch.as_tensor(labels)\n",
      "        return images, labels\n"
     ]
    }
   ],
   "source": [
    "# 4. Pact Folders image Into MyDataSet\n",
    "!cat my_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93db1f8e-3e22-4f4f-abec-63eafbf50c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-26 14:04:16--  http://192.168.192.248:8008/pre/pre_efficientnetv2-s.pth\n",
      "正在连接 192.168.192.248:8008... 已连接。\n",
      "已发出 HTTP 请求，正在等待回应... 200 OK\n",
      "长度： 86671567 (83M) [application/octet-stream]\n",
      "正在保存至: “pre_efficientnetv2-s.pth”\n",
      "\n",
      "pre_efficientnetv2- 100%[===================>]  82.66M   907KB/s    in 2m 45s  \n",
      "\n",
      "2022-01-26 14:07:02 (511 KB/s) - 已保存 “pre_efficientnetv2-s.pth” [86671567/86671567])\n",
      "\n",
      "--2022-01-26 14:07:02--  http://./\n",
      "正在解析主机 . (.)... 111.230.217.109\n",
      "正在连接 . (.)|111.230.217.109|:80... 已连接。\n",
      "已发出 HTTP 请求，正在等待回应... 400 Bad Request\n",
      "2022-01-26 14:07:02 错误 400：Bad Request。\n",
      "\n",
      "下载完毕 --2022-01-26 14:07:02--\n",
      "总用时：2m 46s\n",
      "下载了：1 个文件，2m 45s (511 KB/s) 中的 83M\n"
     ]
    }
   ],
   "source": [
    "# Download the pretrained model\n",
    "!wget http://192.168.192.248:8008/pre.zip ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a1ca048-85bb-4a8b-94c0-158b9f18eec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=16, data_path='/home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/001/', device='cuda:0', epochs=10, freeze_layers=True, lr=0.01, lrf=0.01, num_classes=2, weights='./pre/pre_efficientnetv2-s.pth')\n",
      "Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n",
      "41470 images were found in the dataset.\n",
      "33176 images for training.\n",
      "8294 images for validation.\n",
      "Using 8 dataloader workers every process\n",
      "_IncompatibleKeys(missing_keys=['head.classifier.weight', 'head.classifier.bias'], unexpected_keys=[])\n",
      "training head.project_conv.conv.weight\n",
      "training head.project_conv.bn.weight\n",
      "training head.project_conv.bn.bias\n",
      "training head.classifier.weight\n",
      "training head.classifier.bias\n",
      "[train epoch 0] loss: 1.428, acc: 0.571: 100%|█| 2074/2074 [03:50<00:00,  9.02it\n",
      "[valid epoch 0] loss: 0.584, acc: 0.734: 100%|█| 519/519 [01:20<00:00,  6.47it/s\n",
      "[train epoch 1] loss: 0.919, acc: 0.654: 100%|█| 2074/2074 [03:47<00:00,  9.10it\n",
      "[valid epoch 1] loss: 0.506, acc: 0.783: 100%|█| 519/519 [01:18<00:00,  6.65it/s\n",
      "[train epoch 2] loss: 0.705, acc: 0.705: 100%|█| 2074/2074 [03:48<00:00,  9.09it\n",
      "[valid epoch 2] loss: 0.325, acc: 0.860: 100%|█| 519/519 [01:18<00:00,  6.63it/s\n",
      "[train epoch 3] loss: 0.569, acc: 0.744: 100%|█| 2074/2074 [03:48<00:00,  9.07it\n",
      "[valid epoch 3] loss: 0.215, acc: 0.914: 100%|█| 519/519 [01:18<00:00,  6.62it/s\n",
      "[train epoch 4] loss: 0.500, acc: 0.768: 100%|█| 2074/2074 [03:48<00:00,  9.07it\n",
      "[valid epoch 4] loss: 0.215, acc: 0.913: 100%|█| 519/519 [01:18<00:00,  6.60it/s\n",
      "[train epoch 5] loss: 0.460, acc: 0.783: 100%|█| 2074/2074 [03:48<00:00,  9.07it\n",
      "[valid epoch 5] loss: 0.117, acc: 0.970: 100%|█| 519/519 [01:18<00:00,  6.59it/s\n",
      "[train epoch 6] loss: 0.417, acc: 0.803: 100%|█| 2074/2074 [03:48<00:00,  9.07it\n",
      "[valid epoch 6] loss: 0.121, acc: 0.968: 100%|█| 519/519 [01:18<00:00,  6.58it/s\n",
      "[train epoch 7] loss: 0.405, acc: 0.810: 100%|█| 2074/2074 [03:48<00:00,  9.07it\n",
      "[valid epoch 7] loss: 0.103, acc: 0.977: 100%|█| 519/519 [01:18<00:00,  6.58it/s\n",
      "[train epoch 8] loss: 0.382, acc: 0.820: 100%|█| 2074/2074 [03:48<00:00,  9.07it\n",
      "[valid epoch 8] loss: 0.100, acc: 0.977: 100%|█| 519/519 [01:19<00:00,  6.54it/s\n",
      "[train epoch 9] loss: 0.377, acc: 0.826: 100%|█| 2074/2074 [03:48<00:00,  9.07it\n",
      "[valid epoch 9] loss: 0.093, acc: 0.978: 100%|█| 519/519 [01:19<00:00,  6.52it/s\n"
     ]
    }
   ],
   "source": [
    "# 5. Train the model\n",
    "# Create folders automatically\n",
    "# runs: \n",
    "# weights: model-1,2,3.pth\n",
    "!python train.py --num_classes 2 --epochs 10 --batch-size 16 --lr 0.01 \\\n",
    "--data-path /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/001/ \\\n",
    "--weights ./pre/pre_efficientnetv2-s.pth \\\n",
    "--freeze-layers False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fedf247-2b3f-4c54-b1ef-1f8e3c51d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trainning\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b10691-2dec-4faf-bae9-e0eec79b334c",
   "metadata": {},
   "source": [
    "# 3. Predict One Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e89ff1f2-a333-427b-b248-0a6319eb1f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.3'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "076744bc-9783-4fba-b7f7-969680226290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff58a432280>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print out an augmented training example\n",
    "print('GROUND TRUTH TRAINING EXAMPLE')\n",
    "\n",
    "img = cv2.imread('./test_right.bmp')\n",
    "img2 = img[:,:,::-1]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d2cb994-435e-4801-9694-eaedb9dce320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
      "\n",
      "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          ...,\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "          [-1., -1., -1.,  ..., -1., -1., -1.]]]])\n",
      "class: right   prob: 0.999\n",
      "CPU times: user 48 ms, sys: 12 ms, total: 60 ms\n",
      "Wall time: 3.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python predict/predict.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed54cff-1be2-496f-9025-9166d0f45b21",
   "metadata": {},
   "source": [
    "# Predict the Folder Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0874da15-e60d-4a02-8822-4313d0b9930d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.1047, -1.0501])\n",
      "pre:left true:left 1/11700\n",
      "tensor([ 0.6235, -0.6646])\n",
      "pre:left true:left 2/11700\n",
      "tensor([ 0.4422, -0.4101])\n",
      "pre:left true:left 3/11700\n",
      "tensor([ 0.6197, -0.5404])\n",
      "pre:left true:left 4/11700\n",
      "tensor([ 0.3640, -0.3381])\n",
      "pre:left true:left 5/11700\n",
      "tensor([ 0.7920, -0.6832])\n",
      "pre:left true:left 6/11700\n",
      "tensor([ 0.6969, -0.6972])\n",
      "pre:left true:left 7/11700\n",
      "tensor([ 0.9586, -0.8467])\n",
      "pre:left true:left 8/11700\n",
      "tensor([ 1.2139, -1.1818])\n",
      "pre:left true:left 9/11700\n",
      "tensor([ 0.4176, -0.4409])\n",
      "pre:left true:left 10/11700\n",
      "tensor([ 0.2546, -0.2486])\n",
      "pre:left true:left 11/11700\n",
      "tensor([ 0.8135, -0.7622])\n",
      "pre:left true:left 12/11700\n",
      "tensor([ 0.3115, -0.2590])\n",
      "pre:left true:left 13/11700\n",
      "tensor([ 0.8035, -0.8052])\n",
      "pre:left true:left 14/11700\n",
      "tensor([ 0.7068, -0.7176])\n",
      "pre:left true:left 15/11700\n",
      "tensor([ 0.8214, -0.7199])\n",
      "pre:left true:left 16/11700\n",
      "tensor([ 0.3844, -0.3324])\n",
      "pre:left true:left 17/11700\n",
      "tensor([ 1.1560, -1.0859])\n",
      "pre:left true:left 18/11700\n",
      "tensor([ 0.3208, -0.2852])\n",
      "pre:left true:left 19/11700\n",
      "tensor([ 0.8058, -0.7743])\n",
      "pre:left true:left 20/11700\n",
      "tensor([-0.6291,  0.6208])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左820_0_976_20200412_115644262_8.jpg\n",
      "pre:right true:left 21/11700\n",
      "tensor([ 1.1578, -1.1288])\n",
      "pre:left true:left 22/11700\n",
      "tensor([ 0.9197, -0.9850])\n",
      "pre:left true:left 23/11700\n",
      "tensor([ 0.5077, -0.5681])\n",
      "pre:left true:left 24/11700\n",
      "tensor([ 0.2941, -0.3775])\n",
      "pre:left true:left 25/11700\n",
      "tensor([ 0.9160, -0.8561])\n",
      "pre:left true:left 26/11700\n",
      "tensor([ 0.6716, -0.5492])\n",
      "pre:left true:left 27/11700\n",
      "tensor([ 1.6279, -1.6179])\n",
      "pre:left true:left 28/11700\n",
      "tensor([ 0.7920, -0.6832])\n",
      "pre:left true:left 29/11700\n",
      "tensor([ 0.4376, -0.5257])\n",
      "pre:left true:left 30/11700\n",
      "tensor([ 0.7461, -0.7671])\n",
      "pre:left true:left 31/11700\n",
      "tensor([ 1.2459, -1.2033])\n",
      "pre:left true:left 32/11700\n",
      "tensor([ 1.1003, -1.0478])\n",
      "pre:left true:left 33/11700\n",
      "tensor([ 0.7860, -0.8504])\n",
      "pre:left true:left 34/11700\n",
      "tensor([ 1.1831, -1.1560])\n",
      "pre:left true:left 35/11700\n",
      "tensor([ 0.8675, -0.8609])\n",
      "pre:left true:left 36/11700\n",
      "tensor([ 0.5283, -0.4433])\n",
      "pre:left true:left 37/11700\n",
      "tensor([ 0.3102, -0.2881])\n",
      "pre:left true:left 38/11700\n",
      "tensor([ 0.5421, -0.5177])\n",
      "pre:left true:left 39/11700\n",
      "tensor([ 0.7488, -0.7179])\n",
      "pre:left true:left 40/11700\n",
      "tensor([ 0.2618, -0.3042])\n",
      "pre:left true:left 41/11700\n",
      "tensor([ 0.5975, -0.5323])\n",
      "pre:left true:left 42/11700\n",
      "tensor([ 0.1421, -0.1493])\n",
      "pre:left true:left 43/11700\n",
      "tensor([ 0.5291, -0.4787])\n",
      "pre:left true:left 44/11700\n",
      "tensor([ 0.4935, -0.5421])\n",
      "pre:left true:left 45/11700\n",
      "tensor([ 0.6051, -0.5470])\n",
      "pre:left true:left 46/11700\n",
      "tensor([ 0.8214, -0.8943])\n",
      "pre:left true:left 47/11700\n",
      "tensor([ 0.4748, -0.4467])\n",
      "pre:left true:left 48/11700\n",
      "tensor([ 0.0921, -0.0055])\n",
      "pre:left true:left 49/11700\n",
      "tensor([ 0.2245, -0.2313])\n",
      "pre:left true:left 50/11700\n",
      "tensor([ 1.1246, -1.0867])\n",
      "pre:left true:left 51/11700\n",
      "tensor([ 0.6472, -0.6383])\n",
      "pre:left true:left 52/11700\n",
      "tensor([ 0.5574, -0.5910])\n",
      "pre:left true:left 53/11700\n",
      "tensor([ 0.7129, -0.6714])\n",
      "pre:left true:left 54/11700\n",
      "tensor([ 0.9113, -0.8767])\n",
      "pre:left true:left 55/11700\n",
      "tensor([-0.1777,  0.1563])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左608_0_764_20200412_115207969_7.jpg\n",
      "pre:right true:left 56/11700\n",
      "tensor([ 0.4457, -0.4871])\n",
      "pre:left true:left 57/11700\n",
      "tensor([ 0.6726, -0.5809])\n",
      "pre:left true:left 58/11700\n",
      "tensor([ 0.0825, -0.0312])\n",
      "pre:left true:left 59/11700\n",
      "tensor([ 0.8019, -0.7358])\n",
      "pre:left true:left 60/11700\n",
      "tensor([ 0.0029, -0.0191])\n",
      "pre:left true:left 61/11700\n",
      "tensor([ 1.2128, -1.1982])\n",
      "pre:left true:left 62/11700\n",
      "tensor([ 1.0146, -0.9994])\n",
      "pre:left true:left 63/11700\n",
      "tensor([ 0.2883, -0.2505])\n",
      "pre:left true:left 64/11700\n",
      "tensor([ 0.7241, -0.7519])\n",
      "pre:left true:left 65/11700\n",
      "tensor([ 0.6243, -0.5907])\n",
      "pre:left true:left 66/11700\n",
      "tensor([ 0.4517, -0.3967])\n",
      "pre:left true:left 67/11700\n",
      "tensor([ 1.0762, -1.0596])\n",
      "pre:left true:left 68/11700\n",
      "tensor([-0.3031,  0.3088])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左446_0_602_20200412_114836836.jpg\n",
      "pre:right true:left 69/11700\n",
      "tensor([ 0.6203, -0.5764])\n",
      "pre:left true:left 70/11700\n",
      "tensor([ 0.5125, -0.5596])\n",
      "pre:left true:left 71/11700\n",
      "tensor([ 0.8111, -0.7244])\n",
      "pre:left true:left 72/11700\n",
      "tensor([-0.2194,  0.2748])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1433_0_1589_20200412_121003157_0.jpg\n",
      "pre:right true:left 73/11700\n",
      "tensor([-0.0724,  0.1116])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1152_0_1308_20200412_120356950_9.jpg\n",
      "pre:right true:left 74/11700\n",
      "tensor([ 0.6070, -0.6315])\n",
      "pre:left true:left 75/11700\n",
      "tensor([-0.6767,  0.6640])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左304_0_304_20200412_105539887_5.jpg\n",
      "pre:right true:left 76/11700\n",
      "tensor([-0.0800,  0.1152])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左990_0_990_20200412_112011687_9.jpg\n",
      "pre:right true:left 77/11700\n",
      "tensor([ 0.2643, -0.1309])\n",
      "pre:left true:left 78/11700\n",
      "tensor([ 0.0600, -0.1538])\n",
      "pre:left true:left 79/11700\n",
      "tensor([-0.2771,  0.2923])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左823_0_979_20200412_115648173_9.jpg\n",
      "pre:right true:left 80/11700\n",
      "tensor([ 0.9311, -0.8510])\n",
      "pre:left true:left 81/11700\n",
      "tensor([ 0.5829, -0.6152])\n",
      "pre:left true:left 82/11700\n",
      "tensor([ 0.2187, -0.0553])\n",
      "pre:left true:left 83/11700\n",
      "tensor([ 0.4309, -0.4964])\n",
      "pre:left true:left 84/11700\n",
      "tensor([ 1.4723, -1.3887])\n",
      "pre:left true:left 85/11700\n",
      "tensor([ 0.6589, -0.4932])\n",
      "pre:left true:left 86/11700\n",
      "tensor([ 0.5188, -0.4773])\n",
      "pre:left true:left 87/11700\n",
      "tensor([ 0.2539, -0.2616])\n",
      "pre:left true:left 88/11700\n",
      "tensor([ 0.8014, -0.8068])\n",
      "pre:left true:left 89/11700\n",
      "tensor([-0.0418,  0.0599])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左378_0_378_20200412_110547923_0.jpg\n",
      "pre:right true:left 90/11700\n",
      "tensor([ 1.1801, -1.1874])\n",
      "pre:left true:left 91/11700\n",
      "tensor([ 0.0713, -0.0365])\n",
      "pre:left true:left 92/11700\n",
      "tensor([-0.0382,  0.0549])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左579_0_735_20200412_115130164_2.jpg\n",
      "pre:right true:left 93/11700\n",
      "tensor([ 1.1914, -1.1865])\n",
      "pre:left true:left 94/11700\n",
      "tensor([ 0.2431, -0.1998])\n",
      "pre:left true:left 95/11700\n",
      "tensor([ 1.1825, -1.2125])\n",
      "pre:left true:left 96/11700\n",
      "tensor([ 1.5635, -1.5866])\n",
      "pre:left true:left 97/11700\n",
      "tensor([ 0.4627, -0.4710])\n",
      "pre:left true:left 98/11700\n",
      "tensor([ 1.1418, -1.1040])\n",
      "pre:left true:left 99/11700\n",
      "tensor([ 0.1411, -0.1085])\n",
      "pre:left true:left 100/11700\n",
      "tensor([ 0.1880, -0.0749])\n",
      "pre:left true:left 101/11700\n",
      "tensor([ 1.0652, -1.1036])\n",
      "pre:left true:left 102/11700\n",
      "tensor([0.2131, 0.0242])\n",
      "pre:left true:left 103/11700\n",
      "tensor([ 0.6151, -0.6200])\n",
      "pre:left true:left 104/11700\n",
      "tensor([ 0.8230, -0.7583])\n",
      "pre:left true:left 105/11700\n",
      "tensor([ 0.4828, -0.4171])\n",
      "pre:left true:left 106/11700\n",
      "tensor([ 0.5475, -0.6520])\n",
      "pre:left true:left 107/11700\n",
      "tensor([ 0.6653, -0.5717])\n",
      "pre:left true:left 108/11700\n",
      "tensor([-0.1618,  0.1499])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左420_0_576_20200412_114802970_10.jpg\n",
      "pre:right true:left 109/11700\n",
      "tensor([ 0.6101, -0.4750])\n",
      "pre:left true:left 110/11700\n",
      "tensor([ 0.8059, -0.8123])\n",
      "pre:left true:left 111/11700\n",
      "tensor([ 1.4588, -1.3966])\n",
      "pre:left true:left 112/11700\n",
      "tensor([ 0.5230, -0.3753])\n",
      "pre:left true:left 113/11700\n",
      "tensor([ 1.3467, -1.2363])\n",
      "pre:left true:left 114/11700\n",
      "tensor([ 0.4439, -0.3176])\n",
      "pre:left true:left 115/11700\n",
      "tensor([ 0.6731, -0.5693])\n",
      "pre:left true:left 116/11700\n",
      "tensor([ 0.2284, -0.1612])\n",
      "pre:left true:left 117/11700\n",
      "tensor([-0.1297,  0.0869])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左605_0_761_20200412_115204064_9.jpg\n",
      "pre:right true:left 118/11700\n",
      "tensor([ 0.4969, -0.4904])\n",
      "pre:left true:left 119/11700\n",
      "tensor([ 1.0024, -1.0299])\n",
      "pre:left true:left 120/11700\n",
      "tensor([ 0.7825, -0.8045])\n",
      "pre:left true:left 121/11700\n",
      "tensor([ 0.1714, -0.2258])\n",
      "pre:left true:left 122/11700\n",
      "tensor([-0.0928,  0.0634])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左981_0_981_20200412_111959966_10.jpg\n",
      "pre:right true:left 123/11700\n",
      "tensor([ 0.7034, -0.6337])\n",
      "pre:left true:left 124/11700\n",
      "tensor([ 0.1201, -0.0321])\n",
      "pre:left true:left 125/11700\n",
      "tensor([ 0.9923, -1.0059])\n",
      "pre:left true:left 126/11700\n",
      "tensor([ 0.7248, -0.6824])\n",
      "pre:left true:left 127/11700\n",
      "tensor([ 0.5650, -0.4991])\n",
      "pre:left true:left 128/11700\n",
      "tensor([ 0.3112, -0.3291])\n",
      "pre:left true:left 129/11700\n",
      "tensor([ 1.0960, -1.0411])\n",
      "pre:left true:left 130/11700\n",
      "tensor([ 0.5320, -0.5319])\n",
      "pre:left true:left 131/11700\n",
      "tensor([ 1.3617, -1.3357])\n",
      "pre:left true:left 132/11700\n",
      "tensor([ 0.4491, -0.4710])\n",
      "pre:left true:left 133/11700\n",
      "tensor([ 0.7559, -0.7542])\n",
      "pre:left true:left 134/11700\n",
      "tensor([ 0.4857, -0.4985])\n",
      "pre:left true:left 135/11700\n",
      "tensor([ 1.0292, -1.0803])\n",
      "pre:left true:left 136/11700\n",
      "tensor([ 2.1452, -2.2252])\n",
      "pre:left true:left 137/11700\n",
      "tensor([ 0.2721, -0.2293])\n",
      "pre:left true:left 138/11700\n",
      "tensor([ 0.9352, -0.9816])\n",
      "pre:left true:left 139/11700\n",
      "tensor([-0.4059,  0.3330])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左277_0_277_20200412_110323869_1.jpg\n",
      "pre:right true:left 140/11700\n",
      "tensor([-0.2715,  0.2328])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左615_0_615_20200412_111125989_10.jpg\n",
      "pre:right true:left 141/11700\n",
      "tensor([ 0.5637, -0.5153])\n",
      "pre:left true:left 142/11700\n",
      "tensor([ 0.2478, -0.2032])\n",
      "pre:left true:left 143/11700\n",
      "tensor([0.0339, 0.0297])\n",
      "pre:left true:left 144/11700\n",
      "tensor([-0.4304,  0.4777])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左378_0_378_20200412_110547923_1.jpg\n",
      "pre:right true:left 145/11700\n",
      "tensor([-0.0370, -0.0085])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左374_0_530_20200412_114703026_2.jpg\n",
      "pre:right true:left 146/11700\n",
      "tensor([ 0.3071, -0.3039])\n",
      "pre:left true:left 147/11700\n",
      "tensor([-0.1495,  0.1806])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左606_0_606_20200412_111113150.jpg\n",
      "pre:right true:left 148/11700\n",
      "tensor([ 0.4643, -0.4169])\n",
      "pre:left true:left 149/11700\n",
      "tensor([ 1.1301, -1.1165])\n",
      "pre:left true:left 150/11700\n",
      "tensor([ 1.4035, -1.3882])\n",
      "pre:left true:left 151/11700\n",
      "tensor([ 0.7547, -0.8056])\n",
      "pre:left true:left 152/11700\n",
      "tensor([ 0.8870, -0.7630])\n",
      "pre:left true:left 153/11700\n",
      "tensor([ 0.4027, -0.4391])\n",
      "pre:left true:left 154/11700\n",
      "tensor([ 0.0382, -0.0375])\n",
      "pre:left true:left 155/11700\n",
      "tensor([ 0.8727, -0.8816])\n",
      "pre:left true:left 156/11700\n",
      "tensor([ 0.9345, -0.9632])\n",
      "pre:left true:left 157/11700\n",
      "tensor([ 0.2915, -0.1985])\n",
      "pre:left true:left 158/11700\n",
      "tensor([ 0.6999, -0.6702])\n",
      "pre:left true:left 159/11700\n",
      "tensor([0.0102, 0.0170])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左714_0_870_20200412_115426118_6.jpg\n",
      "pre:right true:left 160/11700\n",
      "tensor([ 0.3544, -0.3175])\n",
      "pre:left true:left 161/11700\n",
      "tensor([ 1.6914, -1.7232])\n",
      "pre:left true:left 162/11700\n",
      "tensor([ 0.5791, -0.6114])\n",
      "pre:left true:left 163/11700\n",
      "tensor([ 0.6499, -0.7325])\n",
      "pre:left true:left 164/11700\n",
      "tensor([ 0.4780, -0.4372])\n",
      "pre:left true:left 165/11700\n",
      "tensor([ 0.4138, -0.5658])\n",
      "pre:left true:left 166/11700\n",
      "tensor([ 1.0272, -1.0170])\n",
      "pre:left true:left 167/11700\n",
      "tensor([0.0945, 0.0004])\n",
      "pre:left true:left 168/11700\n",
      "tensor([ 0.4569, -0.4362])\n",
      "pre:left true:left 169/11700\n",
      "tensor([ 1.2518, -1.2931])\n",
      "pre:left true:left 170/11700\n",
      "tensor([ 0.8240, -0.7166])\n",
      "pre:left true:left 171/11700\n",
      "tensor([ 0.4956, -0.5602])\n",
      "pre:left true:left 172/11700\n",
      "tensor([ 0.4797, -0.4339])\n",
      "pre:left true:left 173/11700\n",
      "tensor([-0.2393,  0.2187])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左524_0_680_20200412_115018501_4.jpg\n",
      "pre:right true:left 174/11700\n",
      "tensor([ 0.0936, -0.0314])\n",
      "pre:left true:left 175/11700\n",
      "tensor([ 0.6747, -0.7020])\n",
      "pre:left true:left 176/11700\n",
      "tensor([ 0.9077, -0.8420])\n",
      "pre:left true:left 177/11700\n",
      "tensor([ 0.8083, -0.8346])\n",
      "pre:left true:left 178/11700\n",
      "tensor([ 0.3320, -0.2695])\n",
      "pre:left true:left 179/11700\n",
      "tensor([ 0.6051, -0.5617])\n",
      "pre:left true:left 180/11700\n",
      "tensor([ 0.3860, -0.3690])\n",
      "pre:left true:left 181/11700\n",
      "tensor([-0.0851,  0.0635])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左845_0_1001_20200412_115716845_2.jpg\n",
      "pre:right true:left 182/11700\n",
      "tensor([ 0.1377, -0.1285])\n",
      "pre:left true:left 183/11700\n",
      "tensor([ 0.5050, -0.4733])\n",
      "pre:left true:left 184/11700\n",
      "tensor([ 1.0304, -1.0045])\n",
      "pre:left true:left 185/11700\n",
      "tensor([ 0.2906, -0.3658])\n",
      "pre:left true:left 186/11700\n",
      "tensor([ 0.4478, -0.3593])\n",
      "pre:left true:left 187/11700\n",
      "tensor([ 0.3338, -0.2384])\n",
      "pre:left true:left 188/11700\n",
      "tensor([ 0.5359, -0.5093])\n",
      "pre:left true:left 189/11700\n",
      "tensor([ 0.3436, -0.3052])\n",
      "pre:left true:left 190/11700\n",
      "tensor([ 0.6146, -0.6113])\n",
      "pre:left true:left 191/11700\n",
      "tensor([ 0.7571, -0.7051])\n",
      "pre:left true:left 192/11700\n",
      "tensor([ 0.1993, -0.0745])\n",
      "pre:left true:left 193/11700\n",
      "tensor([ 0.8099, -0.8541])\n",
      "pre:left true:left 194/11700\n",
      "tensor([ 0.7838, -0.7216])\n",
      "pre:left true:left 195/11700\n",
      "tensor([ 0.6590, -0.7069])\n",
      "pre:left true:left 196/11700\n",
      "tensor([ 0.7216, -0.6458])\n",
      "pre:left true:left 197/11700\n",
      "tensor([0.0169, 0.0803])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1521_0_1677_20200412_121157876_1.jpg\n",
      "pre:right true:left 198/11700\n",
      "tensor([ 0.6499, -0.6234])\n",
      "pre:left true:left 199/11700\n",
      "tensor([ 0.6060, -0.5563])\n",
      "pre:left true:left 200/11700\n",
      "tensor([ 0.4792, -0.4192])\n",
      "pre:left true:left 201/11700\n",
      "tensor([ 1.2109, -1.2181])\n",
      "pre:left true:left 202/11700\n",
      "tensor([ 1.0803, -1.0362])\n",
      "pre:left true:left 203/11700\n",
      "tensor([ 0.4150, -0.3834])\n",
      "pre:left true:left 204/11700\n",
      "tensor([ 0.0580, -0.0749])\n",
      "pre:left true:left 205/11700\n",
      "tensor([ 1.1592, -1.2206])\n",
      "pre:left true:left 206/11700\n",
      "tensor([ 0.6229, -0.5691])\n",
      "pre:left true:left 207/11700\n",
      "tensor([ 0.6842, -0.6645])\n",
      "pre:left true:left 208/11700\n",
      "tensor([-0.3641,  0.3772])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/右1204_0_1360_20200412_120504707_5.jpg\n",
      "pre:right true:left 209/11700\n",
      "tensor([ 1.0852, -1.0325])\n",
      "pre:left true:left 210/11700\n",
      "tensor([ 0.7964, -0.8353])\n",
      "pre:left true:left 211/11700\n",
      "tensor([ 0.7064, -0.6748])\n",
      "pre:left true:left 212/11700\n",
      "tensor([ 0.5402, -0.5547])\n",
      "pre:left true:left 213/11700\n",
      "tensor([ 1.0579, -1.1123])\n",
      "pre:left true:left 214/11700\n",
      "tensor([ 0.1726, -0.2232])\n",
      "pre:left true:left 215/11700\n",
      "tensor([ 0.2981, -0.2644])\n",
      "pre:left true:left 216/11700\n",
      "tensor([-0.0889,  0.0556])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左192_0_192_20200412_110122651_3.jpg\n",
      "pre:right true:left 217/11700\n",
      "tensor([ 0.4620, -0.4663])\n",
      "pre:left true:left 218/11700\n",
      "tensor([0.0111, 0.0536])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左789_0_945_20200412_115603865_0.jpg\n",
      "pre:right true:left 219/11700\n",
      "tensor([ 1.1994, -1.1236])\n",
      "pre:left true:left 220/11700\n",
      "tensor([ 0.2663, -0.2177])\n",
      "pre:left true:left 221/11700\n",
      "tensor([0.0521, 0.0092])\n",
      "pre:left true:left 222/11700\n",
      "tensor([ 1.6378, -1.6163])\n",
      "pre:left true:left 223/11700\n",
      "tensor([ 0.5975, -0.6112])\n",
      "pre:left true:left 224/11700\n",
      "tensor([ 0.3600, -0.4065])\n",
      "pre:left true:left 225/11700\n",
      "tensor([ 0.3644, -0.3541])\n",
      "pre:left true:left 226/11700\n",
      "tensor([ 0.7897, -0.8050])\n",
      "pre:left true:left 227/11700\n",
      "tensor([ 0.8377, -0.8087])\n",
      "pre:left true:left 228/11700\n",
      "tensor([-0.1575,  0.1240])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左307_0_307_20200412_110406653_4.jpg\n",
      "pre:right true:left 229/11700\n",
      "tensor([ 1.1273, -1.0385])\n",
      "pre:left true:left 230/11700\n",
      "tensor([ 1.1142, -1.1358])\n",
      "pre:left true:left 231/11700\n",
      "tensor([ 0.8101, -0.7797])\n",
      "pre:left true:left 232/11700\n",
      "tensor([ 0.3097, -0.3116])\n",
      "pre:left true:left 233/11700\n",
      "tensor([ 0.0871, -0.2503])\n",
      "pre:left true:left 234/11700\n",
      "tensor([-0.1377,  0.1484])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1108_0_1264_20200412_120259594_2.jpg\n",
      "pre:right true:left 235/11700\n",
      "tensor([ 0.6938, -0.6973])\n",
      "pre:left true:left 236/11700\n",
      "tensor([ 1.4556, -1.4673])\n",
      "pre:left true:left 237/11700\n",
      "tensor([ 0.2457, -0.2829])\n",
      "pre:left true:left 238/11700\n",
      "tensor([-0.3728,  0.4296])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左811_0_811_20200412_111605535_1.jpg\n",
      "pre:right true:left 239/11700\n",
      "tensor([ 0.1202, -0.0572])\n",
      "pre:left true:left 240/11700\n",
      "tensor([ 0.4384, -0.4454])\n",
      "pre:left true:left 241/11700\n",
      "tensor([ 0.0753, -0.0852])\n",
      "pre:left true:left 242/11700\n",
      "tensor([0.0057, 0.0156])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左152_0_152_20200412_110025594_10.jpg\n",
      "pre:right true:left 243/11700\n",
      "tensor([0.0729, 0.0111])\n",
      "pre:left true:left 244/11700\n",
      "tensor([ 0.8234, -0.8609])\n",
      "pre:left true:left 245/11700\n",
      "tensor([-0.1332,  0.2255])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左436_0_592_20200412_114823812_8.jpg\n",
      "pre:right true:left 246/11700\n",
      "tensor([-0.7957,  0.7876])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左344_0_500_20200412_114623927_5.jpg\n",
      "pre:right true:left 247/11700\n",
      "tensor([ 0.8615, -0.7827])\n",
      "pre:left true:left 248/11700\n",
      "tensor([-0.0963,  0.0198])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左600_0_600_20200412_111104575.jpg\n",
      "pre:right true:left 249/11700\n",
      "tensor([-0.1710,  0.2547])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1302_0_1302_20200412_112658222_7.jpg\n",
      "pre:right true:left 250/11700\n",
      "tensor([ 1.2169, -1.0962])\n",
      "pre:left true:left 251/11700\n",
      "tensor([ 0.5870, -0.6133])\n",
      "pre:left true:left 252/11700\n",
      "tensor([ 0.5858, -0.6072])\n",
      "pre:left true:left 253/11700\n",
      "tensor([ 1.0879, -1.1653])\n",
      "pre:left true:left 254/11700\n",
      "tensor([ 0.8032, -0.8064])\n",
      "pre:left true:left 255/11700\n",
      "tensor([ 0.8354, -0.8706])\n",
      "pre:left true:left 256/11700\n",
      "tensor([ 0.7029, -0.8664])\n",
      "pre:left true:left 257/11700\n",
      "tensor([ 1.0700, -1.1288])\n",
      "pre:left true:left 258/11700\n",
      "tensor([ 0.3370, -0.3427])\n",
      "pre:left true:left 259/11700\n",
      "tensor([ 0.1898, -0.1997])\n",
      "pre:left true:left 260/11700\n",
      "tensor([ 1.0179, -1.0170])\n",
      "pre:left true:left 261/11700\n",
      "tensor([ 0.1474, -0.1381])\n",
      "pre:left true:left 262/11700\n",
      "tensor([-0.1444,  0.1244])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左820_0_976_20200412_115644262_3.jpg\n",
      "pre:right true:left 263/11700\n",
      "tensor([ 1.5911, -1.6267])\n",
      "pre:left true:left 264/11700\n",
      "tensor([ 0.4090, -0.3432])\n",
      "pre:left true:left 265/11700\n",
      "tensor([ 0.1266, -0.1908])\n",
      "pre:left true:left 266/11700\n",
      "tensor([ 1.1121, -1.0713])\n",
      "pre:left true:left 267/11700\n",
      "tensor([ 0.9229, -0.8756])\n",
      "pre:left true:left 268/11700\n",
      "tensor([ 0.2429, -0.1476])\n",
      "pre:left true:left 269/11700\n",
      "tensor([ 0.1457, -0.0586])\n",
      "pre:left true:left 270/11700\n",
      "tensor([ 0.3295, -0.3495])\n",
      "pre:left true:left 271/11700\n",
      "tensor([ 0.7631, -0.7202])\n",
      "pre:left true:left 272/11700\n",
      "tensor([ 0.0736, -0.0864])\n",
      "pre:left true:left 273/11700\n",
      "tensor([ 0.5486, -0.4708])\n",
      "pre:left true:left 274/11700\n",
      "tensor([ 0.3874, -0.3846])\n",
      "pre:left true:left 275/11700\n",
      "tensor([ 0.2107, -0.2368])\n",
      "pre:left true:left 276/11700\n",
      "tensor([ 0.8124, -0.7921])\n",
      "pre:left true:left 277/11700\n",
      "tensor([ 0.5434, -0.5363])\n",
      "pre:left true:left 278/11700\n",
      "tensor([ 0.5826, -0.6769])\n",
      "pre:left true:left 279/11700\n",
      "tensor([ 0.7736, -0.7669])\n",
      "pre:left true:left 280/11700\n",
      "tensor([-0.3000,  0.4089])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1238_0_1238_20200412_112534829_5.jpg\n",
      "pre:right true:left 281/11700\n",
      "tensor([ 0.7297, -0.7987])\n",
      "pre:left true:left 282/11700\n",
      "tensor([ 0.9975, -0.9531])\n",
      "pre:left true:left 283/11700\n",
      "tensor([ 0.5860, -0.5222])\n",
      "pre:left true:left 284/11700\n",
      "tensor([ 0.5118, -0.4604])\n",
      "pre:left true:left 285/11700\n",
      "tensor([ 0.5953, -0.5196])\n",
      "pre:left true:left 286/11700\n",
      "tensor([ 0.4316, -0.4154])\n",
      "pre:left true:left 287/11700\n",
      "tensor([ 0.6112, -0.4773])\n",
      "pre:left true:left 288/11700\n",
      "tensor([ 0.3381, -0.3484])\n",
      "pre:left true:left 289/11700\n",
      "tensor([ 1.0163, -0.9674])\n",
      "pre:left true:left 290/11700\n",
      "tensor([ 1.1863, -1.1790])\n",
      "pre:left true:left 291/11700\n",
      "tensor([ 1.2928, -1.2708])\n",
      "pre:left true:left 292/11700\n",
      "tensor([ 1.3204, -1.3876])\n",
      "pre:left true:left 293/11700\n",
      "tensor([-0.0871,  0.1970])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1592_0_1748_20200412_121330413_10.jpg\n",
      "pre:right true:left 294/11700\n",
      "tensor([ 0.7198, -0.7678])\n",
      "pre:left true:left 295/11700\n",
      "tensor([ 0.7457, -0.7952])\n",
      "pre:left true:left 296/11700\n",
      "tensor([ 0.4271, -0.2764])\n",
      "pre:left true:left 297/11700\n",
      "tensor([ 0.2642, -0.2348])\n",
      "pre:left true:left 298/11700\n",
      "tensor([ 0.2769, -0.2598])\n",
      "pre:left true:left 299/11700\n",
      "tensor([-0.1218,  0.1606])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左647_0_647_20200412_111211623_9.jpg\n",
      "pre:right true:left 300/11700\n",
      "tensor([-0.1874,  0.3020])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左730_0_886_20200412_115446978_4.jpg\n",
      "pre:right true:left 301/11700\n",
      "tensor([ 0.7124, -0.7007])\n",
      "pre:left true:left 302/11700\n",
      "tensor([ 0.7813, -0.7520])\n",
      "pre:left true:left 303/11700\n",
      "tensor([ 0.2104, -0.2188])\n",
      "pre:left true:left 304/11700\n",
      "tensor([ 0.6997, -0.7028])\n",
      "pre:left true:left 305/11700\n",
      "tensor([ 0.5974, -0.6883])\n",
      "pre:left true:left 306/11700\n",
      "tensor([ 1.0059, -1.0051])\n",
      "pre:left true:left 307/11700\n",
      "tensor([ 0.6936, -0.6534])\n",
      "pre:left true:left 308/11700\n",
      "tensor([ 0.0214, -0.0747])\n",
      "pre:left true:left 309/11700\n",
      "tensor([ 0.1968, -0.1746])\n",
      "pre:left true:left 310/11700\n",
      "tensor([ 0.5642, -0.5787])\n",
      "pre:left true:left 311/11700\n",
      "tensor([ 0.4671, -0.4370])\n",
      "pre:left true:left 312/11700\n",
      "tensor([-0.2013,  0.1383])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左339_0_339_20200412_110452288_8.jpg\n",
      "pre:right true:left 313/11700\n",
      "tensor([ 0.5413, -0.4805])\n",
      "pre:left true:left 314/11700\n",
      "tensor([ 0.7621, -0.7857])\n",
      "pre:left true:left 315/11700\n",
      "tensor([-0.0693,  0.0510])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1613_0_1769_20200412_121357799_0.jpg\n",
      "pre:right true:left 316/11700\n",
      "tensor([ 0.5814, -0.5920])\n",
      "pre:left true:left 317/11700\n",
      "tensor([ 0.7469, -0.7732])\n",
      "pre:left true:left 318/11700\n",
      "tensor([ 0.0314, -0.0544])\n",
      "pre:left true:left 319/11700\n",
      "tensor([-0.8702,  0.7334])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1332_0_1488_20200412_120751532_8.jpg\n",
      "pre:right true:left 320/11700\n",
      "tensor([ 0.4349, -0.5331])\n",
      "pre:left true:left 321/11700\n",
      "tensor([ 0.7966, -0.8412])\n",
      "pre:left true:left 322/11700\n",
      "tensor([ 0.3384, -0.2650])\n",
      "pre:left true:left 323/11700\n",
      "tensor([ 0.7374, -0.5695])\n",
      "pre:left true:left 324/11700\n",
      "tensor([-0.0754,  0.2470])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1146_0_1146_20200412_112334945_8.jpg\n",
      "pre:right true:left 325/11700\n",
      "tensor([ 0.7954, -0.7600])\n",
      "pre:left true:left 326/11700\n",
      "tensor([ 0.6193, -0.6211])\n",
      "pre:left true:left 327/11700\n",
      "tensor([ 0.7089, -0.5510])\n",
      "pre:left true:left 328/11700\n",
      "tensor([ 0.1563, -0.1263])\n",
      "pre:left true:left 329/11700\n",
      "tensor([ 0.4854, -0.5230])\n",
      "pre:left true:left 330/11700\n",
      "tensor([ 0.2656, -0.3190])\n",
      "pre:left true:left 331/11700\n",
      "tensor([ 0.3167, -0.2747])\n",
      "pre:left true:left 332/11700\n",
      "tensor([-0.0612,  0.0393])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1448_0_1604_20200412_121022709_9.jpg\n",
      "pre:right true:left 333/11700\n",
      "tensor([ 0.7824, -0.7572])\n",
      "pre:left true:left 334/11700\n",
      "tensor([ 0.3252, -0.3141])\n",
      "pre:left true:left 335/11700\n",
      "tensor([ 0.6230, -0.6291])\n",
      "pre:left true:left 336/11700\n",
      "tensor([ 0.6280, -0.6103])\n",
      "pre:left true:left 337/11700\n",
      "tensor([ 0.8333, -0.8409])\n",
      "pre:left true:left 338/11700\n",
      "tensor([ 0.2667, -0.2826])\n",
      "pre:left true:left 339/11700\n",
      "tensor([ 1.2280, -1.2877])\n",
      "pre:left true:left 340/11700\n",
      "tensor([ 0.7620, -0.7582])\n",
      "pre:left true:left 341/11700\n",
      "tensor([-0.6100,  0.5170])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左975_0_975_20200412_111952130_10.jpg\n",
      "pre:right true:left 342/11700\n",
      "tensor([ 0.1373, -0.1505])\n",
      "pre:left true:left 343/11700\n",
      "tensor([ 0.9911, -1.0696])\n",
      "pre:left true:left 344/11700\n",
      "tensor([ 1.0109, -1.0293])\n",
      "pre:left true:left 345/11700\n",
      "tensor([ 0.1274, -0.0968])\n",
      "pre:left true:left 346/11700\n",
      "tensor([ 0.1273, -0.1495])\n",
      "pre:left true:left 347/11700\n",
      "tensor([ 0.3992, -0.3828])\n",
      "pre:left true:left 348/11700\n",
      "tensor([-0.2022,  0.1773])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1507_0_1663_20200412_121139621_5.jpg\n",
      "pre:right true:left 349/11700\n",
      "tensor([ 0.1338, -0.1019])\n",
      "pre:left true:left 350/11700\n",
      "tensor([ 0.4483, -0.4861])\n",
      "pre:left true:left 351/11700\n",
      "tensor([ 0.5067, -0.4729])\n",
      "pre:left true:left 352/11700\n",
      "tensor([ 0.9197, -0.8623])\n",
      "pre:left true:left 353/11700\n",
      "tensor([ 1.0684, -0.9628])\n",
      "pre:left true:left 354/11700\n",
      "tensor([ 0.7502, -0.7607])\n",
      "pre:left true:left 355/11700\n",
      "tensor([ 1.0174, -1.0347])\n",
      "pre:left true:left 356/11700\n",
      "tensor([ 0.5689, -0.5469])\n",
      "pre:left true:left 357/11700\n",
      "tensor([-0.0829,  0.1262])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左378_0_378_20200412_110547923_2.jpg\n",
      "pre:right true:left 358/11700\n",
      "tensor([0.0863, 0.0012])\n",
      "pre:left true:left 359/11700\n",
      "tensor([ 0.4662, -0.4096])\n",
      "pre:left true:left 360/11700\n",
      "tensor([-0.6360,  0.7827])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左634_0_634_20200412_111153081_1.jpg\n",
      "pre:right true:left 361/11700\n",
      "tensor([ 0.6083, -0.7364])\n",
      "pre:left true:left 362/11700\n",
      "tensor([ 0.8588, -0.8360])\n",
      "pre:left true:left 363/11700\n",
      "tensor([ 0.8194, -0.8086])\n",
      "pre:left true:left 364/11700\n",
      "tensor([ 0.8624, -0.8443])\n",
      "pre:left true:left 365/11700\n",
      "tensor([ 0.3882, -0.3543])\n",
      "pre:left true:left 366/11700\n",
      "tensor([-0.1865,  0.2127])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左984_0_984_20200412_112003866_2.jpg\n",
      "pre:right true:left 367/11700\n",
      "tensor([ 0.7671, -0.7152])\n",
      "pre:left true:left 368/11700\n",
      "tensor([ 0.8077, -0.8210])\n",
      "pre:left true:left 369/11700\n",
      "tensor([ 1.5900, -1.5796])\n",
      "pre:left true:left 370/11700\n",
      "tensor([ 0.6974, -0.6743])\n",
      "pre:left true:left 371/11700\n",
      "tensor([-0.1052,  0.1353])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1133_0_1289_20200412_120332193_6.jpg\n",
      "pre:right true:left 372/11700\n",
      "tensor([ 0.9191, -0.9953])\n",
      "pre:left true:left 373/11700\n",
      "tensor([ 0.7338, -0.6713])\n",
      "pre:left true:left 374/11700\n",
      "tensor([ 0.5841, -0.5233])\n",
      "pre:left true:left 375/11700\n",
      "tensor([0.0995, 0.0181])\n",
      "pre:left true:left 376/11700\n",
      "tensor([ 0.8287, -0.8334])\n",
      "pre:left true:left 377/11700\n",
      "tensor([ 0.1755, -0.1949])\n",
      "pre:left true:left 378/11700\n",
      "tensor([-0.1149,  0.1181])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左320_0_476_20200412_114552663_2.jpg\n",
      "pre:right true:left 379/11700\n",
      "tensor([ 0.7015, -0.7131])\n",
      "pre:left true:left 380/11700\n",
      "tensor([ 1.0299, -0.9587])\n",
      "pre:left true:left 381/11700\n",
      "tensor([ 0.2478, -0.3273])\n",
      "pre:left true:left 382/11700\n",
      "tensor([ 0.9009, -0.8612])\n",
      "pre:left true:left 383/11700\n",
      "tensor([ 1.1234, -1.1401])\n",
      "pre:left true:left 384/11700\n",
      "tensor([ 0.2857, -0.2768])\n",
      "pre:left true:left 385/11700\n",
      "tensor([ 0.6044, -0.5383])\n",
      "pre:left true:left 386/11700\n",
      "tensor([ 0.4562, -0.3887])\n",
      "pre:left true:left 387/11700\n",
      "tensor([ 1.0845, -1.0881])\n",
      "pre:left true:left 388/11700\n",
      "tensor([-0.3614,  0.3076])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左589_0_745_20200412_115143203_10.jpg\n",
      "pre:right true:left 389/11700\n",
      "tensor([ 0.3326, -0.2497])\n",
      "pre:left true:left 390/11700\n",
      "tensor([ 0.7302, -0.7389])\n",
      "pre:left true:left 391/11700\n",
      "tensor([-0.3782,  0.4118])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左986_0_986_20200412_112006470_3.jpg\n",
      "pre:right true:left 392/11700\n",
      "tensor([ 0.8285, -0.9242])\n",
      "pre:left true:left 393/11700\n",
      "tensor([ 0.2857, -0.2389])\n",
      "pre:left true:left 394/11700\n",
      "tensor([ 0.5296, -0.4447])\n",
      "pre:left true:left 395/11700\n",
      "tensor([ 0.3290, -0.2676])\n",
      "pre:left true:left 396/11700\n",
      "tensor([ 0.8673, -0.8169])\n",
      "pre:left true:left 397/11700\n",
      "tensor([ 1.4677, -1.4853])\n",
      "pre:left true:left 398/11700\n",
      "tensor([ 0.1388, -0.2009])\n",
      "pre:left true:left 399/11700\n",
      "tensor([ 0.1325, -0.1901])\n",
      "pre:left true:left 400/11700\n",
      "tensor([0.0809, 0.0095])\n",
      "pre:left true:left 401/11700\n",
      "tensor([ 0.9616, -0.9068])\n",
      "pre:left true:left 402/11700\n",
      "tensor([ 0.4464, -0.4531])\n",
      "pre:left true:left 403/11700\n",
      "tensor([ 1.2168, -1.1811])\n",
      "pre:left true:left 404/11700\n",
      "tensor([ 0.3787, -0.3907])\n",
      "pre:left true:left 405/11700\n",
      "tensor([ 0.9007, -0.8359])\n",
      "pre:left true:left 406/11700\n",
      "tensor([ 0.4395, -0.3824])\n",
      "pre:left true:left 407/11700\n",
      "tensor([ 0.6206, -0.6334])\n",
      "pre:left true:left 408/11700\n",
      "tensor([ 0.1436, -0.1689])\n",
      "pre:left true:left 409/11700\n",
      "tensor([ 0.4597, -0.3955])\n",
      "pre:left true:left 410/11700\n",
      "tensor([ 0.9195, -0.8700])\n",
      "pre:left true:left 411/11700\n",
      "tensor([ 0.9962, -1.0083])\n",
      "pre:left true:left 412/11700\n",
      "tensor([ 0.1178, -0.1334])\n",
      "pre:left true:left 413/11700\n",
      "tensor([ 0.8007, -0.7794])\n",
      "pre:left true:left 414/11700\n",
      "tensor([ 0.9772, -1.0182])\n",
      "pre:left true:left 415/11700\n",
      "tensor([ 0.4614, -0.5543])\n",
      "pre:left true:left 416/11700\n",
      "tensor([ 0.6991, -0.6824])\n",
      "pre:left true:left 417/11700\n",
      "tensor([ 0.4317, -0.4947])\n",
      "pre:left true:left 418/11700\n",
      "tensor([-0.1812,  0.1556])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左892_0_1048_20200412_115818084_4.jpg\n",
      "pre:right true:left 419/11700\n",
      "tensor([ 0.5513, -0.4873])\n",
      "pre:left true:left 420/11700\n",
      "tensor([ 0.7553, -0.8194])\n",
      "pre:left true:left 421/11700\n",
      "tensor([ 0.2950, -0.3209])\n",
      "pre:left true:left 422/11700\n",
      "tensor([ 0.6232, -0.5840])\n",
      "pre:left true:left 423/11700\n",
      "tensor([ 0.1010, -0.1712])\n",
      "pre:left true:left 424/11700\n",
      "tensor([ 0.4081, -0.2620])\n",
      "pre:left true:left 425/11700\n",
      "tensor([ 0.7397, -0.7625])\n",
      "pre:left true:left 426/11700\n",
      "tensor([ 0.5758, -0.6299])\n",
      "pre:left true:left 427/11700\n",
      "tensor([ 0.1362, -0.1908])\n",
      "pre:left true:left 428/11700\n",
      "tensor([ 0.1457, -0.0586])\n",
      "pre:left true:left 429/11700\n",
      "tensor([ 0.3860, -0.4743])\n",
      "pre:left true:left 430/11700\n",
      "tensor([ 0.1815, -0.1834])\n",
      "pre:left true:left 431/11700\n",
      "tensor([ 1.3654, -1.3675])\n",
      "pre:left true:left 432/11700\n",
      "tensor([ 0.4319, -0.4764])\n",
      "pre:left true:left 433/11700\n",
      "tensor([ 1.2154, -1.1386])\n",
      "pre:left true:left 434/11700\n",
      "tensor([ 0.4181, -0.3954])\n",
      "pre:left true:left 435/11700\n",
      "tensor([ 1.0218, -1.0247])\n",
      "pre:left true:left 436/11700\n",
      "tensor([-0.0597,  0.1831])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1556_0_1712_20200412_121243498.jpg\n",
      "pre:right true:left 437/11700\n",
      "tensor([ 0.3840, -0.3219])\n",
      "pre:left true:left 438/11700\n",
      "tensor([ 0.4101, -0.3862])\n",
      "pre:left true:left 439/11700\n",
      "tensor([ 0.4980, -0.5753])\n",
      "pre:left true:left 440/11700\n",
      "tensor([ 0.3971, -0.3593])\n",
      "pre:left true:left 441/11700\n",
      "tensor([ 0.9325, -0.9852])\n",
      "pre:left true:left 442/11700\n",
      "tensor([ 0.8551, -0.9454])\n",
      "pre:left true:left 443/11700\n",
      "tensor([ 0.2957, -0.3097])\n",
      "pre:left true:left 444/11700\n",
      "tensor([ 1.3588, -1.3004])\n",
      "pre:left true:left 445/11700\n",
      "tensor([-0.5049,  0.4836])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左888_0_888_20200412_111755369.jpg\n",
      "pre:right true:left 446/11700\n",
      "tensor([ 0.7799, -0.7235])\n",
      "pre:left true:left 447/11700\n",
      "tensor([ 0.1369, -0.0959])\n",
      "pre:left true:left 448/11700\n",
      "tensor([ 0.2366, -0.2059])\n",
      "pre:left true:left 449/11700\n",
      "tensor([ 0.8908, -0.8514])\n",
      "pre:left true:left 450/11700\n",
      "tensor([-0.0653,  0.0903])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1578_0_1734_20200412_121312167_5.jpg\n",
      "pre:right true:left 451/11700\n",
      "tensor([ 0.5501, -0.5692])\n",
      "pre:left true:left 452/11700\n",
      "tensor([ 0.9171, -0.9257])\n",
      "pre:left true:left 453/11700\n",
      "tensor([ 0.9326, -1.0093])\n",
      "pre:left true:left 454/11700\n",
      "tensor([-0.3310,  0.3594])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左299_0_299_20200412_110355266_4.jpg\n",
      "pre:right true:left 455/11700\n",
      "tensor([ 0.2012, -0.1140])\n",
      "pre:left true:left 456/11700\n",
      "tensor([ 0.0892, -0.0841])\n",
      "pre:left true:left 457/11700\n",
      "tensor([-0.0988,  0.1439])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左526_0_682_20200412_115021100_2.jpg\n",
      "pre:right true:left 458/11700\n",
      "tensor([ 0.6872, -0.5895])\n",
      "pre:left true:left 459/11700\n",
      "tensor([ 1.1109, -1.0966])\n",
      "pre:left true:left 460/11700\n",
      "tensor([ 0.4651, -0.4437])\n",
      "pre:left true:left 461/11700\n",
      "tensor([ 0.6510, -0.6017])\n",
      "pre:left true:left 462/11700\n",
      "tensor([ 0.6352, -0.5855])\n",
      "pre:left true:left 463/11700\n",
      "tensor([ 0.4989, -0.4168])\n",
      "pre:left true:left 464/11700\n",
      "tensor([ 0.0932, -0.0728])\n",
      "pre:left true:left 465/11700\n",
      "tensor([ 1.3311, -1.3489])\n",
      "pre:left true:left 466/11700\n",
      "tensor([ 0.4011, -0.4593])\n",
      "pre:left true:left 467/11700\n",
      "tensor([ 0.4577, -0.4660])\n",
      "pre:left true:left 468/11700\n",
      "tensor([ 1.2081, -1.2371])\n",
      "pre:left true:left 469/11700\n",
      "tensor([ 0.3288, -0.3268])\n",
      "pre:left true:left 470/11700\n",
      "tensor([0.0572, 0.0048])\n",
      "pre:left true:left 471/11700\n",
      "tensor([ 0.5990, -0.5541])\n",
      "pre:left true:left 472/11700\n",
      "tensor([ 0.4314, -0.4033])\n",
      "pre:left true:left 473/11700\n",
      "tensor([ 0.6126, -0.7227])\n",
      "pre:left true:left 474/11700\n",
      "tensor([ 0.6647, -0.6540])\n",
      "pre:left true:left 475/11700\n",
      "tensor([ 1.3777, -1.3705])\n",
      "pre:left true:left 476/11700\n",
      "tensor([ 0.6331, -0.6648])\n",
      "pre:left true:left 477/11700\n",
      "tensor([ 0.8300, -0.8087])\n",
      "pre:left true:left 478/11700\n",
      "tensor([ 0.9613, -0.9717])\n",
      "pre:left true:left 479/11700\n",
      "tensor([ 1.3819, -1.3330])\n",
      "pre:left true:left 480/11700\n",
      "tensor([ 0.1954, -0.1536])\n",
      "pre:left true:left 481/11700\n",
      "tensor([ 0.6700, -0.6136])\n",
      "pre:left true:left 482/11700\n",
      "tensor([ 0.2513, -0.2184])\n",
      "pre:left true:left 483/11700\n",
      "tensor([ 0.6310, -0.6353])\n",
      "pre:left true:left 484/11700\n",
      "tensor([ 0.4857, -0.4952])\n",
      "pre:left true:left 485/11700\n",
      "tensor([ 0.7995, -0.7634])\n",
      "pre:left true:left 486/11700\n",
      "tensor([ 0.7096, -0.6980])\n",
      "pre:left true:left 487/11700\n",
      "tensor([ 0.4814, -0.4823])\n",
      "pre:left true:left 488/11700\n",
      "tensor([ 1.4677, -1.4853])\n",
      "pre:left true:left 489/11700\n",
      "tensor([ 1.0770, -1.0298])\n",
      "pre:left true:left 490/11700\n",
      "tensor([ 0.6828, -0.6345])\n",
      "pre:left true:left 491/11700\n",
      "tensor([ 0.2305, -0.2463])\n",
      "pre:left true:left 492/11700\n",
      "tensor([ 0.9442, -0.9923])\n",
      "pre:left true:left 493/11700\n",
      "tensor([ 0.9387, -0.8854])\n",
      "pre:left true:left 494/11700\n",
      "tensor([ 0.4326, -0.3978])\n",
      "pre:left true:left 495/11700\n",
      "tensor([ 0.6935, -0.6511])\n",
      "pre:left true:left 496/11700\n",
      "tensor([ 0.8429, -0.7895])\n",
      "pre:left true:left 497/11700\n",
      "tensor([ 0.6175, -0.5499])\n",
      "pre:left true:left 498/11700\n",
      "tensor([ 0.1220, -0.1395])\n",
      "pre:left true:left 499/11700\n",
      "tensor([ 0.7537, -0.6782])\n",
      "pre:left true:left 500/11700\n",
      "tensor([ 0.5494, -0.3913])\n",
      "pre:left true:left 501/11700\n",
      "tensor([ 0.7318, -0.8211])\n",
      "pre:left true:left 502/11700\n",
      "tensor([ 0.7999, -0.8539])\n",
      "pre:left true:left 503/11700\n",
      "tensor([ 0.2948, -0.3684])\n",
      "pre:left true:left 504/11700\n",
      "tensor([ 0.4087, -0.4113])\n",
      "pre:left true:left 505/11700\n",
      "tensor([ 0.3295, -0.3046])\n",
      "pre:left true:left 506/11700\n",
      "tensor([ 0.2025, -0.2530])\n",
      "pre:left true:left 507/11700\n",
      "tensor([ 0.2934, -0.3169])\n",
      "pre:left true:left 508/11700\n",
      "tensor([-0.0911,  0.0434])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左376_0_376_20200412_110545063_9.jpg\n",
      "pre:right true:left 509/11700\n",
      "tensor([ 0.5471, -0.5735])\n",
      "pre:left true:left 510/11700\n",
      "tensor([ 0.1672, -0.1715])\n",
      "pre:left true:left 511/11700\n",
      "tensor([ 0.3230, -0.3533])\n",
      "pre:left true:left 512/11700\n",
      "tensor([ 0.5012, -0.3063])\n",
      "pre:left true:left 513/11700\n",
      "tensor([ 1.4522, -1.5002])\n",
      "pre:left true:left 514/11700\n",
      "tensor([ 0.2622, -0.2674])\n",
      "pre:left true:left 515/11700\n",
      "tensor([ 1.2706, -1.2595])\n",
      "pre:left true:left 516/11700\n",
      "tensor([ 0.9136, -0.8539])\n",
      "pre:left true:left 517/11700\n",
      "tensor([ 0.5081, -0.5130])\n",
      "pre:left true:left 518/11700\n",
      "tensor([-0.0366,  0.1351])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1401_0_1557_20200412_120921450_2.jpg\n",
      "pre:right true:left 519/11700\n",
      "tensor([ 0.8099, -0.8294])\n",
      "pre:left true:left 520/11700\n",
      "tensor([ 1.2249, -1.1625])\n",
      "pre:left true:left 521/11700\n",
      "tensor([ 0.6320, -0.7349])\n",
      "pre:left true:left 522/11700\n",
      "tensor([ 0.2029, -0.2043])\n",
      "pre:left true:left 523/11700\n",
      "tensor([ 1.0741, -1.0707])\n",
      "pre:left true:left 524/11700\n",
      "tensor([ 0.6540, -0.7271])\n",
      "pre:left true:left 525/11700\n",
      "tensor([ 0.6947, -0.6581])\n",
      "pre:left true:left 526/11700\n",
      "tensor([ 1.1177, -1.0847])\n",
      "pre:left true:left 527/11700\n",
      "tensor([ 0.8235, -0.8728])\n",
      "pre:left true:left 528/11700\n",
      "tensor([ 0.8834, -0.9205])\n",
      "pre:left true:left 529/11700\n",
      "tensor([ 0.2102, -0.3372])\n",
      "pre:left true:left 530/11700\n",
      "tensor([ 0.5752, -0.6371])\n",
      "pre:left true:left 531/11700\n",
      "tensor([ 0.5577, -0.5681])\n",
      "pre:left true:left 532/11700\n",
      "tensor([ 0.5805, -0.5707])\n",
      "pre:left true:left 533/11700\n",
      "tensor([ 0.2998, -0.2516])\n",
      "pre:left true:left 534/11700\n",
      "tensor([ 0.9758, -0.9955])\n",
      "pre:left true:left 535/11700\n",
      "tensor([ 0.6374, -0.5275])\n",
      "pre:left true:left 536/11700\n",
      "tensor([ 0.4580, -0.4785])\n",
      "pre:left true:left 537/11700\n",
      "tensor([ 0.4692, -0.5086])\n",
      "pre:left true:left 538/11700\n",
      "tensor([ 1.0043, -0.8967])\n",
      "pre:left true:left 539/11700\n",
      "tensor([-0.1684,  0.2701])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左617_0_617_20200412_111128829_1.jpg\n",
      "pre:right true:left 540/11700\n",
      "tensor([ 0.5319, -0.4608])\n",
      "pre:left true:left 541/11700\n",
      "tensor([ 0.4546, -0.3499])\n",
      "pre:left true:left 542/11700\n",
      "tensor([ 0.5654, -0.4936])\n",
      "pre:left true:left 543/11700\n",
      "tensor([ 0.6758, -0.8183])\n",
      "pre:left true:left 544/11700\n",
      "tensor([ 0.6735, -0.5818])\n",
      "pre:left true:left 545/11700\n",
      "tensor([ 0.4404, -0.4494])\n",
      "pre:left true:left 546/11700\n",
      "tensor([ 0.8381, -0.7637])\n",
      "pre:left true:left 547/11700\n",
      "tensor([ 1.0107, -1.0120])\n",
      "pre:left true:left 548/11700\n",
      "tensor([ 0.6258, -0.6193])\n",
      "pre:left true:left 549/11700\n",
      "tensor([-0.1432,  0.2074])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左807_0_963_20200412_115627339_10.jpg\n",
      "pre:right true:left 550/11700\n",
      "tensor([ 0.3102, -0.3303])\n",
      "pre:left true:left 551/11700\n",
      "tensor([ 0.8727, -0.8583])\n",
      "pre:left true:left 552/11700\n",
      "tensor([ 0.0399, -0.0884])\n",
      "pre:left true:left 553/11700\n",
      "tensor([-0.3858,  0.3616])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1333_0_1333_20200412_112748533_8.jpg\n",
      "pre:right true:left 554/11700\n",
      "tensor([-0.0055,  0.0067])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/右1204_0_1360_20200412_120504707_7.jpg\n",
      "pre:right true:left 555/11700\n",
      "tensor([ 0.3113, -0.2835])\n",
      "pre:left true:left 556/11700\n",
      "tensor([0.0139, 0.0871])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1597_0_1753_20200412_121336950_1.jpg\n",
      "pre:right true:left 557/11700\n",
      "tensor([ 1.2138, -1.1280])\n",
      "pre:left true:left 558/11700\n",
      "tensor([ 1.1490, -1.1852])\n",
      "pre:left true:left 559/11700\n",
      "tensor([ 0.6732, -0.7346])\n",
      "pre:left true:left 560/11700\n",
      "tensor([-0.2138,  0.2481])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左804_0_804_20200412_111555570_9.jpg\n",
      "pre:right true:left 561/11700\n",
      "tensor([ 0.6017, -0.7079])\n",
      "pre:left true:left 562/11700\n",
      "tensor([ 0.0757, -0.1090])\n",
      "pre:left true:left 563/11700\n",
      "tensor([ 0.3786, -0.3338])\n",
      "pre:left true:left 564/11700\n",
      "tensor([ 1.3631, -1.4443])\n",
      "pre:left true:left 565/11700\n",
      "tensor([ 0.4481, -0.3359])\n",
      "pre:left true:left 566/11700\n",
      "tensor([ 0.1394, -0.0811])\n",
      "pre:left true:left 567/11700\n",
      "tensor([ 0.3680, -0.2918])\n",
      "pre:left true:left 568/11700\n",
      "tensor([-0.6174,  0.7142])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左444_0_600_20200412_114834237_5.jpg\n",
      "pre:right true:left 569/11700\n",
      "tensor([-0.0157,  0.2176])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左787_0_943_20200412_115601257_6.jpg\n",
      "pre:right true:left 570/11700\n",
      "tensor([ 1.0332, -1.0732])\n",
      "pre:left true:left 571/11700\n",
      "tensor([ 1.0949, -1.0179])\n",
      "pre:left true:left 572/11700\n",
      "tensor([ 0.7605, -0.7397])\n",
      "pre:left true:left 573/11700\n",
      "tensor([ 0.8491, -0.7777])\n",
      "pre:left true:left 574/11700\n",
      "tensor([ 0.3909, -0.2894])\n",
      "pre:left true:left 575/11700\n",
      "tensor([-0.0490,  0.1130])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左625_0_781_20200412_115230120_0.jpg\n",
      "pre:right true:left 576/11700\n",
      "tensor([ 1.0513, -0.9321])\n",
      "pre:left true:left 577/11700\n",
      "tensor([ 1.4312, -1.3952])\n",
      "pre:left true:left 578/11700\n",
      "tensor([ 0.3814, -0.3322])\n",
      "pre:left true:left 579/11700\n",
      "tensor([ 0.2971, -0.2616])\n",
      "pre:left true:left 580/11700\n",
      "tensor([ 0.6657, -0.6358])\n",
      "pre:left true:left 581/11700\n",
      "tensor([ 1.3312, -1.3448])\n",
      "pre:left true:left 582/11700\n",
      "tensor([ 1.0579, -0.9469])\n",
      "pre:left true:left 583/11700\n",
      "tensor([ 0.9236, -0.8397])\n",
      "pre:left true:left 584/11700\n",
      "tensor([ 0.4338, -0.4291])\n",
      "pre:left true:left 585/11700\n",
      "tensor([ 0.8656, -0.8739])\n",
      "pre:left true:left 586/11700\n",
      "tensor([-0.1996,  0.2656])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左957_0_957_20200412_111928680_9.jpg\n",
      "pre:right true:left 587/11700\n",
      "tensor([-0.1992,  0.1654])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左862_0_1018_20200412_115739004_10.jpg\n",
      "pre:right true:left 588/11700\n",
      "tensor([ 0.4729, -0.4376])\n",
      "pre:left true:left 589/11700\n",
      "tensor([ 1.1719, -1.2155])\n",
      "pre:left true:left 590/11700\n",
      "tensor([ 1.0793, -1.0237])\n",
      "pre:left true:left 591/11700\n",
      "tensor([ 0.5353, -0.4702])\n",
      "pre:left true:left 592/11700\n",
      "tensor([ 0.0651, -0.1345])\n",
      "pre:left true:left 593/11700\n",
      "tensor([ 1.2327, -1.3169])\n",
      "pre:left true:left 594/11700\n",
      "tensor([ 0.9810, -1.0247])\n",
      "pre:left true:left 595/11700\n",
      "tensor([ 0.1373, -0.0590])\n",
      "pre:left true:left 596/11700\n",
      "tensor([ 0.7102, -0.7681])\n",
      "pre:left true:left 597/11700\n",
      "tensor([ 1.7337, -1.6024])\n",
      "pre:left true:left 598/11700\n",
      "tensor([ 0.2772, -0.2127])\n",
      "pre:left true:left 599/11700\n",
      "tensor([ 1.1635, -1.3015])\n",
      "pre:left true:left 600/11700\n",
      "tensor([ 0.6943, -0.7371])\n",
      "pre:left true:left 601/11700\n",
      "tensor([ 0.2631, -0.3232])\n",
      "pre:left true:left 602/11700\n",
      "tensor([ 1.5961, -1.6417])\n",
      "pre:left true:left 603/11700\n",
      "tensor([ 0.3795, -0.4006])\n",
      "pre:left true:left 604/11700\n",
      "tensor([ 0.2577, -0.2430])\n",
      "pre:left true:left 605/11700\n",
      "tensor([ 0.8141, -0.7882])\n",
      "pre:left true:left 606/11700\n",
      "tensor([ 0.7182, -0.7503])\n",
      "pre:left true:left 607/11700\n",
      "tensor([ 0.9039, -0.9525])\n",
      "pre:left true:left 608/11700\n",
      "tensor([ 0.6963, -0.7500])\n",
      "pre:left true:left 609/11700\n",
      "tensor([ 0.6126, -0.5629])\n",
      "pre:left true:left 610/11700\n",
      "tensor([ 0.3680, -0.2881])\n",
      "pre:left true:left 611/11700\n",
      "tensor([-0.0007, -0.0470])\n",
      "pre:left true:left 612/11700\n",
      "tensor([ 0.4321, -0.4259])\n",
      "pre:left true:left 613/11700\n",
      "tensor([ 0.8444, -0.8674])\n",
      "pre:left true:left 614/11700\n",
      "tensor([ 1.0778, -1.1220])\n",
      "pre:left true:left 615/11700\n",
      "tensor([ 0.9711, -0.9438])\n",
      "pre:left true:left 616/11700\n",
      "tensor([ 1.1967, -1.1960])\n",
      "pre:left true:left 617/11700\n",
      "tensor([ 0.2119, -0.2175])\n",
      "pre:left true:left 618/11700\n",
      "tensor([ 1.1044, -1.0096])\n",
      "pre:left true:left 619/11700\n",
      "tensor([ 0.3607, -0.4566])\n",
      "pre:left true:left 620/11700\n",
      "tensor([ 0.3910, -0.4147])\n",
      "pre:left true:left 621/11700\n",
      "tensor([ 0.4497, -0.3366])\n",
      "pre:left true:left 622/11700\n",
      "tensor([ 0.3958, -0.4405])\n",
      "pre:left true:left 623/11700\n",
      "tensor([ 0.6351, -0.8190])\n",
      "pre:left true:left 624/11700\n",
      "tensor([ 0.8117, -0.7111])\n",
      "pre:left true:left 625/11700\n",
      "tensor([ 0.3980, -0.3729])\n",
      "pre:left true:left 626/11700\n",
      "tensor([-0.2367,  0.3351])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左647_0_647_20200412_111211623_3.jpg\n",
      "pre:right true:left 627/11700\n",
      "tensor([ 0.2674, -0.2305])\n",
      "pre:left true:left 628/11700\n",
      "tensor([ 0.6787, -0.6198])\n",
      "pre:left true:left 629/11700\n",
      "tensor([ 0.7849, -0.8490])\n",
      "pre:left true:left 630/11700\n",
      "tensor([ 0.4908, -0.4813])\n",
      "pre:left true:left 631/11700\n",
      "tensor([ 0.8294, -0.7935])\n",
      "pre:left true:left 632/11700\n",
      "tensor([-0.0939,  0.0647])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左87_0_87_20200412_105852899_7.jpg\n",
      "pre:right true:left 633/11700\n",
      "tensor([ 0.5027, -0.4227])\n",
      "pre:left true:left 634/11700\n",
      "tensor([ 0.9043, -0.8303])\n",
      "pre:left true:left 635/11700\n",
      "tensor([ 0.3788, -0.3357])\n",
      "pre:left true:left 636/11700\n",
      "tensor([ 0.7826, -0.7898])\n",
      "pre:left true:left 637/11700\n",
      "tensor([0.0081, 0.0689])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左621_0_777_20200412_115224917_4.jpg\n",
      "pre:right true:left 638/11700\n",
      "tensor([ 0.5785, -0.6059])\n",
      "pre:left true:left 639/11700\n",
      "tensor([ 0.7257, -0.7073])\n",
      "pre:left true:left 640/11700\n",
      "tensor([ 0.2928, -0.3290])\n",
      "pre:left true:left 641/11700\n",
      "tensor([ 0.8301, -0.8927])\n",
      "pre:left true:left 642/11700\n",
      "tensor([ 0.8925, -0.9073])\n",
      "pre:left true:left 643/11700\n",
      "tensor([ 0.3936, -0.3901])\n",
      "pre:left true:left 644/11700\n",
      "tensor([ 0.6717, -0.6361])\n",
      "pre:left true:left 645/11700\n",
      "tensor([-0.3159,  0.2611])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左700_0_856_20200412_115407862_2.jpg\n",
      "pre:right true:left 646/11700\n",
      "tensor([ 0.3358, -0.3862])\n",
      "pre:left true:left 647/11700\n",
      "tensor([ 0.2189, -0.2531])\n",
      "pre:left true:left 648/11700\n",
      "tensor([ 0.3417, -0.2740])\n",
      "pre:left true:left 649/11700\n",
      "tensor([ 0.8346, -0.7990])\n",
      "pre:left true:left 650/11700\n",
      "tensor([ 1.2358, -1.1027])\n",
      "pre:left true:left 651/11700\n",
      "tensor([ 0.5897, -0.6127])\n",
      "pre:left true:left 652/11700\n",
      "tensor([ 1.0453, -0.9523])\n",
      "pre:left true:left 653/11700\n",
      "tensor([ 0.7837, -0.8379])\n",
      "pre:left true:left 654/11700\n",
      "tensor([ 1.3405, -1.3521])\n",
      "pre:left true:left 655/11700\n",
      "tensor([ 0.6385, -0.6636])\n",
      "pre:left true:left 656/11700\n",
      "tensor([ 0.8795, -0.8879])\n",
      "pre:left true:left 657/11700\n",
      "tensor([-0.1466,  0.1399])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左917_0_917_20200412_111836594_10.jpg\n",
      "pre:right true:left 658/11700\n",
      "tensor([ 0.1240, -0.0688])\n",
      "pre:left true:left 659/11700\n",
      "tensor([ 0.6508, -0.6261])\n",
      "pre:left true:left 660/11700\n",
      "tensor([ 0.9312, -0.8658])\n",
      "pre:left true:left 661/11700\n",
      "tensor([ 0.3281, -0.3306])\n",
      "pre:left true:left 662/11700\n",
      "tensor([ 0.6636, -0.6574])\n",
      "pre:left true:left 663/11700\n",
      "tensor([ 0.2760, -0.2728])\n",
      "pre:left true:left 664/11700\n",
      "tensor([ 0.5248, -0.5635])\n",
      "pre:left true:left 665/11700\n",
      "tensor([ 0.5426, -0.5083])\n",
      "pre:left true:left 666/11700\n",
      "tensor([0.0309, 0.0201])\n",
      "pre:left true:left 667/11700\n",
      "tensor([ 0.1583, -0.1917])\n",
      "pre:left true:left 668/11700\n",
      "tensor([ 1.3298, -1.3257])\n",
      "pre:left true:left 669/11700\n",
      "tensor([ 0.4554, -0.5347])\n",
      "pre:left true:left 670/11700\n",
      "tensor([-0.1975,  0.2534])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左993_0_1149_20200412_120029734_5.jpg\n",
      "pre:right true:left 671/11700\n",
      "tensor([ 0.0300, -0.0142])\n",
      "pre:left true:left 672/11700\n",
      "tensor([ 0.3441, -0.4009])\n",
      "pre:left true:left 673/11700\n",
      "tensor([ 0.6749, -0.6561])\n",
      "pre:left true:left 674/11700\n",
      "tensor([ 0.7650, -0.6578])\n",
      "pre:left true:left 675/11700\n",
      "tensor([ 0.0552, -0.1670])\n",
      "pre:left true:left 676/11700\n",
      "tensor([ 0.5000, -0.5338])\n",
      "pre:left true:left 677/11700\n",
      "tensor([ 0.8049, -0.7752])\n",
      "pre:left true:left 678/11700\n",
      "tensor([-0.0976,  0.0742])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左603_0_603_20200412_111108855_3.jpg\n",
      "pre:right true:left 679/11700\n",
      "tensor([ 0.2280, -0.1750])\n",
      "pre:left true:left 680/11700\n",
      "tensor([-0.3002,  0.3046])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左369_0_525_20200412_114656522_9.jpg\n",
      "pre:right true:left 681/11700\n",
      "tensor([ 0.1509, -0.1083])\n",
      "pre:left true:left 682/11700\n",
      "tensor([ 0.6859, -0.5791])\n",
      "pre:left true:left 683/11700\n",
      "tensor([ 0.4114, -0.3396])\n",
      "pre:left true:left 684/11700\n",
      "tensor([-0.2319,  0.3057])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左334_0_334_20200412_110445177_5.jpg\n",
      "pre:right true:left 685/11700\n",
      "tensor([ 0.7904, -0.8045])\n",
      "pre:left true:left 686/11700\n",
      "tensor([ 0.4750, -0.4293])\n",
      "pre:left true:left 687/11700\n",
      "tensor([ 1.1725, -1.1449])\n",
      "pre:left true:left 688/11700\n",
      "tensor([ 0.6639, -0.7303])\n",
      "pre:left true:left 689/11700\n",
      "tensor([ 0.9199, -0.8605])\n",
      "pre:left true:left 690/11700\n",
      "tensor([-0.3295,  0.3612])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左402_0_402_20200412_110622150_8.jpg\n",
      "pre:right true:left 691/11700\n",
      "tensor([ 0.5567, -0.5540])\n",
      "pre:left true:left 692/11700\n",
      "tensor([ 0.2816, -0.1255])\n",
      "pre:left true:left 693/11700\n",
      "tensor([-0.0169, -0.0592])\n",
      "pre:left true:left 694/11700\n",
      "tensor([ 0.6219, -0.7187])\n",
      "pre:left true:left 695/11700\n",
      "tensor([-0.0634,  0.0489])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左638_0_794_20200412_115247063_1.jpg\n",
      "pre:right true:left 696/11700\n",
      "tensor([ 0.5817, -0.5199])\n",
      "pre:left true:left 697/11700\n",
      "tensor([ 1.5357, -1.5584])\n",
      "pre:left true:left 698/11700\n",
      "tensor([-0.0134,  0.0036])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左791_0_791_20200412_111537015_4.jpg\n",
      "pre:right true:left 699/11700\n",
      "tensor([ 0.6765, -0.6631])\n",
      "pre:left true:left 700/11700\n",
      "tensor([ 1.3642, -1.4018])\n",
      "pre:left true:left 701/11700\n",
      "tensor([ 1.2277, -1.1190])\n",
      "pre:left true:left 702/11700\n",
      "tensor([ 0.3980, -0.1631])\n",
      "pre:left true:left 703/11700\n",
      "tensor([ 0.3950, -0.2297])\n",
      "pre:left true:left 704/11700\n",
      "tensor([-0.2684,  0.3302])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左109_0_109_20200412_105924272_0.jpg\n",
      "pre:right true:left 705/11700\n",
      "tensor([-0.0965,  0.0995])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左636_0_792_20200412_115244458_3.jpg\n",
      "pre:right true:left 706/11700\n",
      "tensor([ 0.1310, -0.0485])\n",
      "pre:left true:left 707/11700\n",
      "tensor([ 0.7140, -0.7031])\n",
      "pre:left true:left 708/11700\n",
      "tensor([ 0.2391, -0.2308])\n",
      "pre:left true:left 709/11700\n",
      "tensor([ 0.4576, -0.4980])\n",
      "pre:left true:left 710/11700\n",
      "tensor([-0.0990,  0.0736])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左770_0_926_20200412_115539115_9.jpg\n",
      "pre:right true:left 711/11700\n",
      "tensor([ 0.4814, -0.4142])\n",
      "pre:left true:left 712/11700\n",
      "tensor([ 0.0039, -0.0916])\n",
      "pre:left true:left 713/11700\n",
      "tensor([ 0.3603, -0.3586])\n",
      "pre:left true:left 714/11700\n",
      "tensor([ 1.7259, -1.7283])\n",
      "pre:left true:left 715/11700\n",
      "tensor([ 0.6715, -0.5916])\n",
      "pre:left true:left 716/11700\n",
      "tensor([ 0.5161, -0.5021])\n",
      "pre:left true:left 717/11700\n",
      "tensor([ 0.3727, -0.2978])\n",
      "pre:left true:left 718/11700\n",
      "tensor([ 0.9709, -0.9314])\n",
      "pre:left true:left 719/11700\n",
      "tensor([ 0.7559, -0.7816])\n",
      "pre:left true:left 720/11700\n",
      "tensor([ 1.1442, -1.1859])\n",
      "pre:left true:left 721/11700\n",
      "tensor([ 1.1304, -1.2328])\n",
      "pre:left true:left 722/11700\n",
      "tensor([ 0.0715, -0.0373])\n",
      "pre:left true:left 723/11700\n",
      "tensor([ 0.7167, -0.7143])\n",
      "pre:left true:left 724/11700\n",
      "tensor([ 0.8376, -0.8460])\n",
      "pre:left true:left 725/11700\n",
      "tensor([ 0.6996, -0.7777])\n",
      "pre:left true:left 726/11700\n",
      "tensor([ 1.1736, -1.0778])\n",
      "pre:left true:left 727/11700\n",
      "tensor([ 0.4737, -0.4785])\n",
      "pre:left true:left 728/11700\n",
      "tensor([ 0.4202, -0.3880])\n",
      "pre:left true:left 729/11700\n",
      "tensor([ 0.0736, -0.0239])\n",
      "pre:left true:left 730/11700\n",
      "tensor([-0.0116,  0.0767])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左591_0_591_20200412_111051747_10.jpg\n",
      "pre:right true:left 731/11700\n",
      "tensor([ 0.5366, -0.4579])\n",
      "pre:left true:left 732/11700\n",
      "tensor([ 1.4013, -1.4247])\n",
      "pre:left true:left 733/11700\n",
      "tensor([ 0.2678, -0.3002])\n",
      "pre:left true:left 734/11700\n",
      "tensor([-0.5458,  0.5413])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左519_0_675_20200412_115011993_3.jpg\n",
      "pre:right true:left 735/11700\n",
      "tensor([ 0.8448, -0.8280])\n",
      "pre:left true:left 736/11700\n",
      "tensor([ 0.6796, -0.7008])\n",
      "pre:left true:left 737/11700\n",
      "tensor([ 0.4478, -0.4207])\n",
      "pre:left true:left 738/11700\n",
      "tensor([ 0.5884, -0.6204])\n",
      "pre:left true:left 739/11700\n",
      "tensor([ 1.2252, -1.1950])\n",
      "pre:left true:left 740/11700\n",
      "tensor([ 0.5240, -0.4775])\n",
      "pre:left true:left 741/11700\n",
      "tensor([ 1.1802, -1.2254])\n",
      "pre:left true:left 742/11700\n",
      "tensor([ 0.4429, -0.5121])\n",
      "pre:left true:left 743/11700\n",
      "tensor([ 0.4414, -0.4665])\n",
      "pre:left true:left 744/11700\n",
      "tensor([ 0.6511, -0.6121])\n",
      "pre:left true:left 745/11700\n",
      "tensor([ 0.7169, -0.7248])\n",
      "pre:left true:left 746/11700\n",
      "tensor([ 0.9070, -0.9420])\n",
      "pre:left true:left 747/11700\n",
      "tensor([ 0.6321, -0.6841])\n",
      "pre:left true:left 748/11700\n",
      "tensor([ 0.9747, -0.9550])\n",
      "pre:left true:left 749/11700\n",
      "tensor([ 1.0840, -0.9978])\n",
      "pre:left true:left 750/11700\n",
      "tensor([ 0.8136, -0.8311])\n",
      "pre:left true:left 751/11700\n",
      "tensor([ 0.3443, -0.3607])\n",
      "pre:left true:left 752/11700\n",
      "tensor([ 0.6400, -0.6730])\n",
      "pre:left true:left 753/11700\n",
      "tensor([ 0.5813, -0.5735])\n",
      "pre:left true:left 754/11700\n",
      "tensor([ 0.6238, -0.6199])\n",
      "pre:left true:left 755/11700\n",
      "tensor([ 0.4095, -0.4048])\n",
      "pre:left true:left 756/11700\n",
      "tensor([0.0544, 0.0213])\n",
      "pre:left true:left 757/11700\n",
      "tensor([ 0.6805, -0.7283])\n",
      "pre:left true:left 758/11700\n",
      "tensor([ 0.8654, -0.8908])\n",
      "pre:left true:left 759/11700\n",
      "tensor([ 0.9000, -0.8803])\n",
      "pre:left true:left 760/11700\n",
      "tensor([ 0.3435, -0.3157])\n",
      "pre:left true:left 761/11700\n",
      "tensor([ 0.0802, -0.0722])\n",
      "pre:left true:left 762/11700\n",
      "tensor([ 1.0983, -1.0746])\n",
      "pre:left true:left 763/11700\n",
      "tensor([ 0.8622, -0.9103])\n",
      "pre:left true:left 764/11700\n",
      "tensor([ 0.4731, -0.5408])\n",
      "pre:left true:left 765/11700\n",
      "tensor([ 0.9736, -0.8460])\n",
      "pre:left true:left 766/11700\n",
      "tensor([ 0.5534, -0.5875])\n",
      "pre:left true:left 767/11700\n",
      "tensor([-0.1774,  0.2003])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左260_0_260_20200412_110259633_9.jpg\n",
      "pre:right true:left 768/11700\n",
      "tensor([ 0.7936, -0.8329])\n",
      "pre:left true:left 769/11700\n",
      "tensor([ 0.3664, -0.4406])\n",
      "pre:left true:left 770/11700\n",
      "tensor([ 0.8353, -0.8884])\n",
      "pre:left true:left 771/11700\n",
      "tensor([ 0.5375, -0.4910])\n",
      "pre:left true:left 772/11700\n",
      "tensor([ 0.4922, -0.4548])\n",
      "pre:left true:left 773/11700\n",
      "tensor([ 0.8898, -0.9350])\n",
      "pre:left true:left 774/11700\n",
      "tensor([ 0.6379, -0.5830])\n",
      "pre:left true:left 775/11700\n",
      "tensor([ 0.8367, -0.8598])\n",
      "pre:left true:left 776/11700\n",
      "tensor([ 0.3526, -0.3677])\n",
      "pre:left true:left 777/11700\n",
      "tensor([ 0.8409, -0.7750])\n",
      "pre:left true:left 778/11700\n",
      "tensor([ 1.0461, -1.1586])\n",
      "pre:left true:left 779/11700\n",
      "tensor([ 1.2575, -1.2087])\n",
      "pre:left true:left 780/11700\n",
      "tensor([ 0.3894, -0.4203])\n",
      "pre:left true:left 781/11700\n",
      "tensor([0.1352, 0.0187])\n",
      "pre:left true:left 782/11700\n",
      "tensor([ 0.8385, -0.7449])\n",
      "pre:left true:left 783/11700\n",
      "tensor([ 1.2016, -1.1742])\n",
      "pre:left true:left 784/11700\n",
      "tensor([ 0.8997, -0.8704])\n",
      "pre:left true:left 785/11700\n",
      "tensor([ 0.5661, -0.4230])\n",
      "pre:left true:left 786/11700\n",
      "tensor([-0.0199,  0.0925])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左72_0_72_20200412_105831500_1.jpg\n",
      "pre:right true:left 787/11700\n",
      "tensor([-0.4488,  0.5515])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左304_0_304_20200412_105539887_9.jpg\n",
      "pre:right true:left 788/11700\n",
      "tensor([-0.2326,  0.2551])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左814_0_970_20200412_115636447_6.jpg\n",
      "pre:right true:left 789/11700\n",
      "tensor([ 0.5594, -0.3824])\n",
      "pre:left true:left 790/11700\n",
      "tensor([ 0.1090, -0.1325])\n",
      "pre:left true:left 791/11700\n",
      "tensor([ 0.6533, -0.6856])\n",
      "pre:left true:left 792/11700\n",
      "tensor([ 0.8436, -0.7911])\n",
      "pre:left true:left 793/11700\n",
      "tensor([0.0111, 0.0632])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左808_0_964_20200412_115628626_5.jpg\n",
      "pre:right true:left 794/11700\n",
      "tensor([ 0.5826, -0.6769])\n",
      "pre:left true:left 795/11700\n",
      "tensor([ 0.4825, -0.4881])\n",
      "pre:left true:left 796/11700\n",
      "tensor([ 0.4440, -0.5414])\n",
      "pre:left true:left 797/11700\n",
      "tensor([ 0.2028, -0.2279])\n",
      "pre:left true:left 798/11700\n",
      "tensor([ 0.4396, -0.4682])\n",
      "pre:left true:left 799/11700\n",
      "tensor([ 0.2190, -0.1863])\n",
      "pre:left true:left 800/11700\n",
      "tensor([ 0.4769, -0.4973])\n",
      "pre:left true:left 801/11700\n",
      "tensor([ 0.1565, -0.0971])\n",
      "pre:left true:left 802/11700\n",
      "tensor([ 0.4987, -0.5003])\n",
      "pre:left true:left 803/11700\n",
      "tensor([ 0.6549, -0.7339])\n",
      "pre:left true:left 804/11700\n",
      "tensor([ 0.7811, -0.8222])\n",
      "pre:left true:left 805/11700\n",
      "tensor([ 0.7724, -0.8063])\n",
      "pre:left true:left 806/11700\n",
      "tensor([ 0.3281, -0.2330])\n",
      "pre:left true:left 807/11700\n",
      "tensor([ 0.5490, -0.6064])\n",
      "pre:left true:left 808/11700\n",
      "tensor([ 0.6838, -0.6139])\n",
      "pre:left true:left 809/11700\n",
      "tensor([-0.8904,  1.0311])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左850_0_1006_20200412_115723362_8.jpg\n",
      "pre:right true:left 810/11700\n",
      "tensor([ 0.3981, -0.3867])\n",
      "pre:left true:left 811/11700\n",
      "tensor([ 0.2066, -0.2158])\n",
      "pre:left true:left 812/11700\n",
      "tensor([ 0.5837, -0.6068])\n",
      "pre:left true:left 813/11700\n",
      "tensor([ 0.6610, -0.7072])\n",
      "pre:left true:left 814/11700\n",
      "tensor([ 0.2127, -0.1797])\n",
      "pre:left true:left 815/11700\n",
      "tensor([ 0.2798, -0.3371])\n",
      "pre:left true:left 816/11700\n",
      "tensor([ 1.0873, -0.9887])\n",
      "pre:left true:left 817/11700\n",
      "tensor([ 0.1543, -0.2226])\n",
      "pre:left true:left 818/11700\n",
      "tensor([ 0.5885, -0.6531])\n",
      "pre:left true:left 819/11700\n",
      "tensor([ 0.9357, -0.8916])\n",
      "pre:left true:left 820/11700\n",
      "tensor([ 0.4920, -0.4506])\n",
      "pre:left true:left 821/11700\n",
      "tensor([ 0.6526, -0.7221])\n",
      "pre:left true:left 822/11700\n",
      "tensor([-0.0767, -0.0002])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左425_0_581_20200412_114809477.jpg\n",
      "pre:right true:left 823/11700\n",
      "tensor([ 0.4963, -0.4585])\n",
      "pre:left true:left 824/11700\n",
      "tensor([ 1.3724, -1.3601])\n",
      "pre:left true:left 825/11700\n",
      "tensor([ 0.5592, -0.5191])\n",
      "pre:left true:left 826/11700\n",
      "tensor([ 0.9578, -0.8434])\n",
      "pre:left true:left 827/11700\n",
      "tensor([ 0.2381, -0.2712])\n",
      "pre:left true:left 828/11700\n",
      "tensor([ 0.8513, -0.8830])\n",
      "pre:left true:left 829/11700\n",
      "tensor([ 0.4519, -0.4464])\n",
      "pre:left true:left 830/11700\n",
      "tensor([ 0.4610, -0.4627])\n",
      "pre:left true:left 831/11700\n",
      "tensor([ 0.1327, -0.0770])\n",
      "pre:left true:left 832/11700\n",
      "tensor([ 1.1725, -1.1313])\n",
      "pre:left true:left 833/11700\n",
      "tensor([ 0.4440, -0.5414])\n",
      "pre:left true:left 834/11700\n",
      "tensor([ 0.6135, -0.6719])\n",
      "pre:left true:left 835/11700\n",
      "tensor([ 0.9090, -0.8671])\n",
      "pre:left true:left 836/11700\n",
      "tensor([ 0.5204, -0.5314])\n",
      "pre:left true:left 837/11700\n",
      "tensor([ 0.5552, -0.5797])\n",
      "pre:left true:left 838/11700\n",
      "tensor([ 0.6459, -0.5493])\n",
      "pre:left true:left 839/11700\n",
      "tensor([-0.4408,  0.4206])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左780_0_936_20200412_115552136_10.jpg\n",
      "pre:right true:left 840/11700\n",
      "tensor([-0.1133,  0.2266])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左84_0_84_20200412_105848614_5.jpg\n",
      "pre:right true:left 841/11700\n",
      "tensor([ 0.5620, -0.4869])\n",
      "pre:left true:left 842/11700\n",
      "tensor([ 0.1440, -0.1647])\n",
      "pre:left true:left 843/11700\n",
      "tensor([ 0.1960, -0.2028])\n",
      "pre:left true:left 844/11700\n",
      "tensor([ 0.2321, -0.2622])\n",
      "pre:left true:left 845/11700\n",
      "tensor([ 1.0370, -1.0802])\n",
      "pre:left true:left 846/11700\n",
      "tensor([ 1.0349, -0.9976])\n",
      "pre:left true:left 847/11700\n",
      "tensor([ 0.0429, -0.0791])\n",
      "pre:left true:left 848/11700\n",
      "tensor([ 0.4643, -0.4499])\n",
      "pre:left true:left 849/11700\n",
      "tensor([ 1.1742, -1.1828])\n",
      "pre:left true:left 850/11700\n",
      "tensor([ 0.2647, -0.3095])\n",
      "pre:left true:left 851/11700\n",
      "tensor([ 0.2247, -0.1986])\n",
      "pre:left true:left 852/11700\n",
      "tensor([ 0.3143, -0.3302])\n",
      "pre:left true:left 853/11700\n",
      "tensor([ 0.3947, -0.4162])\n",
      "pre:left true:left 854/11700\n",
      "tensor([-0.2864,  0.2984])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左840_0_996_20200412_115710343_9.jpg\n",
      "pre:right true:left 855/11700\n",
      "tensor([ 0.6614, -0.6063])\n",
      "pre:left true:left 856/11700\n",
      "tensor([ 0.3538, -0.3657])\n",
      "pre:left true:left 857/11700\n",
      "tensor([ 0.3195, -0.4218])\n",
      "pre:left true:left 858/11700\n",
      "tensor([ 0.6629, -0.6013])\n",
      "pre:left true:left 859/11700\n",
      "tensor([ 0.0570, -0.0268])\n",
      "pre:left true:left 860/11700\n",
      "tensor([ 0.5190, -0.5476])\n",
      "pre:left true:left 861/11700\n",
      "tensor([ 1.2422, -1.1297])\n",
      "pre:left true:left 862/11700\n",
      "tensor([ 0.0830, -0.1137])\n",
      "pre:left true:left 863/11700\n",
      "tensor([ 0.8595, -0.7685])\n",
      "pre:left true:left 864/11700\n",
      "tensor([0.0274, 0.0238])\n",
      "pre:left true:left 865/11700\n",
      "tensor([ 0.2657, -0.1811])\n",
      "pre:left true:left 866/11700\n",
      "tensor([ 1.1334, -1.0060])\n",
      "pre:left true:left 867/11700\n",
      "tensor([ 0.0273, -0.0443])\n",
      "pre:left true:left 868/11700\n",
      "tensor([ 0.7091, -0.8118])\n",
      "pre:left true:left 869/11700\n",
      "tensor([ 0.1069, -0.0250])\n",
      "pre:left true:left 870/11700\n",
      "tensor([ 0.4627, -0.5039])\n",
      "pre:left true:left 871/11700\n",
      "tensor([ 0.4918, -0.5145])\n",
      "pre:left true:left 872/11700\n",
      "tensor([ 0.6140, -0.5527])\n",
      "pre:left true:left 873/11700\n",
      "tensor([-0.3008,  0.2552])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左935_0_935_20200412_111900032_9.jpg\n",
      "pre:right true:left 874/11700\n",
      "tensor([ 0.0463, -0.0989])\n",
      "pre:left true:left 875/11700\n",
      "tensor([-0.5189,  0.5067])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左804_0_804_20200412_111555570_0.jpg\n",
      "pre:right true:left 876/11700\n",
      "tensor([ 0.6567, -0.6387])\n",
      "pre:left true:left 877/11700\n",
      "tensor([ 0.7096, -0.6128])\n",
      "pre:left true:left 878/11700\n",
      "tensor([ 0.9411, -0.8547])\n",
      "pre:left true:left 879/11700\n",
      "tensor([ 0.7600, -0.7567])\n",
      "pre:left true:left 880/11700\n",
      "tensor([-0.1832,  0.2228])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左451_0_451_20200412_110732049_8.jpg\n",
      "pre:right true:left 881/11700\n",
      "tensor([ 0.6221, -0.6126])\n",
      "pre:left true:left 882/11700\n",
      "tensor([ 0.5727, -0.5393])\n",
      "pre:left true:left 883/11700\n",
      "tensor([ 0.5078, -0.3551])\n",
      "pre:left true:left 884/11700\n",
      "tensor([-0.4067,  0.4149])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左401_0_557_20200412_114738212_6.jpg\n",
      "pre:right true:left 885/11700\n",
      "tensor([ 0.5423, -0.4727])\n",
      "pre:left true:left 886/11700\n",
      "tensor([-0.2334,  0.2126])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1329_0_1329_20200412_112743331_0.jpg\n",
      "pre:right true:left 887/11700\n",
      "tensor([ 0.8035, -0.8052])\n",
      "pre:left true:left 888/11700\n",
      "tensor([ 1.3185, -1.3004])\n",
      "pre:left true:left 889/11700\n",
      "tensor([ 0.9204, -0.8803])\n",
      "pre:left true:left 890/11700\n",
      "tensor([ 0.0510, -0.0255])\n",
      "pre:left true:left 891/11700\n",
      "tensor([ 0.6606, -0.5172])\n",
      "pre:left true:left 892/11700\n",
      "tensor([ 0.5893, -0.5990])\n",
      "pre:left true:left 893/11700\n",
      "tensor([ 0.6201, -0.5674])\n",
      "pre:left true:left 894/11700\n",
      "tensor([ 0.2138, -0.2800])\n",
      "pre:left true:left 895/11700\n",
      "tensor([ 1.1008, -1.0409])\n",
      "pre:left true:left 896/11700\n",
      "tensor([ 1.6311, -1.6404])\n",
      "pre:left true:left 897/11700\n",
      "tensor([ 0.4634, -0.4464])\n",
      "pre:left true:left 898/11700\n",
      "tensor([ 0.0590, -0.0751])\n",
      "pre:left true:left 899/11700\n",
      "tensor([ 0.6272, -0.4790])\n",
      "pre:left true:left 900/11700\n",
      "tensor([-0.1066,  0.1276])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左491_0_647_20200412_114935493_6.jpg\n",
      "pre:right true:left 901/11700\n",
      "tensor([-0.1574,  0.1665])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左256_0_412_20200412_114429261_5.jpg\n",
      "pre:right true:left 902/11700\n",
      "tensor([ 0.3079, -0.3173])\n",
      "pre:left true:left 903/11700\n",
      "tensor([ 0.5164, -0.4037])\n",
      "pre:left true:left 904/11700\n",
      "tensor([ 0.6058, -0.5383])\n",
      "pre:left true:left 905/11700\n",
      "tensor([ 0.5098, -0.4978])\n",
      "pre:left true:left 906/11700\n",
      "tensor([ 0.2683, -0.1896])\n",
      "pre:left true:left 907/11700\n",
      "tensor([ 1.5104, -1.4720])\n",
      "pre:left true:left 908/11700\n",
      "tensor([ 0.8508, -0.9043])\n",
      "pre:left true:left 909/11700\n",
      "tensor([-0.2225,  0.3412])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左600_0_600_20200412_111104575_7.jpg\n",
      "pre:right true:left 910/11700\n",
      "tensor([ 0.5533, -0.4800])\n",
      "pre:left true:left 911/11700\n",
      "tensor([ 0.3507, -0.3219])\n",
      "pre:left true:left 912/11700\n",
      "tensor([ 0.7581, -0.7508])\n",
      "pre:left true:left 913/11700\n",
      "tensor([ 0.6388, -0.6962])\n",
      "pre:left true:left 914/11700\n",
      "tensor([ 0.5284, -0.4993])\n",
      "pre:left true:left 915/11700\n",
      "tensor([ 0.7435, -0.6510])\n",
      "pre:left true:left 916/11700\n",
      "tensor([ 0.4848, -0.4242])\n",
      "pre:left true:left 917/11700\n",
      "tensor([ 0.6742, -0.6395])\n",
      "pre:left true:left 918/11700\n",
      "tensor([ 0.4438, -0.3003])\n",
      "pre:left true:left 919/11700\n",
      "tensor([ 2.2277, -2.1078])\n",
      "pre:left true:left 920/11700\n",
      "tensor([ 0.0272, -0.0730])\n",
      "pre:left true:left 921/11700\n",
      "tensor([ 0.7373, -0.6884])\n",
      "pre:left true:left 922/11700\n",
      "tensor([ 0.3274, -0.1924])\n",
      "pre:left true:left 923/11700\n",
      "tensor([ 0.3448, -0.3347])\n",
      "pre:left true:left 924/11700\n",
      "tensor([ 0.4100, -0.3510])\n",
      "pre:left true:left 925/11700\n",
      "tensor([-0.0331,  0.0322])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左156_0_156_20200412_110031305.jpg\n",
      "pre:right true:left 926/11700\n",
      "tensor([ 1.0127, -0.9791])\n",
      "pre:left true:left 927/11700\n",
      "tensor([ 0.4733, -0.5172])\n",
      "pre:left true:left 928/11700\n",
      "tensor([ 0.4571, -0.4062])\n",
      "pre:left true:left 929/11700\n",
      "tensor([0.1308, 0.0365])\n",
      "pre:left true:left 930/11700\n",
      "tensor([-0.2738,  0.3498])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左316_0_316_20200412_110419502_4.jpg\n",
      "pre:right true:left 931/11700\n",
      "tensor([-0.0431,  0.0672])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1306_0_1306_20200412_112703459_5.jpg\n",
      "pre:right true:left 932/11700\n",
      "tensor([0.0117, 0.0440])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左648_0_804_20200412_115300105_2.jpg\n",
      "pre:right true:left 933/11700\n",
      "tensor([ 0.1782, -0.1131])\n",
      "pre:left true:left 934/11700\n",
      "tensor([ 0.4915, -0.4123])\n",
      "pre:left true:left 935/11700\n",
      "tensor([ 0.3723, -0.3890])\n",
      "pre:left true:left 936/11700\n",
      "tensor([0.0538, 0.0109])\n",
      "pre:left true:left 937/11700\n",
      "tensor([ 0.8377, -0.8831])\n",
      "pre:left true:left 938/11700\n",
      "tensor([ 0.2605, -0.1963])\n",
      "pre:left true:left 939/11700\n",
      "tensor([ 0.5147, -0.5052])\n",
      "pre:left true:left 940/11700\n",
      "tensor([ 0.6432, -0.6560])\n",
      "pre:left true:left 941/11700\n",
      "tensor([ 0.4699, -0.5870])\n",
      "pre:left true:left 942/11700\n",
      "tensor([ 0.4080, -0.1983])\n",
      "pre:left true:left 943/11700\n",
      "tensor([ 0.4576, -0.4153])\n",
      "pre:left true:left 944/11700\n",
      "tensor([ 0.6458, -0.5844])\n",
      "pre:left true:left 945/11700\n",
      "tensor([ 0.1521, -0.1181])\n",
      "pre:left true:left 946/11700\n",
      "tensor([ 0.7760, -0.7356])\n",
      "pre:left true:left 947/11700\n",
      "tensor([-0.4231,  0.5613])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左374_0_374_20200412_110542219_4.jpg\n",
      "pre:right true:left 948/11700\n",
      "tensor([ 0.1473, -0.0814])\n",
      "pre:left true:left 949/11700\n",
      "tensor([ 0.4607, -0.4798])\n",
      "pre:left true:left 950/11700\n",
      "tensor([ 0.4266, -0.3171])\n",
      "pre:left true:left 951/11700\n",
      "tensor([ 1.0611, -1.0505])\n",
      "pre:left true:left 952/11700\n",
      "tensor([ 0.2908, -0.3361])\n",
      "pre:left true:left 953/11700\n",
      "tensor([ 0.4669, -0.4403])\n",
      "pre:left true:left 954/11700\n",
      "tensor([ 0.9012, -0.9355])\n",
      "pre:left true:left 955/11700\n",
      "tensor([ 1.8096, -1.8781])\n",
      "pre:left true:left 956/11700\n",
      "tensor([ 0.7226, -0.6776])\n",
      "pre:left true:left 957/11700\n",
      "tensor([ 0.6849, -0.6542])\n",
      "pre:left true:left 958/11700\n",
      "tensor([ 0.4059, -0.2929])\n",
      "pre:left true:left 959/11700\n",
      "tensor([ 1.3794, -1.3334])\n",
      "pre:left true:left 960/11700\n",
      "tensor([-0.2138,  0.1375])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左802_0_802_20200412_111552717_5.jpg\n",
      "pre:right true:left 961/11700\n",
      "tensor([ 0.9057, -0.8362])\n",
      "pre:left true:left 962/11700\n",
      "tensor([ 0.3724, -0.2767])\n",
      "pre:left true:left 963/11700\n",
      "tensor([ 0.8058, -0.8173])\n",
      "pre:left true:left 964/11700\n",
      "tensor([ 1.4864, -1.5749])\n",
      "pre:left true:left 965/11700\n",
      "tensor([ 0.2844, -0.1796])\n",
      "pre:left true:left 966/11700\n",
      "tensor([ 0.8120, -0.8404])\n",
      "pre:left true:left 967/11700\n",
      "tensor([ 1.1654, -1.0686])\n",
      "pre:left true:left 968/11700\n",
      "tensor([-0.0958,  0.1622])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左727_0_727_20200412_111405748_4.jpg\n",
      "pre:right true:left 969/11700\n",
      "tensor([ 0.4964, -0.3754])\n",
      "pre:left true:left 970/11700\n",
      "tensor([ 1.1677, -1.1370])\n",
      "pre:left true:left 971/11700\n",
      "tensor([ 0.5224, -0.5666])\n",
      "pre:left true:left 972/11700\n",
      "tensor([ 0.9280, -0.9399])\n",
      "pre:left true:left 973/11700\n",
      "tensor([ 0.9029, -0.8465])\n",
      "pre:left true:left 974/11700\n",
      "tensor([ 1.2125, -1.2933])\n",
      "pre:left true:left 975/11700\n",
      "tensor([-0.3895,  0.4082])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左265_0_265_20200412_110306768_1.jpg\n",
      "pre:right true:left 976/11700\n",
      "tensor([ 0.7456, -0.7080])\n",
      "pre:left true:left 977/11700\n",
      "tensor([ 0.9518, -0.8846])\n",
      "pre:left true:left 978/11700\n",
      "tensor([ 0.5114, -0.5277])\n",
      "pre:left true:left 979/11700\n",
      "tensor([-0.0195,  0.0575])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左175_0_331_20200412_114243715_2.jpg\n",
      "pre:right true:left 980/11700\n",
      "tensor([ 0.9821, -0.8816])\n",
      "pre:left true:left 981/11700\n",
      "tensor([ 0.4051, -0.4343])\n",
      "pre:left true:left 982/11700\n",
      "tensor([ 0.3427, -0.3429])\n",
      "pre:left true:left 983/11700\n",
      "tensor([-0.0228, -0.0826])\n",
      "pre:left true:left 984/11700\n",
      "tensor([ 0.4896, -0.4857])\n",
      "pre:left true:left 985/11700\n",
      "tensor([-0.0307,  0.0914])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左808_0_964_20200412_115628626_4.jpg\n",
      "pre:right true:left 986/11700\n",
      "tensor([-0.0597,  0.1831])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1556_0_1712_20200412_121243498_10.jpg\n",
      "pre:right true:left 987/11700\n",
      "tensor([ 1.0104, -0.9956])\n",
      "pre:left true:left 988/11700\n",
      "tensor([ 1.1418, -1.1040])\n",
      "pre:left true:left 989/11700\n",
      "tensor([ 0.3674, -0.3157])\n",
      "pre:left true:left 990/11700\n",
      "tensor([ 0.9483, -0.9825])\n",
      "pre:left true:left 991/11700\n",
      "tensor([ 0.9312, -0.8727])\n",
      "pre:left true:left 992/11700\n",
      "tensor([ 0.5079, -0.3973])\n",
      "pre:left true:left 993/11700\n",
      "tensor([ 0.1924, -0.2410])\n",
      "pre:left true:left 994/11700\n",
      "tensor([ 0.3262, -0.3679])\n",
      "pre:left true:left 995/11700\n",
      "tensor([ 0.2630, -0.1924])\n",
      "pre:left true:left 996/11700\n",
      "tensor([ 0.1106, -0.0323])\n",
      "pre:left true:left 997/11700\n",
      "tensor([ 0.5889, -0.5512])\n",
      "pre:left true:left 998/11700\n",
      "tensor([ 0.3119, -0.2637])\n",
      "pre:left true:left 999/11700\n",
      "tensor([-0.5713,  0.6174])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1291_0_1291_20200412_112643889_10.jpg\n",
      "pre:right true:left 1000/11700\n",
      "tensor([ 0.3513, -0.3736])\n",
      "pre:left true:left 1001/11700\n",
      "tensor([ 0.2042, -0.2047])\n",
      "pre:left true:left 1002/11700\n",
      "tensor([ 0.0090, -0.0169])\n",
      "pre:left true:left 1003/11700\n",
      "tensor([ 0.6032, -0.6355])\n",
      "pre:left true:left 1004/11700\n",
      "tensor([ 0.4020, -0.4360])\n",
      "pre:left true:left 1005/11700\n",
      "tensor([ 1.1885, -1.0702])\n",
      "pre:left true:left 1006/11700\n",
      "tensor([-0.4653,  0.5234])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左981_0_981_20200412_111959966_3.jpg\n",
      "pre:right true:left 1007/11700\n",
      "tensor([ 0.8165, -0.7878])\n",
      "pre:left true:left 1008/11700\n",
      "tensor([-0.1111,  0.1657])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1521_0_1677_20200412_121157876_7.jpg\n",
      "pre:right true:left 1009/11700\n",
      "tensor([ 0.9434, -0.9228])\n",
      "pre:left true:left 1010/11700\n",
      "tensor([ 0.9256, -1.0172])\n",
      "pre:left true:left 1011/11700\n",
      "tensor([ 0.0678, -0.0563])\n",
      "pre:left true:left 1012/11700\n",
      "tensor([ 0.7301, -0.7279])\n",
      "pre:left true:left 1013/11700\n",
      "tensor([ 1.0131, -1.0437])\n",
      "pre:left true:left 1014/11700\n",
      "tensor([-0.1715,  0.2723])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左807_0_963_20200412_115627339_9.jpg\n",
      "pre:right true:left 1015/11700\n",
      "tensor([0.0887, 0.0275])\n",
      "pre:left true:left 1016/11700\n",
      "tensor([ 0.6522, -0.6453])\n",
      "pre:left true:left 1017/11700\n",
      "tensor([-0.0555,  0.0168])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左521_0_677_20200412_115014578_3.jpg\n",
      "pre:right true:left 1018/11700\n",
      "tensor([ 0.8678, -0.8652])\n",
      "pre:left true:left 1019/11700\n",
      "tensor([ 0.2797, -0.2668])\n",
      "pre:left true:left 1020/11700\n",
      "tensor([ 0.0714, -0.1064])\n",
      "pre:left true:left 1021/11700\n",
      "tensor([ 0.1840, -0.0851])\n",
      "pre:left true:left 1022/11700\n",
      "tensor([ 1.4162, -1.2756])\n",
      "pre:left true:left 1023/11700\n",
      "tensor([ 0.5127, -0.4427])\n",
      "pre:left true:left 1024/11700\n",
      "tensor([0.0832, 0.0211])\n",
      "pre:left true:left 1025/11700\n",
      "tensor([ 0.6480, -0.6025])\n",
      "pre:left true:left 1026/11700\n",
      "tensor([ 0.8043, -0.8565])\n",
      "pre:left true:left 1027/11700\n",
      "tensor([ 0.3663, -0.4340])\n",
      "pre:left true:left 1028/11700\n",
      "tensor([-0.1379,  0.2228])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1320_0_1320_20200412_112731601_4.jpg\n",
      "pre:right true:left 1029/11700\n",
      "tensor([ 0.5571, -0.5839])\n",
      "pre:left true:left 1030/11700\n",
      "tensor([-0.2661,  0.1869])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左410_0_410_20200412_110633567_9.jpg\n",
      "pre:right true:left 1031/11700\n",
      "tensor([ 0.1481, -0.0600])\n",
      "pre:left true:left 1032/11700\n",
      "tensor([-0.1174,  0.1767])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1387_0_1543_20200412_120903209_4.jpg\n",
      "pre:right true:left 1033/11700\n",
      "tensor([0.0337, 0.0166])\n",
      "pre:left true:left 1034/11700\n",
      "tensor([ 0.6654, -0.7812])\n",
      "pre:left true:left 1035/11700\n",
      "tensor([-0.0801,  0.0303])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左471_0_627_20200412_114909437_8.jpg\n",
      "pre:right true:left 1036/11700\n",
      "tensor([ 0.0714, -0.1064])\n",
      "pre:left true:left 1037/11700\n",
      "tensor([-0.3226,  0.2638])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1470_0_1626_20200412_121051395_8.jpg\n",
      "pre:right true:left 1038/11700\n",
      "tensor([-0.5578,  0.4512])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左430_0_586_20200412_114815979_4.jpg\n",
      "pre:right true:left 1039/11700\n",
      "tensor([ 0.2661, -0.2451])\n",
      "pre:left true:left 1040/11700\n",
      "tensor([ 0.5687, -0.5477])\n",
      "pre:left true:left 1041/11700\n",
      "tensor([-0.6884,  0.6149])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左569_0_569_20200412_111020354_5.jpg\n",
      "pre:right true:left 1042/11700\n",
      "tensor([ 0.9311, -0.8757])\n",
      "pre:left true:left 1043/11700\n",
      "tensor([ 0.6337, -0.6525])\n",
      "pre:left true:left 1044/11700\n",
      "tensor([ 0.4247, -0.3761])\n",
      "pre:left true:left 1045/11700\n",
      "tensor([ 0.3651, -0.3212])\n",
      "pre:left true:left 1046/11700\n",
      "tensor([ 0.5839, -0.5533])\n",
      "pre:left true:left 1047/11700\n",
      "tensor([ 0.1074, -0.0907])\n",
      "pre:left true:left 1048/11700\n",
      "tensor([ 1.3147, -1.3080])\n",
      "pre:left true:left 1049/11700\n",
      "tensor([ 0.6228, -0.6286])\n",
      "pre:left true:left 1050/11700\n",
      "tensor([-0.7737,  0.8560])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左755_0_911_20200412_115519560_0.jpg\n",
      "pre:right true:left 1051/11700\n",
      "tensor([ 0.2186, -0.1508])\n",
      "pre:left true:left 1052/11700\n",
      "tensor([ 0.6591, -0.5699])\n",
      "pre:left true:left 1053/11700\n",
      "tensor([ 1.6004, -1.5536])\n",
      "pre:left true:left 1054/11700\n",
      "tensor([ 0.5364, -0.5657])\n",
      "pre:left true:left 1055/11700\n",
      "tensor([ 0.5255, -0.3887])\n",
      "pre:left true:left 1056/11700\n",
      "tensor([ 0.4571, -0.5078])\n",
      "pre:left true:left 1057/11700\n",
      "tensor([ 0.2385, -0.2361])\n",
      "pre:left true:left 1058/11700\n",
      "tensor([ 1.3133, -1.3457])\n",
      "pre:left true:left 1059/11700\n",
      "tensor([ 1.0703, -1.0685])\n",
      "pre:left true:left 1060/11700\n",
      "tensor([-0.7921,  0.8122])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左791_0_947_20200412_115606477_5.jpg\n",
      "pre:right true:left 1061/11700\n",
      "tensor([ 0.6448, -0.6318])\n",
      "pre:left true:left 1062/11700\n",
      "tensor([ 0.3589, -0.4062])\n",
      "pre:left true:left 1063/11700\n",
      "tensor([ 0.3040, -0.1288])\n",
      "pre:left true:left 1064/11700\n",
      "tensor([ 0.4242, -0.3701])\n",
      "pre:left true:left 1065/11700\n",
      "tensor([ 0.3170, -0.2311])\n",
      "pre:left true:left 1066/11700\n",
      "tensor([ 0.2475, -0.2960])\n",
      "pre:left true:left 1067/11700\n",
      "tensor([ 0.1326, -0.1329])\n",
      "pre:left true:left 1068/11700\n",
      "tensor([ 0.8334, -0.7579])\n",
      "pre:left true:left 1069/11700\n",
      "tensor([ 0.4643, -0.4169])\n",
      "pre:left true:left 1070/11700\n",
      "tensor([ 0.9002, -0.8348])\n",
      "pre:left true:left 1071/11700\n",
      "tensor([ 1.2297, -1.2119])\n",
      "pre:left true:left 1072/11700\n",
      "tensor([ 0.3890, -0.2933])\n",
      "pre:left true:left 1073/11700\n",
      "tensor([ 0.3496, -0.3606])\n",
      "pre:left true:left 1074/11700\n",
      "tensor([ 0.6780, -0.6019])\n",
      "pre:left true:left 1075/11700\n",
      "tensor([ 1.0138, -0.9361])\n",
      "pre:left true:left 1076/11700\n",
      "tensor([ 0.6109, -0.5190])\n",
      "pre:left true:left 1077/11700\n",
      "tensor([ 0.1093, -0.1438])\n",
      "pre:left true:left 1078/11700\n",
      "tensor([ 1.0885, -0.9748])\n",
      "pre:left true:left 1079/11700\n",
      "tensor([ 0.8260, -0.8168])\n",
      "pre:left true:left 1080/11700\n",
      "tensor([ 0.0345, -0.0072])\n",
      "pre:left true:left 1081/11700\n",
      "tensor([ 0.4359, -0.4075])\n",
      "pre:left true:left 1082/11700\n",
      "tensor([ 0.6692, -0.6542])\n",
      "pre:left true:left 1083/11700\n",
      "tensor([ 1.0396, -0.9624])\n",
      "pre:left true:left 1084/11700\n",
      "tensor([ 0.5161, -0.3849])\n",
      "pre:left true:left 1085/11700\n",
      "tensor([ 0.7877, -0.7460])\n",
      "pre:left true:left 1086/11700\n",
      "tensor([ 0.6808, -0.6640])\n",
      "pre:left true:left 1087/11700\n",
      "tensor([ 0.1718, -0.1336])\n",
      "pre:left true:left 1088/11700\n",
      "tensor([ 0.3758, -0.2470])\n",
      "pre:left true:left 1089/11700\n",
      "tensor([ 0.3871, -0.2970])\n",
      "pre:left true:left 1090/11700\n",
      "tensor([ 0.4350, -0.3132])\n",
      "pre:left true:left 1091/11700\n",
      "tensor([ 0.3084, -0.2498])\n",
      "pre:left true:left 1092/11700\n",
      "tensor([ 0.6228, -0.5848])\n",
      "pre:left true:left 1093/11700\n",
      "tensor([ 0.4663, -0.4410])\n",
      "pre:left true:left 1094/11700\n",
      "tensor([ 0.5417, -0.3737])\n",
      "pre:left true:left 1095/11700\n",
      "tensor([ 0.3750, -0.3538])\n",
      "pre:left true:left 1096/11700\n",
      "tensor([ 1.2141, -1.2056])\n",
      "pre:left true:left 1097/11700\n",
      "tensor([ 0.6625, -0.6082])\n",
      "pre:left true:left 1098/11700\n",
      "tensor([ 0.2674, -0.3456])\n",
      "pre:left true:left 1099/11700\n",
      "tensor([ 0.3713, -0.3338])\n",
      "pre:left true:left 1100/11700\n",
      "tensor([ 0.5744, -0.5873])\n",
      "pre:left true:left 1101/11700\n",
      "tensor([ 0.9706, -0.8834])\n",
      "pre:left true:left 1102/11700\n",
      "tensor([ 0.1856, -0.1717])\n",
      "pre:left true:left 1103/11700\n",
      "tensor([ 1.0262, -1.0256])\n",
      "pre:left true:left 1104/11700\n",
      "tensor([ 0.3636, -0.3514])\n",
      "pre:left true:left 1105/11700\n",
      "tensor([ 0.4005, -0.4289])\n",
      "pre:left true:left 1106/11700\n",
      "tensor([ 0.5106, -0.4925])\n",
      "pre:left true:left 1107/11700\n",
      "tensor([ 0.7285, -0.6795])\n",
      "pre:left true:left 1108/11700\n",
      "tensor([ 0.1543, -0.1003])\n",
      "pre:left true:left 1109/11700\n",
      "tensor([ 0.1164, -0.0412])\n",
      "pre:left true:left 1110/11700\n",
      "tensor([ 0.5284, -0.5471])\n",
      "pre:left true:left 1111/11700\n",
      "tensor([ 1.2267, -1.2294])\n",
      "pre:left true:left 1112/11700\n",
      "tensor([ 0.5798, -0.4571])\n",
      "pre:left true:left 1113/11700\n",
      "tensor([0.0133, 0.0139])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左842_0_998_20200412_115712939_1.jpg\n",
      "pre:right true:left 1114/11700\n",
      "tensor([ 0.3320, -0.3006])\n",
      "pre:left true:left 1115/11700\n",
      "tensor([ 0.8251, -0.7591])\n",
      "pre:left true:left 1116/11700\n",
      "tensor([-0.5226,  0.5916])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左258_0_414_20200412_114431875_9.jpg\n",
      "pre:right true:left 1117/11700\n",
      "tensor([ 0.2493, -0.1837])\n",
      "pre:left true:left 1118/11700\n",
      "tensor([ 1.0963, -1.1609])\n",
      "pre:left true:left 1119/11700\n",
      "tensor([ 0.9259, -0.9270])\n",
      "pre:left true:left 1120/11700\n",
      "tensor([ 1.0076, -1.0114])\n",
      "pre:left true:left 1121/11700\n",
      "tensor([ 1.2570, -1.2385])\n",
      "pre:left true:left 1122/11700\n",
      "tensor([ 0.8204, -0.8833])\n",
      "pre:left true:left 1123/11700\n",
      "tensor([ 0.4346, -0.4210])\n",
      "pre:left true:left 1124/11700\n",
      "tensor([ 0.7323, -0.7149])\n",
      "pre:left true:left 1125/11700\n",
      "tensor([ 0.6603, -0.6532])\n",
      "pre:left true:left 1126/11700\n",
      "tensor([-0.0799,  0.2175])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左307_0_463_20200412_114535722_1.jpg\n",
      "pre:right true:left 1127/11700\n",
      "tensor([ 0.2415, -0.1513])\n",
      "pre:left true:left 1128/11700\n",
      "tensor([ 0.6931, -0.6997])\n",
      "pre:left true:left 1129/11700\n",
      "tensor([ 0.2671, -0.2248])\n",
      "pre:left true:left 1130/11700\n",
      "tensor([-0.1034,  0.1864])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左480_0_636_20200412_114921166_9.jpg\n",
      "pre:right true:left 1131/11700\n",
      "tensor([ 0.5259, -0.3829])\n",
      "pre:left true:left 1132/11700\n",
      "tensor([ 0.7814, -0.8686])\n",
      "pre:left true:left 1133/11700\n",
      "tensor([ 0.9621, -1.0002])\n",
      "pre:left true:left 1134/11700\n",
      "tensor([ 0.2666, -0.3651])\n",
      "pre:left true:left 1135/11700\n",
      "tensor([ 0.4859, -0.4702])\n",
      "pre:left true:left 1136/11700\n",
      "tensor([ 0.2361, -0.2742])\n",
      "pre:left true:left 1137/11700\n",
      "tensor([ 0.4662, -0.3943])\n",
      "pre:left true:left 1138/11700\n",
      "tensor([ 0.6244, -0.5451])\n",
      "pre:left true:left 1139/11700\n",
      "tensor([ 1.3761, -1.4143])\n",
      "pre:left true:left 1140/11700\n",
      "tensor([ 0.1362, -0.1908])\n",
      "pre:left true:left 1141/11700\n",
      "tensor([ 0.0317, -0.0173])\n",
      "pre:left true:left 1142/11700\n",
      "tensor([ 0.1877, -0.1247])\n",
      "pre:left true:left 1143/11700\n",
      "tensor([-0.0941,  0.0367])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1409_0_1565_20200412_120931892_7.jpg\n",
      "pre:right true:left 1144/11700\n",
      "tensor([ 0.5823, -0.5672])\n",
      "pre:left true:left 1145/11700\n",
      "tensor([ 0.2750, -0.4473])\n",
      "pre:left true:left 1146/11700\n",
      "tensor([-0.3774,  0.4481])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左526_0_682_20200412_115021100_10.jpg\n",
      "pre:right true:left 1147/11700\n",
      "tensor([ 0.8047, -0.9045])\n",
      "pre:left true:left 1148/11700\n",
      "tensor([ 0.0172, -0.0334])\n",
      "pre:left true:left 1149/11700\n",
      "tensor([ 0.8273, -0.8435])\n",
      "pre:left true:left 1150/11700\n",
      "tensor([-0.1854,  0.1241])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左442_0_442_20200412_110719211_6.jpg\n",
      "pre:right true:left 1151/11700\n",
      "tensor([ 0.7372, -0.7959])\n",
      "pre:left true:left 1152/11700\n",
      "tensor([ 0.2720, -0.1586])\n",
      "pre:left true:left 1153/11700\n",
      "tensor([ 0.1075, -0.1732])\n",
      "pre:left true:left 1154/11700\n",
      "tensor([-0.1370,  0.2377])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1348_0_1504_20200412_120812383_8.jpg\n",
      "pre:right true:left 1155/11700\n",
      "tensor([ 0.2455, -0.1927])\n",
      "pre:left true:left 1156/11700\n",
      "tensor([ 1.0187, -1.0545])\n",
      "pre:left true:left 1157/11700\n",
      "tensor([ 0.8741, -0.9118])\n",
      "pre:left true:left 1158/11700\n",
      "tensor([ 0.7641, -0.6913])\n",
      "pre:left true:left 1159/11700\n",
      "tensor([ 0.3586, -0.3379])\n",
      "pre:left true:left 1160/11700\n",
      "tensor([ 0.6472, -0.6346])\n",
      "pre:left true:left 1161/11700\n",
      "tensor([ 0.5927, -0.6359])\n",
      "pre:left true:left 1162/11700\n",
      "tensor([ 1.0305, -1.0661])\n",
      "pre:left true:left 1163/11700\n",
      "tensor([ 0.5823, -0.5987])\n",
      "pre:left true:left 1164/11700\n",
      "tensor([ 0.4256, -0.3942])\n",
      "pre:left true:left 1165/11700\n",
      "tensor([ 0.9069, -0.9480])\n",
      "pre:left true:left 1166/11700\n",
      "tensor([ 0.5471, -0.6219])\n",
      "pre:left true:left 1167/11700\n",
      "tensor([ 0.7279, -0.7359])\n",
      "pre:left true:left 1168/11700\n",
      "tensor([ 1.0096, -0.9228])\n",
      "pre:left true:left 1169/11700\n",
      "tensor([ 0.6022, -0.6839])\n",
      "pre:left true:left 1170/11700\n",
      "tensor([ 0.3481, -0.2592])\n",
      "pre:left true:left 1171/11700\n",
      "tensor([ 1.4169, -1.3967])\n",
      "pre:left true:left 1172/11700\n",
      "tensor([ 0.1129, -0.1554])\n",
      "pre:left true:left 1173/11700\n",
      "tensor([ 0.5246, -0.5463])\n",
      "pre:left true:left 1174/11700\n",
      "tensor([-0.1432,  0.1298])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左343_0_343_20200412_105626646_5.jpg\n",
      "pre:right true:left 1175/11700\n",
      "tensor([ 0.4986, -0.5622])\n",
      "pre:left true:left 1176/11700\n",
      "tensor([ 0.5409, -0.5535])\n",
      "pre:left true:left 1177/11700\n",
      "tensor([ 0.3472, -0.3987])\n",
      "pre:left true:left 1178/11700\n",
      "tensor([0.0073, 0.0298])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左591_0_591_20200412_111051747_4.jpg\n",
      "pre:right true:left 1179/11700\n",
      "tensor([ 0.5607, -0.5838])\n",
      "pre:left true:left 1180/11700\n",
      "tensor([ 0.0549, -0.0100])\n",
      "pre:left true:left 1181/11700\n",
      "tensor([ 0.0208, -0.0154])\n",
      "pre:left true:left 1182/11700\n",
      "tensor([-0.0190,  0.1416])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左552_0_708_20200412_115054990_9.jpg\n",
      "pre:right true:left 1183/11700\n",
      "tensor([ 0.9302, -0.9241])\n",
      "pre:left true:left 1184/11700\n",
      "tensor([-0.1451,  0.0924])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左447_0_603_20200412_114838168.jpg\n",
      "pre:right true:left 1185/11700\n",
      "tensor([ 0.8972, -0.9798])\n",
      "pre:left true:left 1186/11700\n",
      "tensor([ 0.6501, -0.5628])\n",
      "pre:left true:left 1187/11700\n",
      "tensor([ 0.5300, -0.5136])\n",
      "pre:left true:left 1188/11700\n",
      "tensor([ 1.1602, -1.1227])\n",
      "pre:left true:left 1189/11700\n",
      "tensor([ 1.2976, -1.2881])\n",
      "pre:left true:left 1190/11700\n",
      "tensor([ 0.3178, -0.2387])\n",
      "pre:left true:left 1191/11700\n",
      "tensor([ 0.5284, -0.5471])\n",
      "pre:left true:left 1192/11700\n",
      "tensor([ 0.8661, -0.8892])\n",
      "pre:left true:left 1193/11700\n",
      "tensor([-0.0899,  0.1777])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左653_0_809_20200412_115306601_10.jpg\n",
      "pre:right true:left 1194/11700\n",
      "tensor([ 0.9037, -0.8677])\n",
      "pre:left true:left 1195/11700\n",
      "tensor([ 0.3671, -0.2734])\n",
      "pre:left true:left 1196/11700\n",
      "tensor([-0.0274, -0.0485])\n",
      "pre:left true:left 1197/11700\n",
      "tensor([ 0.8197, -0.8584])\n",
      "pre:left true:left 1198/11700\n",
      "tensor([-0.3392,  0.4000])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1532_0_1688_20200412_121212213_0.jpg\n",
      "pre:right true:left 1199/11700\n",
      "tensor([ 0.9697, -1.0060])\n",
      "pre:left true:left 1200/11700\n",
      "tensor([ 0.2165, -0.3069])\n",
      "pre:left true:left 1201/11700\n",
      "tensor([ 0.6235, -0.6035])\n",
      "pre:left true:left 1202/11700\n",
      "tensor([ 0.3319, -0.2881])\n",
      "pre:left true:left 1203/11700\n",
      "tensor([ 0.5347, -0.5122])\n",
      "pre:left true:left 1204/11700\n",
      "tensor([-0.1132,  0.1667])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左679_0_679_20200412_111257259_5.jpg\n",
      "pre:right true:left 1205/11700\n",
      "tensor([ 0.7429, -0.7311])\n",
      "pre:left true:left 1206/11700\n",
      "tensor([ 0.6910, -0.7685])\n",
      "pre:left true:left 1207/11700\n",
      "tensor([ 0.5708, -0.6006])\n",
      "pre:left true:left 1208/11700\n",
      "tensor([ 0.7019, -0.6080])\n",
      "pre:left true:left 1209/11700\n",
      "tensor([-0.0948,  0.1966])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1494_0_1650_20200412_121122671_4.jpg\n",
      "pre:right true:left 1210/11700\n",
      "tensor([-0.2653,  0.1753])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左835_0_991_20200412_115703810_7.jpg\n",
      "pre:right true:left 1211/11700\n",
      "tensor([ 0.8092, -0.7272])\n",
      "pre:left true:left 1212/11700\n",
      "tensor([-0.0633,  0.0673])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左482_0_638_20200412_114923761_7.jpg\n",
      "pre:right true:left 1213/11700\n",
      "tensor([ 1.3473, -1.4199])\n",
      "pre:left true:left 1214/11700\n",
      "tensor([-0.1956,  0.1515])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1174_0_1174_20200412_112411433_9.jpg\n",
      "pre:right true:left 1215/11700\n",
      "tensor([ 1.0955, -1.0146])\n",
      "pre:left true:left 1216/11700\n",
      "tensor([ 1.2977, -1.2860])\n",
      "pre:left true:left 1217/11700\n",
      "tensor([ 0.9720, -1.0420])\n",
      "pre:left true:left 1218/11700\n",
      "tensor([ 0.6012, -0.4861])\n",
      "pre:left true:left 1219/11700\n",
      "tensor([ 0.6352, -0.5870])\n",
      "pre:left true:left 1220/11700\n",
      "tensor([ 0.7353, -0.7192])\n",
      "pre:left true:left 1221/11700\n",
      "tensor([ 0.3669, -0.3549])\n",
      "pre:left true:left 1222/11700\n",
      "tensor([ 0.6108, -0.6264])\n",
      "pre:left true:left 1223/11700\n",
      "tensor([-0.2473,  0.3601])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左569_0_725_20200412_115117138_8.jpg\n",
      "pre:right true:left 1224/11700\n",
      "tensor([ 1.4594, -1.4199])\n",
      "pre:left true:left 1225/11700\n",
      "tensor([ 0.2473, -0.2710])\n",
      "pre:left true:left 1226/11700\n",
      "tensor([ 0.4938, -0.5274])\n",
      "pre:left true:left 1227/11700\n",
      "tensor([ 0.0165, -0.0384])\n",
      "pre:left true:left 1228/11700\n",
      "tensor([-0.7358,  0.8489])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左809_0_965_20200412_115629938_4.jpg\n",
      "pre:right true:left 1229/11700\n",
      "tensor([-0.0626,  0.0540])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左331_0_487_20200412_114606994_6.jpg\n",
      "pre:right true:left 1230/11700\n",
      "tensor([ 0.3116, -0.3259])\n",
      "pre:left true:left 1231/11700\n",
      "tensor([ 0.6140, -0.6419])\n",
      "pre:left true:left 1232/11700\n",
      "tensor([ 0.5059, -0.4901])\n",
      "pre:left true:left 1233/11700\n",
      "tensor([ 1.1415, -1.1711])\n",
      "pre:left true:left 1234/11700\n",
      "tensor([ 0.3687, -0.3032])\n",
      "pre:left true:left 1235/11700\n",
      "tensor([ 0.3125, -0.3524])\n",
      "pre:left true:left 1236/11700\n",
      "tensor([ 0.7489, -0.7723])\n",
      "pre:left true:left 1237/11700\n",
      "tensor([ 0.8186, -0.7339])\n",
      "pre:left true:left 1238/11700\n",
      "tensor([ 0.7116, -0.7708])\n",
      "pre:left true:left 1239/11700\n",
      "tensor([ 0.7234, -0.6965])\n",
      "pre:left true:left 1240/11700\n",
      "tensor([ 0.3261, -0.3735])\n",
      "pre:left true:left 1241/11700\n",
      "tensor([-0.0523,  0.1092])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左391_0_391_20200412_110606458_2.jpg\n",
      "pre:right true:left 1242/11700\n",
      "tensor([ 1.2046, -1.1363])\n",
      "pre:left true:left 1243/11700\n",
      "tensor([ 0.7295, -0.7073])\n",
      "pre:left true:left 1244/11700\n",
      "tensor([-0.3960,  0.4162])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左462_0_618_20200412_114857727_5.jpg\n",
      "pre:right true:left 1245/11700\n",
      "tensor([-0.5956,  0.6874])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1373_0_1529_20200412_120844971_5.jpg\n",
      "pre:right true:left 1246/11700\n",
      "tensor([ 0.4845, -0.4228])\n",
      "pre:left true:left 1247/11700\n",
      "tensor([-0.0748,  0.0690])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左308_0_464_20200412_114537015_2.jpg\n",
      "pre:right true:left 1248/11700\n",
      "tensor([ 0.0625, -0.0938])\n",
      "pre:left true:left 1249/11700\n",
      "tensor([ 0.5041, -0.5264])\n",
      "pre:left true:left 1250/11700\n",
      "tensor([ 0.5640, -0.5005])\n",
      "pre:left true:left 1251/11700\n",
      "tensor([ 0.6946, -0.6803])\n",
      "pre:left true:left 1252/11700\n",
      "tensor([ 0.7180, -0.7146])\n",
      "pre:left true:left 1253/11700\n",
      "tensor([ 0.3338, -0.4524])\n",
      "pre:left true:left 1254/11700\n",
      "tensor([ 0.0864, -0.1075])\n",
      "pre:left true:left 1255/11700\n",
      "tensor([-0.3029,  0.4010])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左676_0_676_20200412_111252987_4.jpg\n",
      "pre:right true:left 1256/11700\n",
      "tensor([ 1.3710, -1.2045])\n",
      "pre:left true:left 1257/11700\n",
      "tensor([ 1.5795, -1.5398])\n",
      "pre:left true:left 1258/11700\n",
      "tensor([ 0.2923, -0.2675])\n",
      "pre:left true:left 1259/11700\n",
      "tensor([ 0.7884, -0.6253])\n",
      "pre:left true:left 1260/11700\n",
      "tensor([ 0.3461, -0.2676])\n",
      "pre:left true:left 1261/11700\n",
      "tensor([ 0.5884, -0.6126])\n",
      "pre:left true:left 1262/11700\n",
      "tensor([ 0.3166, -0.3769])\n",
      "pre:left true:left 1263/11700\n",
      "tensor([ 0.7647, -0.7906])\n",
      "pre:left true:left 1264/11700\n",
      "tensor([0.1256, 0.0176])\n",
      "pre:left true:left 1265/11700\n",
      "tensor([ 0.5986, -0.5898])\n",
      "pre:left true:left 1266/11700\n",
      "tensor([0.0296, 0.0078])\n",
      "pre:left true:left 1267/11700\n",
      "tensor([-0.2918,  0.2888])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左285_0_441_20200412_114507035_5.jpg\n",
      "pre:right true:left 1268/11700\n",
      "tensor([ 0.6240, -0.6287])\n",
      "pre:left true:left 1269/11700\n",
      "tensor([ 0.3454, -0.3240])\n",
      "pre:left true:left 1270/11700\n",
      "tensor([ 1.2928, -1.2708])\n",
      "pre:left true:left 1271/11700\n",
      "tensor([ 0.3021, -0.2703])\n",
      "pre:left true:left 1272/11700\n",
      "tensor([ 0.1715, -0.1431])\n",
      "pre:left true:left 1273/11700\n",
      "tensor([-0.2097,  0.1812])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1268_0_1424_20200412_120628117_10.jpg\n",
      "pre:right true:left 1274/11700\n",
      "tensor([-0.2417,  0.1813])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左606_0_762_20200412_115205352_5.jpg\n",
      "pre:right true:left 1275/11700\n",
      "tensor([ 0.3409, -0.3192])\n",
      "pre:left true:left 1276/11700\n",
      "tensor([ 0.2982, -0.3323])\n",
      "pre:left true:left 1277/11700\n",
      "tensor([-0.2056,  0.2557])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左304_0_304_20200412_105539887_3.jpg\n",
      "pre:right true:left 1278/11700\n",
      "tensor([ 0.2039, -0.2361])\n",
      "pre:left true:left 1279/11700\n",
      "tensor([ 0.9315, -0.9256])\n",
      "pre:left true:left 1280/11700\n",
      "tensor([-0.1542,  0.2212])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左131_0_131_20200412_105955655.jpg\n",
      "pre:right true:left 1281/11700\n",
      "tensor([ 0.4914, -0.4356])\n",
      "pre:left true:left 1282/11700\n",
      "tensor([ 0.2819, -0.2720])\n",
      "pre:left true:left 1283/11700\n",
      "tensor([ 0.3403, -0.3415])\n",
      "pre:left true:left 1284/11700\n",
      "tensor([ 0.6866, -0.7042])\n",
      "pre:left true:left 1285/11700\n",
      "tensor([ 1.1540, -1.2429])\n",
      "pre:left true:left 1286/11700\n",
      "tensor([ 0.5322, -0.4400])\n",
      "pre:left true:left 1287/11700\n",
      "tensor([ 1.7821, -1.8374])\n",
      "pre:left true:left 1288/11700\n",
      "tensor([ 0.2491, -0.2802])\n",
      "pre:left true:left 1289/11700\n",
      "tensor([ 1.1282, -1.0770])\n",
      "pre:left true:left 1290/11700\n",
      "tensor([ 0.1869, -0.1995])\n",
      "pre:left true:left 1291/11700\n",
      "tensor([ 0.2725, -0.2168])\n",
      "pre:left true:left 1292/11700\n",
      "tensor([-0.2167,  0.2342])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左694_0_850_20200412_115400042_9.jpg\n",
      "pre:right true:left 1293/11700\n",
      "tensor([ 1.1953, -1.1124])\n",
      "pre:left true:left 1294/11700\n",
      "tensor([ 0.5327, -0.5150])\n",
      "pre:left true:left 1295/11700\n",
      "tensor([ 0.0400, -0.0745])\n",
      "pre:left true:left 1296/11700\n",
      "tensor([ 0.9569, -0.9366])\n",
      "pre:left true:left 1297/11700\n",
      "tensor([-0.8840,  0.9529])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左801_0_801_20200412_111551285_5.jpg\n",
      "pre:right true:left 1298/11700\n",
      "tensor([ 0.0522, -0.1536])\n",
      "pre:left true:left 1299/11700\n",
      "tensor([ 0.8777, -0.8699])\n",
      "pre:left true:left 1300/11700\n",
      "tensor([ 1.1362, -1.1997])\n",
      "pre:left true:left 1301/11700\n",
      "tensor([ 0.5941, -0.5196])\n",
      "pre:left true:left 1302/11700\n",
      "tensor([ 0.4163, -0.4266])\n",
      "pre:left true:left 1303/11700\n",
      "tensor([ 0.8182, -0.7037])\n",
      "pre:left true:left 1304/11700\n",
      "tensor([-0.2730,  0.2561])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左324_0_480_20200412_114557880_3.jpg\n",
      "pre:right true:left 1305/11700\n",
      "tensor([ 0.2936, -0.1969])\n",
      "pre:left true:left 1306/11700\n",
      "tensor([0.0272, 0.0785])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左636_0_792_20200412_115244458_1.jpg\n",
      "pre:right true:left 1307/11700\n",
      "tensor([ 0.4027, -0.4600])\n",
      "pre:left true:left 1308/11700\n",
      "tensor([ 0.4508, -0.3661])\n",
      "pre:left true:left 1309/11700\n",
      "tensor([ 0.4968, -0.4646])\n",
      "pre:left true:left 1310/11700\n",
      "tensor([-0.0843,  0.0738])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左732_0_888_20200412_115449596_5.jpg\n",
      "pre:right true:left 1311/11700\n",
      "tensor([ 0.6285, -0.5766])\n",
      "pre:left true:left 1312/11700\n",
      "tensor([ 0.9798, -0.9920])\n",
      "pre:left true:left 1313/11700\n",
      "tensor([ 0.6638, -0.6673])\n",
      "pre:left true:left 1314/11700\n",
      "tensor([-0.2528,  0.2176])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1322_0_1478_20200412_120738512_3.jpg\n",
      "pre:right true:left 1315/11700\n",
      "tensor([ 1.2847, -1.2553])\n",
      "pre:left true:left 1316/11700\n",
      "tensor([ 0.7244, -0.7162])\n",
      "pre:left true:left 1317/11700\n",
      "tensor([ 0.5953, -0.6420])\n",
      "pre:left true:left 1318/11700\n",
      "tensor([ 0.3478, -0.2356])\n",
      "pre:left true:left 1319/11700\n",
      "tensor([ 1.1991, -1.1432])\n",
      "pre:left true:left 1320/11700\n",
      "tensor([ 1.2059, -1.1705])\n",
      "pre:left true:left 1321/11700\n",
      "tensor([ 0.6214, -0.6452])\n",
      "pre:left true:left 1322/11700\n",
      "tensor([ 0.9435, -0.8642])\n",
      "pre:left true:left 1323/11700\n",
      "tensor([ 0.6158, -0.5180])\n",
      "pre:left true:left 1324/11700\n",
      "tensor([ 0.9403, -0.9133])\n",
      "pre:left true:left 1325/11700\n",
      "tensor([-1.3409e-02,  3.0175e-05])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1322_0_1478_20200412_120738512_4.jpg\n",
      "pre:right true:left 1326/11700\n",
      "tensor([ 0.2313, -0.2741])\n",
      "pre:left true:left 1327/11700\n",
      "tensor([ 2.1196, -2.2264])\n",
      "pre:left true:left 1328/11700\n",
      "tensor([ 0.7619, -0.7228])\n",
      "pre:left true:left 1329/11700\n",
      "tensor([ 0.4253, -0.3049])\n",
      "pre:left true:left 1330/11700\n",
      "tensor([0.0135, 0.0707])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左113_0_113_20200412_105929973_8.jpg\n",
      "pre:right true:left 1331/11700\n",
      "tensor([ 0.7230, -0.7372])\n",
      "pre:left true:left 1332/11700\n",
      "tensor([ 0.4129, -0.3640])\n",
      "pre:left true:left 1333/11700\n",
      "tensor([ 0.1207, -0.1521])\n",
      "pre:left true:left 1334/11700\n",
      "tensor([ 0.9879, -0.9645])\n",
      "pre:left true:left 1335/11700\n",
      "tensor([ 1.1747, -1.2539])\n",
      "pre:left true:left 1336/11700\n",
      "tensor([ 0.5412, -0.4918])\n",
      "pre:left true:left 1337/11700\n",
      "tensor([ 0.3506, -0.3219])\n",
      "pre:left true:left 1338/11700\n",
      "tensor([ 0.2702, -0.2755])\n",
      "pre:left true:left 1339/11700\n",
      "tensor([ 0.3210, -0.2412])\n",
      "pre:left true:left 1340/11700\n",
      "tensor([ 0.5992, -0.5734])\n",
      "pre:left true:left 1341/11700\n",
      "tensor([0.0089, 0.0251])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左754_0_754_20200412_111444252_9.jpg\n",
      "pre:right true:left 1342/11700\n",
      "tensor([ 0.6398, -0.7163])\n",
      "pre:left true:left 1343/11700\n",
      "tensor([ 1.0022, -0.9639])\n",
      "pre:left true:left 1344/11700\n",
      "tensor([ 0.6965, -0.6993])\n",
      "pre:left true:left 1345/11700\n",
      "tensor([ 0.4185, -0.3357])\n",
      "pre:left true:left 1346/11700\n",
      "tensor([ 0.6391, -0.6277])\n",
      "pre:left true:left 1347/11700\n",
      "tensor([ 0.1607, -0.2204])\n",
      "pre:left true:left 1348/11700\n",
      "tensor([ 0.6355, -0.5898])\n",
      "pre:left true:left 1349/11700\n",
      "tensor([ 0.4494, -0.3975])\n",
      "pre:left true:left 1350/11700\n",
      "tensor([ 0.1935, -0.2925])\n",
      "pre:left true:left 1351/11700\n",
      "tensor([ 1.0753, -1.0859])\n",
      "pre:left true:left 1352/11700\n",
      "tensor([ 1.5711, -1.5000])\n",
      "pre:left true:left 1353/11700\n",
      "tensor([ 0.1862, -0.1164])\n",
      "pre:left true:left 1354/11700\n",
      "tensor([ 1.4111, -1.4713])\n",
      "pre:left true:left 1355/11700\n",
      "tensor([ 1.5332, -1.4093])\n",
      "pre:left true:left 1356/11700\n",
      "tensor([ 0.3459, -0.3581])\n",
      "pre:left true:left 1357/11700\n",
      "tensor([ 1.3784, -1.3237])\n",
      "pre:left true:left 1358/11700\n",
      "tensor([ 0.1979, -0.0956])\n",
      "pre:left true:left 1359/11700\n",
      "tensor([ 0.5700, -0.5679])\n",
      "pre:left true:left 1360/11700\n",
      "tensor([ 0.8522, -0.7979])\n",
      "pre:left true:left 1361/11700\n",
      "tensor([ 0.6868, -0.7338])\n",
      "pre:left true:left 1362/11700\n",
      "tensor([ 0.4808, -0.3906])\n",
      "pre:left true:left 1363/11700\n",
      "tensor([ 0.6022, -0.6510])\n",
      "pre:left true:left 1364/11700\n",
      "tensor([ 0.3415, -0.2988])\n",
      "pre:left true:left 1365/11700\n",
      "tensor([ 0.7875, -0.7920])\n",
      "pre:left true:left 1366/11700\n",
      "tensor([ 0.2587, -0.3024])\n",
      "pre:left true:left 1367/11700\n",
      "tensor([ 0.6562, -0.5664])\n",
      "pre:left true:left 1368/11700\n",
      "tensor([ 0.8274, -0.6931])\n",
      "pre:left true:left 1369/11700\n",
      "tensor([ 1.3336, -1.3593])\n",
      "pre:left true:left 1370/11700\n",
      "tensor([ 0.5192, -0.5060])\n",
      "pre:left true:left 1371/11700\n",
      "tensor([ 0.6156, -0.5626])\n",
      "pre:left true:left 1372/11700\n",
      "tensor([ 1.0562, -1.0475])\n",
      "pre:left true:left 1373/11700\n",
      "tensor([ 0.2026, -0.2068])\n",
      "pre:left true:left 1374/11700\n",
      "tensor([ 0.5622, -0.5733])\n",
      "pre:left true:left 1375/11700\n",
      "tensor([ 0.9545, -0.9782])\n",
      "pre:left true:left 1376/11700\n",
      "tensor([ 0.9136, -0.8539])\n",
      "pre:left true:left 1377/11700\n",
      "tensor([ 1.5059, -1.5687])\n",
      "pre:left true:left 1378/11700\n",
      "tensor([ 0.3706, -0.3567])\n",
      "pre:left true:left 1379/11700\n",
      "tensor([ 0.2595, -0.2891])\n",
      "pre:left true:left 1380/11700\n",
      "tensor([ 1.1822, -1.2452])\n",
      "pre:left true:left 1381/11700\n",
      "tensor([ 0.6606, -0.6552])\n",
      "pre:left true:left 1382/11700\n",
      "tensor([ 0.1661, -0.2136])\n",
      "pre:left true:left 1383/11700\n",
      "tensor([ 0.0915, -0.0152])\n",
      "pre:left true:left 1384/11700\n",
      "tensor([ 1.0210, -1.0296])\n",
      "pre:left true:left 1385/11700\n",
      "tensor([ 1.1884, -1.2042])\n",
      "pre:left true:left 1386/11700\n",
      "tensor([-0.0060, -0.0854])\n",
      "pre:left true:left 1387/11700\n",
      "tensor([ 0.0821, -0.0585])\n",
      "pre:left true:left 1388/11700\n",
      "tensor([0.0424, 0.0584])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左204_0_360_20200412_114321501_5.jpg\n",
      "pre:right true:left 1389/11700\n",
      "tensor([ 1.1588, -1.0761])\n",
      "pre:left true:left 1390/11700\n",
      "tensor([ 1.1730, -1.2068])\n",
      "pre:left true:left 1391/11700\n",
      "tensor([ 0.0999, -0.0936])\n",
      "pre:left true:left 1392/11700\n",
      "tensor([ 1.1024, -1.0628])\n",
      "pre:left true:left 1393/11700\n",
      "tensor([ 0.4602, -0.5031])\n",
      "pre:left true:left 1394/11700\n",
      "tensor([ 0.0566, -0.0672])\n",
      "pre:left true:left 1395/11700\n",
      "tensor([-0.3033,  0.2818])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左448_0_448_20200412_110727761_5.jpg\n",
      "pre:right true:left 1396/11700\n",
      "tensor([ 0.4031, -0.4143])\n",
      "pre:left true:left 1397/11700\n",
      "tensor([ 0.5239, -0.4249])\n",
      "pre:left true:left 1398/11700\n",
      "tensor([ 0.3749, -0.3973])\n",
      "pre:left true:left 1399/11700\n",
      "tensor([ 0.9930, -0.9299])\n",
      "pre:left true:left 1400/11700\n",
      "tensor([ 0.1728, -0.2209])\n",
      "pre:left true:left 1401/11700\n",
      "tensor([ 0.4646, -0.4257])\n",
      "pre:left true:left 1402/11700\n",
      "tensor([ 0.5885, -0.4876])\n",
      "pre:left true:left 1403/11700\n",
      "tensor([ 0.7849, -0.7994])\n",
      "pre:left true:left 1404/11700\n",
      "tensor([ 0.0498, -0.0666])\n",
      "pre:left true:left 1405/11700\n",
      "tensor([ 0.6155, -0.6199])\n",
      "pre:left true:left 1406/11700\n",
      "tensor([ 0.4854, -0.4623])\n",
      "pre:left true:left 1407/11700\n",
      "tensor([ 0.6603, -0.5653])\n",
      "pre:left true:left 1408/11700\n",
      "tensor([ 0.9834, -0.9865])\n",
      "pre:left true:left 1409/11700\n",
      "tensor([ 0.5599, -0.5980])\n",
      "pre:left true:left 1410/11700\n",
      "tensor([-0.2103,  0.2285])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左227_0_227_20200412_110212568_5.jpg\n",
      "pre:right true:left 1411/11700\n",
      "tensor([ 0.8650, -0.8213])\n",
      "pre:left true:left 1412/11700\n",
      "tensor([ 0.6984, -0.7027])\n",
      "pre:left true:left 1413/11700\n",
      "tensor([ 0.1306, -0.2101])\n",
      "pre:left true:left 1414/11700\n",
      "tensor([-0.4530,  0.4119])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左828_0_984_20200412_115654687_6.jpg\n",
      "pre:right true:left 1415/11700\n",
      "tensor([ 0.6035, -0.6562])\n",
      "pre:left true:left 1416/11700\n",
      "tensor([ 0.1455, -0.1110])\n",
      "pre:left true:left 1417/11700\n",
      "tensor([ 0.8465, -0.7327])\n",
      "pre:left true:left 1418/11700\n",
      "tensor([ 0.7651, -0.7992])\n",
      "pre:left true:left 1419/11700\n",
      "tensor([ 0.3792, -0.2355])\n",
      "pre:left true:left 1420/11700\n",
      "tensor([-0.2239,  0.2321])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左735_0_891_20200412_115453481_1.jpg\n",
      "pre:right true:left 1421/11700\n",
      "tensor([ 0.6315, -0.6140])\n",
      "pre:left true:left 1422/11700\n",
      "tensor([ 0.6156, -0.6087])\n",
      "pre:left true:left 1423/11700\n",
      "tensor([ 1.4528, -1.3708])\n",
      "pre:left true:left 1424/11700\n",
      "tensor([ 0.4944, -0.5035])\n",
      "pre:left true:left 1425/11700\n",
      "tensor([ 0.4215, -0.3098])\n",
      "pre:left true:left 1426/11700\n",
      "tensor([ 0.8623, -0.8795])\n",
      "pre:left true:left 1427/11700\n",
      "tensor([ 0.1946, -0.1031])\n",
      "pre:left true:left 1428/11700\n",
      "tensor([ 1.1189, -1.1920])\n",
      "pre:left true:left 1429/11700\n",
      "tensor([ 0.8002, -0.7516])\n",
      "pre:left true:left 1430/11700\n",
      "tensor([ 0.3238, -0.2530])\n",
      "pre:left true:left 1431/11700\n",
      "tensor([ 0.0458, -0.0519])\n",
      "pre:left true:left 1432/11700\n",
      "tensor([ 0.6323, -0.5975])\n",
      "pre:left true:left 1433/11700\n",
      "tensor([ 1.2899, -1.2230])\n",
      "pre:left true:left 1434/11700\n",
      "tensor([ 1.0400, -1.0319])\n",
      "pre:left true:left 1435/11700\n",
      "tensor([ 0.2321, -0.2657])\n",
      "pre:left true:left 1436/11700\n",
      "tensor([0.0095, 0.0481])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左159_0_315_20200412_114222876_10.jpg\n",
      "pre:right true:left 1437/11700\n",
      "tensor([-0.4440,  0.4841])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左408_0_564_20200412_114747327_7.jpg\n",
      "pre:right true:left 1438/11700\n",
      "tensor([ 0.0287, -0.1146])\n",
      "pre:left true:left 1439/11700\n",
      "tensor([ 0.4735, -0.5033])\n",
      "pre:left true:left 1440/11700\n",
      "tensor([ 1.5628, -1.5907])\n",
      "pre:left true:left 1441/11700\n",
      "tensor([ 0.7669, -0.7489])\n",
      "pre:left true:left 1442/11700\n",
      "tensor([ 0.3626, -0.3741])\n",
      "pre:left true:left 1443/11700\n",
      "tensor([-0.1598,  0.1542])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左760_0_760_20200412_111452809.jpg\n",
      "pre:right true:left 1444/11700\n",
      "tensor([ 0.8436, -0.7911])\n",
      "pre:left true:left 1445/11700\n",
      "tensor([ 0.2192, -0.2195])\n",
      "pre:left true:left 1446/11700\n",
      "tensor([ 0.7173, -0.7269])\n",
      "pre:left true:left 1447/11700\n",
      "tensor([ 1.4878, -1.4899])\n",
      "pre:left true:left 1448/11700\n",
      "tensor([ 0.3874, -0.3436])\n",
      "pre:left true:left 1449/11700\n",
      "tensor([ 0.1590, -0.1643])\n",
      "pre:left true:left 1450/11700\n",
      "tensor([ 0.2271, -0.2867])\n",
      "pre:left true:left 1451/11700\n",
      "tensor([ 0.1955, -0.2086])\n",
      "pre:left true:left 1452/11700\n",
      "tensor([ 0.0335, -0.0066])\n",
      "pre:left true:left 1453/11700\n",
      "tensor([ 0.4174, -0.3960])\n",
      "pre:left true:left 1454/11700\n",
      "tensor([ 0.1980, -0.2423])\n",
      "pre:left true:left 1455/11700\n",
      "tensor([ 0.5496, -0.4425])\n",
      "pre:left true:left 1456/11700\n",
      "tensor([-0.1285,  0.2146])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左712_0_868_20200412_115423513_0.jpg\n",
      "pre:right true:left 1457/11700\n",
      "tensor([ 0.8090, -0.8009])\n",
      "pre:left true:left 1458/11700\n",
      "tensor([ 1.5168, -1.6158])\n",
      "pre:left true:left 1459/11700\n",
      "tensor([ 0.8267, -0.7729])\n",
      "pre:left true:left 1460/11700\n",
      "tensor([ 1.6758, -1.7483])\n",
      "pre:left true:left 1461/11700\n",
      "tensor([ 0.3292, -0.2291])\n",
      "pre:left true:left 1462/11700\n",
      "tensor([ 0.3063, -0.3267])\n",
      "pre:left true:left 1463/11700\n",
      "tensor([ 1.4527, -1.3941])\n",
      "pre:left true:left 1464/11700\n",
      "tensor([ 0.6619, -0.6056])\n",
      "pre:left true:left 1465/11700\n",
      "tensor([ 0.5055, -0.4198])\n",
      "pre:left true:left 1466/11700\n",
      "tensor([-0.3736,  0.4715])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左258_0_414_20200412_114431875_1.jpg\n",
      "pre:right true:left 1467/11700\n",
      "tensor([ 0.2787, -0.2938])\n",
      "pre:left true:left 1468/11700\n",
      "tensor([ 0.4654, -0.3663])\n",
      "pre:left true:left 1469/11700\n",
      "tensor([ 0.9639, -0.8816])\n",
      "pre:left true:left 1470/11700\n",
      "tensor([-0.2159,  0.2156])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左208_0_208_20200412_110145465_7.jpg\n",
      "pre:right true:left 1471/11700\n",
      "tensor([ 0.5579, -0.5135])\n",
      "pre:left true:left 1472/11700\n",
      "tensor([-0.6266,  0.6911])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左986_0_986_20200412_112006470_7.jpg\n",
      "pre:right true:left 1473/11700\n",
      "tensor([ 0.9029, -0.9379])\n",
      "pre:left true:left 1474/11700\n",
      "tensor([ 0.7002, -0.7772])\n",
      "pre:left true:left 1475/11700\n",
      "tensor([ 0.4373, -0.4550])\n",
      "pre:left true:left 1476/11700\n",
      "tensor([ 0.8250, -0.7967])\n",
      "pre:left true:left 1477/11700\n",
      "tensor([ 0.8731, -0.8733])\n",
      "pre:left true:left 1478/11700\n",
      "tensor([ 0.3091, -0.3527])\n",
      "pre:left true:left 1479/11700\n",
      "tensor([ 0.8877, -0.8570])\n",
      "pre:left true:left 1480/11700\n",
      "tensor([ 0.1932, -0.2033])\n",
      "pre:left true:left 1481/11700\n",
      "tensor([ 0.4071, -0.3525])\n",
      "pre:left true:left 1482/11700\n",
      "tensor([ 0.7622, -0.6406])\n",
      "pre:left true:left 1483/11700\n",
      "tensor([ 0.4332, -0.4363])\n",
      "pre:left true:left 1484/11700\n",
      "tensor([ 0.3561, -0.3974])\n",
      "pre:left true:left 1485/11700\n",
      "tensor([ 0.9505, -0.9067])\n",
      "pre:left true:left 1486/11700\n",
      "tensor([ 0.5346, -0.5437])\n",
      "pre:left true:left 1487/11700\n",
      "tensor([ 0.0645, -0.1395])\n",
      "pre:left true:left 1488/11700\n",
      "tensor([ 0.0301, -0.1203])\n",
      "pre:left true:left 1489/11700\n",
      "tensor([ 0.5224, -0.4636])\n",
      "pre:left true:left 1490/11700\n",
      "tensor([ 0.4604, -0.3756])\n",
      "pre:left true:left 1491/11700\n",
      "tensor([ 0.2803, -0.2523])\n",
      "pre:left true:left 1492/11700\n",
      "tensor([ 0.5426, -0.5528])\n",
      "pre:left true:left 1493/11700\n",
      "tensor([ 0.9001, -0.8040])\n",
      "pre:left true:left 1494/11700\n",
      "tensor([ 0.3608, -0.2756])\n",
      "pre:left true:left 1495/11700\n",
      "tensor([ 0.1777, -0.1983])\n",
      "pre:left true:left 1496/11700\n",
      "tensor([ 0.5179, -0.5478])\n",
      "pre:left true:left 1497/11700\n",
      "tensor([ 0.3940, -0.3479])\n",
      "pre:left true:left 1498/11700\n",
      "tensor([ 0.1868, -0.1561])\n",
      "pre:left true:left 1499/11700\n",
      "tensor([ 0.4429, -0.4919])\n",
      "pre:left true:left 1500/11700\n",
      "tensor([-0.5713,  0.5094])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1090_0_1090_20200412_112221981_9.jpg\n",
      "pre:right true:left 1501/11700\n",
      "tensor([ 0.1659, -0.1055])\n",
      "pre:left true:left 1502/11700\n",
      "tensor([-0.5384,  0.5669])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左223_0_223_20200412_110206863_7.jpg\n",
      "pre:right true:left 1503/11700\n",
      "tensor([0.0015, 0.0121])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1302_0_1458_20200412_120712431.jpg\n",
      "pre:right true:left 1504/11700\n",
      "tensor([-0.0581,  0.3184])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左316_0_316_20200412_105554268_1.jpg\n",
      "pre:right true:left 1505/11700\n",
      "tensor([ 0.4053, -0.4117])\n",
      "pre:left true:left 1506/11700\n",
      "tensor([ 0.3530, -0.2910])\n",
      "pre:left true:left 1507/11700\n",
      "tensor([ 1.2938, -1.3417])\n",
      "pre:left true:left 1508/11700\n",
      "tensor([ 1.0023, -0.9307])\n",
      "pre:left true:left 1509/11700\n",
      "tensor([-0.0513,  0.0746])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左535_0_535_20200412_110931848_4.jpg\n",
      "pre:right true:left 1510/11700\n",
      "tensor([ 0.3006, -0.3208])\n",
      "pre:left true:left 1511/11700\n",
      "tensor([ 0.7546, -0.7755])\n",
      "pre:left true:left 1512/11700\n",
      "tensor([ 1.3111, -1.3136])\n",
      "pre:left true:left 1513/11700\n",
      "tensor([ 0.4993, -0.5252])\n",
      "pre:left true:left 1514/11700\n",
      "tensor([ 1.3573, -1.3636])\n",
      "pre:left true:left 1515/11700\n",
      "tensor([ 0.7634, -0.8084])\n",
      "pre:left true:left 1516/11700\n",
      "tensor([ 0.6780, -0.7528])\n",
      "pre:left true:left 1517/11700\n",
      "tensor([ 0.8567, -0.9444])\n",
      "pre:left true:left 1518/11700\n",
      "tensor([ 0.4213, -0.3578])\n",
      "pre:left true:left 1519/11700\n",
      "tensor([ 0.6740, -0.6284])\n",
      "pre:left true:left 1520/11700\n",
      "tensor([ 0.5883, -0.5090])\n",
      "pre:left true:left 1521/11700\n",
      "tensor([ 0.1795, -0.1409])\n",
      "pre:left true:left 1522/11700\n",
      "tensor([ 0.7822, -0.8616])\n",
      "pre:left true:left 1523/11700\n",
      "tensor([-0.0205,  0.0435])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左665_0_665_20200412_111237299_2.jpg\n",
      "pre:right true:left 1524/11700\n",
      "tensor([0.0169, 0.0400])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左548_0_704_20200412_115049781_10.jpg\n",
      "pre:right true:left 1525/11700\n",
      "tensor([ 1.0955, -1.0501])\n",
      "pre:left true:left 1526/11700\n",
      "tensor([ 0.1453, -0.1517])\n",
      "pre:left true:left 1527/11700\n",
      "tensor([ 0.8260, -0.7875])\n",
      "pre:left true:left 1528/11700\n",
      "tensor([ 0.5293, -0.5579])\n",
      "pre:left true:left 1529/11700\n",
      "tensor([-0.0952,  0.0253])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左369_0_369_20200412_110535086.jpg\n",
      "pre:right true:left 1530/11700\n",
      "tensor([ 1.0876, -1.1314])\n",
      "pre:left true:left 1531/11700\n",
      "tensor([ 0.4857, -0.5241])\n",
      "pre:left true:left 1532/11700\n",
      "tensor([ 0.9597, -0.9138])\n",
      "pre:left true:left 1533/11700\n",
      "tensor([ 0.9430, -0.9729])\n",
      "pre:left true:left 1534/11700\n",
      "tensor([ 0.5293, -0.5664])\n",
      "pre:left true:left 1535/11700\n",
      "tensor([ 0.1781, -0.1448])\n",
      "pre:left true:left 1536/11700\n",
      "tensor([ 0.9307, -0.9767])\n",
      "pre:left true:left 1537/11700\n",
      "tensor([ 0.5443, -0.5647])\n",
      "pre:left true:left 1538/11700\n",
      "tensor([ 0.0580, -0.0749])\n",
      "pre:left true:left 1539/11700\n",
      "tensor([ 1.0782, -1.1309])\n",
      "pre:left true:left 1540/11700\n",
      "tensor([ 1.2565, -1.3021])\n",
      "pre:left true:left 1541/11700\n",
      "tensor([ 0.0927, -0.1649])\n",
      "pre:left true:left 1542/11700\n",
      "tensor([ 1.1953, -1.0836])\n",
      "pre:left true:left 1543/11700\n",
      "tensor([ 0.3799, -0.3975])\n",
      "pre:left true:left 1544/11700\n",
      "tensor([-0.1015,  0.1427])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左715_0_871_20200412_115427427_0.jpg\n",
      "pre:right true:left 1545/11700\n",
      "tensor([ 0.0730, -0.0543])\n",
      "pre:left true:left 1546/11700\n",
      "tensor([ 1.0569, -0.9395])\n",
      "pre:left true:left 1547/11700\n",
      "tensor([ 0.8258, -0.8218])\n",
      "pre:left true:left 1548/11700\n",
      "tensor([ 0.0642, -0.0771])\n",
      "pre:left true:left 1549/11700\n",
      "tensor([ 0.3722, -0.3601])\n",
      "pre:left true:left 1550/11700\n",
      "tensor([ 1.1553, -1.0909])\n",
      "pre:left true:left 1551/11700\n",
      "tensor([ 1.2613, -1.1995])\n",
      "pre:left true:left 1552/11700\n",
      "tensor([ 0.2107, -0.2368])\n",
      "pre:left true:left 1553/11700\n",
      "tensor([ 0.8857, -0.8467])\n",
      "pre:left true:left 1554/11700\n",
      "tensor([ 0.5756, -0.5139])\n",
      "pre:left true:left 1555/11700\n",
      "tensor([ 0.7758, -0.6637])\n",
      "pre:left true:left 1556/11700\n",
      "tensor([ 1.1118, -1.2210])\n",
      "pre:left true:left 1557/11700\n",
      "tensor([ 0.4738, -0.4877])\n",
      "pre:left true:left 1558/11700\n",
      "tensor([ 0.9041, -0.8516])\n",
      "pre:left true:left 1559/11700\n",
      "tensor([ 0.1761, -0.0591])\n",
      "pre:left true:left 1560/11700\n",
      "tensor([-0.5423,  0.5861])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左736_0_892_20200412_115454791_8.jpg\n",
      "pre:right true:left 1561/11700\n",
      "tensor([ 0.1526, -0.1758])\n",
      "pre:left true:left 1562/11700\n",
      "tensor([ 1.1920, -1.1906])\n",
      "pre:left true:left 1563/11700\n",
      "tensor([ 0.0785, -0.0494])\n",
      "pre:left true:left 1564/11700\n",
      "tensor([ 0.5865, -0.6422])\n",
      "pre:left true:left 1565/11700\n",
      "tensor([ 1.0616, -1.0466])\n",
      "pre:left true:left 1566/11700\n",
      "tensor([ 0.9643, -0.9983])\n",
      "pre:left true:left 1567/11700\n",
      "tensor([ 0.6803, -0.6132])\n",
      "pre:left true:left 1568/11700\n",
      "tensor([ 0.6262, -0.6463])\n",
      "pre:left true:left 1569/11700\n",
      "tensor([ 0.4745, -0.5200])\n",
      "pre:left true:left 1570/11700\n",
      "tensor([ 0.2954, -0.2391])\n",
      "pre:left true:left 1571/11700\n",
      "tensor([ 0.1683, -0.1560])\n",
      "pre:left true:left 1572/11700\n",
      "tensor([ 0.1226, -0.0481])\n",
      "pre:left true:left 1573/11700\n",
      "tensor([ 0.6983, -0.6311])\n",
      "pre:left true:left 1574/11700\n",
      "tensor([ 0.3899, -0.4036])\n",
      "pre:left true:left 1575/11700\n",
      "tensor([ 0.3786, -0.2753])\n",
      "pre:left true:left 1576/11700\n",
      "tensor([-0.1990,  0.1607])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左273_0_429_20200412_114451413_3.jpg\n",
      "pre:right true:left 1577/11700\n",
      "tensor([ 1.3981, -1.3140])\n",
      "pre:left true:left 1578/11700\n",
      "tensor([ 0.8429, -0.8727])\n",
      "pre:left true:left 1579/11700\n",
      "tensor([ 0.2870, -0.2593])\n",
      "pre:left true:left 1580/11700\n",
      "tensor([-0.2827,  0.3088])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左64_0_220_20200412_114019066_0.jpg\n",
      "pre:right true:left 1581/11700\n",
      "tensor([ 0.3224, -0.1447])\n",
      "pre:left true:left 1582/11700\n",
      "tensor([ 0.0246, -0.0800])\n",
      "pre:left true:left 1583/11700\n",
      "tensor([ 1.1822, -1.1279])\n",
      "pre:left true:left 1584/11700\n",
      "tensor([-0.1559,  0.2114])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1544_0_1700_20200412_121227841_7.jpg\n",
      "pre:right true:left 1585/11700\n",
      "tensor([ 0.9904, -0.9827])\n",
      "pre:left true:left 1586/11700\n",
      "tensor([-0.1542,  0.2212])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左131_0_131_20200412_105955655_10.jpg\n",
      "pre:right true:left 1587/11700\n",
      "tensor([ 0.6497, -0.6325])\n",
      "pre:left true:left 1588/11700\n",
      "tensor([-0.0483,  0.1219])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1326_0_1326_20200412_112739412_0.jpg\n",
      "pre:right true:left 1589/11700\n",
      "tensor([ 0.4784, -0.3960])\n",
      "pre:left true:left 1590/11700\n",
      "tensor([ 1.4036, -1.3675])\n",
      "pre:left true:left 1591/11700\n",
      "tensor([ 0.9040, -0.8290])\n",
      "pre:left true:left 1592/11700\n",
      "tensor([ 0.4974, -0.4156])\n",
      "pre:left true:left 1593/11700\n",
      "tensor([ 0.8199, -0.8804])\n",
      "pre:left true:left 1594/11700\n",
      "tensor([-0.1889,  0.1594])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左844_0_1000_20200412_115715544_0.jpg\n",
      "pre:right true:left 1595/11700\n",
      "tensor([ 1.1420, -1.2151])\n",
      "pre:left true:left 1596/11700\n",
      "tensor([ 0.2154, -0.1830])\n",
      "pre:left true:left 1597/11700\n",
      "tensor([ 0.5316, -0.4981])\n",
      "pre:left true:left 1598/11700\n",
      "tensor([ 0.0833, -0.0173])\n",
      "pre:left true:left 1599/11700\n",
      "tensor([ 1.1519, -1.0999])\n",
      "pre:left true:left 1600/11700\n",
      "tensor([ 1.2887, -1.3287])\n",
      "pre:left true:left 1601/11700\n",
      "tensor([ 0.1771, -0.1568])\n",
      "pre:left true:left 1602/11700\n",
      "tensor([ 0.5159, -0.5291])\n",
      "pre:left true:left 1603/11700\n",
      "tensor([ 0.5390, -0.5053])\n",
      "pre:left true:left 1604/11700\n",
      "tensor([-0.1482,  0.1343])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左672_0_672_20200412_111247280_9.jpg\n",
      "pre:right true:left 1605/11700\n",
      "tensor([ 0.3073, -0.2163])\n",
      "pre:left true:left 1606/11700\n",
      "tensor([ 0.1869, -0.2238])\n",
      "pre:left true:left 1607/11700\n",
      "tensor([ 0.3689, -0.3070])\n",
      "pre:left true:left 1608/11700\n",
      "tensor([ 0.8912, -0.8580])\n",
      "pre:left true:left 1609/11700\n",
      "tensor([ 0.1547, -0.1228])\n",
      "pre:left true:left 1610/11700\n",
      "tensor([ 0.5390, -0.4942])\n",
      "pre:left true:left 1611/11700\n",
      "tensor([ 0.9159, -0.7873])\n",
      "pre:left true:left 1612/11700\n",
      "tensor([ 0.7558, -0.7712])\n",
      "pre:left true:left 1613/11700\n",
      "tensor([-0.2035,  0.3723])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左592_0_592_20200412_111053164_5.jpg\n",
      "pre:right true:left 1614/11700\n",
      "tensor([ 0.2883, -0.2505])\n",
      "pre:left true:left 1615/11700\n",
      "tensor([ 0.5166, -0.4843])\n",
      "pre:left true:left 1616/11700\n",
      "tensor([ 0.4231, -0.4611])\n",
      "pre:left true:left 1617/11700\n",
      "tensor([ 0.4170, -0.4370])\n",
      "pre:left true:left 1618/11700\n",
      "tensor([-0.0627,  0.0395])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左792_0_948_20200412_115607770_4.jpg\n",
      "pre:right true:left 1619/11700\n",
      "tensor([ 1.0804, -1.0167])\n",
      "pre:left true:left 1620/11700\n",
      "tensor([ 0.4348, -0.3391])\n",
      "pre:left true:left 1621/11700\n",
      "tensor([ 0.4627, -0.5039])\n",
      "pre:left true:left 1622/11700\n",
      "tensor([ 0.7476, -0.7548])\n",
      "pre:left true:left 1623/11700\n",
      "tensor([ 1.0208, -0.8933])\n",
      "pre:left true:left 1624/11700\n",
      "tensor([ 0.8279, -0.7541])\n",
      "pre:left true:left 1625/11700\n",
      "tensor([ 0.4711, -0.4700])\n",
      "pre:left true:left 1626/11700\n",
      "tensor([ 1.5386, -1.3762])\n",
      "pre:left true:left 1627/11700\n",
      "tensor([ 0.2879, -0.4099])\n",
      "pre:left true:left 1628/11700\n",
      "tensor([-0.0902,  0.0356])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左592_0_592_20200412_111053164_7.jpg\n",
      "pre:right true:left 1629/11700\n",
      "tensor([ 0.0785, -0.0498])\n",
      "pre:left true:left 1630/11700\n",
      "tensor([ 0.0776, -0.1962])\n",
      "pre:left true:left 1631/11700\n",
      "tensor([ 0.4750, -0.4952])\n",
      "pre:left true:left 1632/11700\n",
      "tensor([ 0.7863, -0.7532])\n",
      "pre:left true:left 1633/11700\n",
      "tensor([ 0.5845, -0.6227])\n",
      "pre:left true:left 1634/11700\n",
      "tensor([ 0.3899, -0.4103])\n",
      "pre:left true:left 1635/11700\n",
      "tensor([ 0.5452, -0.5605])\n",
      "pre:left true:left 1636/11700\n",
      "tensor([ 0.7465, -0.7045])\n",
      "pre:left true:left 1637/11700\n",
      "tensor([ 0.1557, -0.1258])\n",
      "pre:left true:left 1638/11700\n",
      "tensor([ 0.7746, -0.7663])\n",
      "pre:left true:left 1639/11700\n",
      "tensor([ 1.1062, -1.0147])\n",
      "pre:left true:left 1640/11700\n",
      "tensor([ 0.5957, -0.5884])\n",
      "pre:left true:left 1641/11700\n",
      "tensor([ 0.3439, -0.3446])\n",
      "pre:left true:left 1642/11700\n",
      "tensor([-0.4082,  0.3295])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1574_0_1730_20200412_121306937_4.jpg\n",
      "pre:right true:left 1643/11700\n",
      "tensor([ 0.6519, -0.6386])\n",
      "pre:left true:left 1644/11700\n",
      "tensor([ 0.3044, -0.4025])\n",
      "pre:left true:left 1645/11700\n",
      "tensor([ 1.8208, -1.9003])\n",
      "pre:left true:left 1646/11700\n",
      "tensor([ 0.4568, -0.4986])\n",
      "pre:left true:left 1647/11700\n",
      "tensor([ 0.9854, -0.9622])\n",
      "pre:left true:left 1648/11700\n",
      "tensor([ 0.5323, -0.6406])\n",
      "pre:left true:left 1649/11700\n",
      "tensor([ 1.4897, -1.4427])\n",
      "pre:left true:left 1650/11700\n",
      "tensor([ 1.6014, -1.6732])\n",
      "pre:left true:left 1651/11700\n",
      "tensor([ 0.5329, -0.4810])\n",
      "pre:left true:left 1652/11700\n",
      "tensor([-0.1775,  0.1380])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左315_0_471_20200412_114546140_5.jpg\n",
      "pre:right true:left 1653/11700\n",
      "tensor([ 0.7381, -0.7691])\n",
      "pre:left true:left 1654/11700\n",
      "tensor([ 0.8679, -0.7059])\n",
      "pre:left true:left 1655/11700\n",
      "tensor([ 1.2195, -1.1739])\n",
      "pre:left true:left 1656/11700\n",
      "tensor([ 1.0291, -0.9963])\n",
      "pre:left true:left 1657/11700\n",
      "tensor([ 0.4952, -0.5359])\n",
      "pre:left true:left 1658/11700\n",
      "tensor([ 0.2004, -0.1135])\n",
      "pre:left true:left 1659/11700\n",
      "tensor([ 0.2812, -0.2390])\n",
      "pre:left true:left 1660/11700\n",
      "tensor([ 0.8726, -0.7946])\n",
      "pre:left true:left 1661/11700\n",
      "tensor([ 0.4497, -0.4464])\n",
      "pre:left true:left 1662/11700\n",
      "tensor([ 1.4486, -1.4104])\n",
      "pre:left true:left 1663/11700\n",
      "tensor([ 0.3742, -0.2042])\n",
      "pre:left true:left 1664/11700\n",
      "tensor([ 0.4174, -0.4753])\n",
      "pre:left true:left 1665/11700\n",
      "tensor([ 0.2613, -0.2380])\n",
      "pre:left true:left 1666/11700\n",
      "tensor([ 0.4733, -0.4394])\n",
      "pre:left true:left 1667/11700\n",
      "tensor([ 0.7362, -0.7849])\n",
      "pre:left true:left 1668/11700\n",
      "tensor([ 0.5531, -0.5619])\n",
      "pre:left true:left 1669/11700\n",
      "tensor([ 0.3671, -0.2904])\n",
      "pre:left true:left 1670/11700\n",
      "tensor([ 0.6741, -0.6242])\n",
      "pre:left true:left 1671/11700\n",
      "tensor([ 0.2084, -0.1355])\n",
      "pre:left true:left 1672/11700\n",
      "tensor([ 0.6780, -0.7059])\n",
      "pre:left true:left 1673/11700\n",
      "tensor([ 0.9495, -0.9782])\n",
      "pre:left true:left 1674/11700\n",
      "tensor([ 0.4877, -0.4640])\n",
      "pre:left true:left 1675/11700\n",
      "tensor([ 0.5408, -0.5173])\n",
      "pre:left true:left 1676/11700\n",
      "tensor([ 1.1870, -1.2565])\n",
      "pre:left true:left 1677/11700\n",
      "tensor([ 0.7899, -0.7996])\n",
      "pre:left true:left 1678/11700\n",
      "tensor([ 0.6649, -0.4962])\n",
      "pre:left true:left 1679/11700\n",
      "tensor([ 0.7006, -0.5540])\n",
      "pre:left true:left 1680/11700\n",
      "tensor([-0.0953,  0.1699])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左967_0_967_20200412_111941711_4.jpg\n",
      "pre:right true:left 1681/11700\n",
      "tensor([-0.2383,  0.2393])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1061_0_1061_20200412_112144181_6.jpg\n",
      "pre:right true:left 1682/11700\n",
      "tensor([ 0.3700, -0.3555])\n",
      "pre:left true:left 1683/11700\n",
      "tensor([-0.4465,  0.5246])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1297_0_1453_20200412_120705914_5.jpg\n",
      "pre:right true:left 1684/11700\n",
      "tensor([-0.5085,  0.5048])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1320_0_1320_20200412_112731601_10.jpg\n",
      "pre:right true:left 1685/11700\n",
      "tensor([ 0.6046, -0.5083])\n",
      "pre:left true:left 1686/11700\n",
      "tensor([-0.4368,  0.5111])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左985_0_985_20200412_112005188.jpg\n",
      "pre:right true:left 1687/11700\n",
      "tensor([ 0.5509, -0.5001])\n",
      "pre:left true:left 1688/11700\n",
      "tensor([ 1.0834, -0.9722])\n",
      "pre:left true:left 1689/11700\n",
      "tensor([ 1.4895, -1.4724])\n",
      "pre:left true:left 1690/11700\n",
      "tensor([-0.0585,  0.0617])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左706_0_706_20200412_111335772_8.jpg\n",
      "pre:right true:left 1691/11700\n",
      "tensor([ 0.9260, -0.9077])\n",
      "pre:left true:left 1692/11700\n",
      "tensor([ 0.6245, -0.4651])\n",
      "pre:left true:left 1693/11700\n",
      "tensor([ 0.6138, -0.7107])\n",
      "pre:left true:left 1694/11700\n",
      "tensor([ 0.2814, -0.2040])\n",
      "pre:left true:left 1695/11700\n",
      "tensor([ 0.3743, -0.3665])\n",
      "pre:left true:left 1696/11700\n",
      "tensor([ 0.3340, -0.3414])\n",
      "pre:left true:left 1697/11700\n",
      "tensor([-0.2260,  0.1905])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左307_0_307_20200412_110406653_2.jpg\n",
      "pre:right true:left 1698/11700\n",
      "tensor([ 1.2193, -1.1388])\n",
      "pre:left true:left 1699/11700\n",
      "tensor([ 0.2504, -0.1608])\n",
      "pre:left true:left 1700/11700\n",
      "tensor([ 0.1680, -0.1714])\n",
      "pre:left true:left 1701/11700\n",
      "tensor([ 1.0231, -0.8971])\n",
      "pre:left true:left 1702/11700\n",
      "tensor([ 0.2582, -0.2077])\n",
      "pre:left true:left 1703/11700\n",
      "tensor([ 1.0961, -1.2188])\n",
      "pre:left true:left 1704/11700\n",
      "tensor([ 1.1531, -1.1538])\n",
      "pre:left true:left 1705/11700\n",
      "tensor([ 0.8103, -0.6916])\n",
      "pre:left true:left 1706/11700\n",
      "tensor([ 0.1009, -0.0547])\n",
      "pre:left true:left 1707/11700\n",
      "tensor([0.0084, 0.0278])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/右325_0_325_20200412_110432351_9.jpg\n",
      "pre:right true:left 1708/11700\n",
      "tensor([ 0.2518, -0.3719])\n",
      "pre:left true:left 1709/11700\n",
      "tensor([ 0.8916, -0.8428])\n",
      "pre:left true:left 1710/11700\n",
      "tensor([ 1.4390, -1.3801])\n",
      "pre:left true:left 1711/11700\n",
      "tensor([ 0.5686, -0.5786])\n",
      "pre:left true:left 1712/11700\n",
      "tensor([ 1.0689, -0.9564])\n",
      "pre:left true:left 1713/11700\n",
      "tensor([ 1.3190, -1.3287])\n",
      "pre:left true:left 1714/11700\n",
      "tensor([ 1.0863, -1.1810])\n",
      "pre:left true:left 1715/11700\n",
      "tensor([ 0.8403, -0.8295])\n",
      "pre:left true:left 1716/11700\n",
      "tensor([ 0.3290, -0.2260])\n",
      "pre:left true:left 1717/11700\n",
      "tensor([ 0.6583, -0.6120])\n",
      "pre:left true:left 1718/11700\n",
      "tensor([ 0.9713, -1.0132])\n",
      "pre:left true:left 1719/11700\n",
      "tensor([ 0.4260, -0.4256])\n",
      "pre:left true:left 1720/11700\n",
      "tensor([ 0.9070, -0.8833])\n",
      "pre:left true:left 1721/11700\n",
      "tensor([ 0.2959, -0.2244])\n",
      "pre:left true:left 1722/11700\n",
      "tensor([ 0.8263, -0.9076])\n",
      "pre:left true:left 1723/11700\n",
      "tensor([-0.2278,  0.2767])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1409_0_1565_20200412_120931892_9.jpg\n",
      "pre:right true:left 1724/11700\n",
      "tensor([ 0.4442, -0.5238])\n",
      "pre:left true:left 1725/11700\n",
      "tensor([ 0.9447, -0.8680])\n",
      "pre:left true:left 1726/11700\n",
      "tensor([ 0.2721, -0.2293])\n",
      "pre:left true:left 1727/11700\n",
      "tensor([-0.3845,  0.3167])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左413_0_569_20200412_114753840_5.jpg\n",
      "pre:right true:left 1728/11700\n",
      "tensor([-0.0287,  0.1277])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左716_0_716_20200412_111350037_8.jpg\n",
      "pre:right true:left 1729/11700\n",
      "tensor([ 0.4222, -0.4132])\n",
      "pre:left true:left 1730/11700\n",
      "tensor([ 0.1357, -0.0846])\n",
      "pre:left true:left 1731/11700\n",
      "tensor([ 1.0591, -1.0347])\n",
      "pre:left true:left 1732/11700\n",
      "tensor([ 0.4593, -0.5294])\n",
      "pre:left true:left 1733/11700\n",
      "tensor([ 0.0498, -0.0247])\n",
      "pre:left true:left 1734/11700\n",
      "tensor([ 0.5752, -0.6178])\n",
      "pre:left true:left 1735/11700\n",
      "tensor([ 1.0353, -1.0556])\n",
      "pre:left true:left 1736/11700\n",
      "tensor([ 0.3519, -0.3208])\n",
      "pre:left true:left 1737/11700\n",
      "tensor([ 0.0819, -0.1131])\n",
      "pre:left true:left 1738/11700\n",
      "tensor([ 1.1172, -1.0922])\n",
      "pre:left true:left 1739/11700\n",
      "tensor([ 0.9049, -0.8151])\n",
      "pre:left true:left 1740/11700\n",
      "tensor([ 0.8057, -0.7540])\n",
      "pre:left true:left 1741/11700\n",
      "tensor([ 0.5021, -0.5166])\n",
      "pre:left true:left 1742/11700\n",
      "tensor([ 0.9653, -0.9669])\n",
      "pre:left true:left 1743/11700\n",
      "tensor([ 0.9319, -0.8948])\n",
      "pre:left true:left 1744/11700\n",
      "tensor([ 0.3382, -0.3233])\n",
      "pre:left true:left 1745/11700\n",
      "tensor([ 0.5606, -0.6711])\n",
      "pre:left true:left 1746/11700\n",
      "tensor([ 0.8711, -0.8981])\n",
      "pre:left true:left 1747/11700\n",
      "tensor([ 0.6530, -0.5610])\n",
      "pre:left true:left 1748/11700\n",
      "tensor([ 0.3143, -0.3263])\n",
      "pre:left true:left 1749/11700\n",
      "tensor([ 0.0961, -0.0906])\n",
      "pre:left true:left 1750/11700\n",
      "tensor([ 0.5861, -0.6829])\n",
      "pre:left true:left 1751/11700\n",
      "tensor([ 0.3119, -0.2464])\n",
      "pre:left true:left 1752/11700\n",
      "tensor([ 1.2142, -1.1729])\n",
      "pre:left true:left 1753/11700\n",
      "tensor([ 0.3109, -0.2625])\n",
      "pre:left true:left 1754/11700\n",
      "tensor([ 1.0146, -1.0562])\n",
      "pre:left true:left 1755/11700\n",
      "tensor([-0.3633,  0.4007])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1174_0_1174_20200412_112411433.jpg\n",
      "pre:right true:left 1756/11700\n",
      "tensor([ 0.5494, -0.5578])\n",
      "pre:left true:left 1757/11700\n",
      "tensor([ 0.8156, -0.8004])\n",
      "pre:left true:left 1758/11700\n",
      "tensor([ 0.2097, -0.1147])\n",
      "pre:left true:left 1759/11700\n",
      "tensor([ 0.8402, -0.8754])\n",
      "pre:left true:left 1760/11700\n",
      "tensor([ 0.6224, -0.5459])\n",
      "pre:left true:left 1761/11700\n",
      "tensor([-0.2025,  0.2619])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左881_0_881_20200412_111745390.jpg\n",
      "pre:right true:left 1762/11700\n",
      "tensor([ 0.4689, -0.4938])\n",
      "pre:left true:left 1763/11700\n",
      "tensor([ 0.7005, -0.6845])\n",
      "pre:left true:left 1764/11700\n",
      "tensor([ 0.6055, -0.6184])\n",
      "pre:left true:left 1765/11700\n",
      "tensor([ 0.6146, -0.6188])\n",
      "pre:left true:left 1766/11700\n",
      "tensor([ 0.3339, -0.4099])\n",
      "pre:left true:left 1767/11700\n",
      "tensor([ 0.1432, -0.0752])\n",
      "pre:left true:left 1768/11700\n",
      "tensor([ 0.4744, -0.5149])\n",
      "pre:left true:left 1769/11700\n",
      "tensor([ 0.4802, -0.4930])\n",
      "pre:left true:left 1770/11700\n",
      "tensor([ 0.4607, -0.4943])\n",
      "pre:left true:left 1771/11700\n",
      "tensor([ 0.7940, -0.8556])\n",
      "pre:left true:left 1772/11700\n",
      "tensor([ 0.1394, -0.0807])\n",
      "pre:left true:left 1773/11700\n",
      "tensor([-0.4557,  0.5373])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左441_0_597_20200412_114830349_0.jpg\n",
      "pre:right true:left 1774/11700\n",
      "tensor([-0.2978,  0.3200])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左687_0_843_20200412_115350916_8.jpg\n",
      "pre:right true:left 1775/11700\n",
      "tensor([ 0.4819, -0.4671])\n",
      "pre:left true:left 1776/11700\n",
      "tensor([ 0.5428, -0.4201])\n",
      "pre:left true:left 1777/11700\n",
      "tensor([ 0.5243, -0.4646])\n",
      "pre:left true:left 1778/11700\n",
      "tensor([-0.2450,  0.2811])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左500_0_500_20200412_110841943_0.jpg\n",
      "pre:right true:left 1779/11700\n",
      "tensor([ 0.9144, -0.9335])\n",
      "pre:left true:left 1780/11700\n",
      "tensor([ 0.9338, -0.9254])\n",
      "pre:left true:left 1781/11700\n",
      "tensor([ 0.1020, -0.0606])\n",
      "pre:left true:left 1782/11700\n",
      "tensor([ 0.6238, -0.6325])\n",
      "pre:left true:left 1783/11700\n",
      "tensor([ 0.7078, -0.7063])\n",
      "pre:left true:left 1784/11700\n",
      "tensor([ 0.1490, -0.1363])\n",
      "pre:left true:left 1785/11700\n",
      "tensor([ 0.4737, -0.5027])\n",
      "pre:left true:left 1786/11700\n",
      "tensor([ 0.9300, -0.9400])\n",
      "pre:left true:left 1787/11700\n",
      "tensor([ 0.2954, -0.3112])\n",
      "pre:left true:left 1788/11700\n",
      "tensor([ 0.3353, -0.2080])\n",
      "pre:left true:left 1789/11700\n",
      "tensor([ 0.0862, -0.1843])\n",
      "pre:left true:left 1790/11700\n",
      "tensor([ 1.0297, -1.1014])\n",
      "pre:left true:left 1791/11700\n",
      "tensor([ 1.1961, -1.2090])\n",
      "pre:left true:left 1792/11700\n",
      "tensor([ 0.6246, -0.6574])\n",
      "pre:left true:left 1793/11700\n",
      "tensor([ 0.4198, -0.4298])\n",
      "pre:left true:left 1794/11700\n",
      "tensor([ 1.0373, -0.9521])\n",
      "pre:left true:left 1795/11700\n",
      "tensor([ 1.2419, -1.2321])\n",
      "pre:left true:left 1796/11700\n",
      "tensor([ 0.2165, -0.2113])\n",
      "pre:left true:left 1797/11700\n",
      "tensor([ 0.5929, -0.5409])\n",
      "pre:left true:left 1798/11700\n",
      "tensor([ 0.3502, -0.3623])\n",
      "pre:left true:left 1799/11700\n",
      "tensor([ 0.1783, -0.3010])\n",
      "pre:left true:left 1800/11700\n",
      "tensor([ 0.2518, -0.2734])\n",
      "pre:left true:left 1801/11700\n",
      "tensor([-0.1392,  0.1848])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左489_0_489_20200412_110826252_3.jpg\n",
      "pre:right true:left 1802/11700\n",
      "tensor([ 1.2202, -1.0889])\n",
      "pre:left true:left 1803/11700\n",
      "tensor([-0.3271,  0.2776])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1522_0_1678_20200412_121159184_4.jpg\n",
      "pre:right true:left 1804/11700\n",
      "tensor([ 0.3324, -0.3119])\n",
      "pre:left true:left 1805/11700\n",
      "tensor([ 1.1450, -1.0939])\n",
      "pre:left true:left 1806/11700\n",
      "tensor([ 0.2946, -0.2700])\n",
      "pre:left true:left 1807/11700\n",
      "tensor([ 1.4138, -1.4315])\n",
      "pre:left true:left 1808/11700\n",
      "tensor([ 0.6413, -0.6431])\n",
      "pre:left true:left 1809/11700\n",
      "tensor([ 0.2092, -0.1171])\n",
      "pre:left true:left 1810/11700\n",
      "tensor([-0.4457,  0.6058])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左607_0_763_20200412_115206661_9.jpg\n",
      "pre:right true:left 1811/11700\n",
      "tensor([-0.1246,  0.1407])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左625_0_781_20200412_115230120_6.jpg\n",
      "pre:right true:left 1812/11700\n",
      "tensor([ 0.4417, -0.4329])\n",
      "pre:left true:left 1813/11700\n",
      "tensor([-0.5648,  0.6070])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左828_0_984_20200412_115654687_4.jpg\n",
      "pre:right true:left 1814/11700\n",
      "tensor([ 1.3948, -1.3472])\n",
      "pre:left true:left 1815/11700\n",
      "tensor([ 1.6441, -1.4790])\n",
      "pre:left true:left 1816/11700\n",
      "tensor([ 0.8262, -0.8986])\n",
      "pre:left true:left 1817/11700\n",
      "tensor([ 0.7566, -0.7648])\n",
      "pre:left true:left 1818/11700\n",
      "tensor([ 0.6262, -0.5699])\n",
      "pre:left true:left 1819/11700\n",
      "tensor([ 0.9911, -1.0181])\n",
      "pre:left true:left 1820/11700\n",
      "tensor([-0.4267,  0.4212])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左881_0_1037_20200412_115803770_3.jpg\n",
      "pre:right true:left 1821/11700\n",
      "tensor([0.0127, 0.0298])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左615_0_615_20200412_111125989_0.jpg\n",
      "pre:right true:left 1822/11700\n",
      "tensor([ 0.6068, -0.5960])\n",
      "pre:left true:left 1823/11700\n",
      "tensor([ 1.0074, -1.0070])\n",
      "pre:left true:left 1824/11700\n",
      "tensor([ 0.7684, -0.8239])\n",
      "pre:left true:left 1825/11700\n",
      "tensor([0.0486, 0.0614])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1507_0_1663_20200412_121139621_3.jpg\n",
      "pre:right true:left 1826/11700\n",
      "tensor([ 0.2148, -0.1666])\n",
      "pre:left true:left 1827/11700\n",
      "tensor([ 0.7560, -0.6687])\n",
      "pre:left true:left 1828/11700\n",
      "tensor([ 0.1692, -0.2795])\n",
      "pre:left true:left 1829/11700\n",
      "tensor([ 0.4667, -0.4528])\n",
      "pre:left true:left 1830/11700\n",
      "tensor([ 0.5667, -0.5929])\n",
      "pre:left true:left 1831/11700\n",
      "tensor([ 0.4675, -0.4026])\n",
      "pre:left true:left 1832/11700\n",
      "tensor([ 1.0458, -0.9967])\n",
      "pre:left true:left 1833/11700\n",
      "tensor([ 0.1211, -0.0901])\n",
      "pre:left true:left 1834/11700\n",
      "tensor([ 0.8658, -0.7754])\n",
      "pre:left true:left 1835/11700\n",
      "tensor([ 0.7126, -0.6758])\n",
      "pre:left true:left 1836/11700\n",
      "tensor([ 0.1780, -0.1381])\n",
      "pre:left true:left 1837/11700\n",
      "tensor([ 0.2774, -0.2822])\n",
      "pre:left true:left 1838/11700\n",
      "tensor([ 0.4959, -0.4655])\n",
      "pre:left true:left 1839/11700\n",
      "tensor([ 0.3424, -0.2807])\n",
      "pre:left true:left 1840/11700\n",
      "tensor([-0.9799,  1.0071])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左834_0_990_20200412_115702525_9.jpg\n",
      "pre:right true:left 1841/11700\n",
      "tensor([-0.3455,  0.3322])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左766_0_922_20200412_115533899_3.jpg\n",
      "pre:right true:left 1842/11700\n",
      "tensor([ 1.1425, -1.0254])\n",
      "pre:left true:left 1843/11700\n",
      "tensor([-0.1041,  0.1432])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1210_0_1366_20200412_120512529_2.jpg\n",
      "pre:right true:left 1844/11700\n",
      "tensor([ 1.0658, -1.1631])\n",
      "pre:left true:left 1845/11700\n",
      "tensor([ 0.5869, -0.5801])\n",
      "pre:left true:left 1846/11700\n",
      "tensor([ 1.1144, -1.2024])\n",
      "pre:left true:left 1847/11700\n",
      "tensor([ 0.5861, -0.6829])\n",
      "pre:left true:left 1848/11700\n",
      "tensor([ 0.6994, -0.7489])\n",
      "pre:left true:left 1849/11700\n",
      "tensor([ 0.4883, -0.3443])\n",
      "pre:left true:left 1850/11700\n",
      "tensor([0.0093, 0.0660])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左661_0_661_20200412_111231607_10.jpg\n",
      "pre:right true:left 1851/11700\n",
      "tensor([ 0.9749, -0.9645])\n",
      "pre:left true:left 1852/11700\n",
      "tensor([ 0.7569, -0.7670])\n",
      "pre:left true:left 1853/11700\n",
      "tensor([ 0.9718, -0.9678])\n",
      "pre:left true:left 1854/11700\n",
      "tensor([ 0.8031, -0.7501])\n",
      "pre:left true:left 1855/11700\n",
      "tensor([ 0.9477, -0.8678])\n",
      "pre:left true:left 1856/11700\n",
      "tensor([ 0.2203, -0.2265])\n",
      "pre:left true:left 1857/11700\n",
      "tensor([ 1.5164, -1.4987])\n",
      "pre:left true:left 1858/11700\n",
      "tensor([ 0.7651, -0.7437])\n",
      "pre:left true:left 1859/11700\n",
      "tensor([ 1.0694, -0.9590])\n",
      "pre:left true:left 1860/11700\n",
      "tensor([ 0.4516, -0.4466])\n",
      "pre:left true:left 1861/11700\n",
      "tensor([ 0.0930, -0.0959])\n",
      "pre:left true:left 1862/11700\n",
      "tensor([-0.7597,  0.7702])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左331_0_331_20200412_105612246_4.jpg\n",
      "pre:right true:left 1863/11700\n",
      "tensor([ 0.2214, -0.1670])\n",
      "pre:left true:left 1864/11700\n",
      "tensor([ 0.3438, -0.2717])\n",
      "pre:left true:left 1865/11700\n",
      "tensor([ 0.2152, -0.1504])\n",
      "pre:left true:left 1866/11700\n",
      "tensor([-1.0449,  1.1604])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左596_0_752_20200412_115152325_6.jpg\n",
      "pre:right true:left 1867/11700\n",
      "tensor([ 0.2134, -0.2914])\n",
      "pre:left true:left 1868/11700\n",
      "tensor([ 0.5778, -0.5548])\n",
      "pre:left true:left 1869/11700\n",
      "tensor([ 0.2269, -0.2040])\n",
      "pre:left true:left 1870/11700\n",
      "tensor([ 0.1156, -0.0944])\n",
      "pre:left true:left 1871/11700\n",
      "tensor([ 0.9854, -0.9294])\n",
      "pre:left true:left 1872/11700\n",
      "tensor([ 0.5391, -0.5033])\n",
      "pre:left true:left 1873/11700\n",
      "tensor([ 0.1026, -0.1484])\n",
      "pre:left true:left 1874/11700\n",
      "tensor([ 1.4414, -1.4891])\n",
      "pre:left true:left 1875/11700\n",
      "tensor([ 0.2756, -0.2470])\n",
      "pre:left true:left 1876/11700\n",
      "tensor([ 0.3646, -0.3294])\n",
      "pre:left true:left 1877/11700\n",
      "tensor([ 0.6223, -0.7481])\n",
      "pre:left true:left 1878/11700\n",
      "tensor([-1.1130,  1.3119])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左891_0_891_20200412_111759650_6.jpg\n",
      "pre:right true:left 1879/11700\n",
      "tensor([ 0.1689, -0.1126])\n",
      "pre:left true:left 1880/11700\n",
      "tensor([ 0.9055, -0.8303])\n",
      "pre:left true:left 1881/11700\n",
      "tensor([ 0.2214, -0.3813])\n",
      "pre:left true:left 1882/11700\n",
      "tensor([ 2.1350, -2.1015])\n",
      "pre:left true:left 1883/11700\n",
      "tensor([ 0.5550, -0.5302])\n",
      "pre:left true:left 1884/11700\n",
      "tensor([-0.3436,  0.3520])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左272_0_428_20200412_114450114_10.jpg\n",
      "pre:right true:left 1885/11700\n",
      "tensor([ 0.9470, -0.9200])\n",
      "pre:left true:left 1886/11700\n",
      "tensor([ 0.8596, -0.8593])\n",
      "pre:left true:left 1887/11700\n",
      "tensor([ 0.1944, -0.1321])\n",
      "pre:left true:left 1888/11700\n",
      "tensor([ 0.2621, -0.2684])\n",
      "pre:left true:left 1889/11700\n",
      "tensor([ 0.3616, -0.3290])\n",
      "pre:left true:left 1890/11700\n",
      "tensor([ 0.9183, -0.8732])\n",
      "pre:left true:left 1891/11700\n",
      "tensor([ 0.6594, -0.6847])\n",
      "pre:left true:left 1892/11700\n",
      "tensor([-0.2451,  0.2154])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左421_0_577_20200412_114804268_0.jpg\n",
      "pre:right true:left 1893/11700\n",
      "tensor([ 0.0134, -0.1695])\n",
      "pre:left true:left 1894/11700\n",
      "tensor([ 0.7421, -0.7563])\n",
      "pre:left true:left 1895/11700\n",
      "tensor([ 0.5007, -0.4944])\n",
      "pre:left true:left 1896/11700\n",
      "tensor([ 0.8505, -0.8165])\n",
      "pre:left true:left 1897/11700\n",
      "tensor([ 0.3079, -0.2788])\n",
      "pre:left true:left 1898/11700\n",
      "tensor([ 0.7897, -0.7611])\n",
      "pre:left true:left 1899/11700\n",
      "tensor([ 0.1427, -0.0934])\n",
      "pre:left true:left 1900/11700\n",
      "tensor([ 0.7081, -0.7584])\n",
      "pre:left true:left 1901/11700\n",
      "tensor([ 0.6262, -0.5699])\n",
      "pre:left true:left 1902/11700\n",
      "tensor([ 0.7583, -0.8257])\n",
      "pre:left true:left 1903/11700\n",
      "tensor([ 0.8548, -0.9403])\n",
      "pre:left true:left 1904/11700\n",
      "tensor([ 0.5214, -0.4755])\n",
      "pre:left true:left 1905/11700\n",
      "tensor([ 0.2484, -0.1225])\n",
      "pre:left true:left 1906/11700\n",
      "tensor([ 0.5033, -0.4203])\n",
      "pre:left true:left 1907/11700\n",
      "tensor([ 0.7443, -0.7256])\n",
      "pre:left true:left 1908/11700\n",
      "tensor([ 0.3513, -0.3058])\n",
      "pre:left true:left 1909/11700\n",
      "tensor([ 0.8351, -0.8607])\n",
      "pre:left true:left 1910/11700\n",
      "tensor([ 0.8442, -0.8394])\n",
      "pre:left true:left 1911/11700\n",
      "tensor([ 0.9755, -1.0192])\n",
      "pre:left true:left 1912/11700\n",
      "tensor([-0.5529,  0.6490])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左544_0_544_20200412_110944711_3.jpg\n",
      "pre:right true:left 1913/11700\n",
      "tensor([ 0.9463, -0.9243])\n",
      "pre:left true:left 1914/11700\n",
      "tensor([ 0.6468, -0.6470])\n",
      "pre:left true:left 1915/11700\n",
      "tensor([ 0.2801, -0.1986])\n",
      "pre:left true:left 1916/11700\n",
      "tensor([ 0.0977, -0.0373])\n",
      "pre:left true:left 1917/11700\n",
      "tensor([ 0.0335, -0.0145])\n",
      "pre:left true:left 1918/11700\n",
      "tensor([ 0.4517, -0.3967])\n",
      "pre:left true:left 1919/11700\n",
      "tensor([ 0.8273, -0.6802])\n",
      "pre:left true:left 1920/11700\n",
      "tensor([ 0.5000, -0.5246])\n",
      "pre:left true:left 1921/11700\n",
      "tensor([ 0.5797, -0.3773])\n",
      "pre:left true:left 1922/11700\n",
      "tensor([ 0.2659, -0.1694])\n",
      "pre:left true:left 1923/11700\n",
      "tensor([-0.2911,  0.2632])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左514_0_514_20200412_110901907_8.jpg\n",
      "pre:right true:left 1924/11700\n",
      "tensor([ 0.6529, -0.6052])\n",
      "pre:left true:left 1925/11700\n",
      "tensor([ 0.5278, -0.6206])\n",
      "pre:left true:left 1926/11700\n",
      "tensor([ 0.7443, -0.7401])\n",
      "pre:left true:left 1927/11700\n",
      "tensor([ 1.1148, -1.1655])\n",
      "pre:left true:left 1928/11700\n",
      "tensor([ 0.7059, -0.6297])\n",
      "pre:left true:left 1929/11700\n",
      "tensor([ 0.9971, -0.9637])\n",
      "pre:left true:left 1930/11700\n",
      "tensor([ 1.0802, -1.0591])\n",
      "pre:left true:left 1931/11700\n",
      "tensor([ 0.6809, -0.5158])\n",
      "pre:left true:left 1932/11700\n",
      "tensor([ 0.0976, -0.0596])\n",
      "pre:left true:left 1933/11700\n",
      "tensor([ 0.9857, -0.9853])\n",
      "pre:left true:left 1934/11700\n",
      "tensor([ 1.2696, -1.2255])\n",
      "pre:left true:left 1935/11700\n",
      "tensor([ 1.1004, -1.1492])\n",
      "pre:left true:left 1936/11700\n",
      "tensor([ 0.3596, -0.3694])\n",
      "pre:left true:left 1937/11700\n",
      "tensor([ 0.3514, -0.3582])\n",
      "pre:left true:left 1938/11700\n",
      "tensor([ 0.8090, -0.8103])\n",
      "pre:left true:left 1939/11700\n",
      "tensor([ 0.5255, -0.5711])\n",
      "pre:left true:left 1940/11700\n",
      "tensor([ 0.8965, -0.8795])\n",
      "pre:left true:left 1941/11700\n",
      "tensor([ 0.2064, -0.1472])\n",
      "pre:left true:left 1942/11700\n",
      "tensor([ 1.6528, -1.5533])\n",
      "pre:left true:left 1943/11700\n",
      "tensor([ 0.7101, -0.7933])\n",
      "pre:left true:left 1944/11700\n",
      "tensor([-0.0585, -0.0090])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左487_0_643_20200412_114930272_7.jpg\n",
      "pre:right true:left 1945/11700\n",
      "tensor([ 0.5592, -0.5640])\n",
      "pre:left true:left 1946/11700\n",
      "tensor([ 0.2352, -0.2196])\n",
      "pre:left true:left 1947/11700\n",
      "tensor([ 0.2567, -0.2534])\n",
      "pre:left true:left 1948/11700\n",
      "tensor([ 0.1921, -0.1836])\n",
      "pre:left true:left 1949/11700\n",
      "tensor([ 0.7798, -0.7649])\n",
      "pre:left true:left 1950/11700\n",
      "tensor([ 0.2085, -0.2260])\n",
      "pre:left true:left 1951/11700\n",
      "tensor([ 0.6263, -0.5970])\n",
      "pre:left true:left 1952/11700\n",
      "tensor([ 0.2561, -0.2831])\n",
      "pre:left true:left 1953/11700\n",
      "tensor([0.0613, 0.0237])\n",
      "pre:left true:left 1954/11700\n",
      "tensor([ 0.8009, -0.8310])\n",
      "pre:left true:left 1955/11700\n",
      "tensor([ 0.1100, -0.1992])\n",
      "pre:left true:left 1956/11700\n",
      "tensor([-0.2368,  0.2423])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左74_0_230_20200412_114032091_0.jpg\n",
      "pre:right true:left 1957/11700\n",
      "tensor([ 0.5485, -0.6003])\n",
      "pre:left true:left 1958/11700\n",
      "tensor([-0.1132,  0.1529])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左712_0_868_20200412_115423513_3.jpg\n",
      "pre:right true:left 1959/11700\n",
      "tensor([ 0.1506, -0.0882])\n",
      "pre:left true:left 1960/11700\n",
      "tensor([ 0.2353, -0.2122])\n",
      "pre:left true:left 1961/11700\n",
      "tensor([ 0.6802, -0.7618])\n",
      "pre:left true:left 1962/11700\n",
      "tensor([ 0.3480, -0.2470])\n",
      "pre:left true:left 1963/11700\n",
      "tensor([ 1.1734, -1.1409])\n",
      "pre:left true:left 1964/11700\n",
      "tensor([ 0.2669, -0.3284])\n",
      "pre:left true:left 1965/11700\n",
      "tensor([ 0.8174, -0.8336])\n",
      "pre:left true:left 1966/11700\n",
      "tensor([ 0.5961, -0.5787])\n",
      "pre:left true:left 1967/11700\n",
      "tensor([ 0.5535, -0.5370])\n",
      "pre:left true:left 1968/11700\n",
      "tensor([ 0.8187, -0.8420])\n",
      "pre:left true:left 1969/11700\n",
      "tensor([ 0.8236, -0.7997])\n",
      "pre:left true:left 1970/11700\n",
      "tensor([ 0.0176, -0.0125])\n",
      "pre:left true:left 1971/11700\n",
      "tensor([ 0.4383, -0.4662])\n",
      "pre:left true:left 1972/11700\n",
      "tensor([ 0.6533, -0.6755])\n",
      "pre:left true:left 1973/11700\n",
      "tensor([ 0.5032, -0.5337])\n",
      "pre:left true:left 1974/11700\n",
      "tensor([ 0.0789, -0.0351])\n",
      "pre:left true:left 1975/11700\n",
      "tensor([ 0.7450, -0.7794])\n",
      "pre:left true:left 1976/11700\n",
      "tensor([ 0.7589, -0.7074])\n",
      "pre:left true:left 1977/11700\n",
      "tensor([ 0.7050, -0.6729])\n",
      "pre:left true:left 1978/11700\n",
      "tensor([ 1.0929, -1.0218])\n",
      "pre:left true:left 1979/11700\n",
      "tensor([ 0.6942, -0.6393])\n",
      "pre:left true:left 1980/11700\n",
      "tensor([ 0.0444, -0.0378])\n",
      "pre:left true:left 1981/11700\n",
      "tensor([ 0.1134, -0.0394])\n",
      "pre:left true:left 1982/11700\n",
      "tensor([ 1.1923, -1.2519])\n",
      "pre:left true:left 1983/11700\n",
      "tensor([ 0.0928, -0.1033])\n",
      "pre:left true:left 1984/11700\n",
      "tensor([-0.0122,  0.0565])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1511_0_1667_20200412_121144824_6.jpg\n",
      "pre:right true:left 1985/11700\n",
      "tensor([ 0.9431, -0.9595])\n",
      "pre:left true:left 1986/11700\n",
      "tensor([ 0.4410, -0.4149])\n",
      "pre:left true:left 1987/11700\n",
      "tensor([ 0.5842, -0.6353])\n",
      "pre:left true:left 1988/11700\n",
      "tensor([ 0.3622, -0.4694])\n",
      "pre:left true:left 1989/11700\n",
      "tensor([ 0.5082, -0.4826])\n",
      "pre:left true:left 1990/11700\n",
      "tensor([-0.0818,  0.0913])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1228_0_1384_20200412_120535988_3.jpg\n",
      "pre:right true:left 1991/11700\n",
      "tensor([ 0.3962, -0.4864])\n",
      "pre:left true:left 1992/11700\n",
      "tensor([ 1.2039, -1.1634])\n",
      "pre:left true:left 1993/11700\n",
      "tensor([ 0.1799, -0.1431])\n",
      "pre:left true:left 1994/11700\n",
      "tensor([-0.0574,  0.0437])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左549_0_705_20200412_115051073_2.jpg\n",
      "pre:right true:left 1995/11700\n",
      "tensor([ 1.5080, -1.4418])\n",
      "pre:left true:left 1996/11700\n",
      "tensor([-0.3999,  0.2949])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左304_0_304_20200412_105539887_7.jpg\n",
      "pre:right true:left 1997/11700\n",
      "tensor([ 0.4428, -0.4008])\n",
      "pre:left true:left 1998/11700\n",
      "tensor([ 0.7167, -0.7123])\n",
      "pre:left true:left 1999/11700\n",
      "tensor([-0.0570,  0.0355])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左68_0_68_20200412_105825772_7.jpg\n",
      "pre:right true:left 2000/11700\n",
      "tensor([ 0.4253, -0.4415])\n",
      "pre:left true:left 2001/11700\n",
      "tensor([-0.2318,  0.2335])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1595_0_1751_20200412_121334340.jpg\n",
      "pre:right true:left 2002/11700\n",
      "tensor([ 1.3742, -1.4351])\n",
      "pre:left true:left 2003/11700\n",
      "tensor([ 0.8173, -0.8436])\n",
      "pre:left true:left 2004/11700\n",
      "tensor([ 1.0309, -1.0883])\n",
      "pre:left true:left 2005/11700\n",
      "tensor([ 0.5138, -0.4190])\n",
      "pre:left true:left 2006/11700\n",
      "tensor([ 0.8057, -0.7540])\n",
      "pre:left true:left 2007/11700\n",
      "tensor([ 0.4081, -0.2620])\n",
      "pre:left true:left 2008/11700\n",
      "tensor([-0.0744,  0.0021])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左892_0_1048_20200412_115818084_10.jpg\n",
      "pre:right true:left 2009/11700\n",
      "tensor([ 0.6095, -0.5478])\n",
      "pre:left true:left 2010/11700\n",
      "tensor([ 1.0485, -1.0495])\n",
      "pre:left true:left 2011/11700\n",
      "tensor([ 0.5162, -0.4951])\n",
      "pre:left true:left 2012/11700\n",
      "tensor([-0.2187,  0.2740])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1200_0_1200_20200412_112445301_3.jpg\n",
      "pre:right true:left 2013/11700\n",
      "tensor([ 0.2700, -0.3224])\n",
      "pre:left true:left 2014/11700\n",
      "tensor([ 0.8661, -0.9583])\n",
      "pre:left true:left 2015/11700\n",
      "tensor([ 0.7442, -0.6713])\n",
      "pre:left true:left 2016/11700\n",
      "tensor([-0.2182,  0.3909])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左587_0_743_20200412_115140615_7.jpg\n",
      "pre:right true:left 2017/11700\n",
      "tensor([ 0.9263, -0.8700])\n",
      "pre:left true:left 2018/11700\n",
      "tensor([ 0.8063, -0.8906])\n",
      "pre:left true:left 2019/11700\n",
      "tensor([ 0.4443, -0.3310])\n",
      "pre:left true:left 2020/11700\n",
      "tensor([ 0.5176, -0.4754])\n",
      "pre:left true:left 2021/11700\n",
      "tensor([ 0.5635, -0.6169])\n",
      "pre:left true:left 2022/11700\n",
      "tensor([ 0.9568, -0.9884])\n",
      "pre:left true:left 2023/11700\n",
      "tensor([ 0.7171, -0.6329])\n",
      "pre:left true:left 2024/11700\n",
      "tensor([ 0.3360, -0.2246])\n",
      "pre:left true:left 2025/11700\n",
      "tensor([-0.3219,  0.3531])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1302_0_1458_20200412_120712431_9.jpg\n",
      "pre:right true:left 2026/11700\n",
      "tensor([ 0.7545, -0.8207])\n",
      "pre:left true:left 2027/11700\n",
      "tensor([ 0.4812, -0.5077])\n",
      "pre:left true:left 2028/11700\n",
      "tensor([ 0.5443, -0.5647])\n",
      "pre:left true:left 2029/11700\n",
      "tensor([ 0.6483, -0.7193])\n",
      "pre:left true:left 2030/11700\n",
      "tensor([-0.2868,  0.4440])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1163_0_1163_20200412_112357100_1.jpg\n",
      "pre:right true:left 2031/11700\n",
      "tensor([ 0.4122, -0.3475])\n",
      "pre:left true:left 2032/11700\n",
      "tensor([ 1.0969, -1.1561])\n",
      "pre:left true:left 2033/11700\n",
      "tensor([ 0.7406, -0.6574])\n",
      "pre:left true:left 2034/11700\n",
      "tensor([ 1.0071, -0.9410])\n",
      "pre:left true:left 2035/11700\n",
      "tensor([ 0.6587, -0.5581])\n",
      "pre:left true:left 2036/11700\n",
      "tensor([ 0.4185, -0.3376])\n",
      "pre:left true:left 2037/11700\n",
      "tensor([ 0.2406, -0.2122])\n",
      "pre:left true:left 2038/11700\n",
      "tensor([ 0.6258, -0.5933])\n",
      "pre:left true:left 2039/11700\n",
      "tensor([ 1.1153, -1.0598])\n",
      "pre:left true:left 2040/11700\n",
      "tensor([ 0.6933, -0.7396])\n",
      "pre:left true:left 2041/11700\n",
      "tensor([ 0.2511, -0.2412])\n",
      "pre:left true:left 2042/11700\n",
      "tensor([ 0.5188, -0.5617])\n",
      "pre:left true:left 2043/11700\n",
      "tensor([ 0.9337, -0.9526])\n",
      "pre:left true:left 2044/11700\n",
      "tensor([ 0.8843, -0.8514])\n",
      "pre:left true:left 2045/11700\n",
      "tensor([ 1.0257, -1.0370])\n",
      "pre:left true:left 2046/11700\n",
      "tensor([ 0.7892, -0.8812])\n",
      "pre:left true:left 2047/11700\n",
      "tensor([ 0.4794, -0.3884])\n",
      "pre:left true:left 2048/11700\n",
      "tensor([ 0.4213, -0.4147])\n",
      "pre:left true:left 2049/11700\n",
      "tensor([ 0.0103, -0.0016])\n",
      "pre:left true:left 2050/11700\n",
      "tensor([ 0.7238, -0.7096])\n",
      "pre:left true:left 2051/11700\n",
      "tensor([ 0.5570, -0.5198])\n",
      "pre:left true:left 2052/11700\n",
      "tensor([-0.0762, -0.0075])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1363_0_1519_20200412_120831917_4.jpg\n",
      "pre:right true:left 2053/11700\n",
      "tensor([ 1.5570, -1.5739])\n",
      "pre:left true:left 2054/11700\n",
      "tensor([ 0.7643, -0.7215])\n",
      "pre:left true:left 2055/11700\n",
      "tensor([ 0.6603, -0.5653])\n",
      "pre:left true:left 2056/11700\n",
      "tensor([ 0.7323, -0.7445])\n",
      "pre:left true:left 2057/11700\n",
      "tensor([ 0.5281, -0.5307])\n",
      "pre:left true:left 2058/11700\n",
      "tensor([ 0.0224, -0.0511])\n",
      "pre:left true:left 2059/11700\n",
      "tensor([ 0.7515, -0.7599])\n",
      "pre:left true:left 2060/11700\n",
      "tensor([ 1.1875, -1.2304])\n",
      "pre:left true:left 2061/11700\n",
      "tensor([ 0.8857, -0.8842])\n",
      "pre:left true:left 2062/11700\n",
      "tensor([ 0.4179, -0.4437])\n",
      "pre:left true:left 2063/11700\n",
      "tensor([ 0.3037, -0.2829])\n",
      "pre:left true:left 2064/11700\n",
      "tensor([ 1.0279, -1.1242])\n",
      "pre:left true:left 2065/11700\n",
      "tensor([ 0.0583, -0.0430])\n",
      "pre:left true:left 2066/11700\n",
      "tensor([ 0.5976, -0.4751])\n",
      "pre:left true:left 2067/11700\n",
      "tensor([ 0.8663, -0.8209])\n",
      "pre:left true:left 2068/11700\n",
      "tensor([ 0.4011, -0.3751])\n",
      "pre:left true:left 2069/11700\n",
      "tensor([ 0.5946, -0.6774])\n",
      "pre:left true:left 2070/11700\n",
      "tensor([ 0.0688, -0.1305])\n",
      "pre:left true:left 2071/11700\n",
      "tensor([ 0.7047, -0.6585])\n",
      "pre:left true:left 2072/11700\n",
      "tensor([ 0.5664, -0.6220])\n",
      "pre:left true:left 2073/11700\n",
      "tensor([ 0.5502, -0.5293])\n",
      "pre:left true:left 2074/11700\n",
      "tensor([ 0.6929, -0.6675])\n",
      "pre:left true:left 2075/11700\n",
      "tensor([ 0.4264, -0.3514])\n",
      "pre:left true:left 2076/11700\n",
      "tensor([ 0.5369, -0.4673])\n",
      "pre:left true:left 2077/11700\n",
      "tensor([ 0.7465, -0.7291])\n",
      "pre:left true:left 2078/11700\n",
      "tensor([ 1.1079, -1.0352])\n",
      "pre:left true:left 2079/11700\n",
      "tensor([ 0.2900, -0.2317])\n",
      "pre:left true:left 2080/11700\n",
      "tensor([ 0.0913, -0.0848])\n",
      "pre:left true:left 2081/11700\n",
      "tensor([ 0.1009, -0.0874])\n",
      "pre:left true:left 2082/11700\n",
      "tensor([-0.0986,  0.2369])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左539_0_695_20200412_115038042.jpg\n",
      "pre:right true:left 2083/11700\n",
      "tensor([ 0.9448, -0.8857])\n",
      "pre:left true:left 2084/11700\n",
      "tensor([ 0.3528, -0.3173])\n",
      "pre:left true:left 2085/11700\n",
      "tensor([ 0.2193, -0.2137])\n",
      "pre:left true:left 2086/11700\n",
      "tensor([ 0.1670, -0.0881])\n",
      "pre:left true:left 2087/11700\n",
      "tensor([ 0.5250, -0.3902])\n",
      "pre:left true:left 2088/11700\n",
      "tensor([0.1258, 0.0115])\n",
      "pre:left true:left 2089/11700\n",
      "tensor([-0.2537,  0.3391])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左814_0_970_20200412_115636447_1.jpg\n",
      "pre:right true:left 2090/11700\n",
      "tensor([ 0.0709, -0.0043])\n",
      "pre:left true:left 2091/11700\n",
      "tensor([ 0.9130, -0.9033])\n",
      "pre:left true:left 2092/11700\n",
      "tensor([ 0.0332, -0.0909])\n",
      "pre:left true:left 2093/11700\n",
      "tensor([ 0.1927, -0.1676])\n",
      "pre:left true:left 2094/11700\n",
      "tensor([ 1.1927, -1.1845])\n",
      "pre:left true:left 2095/11700\n",
      "tensor([ 0.7771, -0.7233])\n",
      "pre:left true:left 2096/11700\n",
      "tensor([0.0354, 0.0236])\n",
      "pre:left true:left 2097/11700\n",
      "tensor([ 0.4983, -0.4595])\n",
      "pre:left true:left 2098/11700\n",
      "tensor([ 0.2078, -0.0925])\n",
      "pre:left true:left 2099/11700\n",
      "tensor([ 0.6799, -0.8138])\n",
      "pre:left true:left 2100/11700\n",
      "tensor([ 0.2953, -0.2800])\n",
      "pre:left true:left 2101/11700\n",
      "tensor([ 1.2961, -1.3238])\n",
      "pre:left true:left 2102/11700\n",
      "tensor([ 0.6205, -0.6019])\n",
      "pre:left true:left 2103/11700\n",
      "tensor([ 0.8267, -0.8962])\n",
      "pre:left true:left 2104/11700\n",
      "tensor([ 0.0716, -0.0365])\n",
      "pre:left true:left 2105/11700\n",
      "tensor([-0.1861,  0.1417])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1106_0_1106_20200412_112242823_10.jpg\n",
      "pre:right true:left 2106/11700\n",
      "tensor([ 0.3958, -0.3955])\n",
      "pre:left true:left 2107/11700\n",
      "tensor([ 0.8254, -0.8186])\n",
      "pre:left true:left 2108/11700\n",
      "tensor([ 0.2521, -0.2543])\n",
      "pre:left true:left 2109/11700\n",
      "tensor([ 0.7978, -0.7767])\n",
      "pre:left true:left 2110/11700\n",
      "tensor([ 0.5798, -0.6235])\n",
      "pre:left true:left 2111/11700\n",
      "tensor([-0.0606,  0.0904])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左735_0_891_20200412_115453481_9.jpg\n",
      "pre:right true:left 2112/11700\n",
      "tensor([ 0.2735, -0.2354])\n",
      "pre:left true:left 2113/11700\n",
      "tensor([-0.3552,  0.4817])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左719_0_875_20200412_115432635_2.jpg\n",
      "pre:right true:left 2114/11700\n",
      "tensor([ 0.9695, -0.9773])\n",
      "pre:left true:left 2115/11700\n",
      "tensor([0.0332, 0.0175])\n",
      "pre:left true:left 2116/11700\n",
      "tensor([ 0.5874, -0.7064])\n",
      "pre:left true:left 2117/11700\n",
      "tensor([ 0.4270, -0.3704])\n",
      "pre:left true:left 2118/11700\n",
      "tensor([ 0.3196, -0.3440])\n",
      "pre:left true:left 2119/11700\n",
      "tensor([ 0.2607, -0.3257])\n",
      "pre:left true:left 2120/11700\n",
      "tensor([ 0.3370, -0.3427])\n",
      "pre:left true:left 2121/11700\n",
      "tensor([ 0.4731, -0.4105])\n",
      "pre:left true:left 2122/11700\n",
      "tensor([ 0.4067, -0.4404])\n",
      "pre:left true:left 2123/11700\n",
      "tensor([ 0.6602, -0.6632])\n",
      "pre:left true:left 2124/11700\n",
      "tensor([ 0.1081, -0.0511])\n",
      "pre:left true:left 2125/11700\n",
      "tensor([ 1.3900, -1.4100])\n",
      "pre:left true:left 2126/11700\n",
      "tensor([ 0.8313, -0.9238])\n",
      "pre:left true:left 2127/11700\n",
      "tensor([ 0.3038, -0.3131])\n",
      "pre:left true:left 2128/11700\n",
      "tensor([ 0.4604, -0.5257])\n",
      "pre:left true:left 2129/11700\n",
      "tensor([ 0.7116, -0.6614])\n",
      "pre:left true:left 2130/11700\n",
      "tensor([ 0.9569, -0.9093])\n",
      "pre:left true:left 2131/11700\n",
      "tensor([ 0.2971, -0.3641])\n",
      "pre:left true:left 2132/11700\n",
      "tensor([ 0.2857, -0.4203])\n",
      "pre:left true:left 2133/11700\n",
      "tensor([ 0.7161, -0.7416])\n",
      "pre:left true:left 2134/11700\n",
      "tensor([ 0.5974, -0.4943])\n",
      "pre:left true:left 2135/11700\n",
      "tensor([ 0.5230, -0.5744])\n",
      "pre:left true:left 2136/11700\n",
      "tensor([ 1.1661, -1.1418])\n",
      "pre:left true:left 2137/11700\n",
      "tensor([-0.1594,  0.2775])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左557_0_713_20200412_115101502_2.jpg\n",
      "pre:right true:left 2138/11700\n",
      "tensor([ 1.2809, -1.2555])\n",
      "pre:left true:left 2139/11700\n",
      "tensor([ 0.2316, -0.2030])\n",
      "pre:left true:left 2140/11700\n",
      "tensor([ 1.1982, -1.1834])\n",
      "pre:left true:left 2141/11700\n",
      "tensor([ 0.4432, -0.3931])\n",
      "pre:left true:left 2142/11700\n",
      "tensor([ 0.7242, -0.6188])\n",
      "pre:left true:left 2143/11700\n",
      "tensor([ 0.3818, -0.3445])\n",
      "pre:left true:left 2144/11700\n",
      "tensor([ 0.5456, -0.3817])\n",
      "pre:left true:left 2145/11700\n",
      "tensor([ 0.9184, -0.8988])\n",
      "pre:left true:left 2146/11700\n",
      "tensor([ 0.5328, -0.5406])\n",
      "pre:left true:left 2147/11700\n",
      "tensor([-0.0605,  0.1047])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左791_0_947_20200412_115606477_8.jpg\n",
      "pre:right true:left 2148/11700\n",
      "tensor([ 0.9485, -0.9839])\n",
      "pre:left true:left 2149/11700\n",
      "tensor([ 0.1611, -0.1600])\n",
      "pre:left true:left 2150/11700\n",
      "tensor([-0.1074,  0.1446])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左351_0_507_20200412_114633054.jpg\n",
      "pre:right true:left 2151/11700\n",
      "tensor([ 0.5687, -0.5601])\n",
      "pre:left true:left 2152/11700\n",
      "tensor([ 0.9077, -0.9197])\n",
      "pre:left true:left 2153/11700\n",
      "tensor([ 0.7530, -0.5653])\n",
      "pre:left true:left 2154/11700\n",
      "tensor([-0.0343,  0.0090])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左986_0_986_20200412_112006470_2.jpg\n",
      "pre:right true:left 2155/11700\n",
      "tensor([ 1.2062, -1.3117])\n",
      "pre:left true:left 2156/11700\n",
      "tensor([ 0.5606, -0.5295])\n",
      "pre:left true:left 2157/11700\n",
      "tensor([ 1.7993, -1.8513])\n",
      "pre:left true:left 2158/11700\n",
      "tensor([ 0.3475, -0.3333])\n",
      "pre:left true:left 2159/11700\n",
      "tensor([-0.1827,  0.0931])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左570_0_570_20200412_111021790.jpg\n",
      "pre:right true:left 2160/11700\n",
      "tensor([ 0.6024, -0.5938])\n",
      "pre:left true:left 2161/11700\n",
      "tensor([-0.2711,  0.3088])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左309_0_309_20200412_110409512_0.jpg\n",
      "pre:right true:left 2162/11700\n",
      "tensor([ 0.6871, -0.7496])\n",
      "pre:left true:left 2163/11700\n",
      "tensor([ 1.1588, -1.0761])\n",
      "pre:left true:left 2164/11700\n",
      "tensor([-0.0158, -0.0326])\n",
      "pre:left true:left 2165/11700\n",
      "tensor([ 0.5334, -0.6109])\n",
      "pre:left true:left 2166/11700\n",
      "tensor([ 0.4829, -0.5553])\n",
      "pre:left true:left 2167/11700\n",
      "tensor([ 0.7289, -0.7130])\n",
      "pre:left true:left 2168/11700\n",
      "tensor([ 0.7697, -0.8316])\n",
      "pre:left true:left 2169/11700\n",
      "tensor([ 0.6398, -0.6198])\n",
      "pre:left true:left 2170/11700\n",
      "tensor([-0.4071,  0.4364])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左551_0_707_20200412_115053685_10.jpg\n",
      "pre:right true:left 2171/11700\n",
      "tensor([ 0.2816, -0.3850])\n",
      "pre:left true:left 2172/11700\n",
      "tensor([ 0.1529, -0.1669])\n",
      "pre:left true:left 2173/11700\n",
      "tensor([ 0.8821, -0.8866])\n",
      "pre:left true:left 2174/11700\n",
      "tensor([0.0224, 0.0135])\n",
      "pre:left true:left 2175/11700\n",
      "tensor([ 0.4517, -0.3374])\n",
      "pre:left true:left 2176/11700\n",
      "tensor([ 1.0776, -0.9856])\n",
      "pre:left true:left 2177/11700\n",
      "tensor([ 0.2705, -0.1775])\n",
      "pre:left true:left 2178/11700\n",
      "tensor([ 0.9953, -0.9876])\n",
      "pre:left true:left 2179/11700\n",
      "tensor([ 0.5718, -0.5693])\n",
      "pre:left true:left 2180/11700\n",
      "tensor([ 0.6472, -0.7166])\n",
      "pre:left true:left 2181/11700\n",
      "tensor([ 0.5334, -0.6109])\n",
      "pre:left true:left 2182/11700\n",
      "tensor([ 0.6023, -0.6537])\n",
      "pre:left true:left 2183/11700\n",
      "tensor([ 0.6843, -0.6868])\n",
      "pre:left true:left 2184/11700\n",
      "tensor([ 1.8940, -1.9250])\n",
      "pre:left true:left 2185/11700\n",
      "tensor([-0.0007, -0.0580])\n",
      "pre:left true:left 2186/11700\n",
      "tensor([ 0.6163, -0.6262])\n",
      "pre:left true:left 2187/11700\n",
      "tensor([ 0.0598, -0.1015])\n",
      "pre:left true:left 2188/11700\n",
      "tensor([ 1.3439, -1.3555])\n",
      "pre:left true:left 2189/11700\n",
      "tensor([-0.2617,  0.3370])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左109_0_109_20200412_105924272_10.jpg\n",
      "pre:right true:left 2190/11700\n",
      "tensor([ 0.7109, -0.7889])\n",
      "pre:left true:left 2191/11700\n",
      "tensor([ 0.6802, -0.6274])\n",
      "pre:left true:left 2192/11700\n",
      "tensor([ 0.1274, -0.0852])\n",
      "pre:left true:left 2193/11700\n",
      "tensor([ 0.4590, -0.4248])\n",
      "pre:left true:left 2194/11700\n",
      "tensor([ 0.4990, -0.5478])\n",
      "pre:left true:left 2195/11700\n",
      "tensor([ 0.5518, -0.6367])\n",
      "pre:left true:left 2196/11700\n",
      "tensor([ 0.5596, -0.4268])\n",
      "pre:left true:left 2197/11700\n",
      "tensor([ 0.7457, -0.6264])\n",
      "pre:left true:left 2198/11700\n",
      "tensor([ 0.1154, -0.1907])\n",
      "pre:left true:left 2199/11700\n",
      "tensor([ 0.2344, -0.1942])\n",
      "pre:left true:left 2200/11700\n",
      "tensor([ 0.1445, -0.1171])\n",
      "pre:left true:left 2201/11700\n",
      "tensor([ 0.2249, -0.2835])\n",
      "pre:left true:left 2202/11700\n",
      "tensor([ 0.8486, -0.8009])\n",
      "pre:left true:left 2203/11700\n",
      "tensor([ 0.4514, -0.4889])\n",
      "pre:left true:left 2204/11700\n",
      "tensor([ 0.5025, -0.4956])\n",
      "pre:left true:left 2205/11700\n",
      "tensor([ 0.1069, -0.1265])\n",
      "pre:left true:left 2206/11700\n",
      "tensor([ 0.5924, -0.5955])\n",
      "pre:left true:left 2207/11700\n",
      "tensor([ 0.7311, -0.7811])\n",
      "pre:left true:left 2208/11700\n",
      "tensor([ 0.1979, -0.1537])\n",
      "pre:left true:left 2209/11700\n",
      "tensor([ 0.6147, -0.6067])\n",
      "pre:left true:left 2210/11700\n",
      "tensor([ 1.1649, -1.2124])\n",
      "pre:left true:left 2211/11700\n",
      "tensor([ 0.5279, -0.5193])\n",
      "pre:left true:left 2212/11700\n",
      "tensor([ 0.5679, -0.5763])\n",
      "pre:left true:left 2213/11700\n",
      "tensor([ 1.1683, -1.1576])\n",
      "pre:left true:left 2214/11700\n",
      "tensor([-0.1694,  0.1774])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左475_0_475_20200412_110806277_3.jpg\n",
      "pre:right true:left 2215/11700\n",
      "tensor([-0.1545,  0.1701])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1126_0_1126_20200412_112308896_5.jpg\n",
      "pre:right true:left 2216/11700\n",
      "tensor([0.0342, 0.0475])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左828_0_828_20200412_111629799_6.jpg\n",
      "pre:right true:left 2217/11700\n",
      "tensor([ 1.1701, -1.1219])\n",
      "pre:left true:left 2218/11700\n",
      "tensor([ 0.9467, -0.9589])\n",
      "pre:left true:left 2219/11700\n",
      "tensor([ 0.6805, -0.6621])\n",
      "pre:left true:left 2220/11700\n",
      "tensor([ 0.3795, -0.3925])\n",
      "pre:left true:left 2221/11700\n",
      "tensor([ 0.9791, -0.9787])\n",
      "pre:left true:left 2222/11700\n",
      "tensor([ 0.5783, -0.6243])\n",
      "pre:left true:left 2223/11700\n",
      "tensor([ 0.5488, -0.4959])\n",
      "pre:left true:left 2224/11700\n",
      "tensor([ 1.3942, -1.3826])\n",
      "pre:left true:left 2225/11700\n",
      "tensor([ 1.0856, -0.9913])\n",
      "pre:left true:left 2226/11700\n",
      "tensor([ 1.0499, -1.0852])\n",
      "pre:left true:left 2227/11700\n",
      "tensor([ 0.5703, -0.4452])\n",
      "pre:left true:left 2228/11700\n",
      "tensor([ 0.3161, -0.3146])\n",
      "pre:left true:left 2229/11700\n",
      "tensor([ 0.9900, -0.9641])\n",
      "pre:left true:left 2230/11700\n",
      "tensor([ 0.5244, -0.5342])\n",
      "pre:left true:left 2231/11700\n",
      "tensor([ 0.6420, -0.6612])\n",
      "pre:left true:left 2232/11700\n",
      "tensor([ 0.5761, -0.5800])\n",
      "pre:left true:left 2233/11700\n",
      "tensor([ 0.3867, -0.3027])\n",
      "pre:left true:left 2234/11700\n",
      "tensor([ 0.1699, -0.1930])\n",
      "pre:left true:left 2235/11700\n",
      "tensor([ 0.9290, -0.8614])\n",
      "pre:left true:left 2236/11700\n",
      "tensor([ 1.0151, -1.0648])\n",
      "pre:left true:left 2237/11700\n",
      "tensor([ 0.5476, -0.4817])\n",
      "pre:left true:left 2238/11700\n",
      "tensor([ 0.7379, -0.7189])\n",
      "pre:left true:left 2239/11700\n",
      "tensor([ 1.0221, -1.0899])\n",
      "pre:left true:left 2240/11700\n",
      "tensor([-0.1008,  0.1567])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左659_0_815_20200412_115314448_9.jpg\n",
      "pre:right true:left 2241/11700\n",
      "tensor([ 0.2874, -0.1749])\n",
      "pre:left true:left 2242/11700\n",
      "tensor([ 0.6980, -0.7501])\n",
      "pre:left true:left 2243/11700\n",
      "tensor([ 0.8573, -0.7483])\n",
      "pre:left true:left 2244/11700\n",
      "tensor([ 0.8157, -0.7413])\n",
      "pre:left true:left 2245/11700\n",
      "tensor([ 0.1166, -0.0392])\n",
      "pre:left true:left 2246/11700\n",
      "tensor([ 0.1162, -0.0728])\n",
      "pre:left true:left 2247/11700\n",
      "tensor([ 0.3580, -0.2830])\n",
      "pre:left true:left 2248/11700\n",
      "tensor([-0.4925,  0.4661])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左551_0_707_20200412_115053685_0.jpg\n",
      "pre:right true:left 2249/11700\n",
      "tensor([ 0.7141, -0.7349])\n",
      "pre:left true:left 2250/11700\n",
      "tensor([ 0.5679, -0.6340])\n",
      "pre:left true:left 2251/11700\n",
      "tensor([ 1.0631, -0.9938])\n",
      "pre:left true:left 2252/11700\n",
      "tensor([ 0.9112, -0.8623])\n",
      "pre:left true:left 2253/11700\n",
      "tensor([ 0.2001, -0.2047])\n",
      "pre:left true:left 2254/11700\n",
      "tensor([ 1.3358, -1.3377])\n",
      "pre:left true:left 2255/11700\n",
      "tensor([ 0.1823, -0.1157])\n",
      "pre:left true:left 2256/11700\n",
      "tensor([ 0.4526, -0.4238])\n",
      "pre:left true:left 2257/11700\n",
      "tensor([ 0.4280, -0.3935])\n",
      "pre:left true:left 2258/11700\n",
      "tensor([ 0.6939, -0.6503])\n",
      "pre:left true:left 2259/11700\n",
      "tensor([ 0.2065, -0.2312])\n",
      "pre:left true:left 2260/11700\n",
      "tensor([-0.2060,  0.1400])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左689_0_689_20200412_111311531_9.jpg\n",
      "pre:right true:left 2261/11700\n",
      "tensor([ 0.4956, -0.5602])\n",
      "pre:left true:left 2262/11700\n",
      "tensor([ 0.6196, -0.5634])\n",
      "pre:left true:left 2263/11700\n",
      "tensor([ 0.1277, -0.0416])\n",
      "pre:left true:left 2264/11700\n",
      "tensor([ 0.6691, -0.6727])\n",
      "pre:left true:left 2265/11700\n",
      "tensor([ 0.5431, -0.5104])\n",
      "pre:left true:left 2266/11700\n",
      "tensor([ 0.5756, -0.5764])\n",
      "pre:left true:left 2267/11700\n",
      "tensor([ 1.3695, -1.4310])\n",
      "pre:left true:left 2268/11700\n",
      "tensor([ 0.3863, -0.4108])\n",
      "pre:left true:left 2269/11700\n",
      "tensor([ 0.1414, -0.0788])\n",
      "pre:left true:left 2270/11700\n",
      "tensor([-0.0911,  0.1065])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左387_0_543_20200412_114719968_4.jpg\n",
      "pre:right true:left 2271/11700\n",
      "tensor([ 0.6340, -0.5176])\n",
      "pre:left true:left 2272/11700\n",
      "tensor([ 0.1420, -0.0875])\n",
      "pre:left true:left 2273/11700\n",
      "tensor([-0.0296,  0.0267])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左930_0_930_20200412_111853504_6.jpg\n",
      "pre:right true:left 2274/11700\n",
      "tensor([ 0.6362, -0.5656])\n",
      "pre:left true:left 2275/11700\n",
      "tensor([ 1.0552, -1.0931])\n",
      "pre:left true:left 2276/11700\n",
      "tensor([-0.2234,  0.2268])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左570_0_726_20200412_115118431_3.jpg\n",
      "pre:right true:left 2277/11700\n",
      "tensor([ 0.2665, -0.3130])\n",
      "pre:left true:left 2278/11700\n",
      "tensor([ 0.8698, -0.8749])\n",
      "pre:left true:left 2279/11700\n",
      "tensor([ 0.4518, -0.4670])\n",
      "pre:left true:left 2280/11700\n",
      "tensor([ 0.2460, -0.2332])\n",
      "pre:left true:left 2281/11700\n",
      "tensor([ 0.9325, -0.8928])\n",
      "pre:left true:left 2282/11700\n",
      "tensor([-0.8101,  0.8379])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左695_0_851_20200412_115401357_6.jpg\n",
      "pre:right true:left 2283/11700\n",
      "tensor([ 0.4843, -0.4563])\n",
      "pre:left true:left 2284/11700\n",
      "tensor([ 0.5016, -0.4625])\n",
      "pre:left true:left 2285/11700\n",
      "tensor([ 0.3706, -0.3840])\n",
      "pre:left true:left 2286/11700\n",
      "tensor([ 0.2600, -0.1463])\n",
      "pre:left true:left 2287/11700\n",
      "tensor([ 0.3390, -0.4000])\n",
      "pre:left true:left 2288/11700\n",
      "tensor([ 0.5432, -0.5886])\n",
      "pre:left true:left 2289/11700\n",
      "tensor([ 0.7615, -0.6840])\n",
      "pre:left true:left 2290/11700\n",
      "tensor([0.0095, 0.0481])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左159_0_315_20200412_114222876.jpg\n",
      "pre:right true:left 2291/11700\n",
      "tensor([ 0.5491, -0.5186])\n",
      "pre:left true:left 2292/11700\n",
      "tensor([ 0.1590, -0.2244])\n",
      "pre:left true:left 2293/11700\n",
      "tensor([ 0.8805, -0.9200])\n",
      "pre:left true:left 2294/11700\n",
      "tensor([ 0.6519, -0.5504])\n",
      "pre:left true:left 2295/11700\n",
      "tensor([ 0.2780, -0.2049])\n",
      "pre:left true:left 2296/11700\n",
      "tensor([ 1.2417, -1.3373])\n",
      "pre:left true:left 2297/11700\n",
      "tensor([ 0.5782, -0.6122])\n",
      "pre:left true:left 2298/11700\n",
      "tensor([ 0.6843, -0.7176])\n",
      "pre:left true:left 2299/11700\n",
      "tensor([ 0.3309, -0.3091])\n",
      "pre:left true:left 2300/11700\n",
      "tensor([ 0.2629, -0.2424])\n",
      "pre:left true:left 2301/11700\n",
      "tensor([ 0.4715, -0.4288])\n",
      "pre:left true:left 2302/11700\n",
      "tensor([ 0.6450, -0.6294])\n",
      "pre:left true:left 2303/11700\n",
      "tensor([0.1046, 0.0234])\n",
      "pre:left true:left 2304/11700\n",
      "tensor([ 0.2535, -0.2887])\n",
      "pre:left true:left 2305/11700\n",
      "tensor([ 0.8465, -0.8325])\n",
      "pre:left true:left 2306/11700\n",
      "tensor([ 0.8455, -0.8507])\n",
      "pre:left true:left 2307/11700\n",
      "tensor([ 0.2477, -0.2467])\n",
      "pre:left true:left 2308/11700\n",
      "tensor([ 0.8085, -0.8491])\n",
      "pre:left true:left 2309/11700\n",
      "tensor([ 0.2790, -0.2996])\n",
      "pre:left true:left 2310/11700\n",
      "tensor([ 1.1439, -1.2135])\n",
      "pre:left true:left 2311/11700\n",
      "tensor([ 0.4818, -0.4238])\n",
      "pre:left true:left 2312/11700\n",
      "tensor([ 0.6910, -0.6301])\n",
      "pre:left true:left 2313/11700\n",
      "tensor([ 0.5951, -0.5809])\n",
      "pre:left true:left 2314/11700\n",
      "tensor([ 0.9161, -0.9210])\n",
      "pre:left true:left 2315/11700\n",
      "tensor([ 0.0728, -0.0697])\n",
      "pre:left true:left 2316/11700\n",
      "tensor([ 0.2777, -0.2787])\n",
      "pre:left true:left 2317/11700\n",
      "tensor([ 0.4383, -0.4608])\n",
      "pre:left true:left 2318/11700\n",
      "tensor([ 0.4103, -0.4165])\n",
      "pre:left true:left 2319/11700\n",
      "tensor([ 0.0570, -0.0268])\n",
      "pre:left true:left 2320/11700\n",
      "tensor([ 0.3214, -0.4021])\n",
      "pre:left true:left 2321/11700\n",
      "tensor([ 0.7438, -0.7178])\n",
      "pre:left true:left 2322/11700\n",
      "tensor([ 0.8676, -0.8621])\n",
      "pre:left true:left 2323/11700\n",
      "tensor([ 1.0317, -0.9149])\n",
      "pre:left true:left 2324/11700\n",
      "tensor([ 0.9863, -1.0321])\n",
      "pre:left true:left 2325/11700\n",
      "tensor([ 0.4221, -0.3695])\n",
      "pre:left true:left 2326/11700\n",
      "tensor([ 0.7136, -0.7813])\n",
      "pre:left true:left 2327/11700\n",
      "tensor([ 0.5045, -0.5403])\n",
      "pre:left true:left 2328/11700\n",
      "tensor([ 0.6830, -0.7503])\n",
      "pre:left true:left 2329/11700\n",
      "tensor([ 0.4516, -0.4466])\n",
      "pre:left true:left 2330/11700\n",
      "tensor([-0.0444,  0.0167])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左379_0_535_20200412_114709553_8.jpg\n",
      "pre:right true:left 2331/11700\n",
      "tensor([ 0.2699, -0.2222])\n",
      "pre:left true:left 2332/11700\n",
      "tensor([ 1.2229, -1.2915])\n",
      "pre:left true:left 2333/11700\n",
      "tensor([ 1.4885, -1.3977])\n",
      "pre:left true:left 2334/11700\n",
      "tensor([ 0.4669, -0.4284])\n",
      "pre:left true:left 2335/11700\n",
      "tensor([ 0.6707, -0.6670])\n",
      "pre:left true:left 2336/11700\n",
      "tensor([ 0.5151, -0.4878])\n",
      "pre:left true:left 2337/11700\n",
      "tensor([ 0.6147, -0.6194])\n",
      "pre:left true:left 2338/11700\n",
      "tensor([ 0.5496, -0.4779])\n",
      "pre:left true:left 2339/11700\n",
      "tensor([ 0.0043, -0.0698])\n",
      "pre:left true:left 2340/11700\n",
      "tensor([ 0.2663, -0.2796])\n",
      "pre:left true:left 2341/11700\n",
      "tensor([ 0.3099, -0.3396])\n",
      "pre:left true:left 2342/11700\n",
      "tensor([-0.3235,  0.2986])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左198_0_198_20200412_110131204_1.jpg\n",
      "pre:right true:left 2343/11700\n",
      "tensor([-0.4475,  0.4664])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1330_0_1486_20200412_120748944_2.jpg\n",
      "pre:right true:left 2344/11700\n",
      "tensor([ 0.3646, -0.3323])\n",
      "pre:left true:left 2345/11700\n",
      "tensor([ 0.0176, -0.0125])\n",
      "pre:left true:left 2346/11700\n",
      "tensor([ 0.0984, -0.0923])\n",
      "pre:left true:left 2347/11700\n",
      "tensor([ 1.3511, -1.3721])\n",
      "pre:left true:left 2348/11700\n",
      "tensor([-0.0682,  0.1455])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左316_0_472_20200412_114547440_3.jpg\n",
      "pre:right true:left 2349/11700\n",
      "tensor([ 0.6799, -0.6334])\n",
      "pre:left true:left 2350/11700\n",
      "tensor([ 1.4938, -1.5297])\n",
      "pre:left true:left 2351/11700\n",
      "tensor([ 0.1699, -0.1930])\n",
      "pre:left true:left 2352/11700\n",
      "tensor([ 1.2535, -1.3135])\n",
      "pre:left true:left 2353/11700\n",
      "tensor([ 0.2288, -0.3229])\n",
      "pre:left true:left 2354/11700\n",
      "tensor([ 0.4811, -0.4284])\n",
      "pre:left true:left 2355/11700\n",
      "tensor([ 1.1245, -1.1176])\n",
      "pre:left true:left 2356/11700\n",
      "tensor([ 0.4223, -0.3187])\n",
      "pre:left true:left 2357/11700\n",
      "tensor([ 0.6623, -0.6437])\n",
      "pre:left true:left 2358/11700\n",
      "tensor([ 0.7473, -0.8018])\n",
      "pre:left true:left 2359/11700\n",
      "tensor([-0.0713,  0.0795])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左808_0_964_20200412_115628626_7.jpg\n",
      "pre:right true:left 2360/11700\n",
      "tensor([ 0.7554, -0.8552])\n",
      "pre:left true:left 2361/11700\n",
      "tensor([ 0.4974, -0.4156])\n",
      "pre:left true:left 2362/11700\n",
      "tensor([ 0.6631, -0.6603])\n",
      "pre:left true:left 2363/11700\n",
      "tensor([ 1.2080, -1.2236])\n",
      "pre:left true:left 2364/11700\n",
      "tensor([0.0380, 0.2045])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1538_0_1694_20200412_121220028_2.jpg\n",
      "pre:right true:left 2365/11700\n",
      "tensor([ 0.5607, -0.5038])\n",
      "pre:left true:left 2366/11700\n",
      "tensor([ 1.1535, -1.1095])\n",
      "pre:left true:left 2367/11700\n",
      "tensor([ 0.6908, -0.6431])\n",
      "pre:left true:left 2368/11700\n",
      "tensor([-0.3878,  0.4053])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1247_0_1247_20200412_112546556_5.jpg\n",
      "pre:right true:left 2369/11700\n",
      "tensor([ 0.3030, -0.2642])\n",
      "pre:left true:left 2370/11700\n",
      "tensor([ 0.5950, -0.5346])\n",
      "pre:left true:left 2371/11700\n",
      "tensor([ 0.5246, -0.4909])\n",
      "pre:left true:left 2372/11700\n",
      "tensor([-0.3005,  0.3317])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左472_0_628_20200412_114910718_2.jpg\n",
      "pre:right true:left 2373/11700\n",
      "tensor([ 0.2353, -0.2019])\n",
      "pre:left true:left 2374/11700\n",
      "tensor([ 0.1493, -0.0824])\n",
      "pre:left true:left 2375/11700\n",
      "tensor([ 0.2129, -0.1951])\n",
      "pre:left true:left 2376/11700\n",
      "tensor([ 0.3008, -0.3253])\n",
      "pre:left true:left 2377/11700\n",
      "tensor([ 0.7515, -0.7984])\n",
      "pre:left true:left 2378/11700\n",
      "tensor([ 1.1256, -1.0875])\n",
      "pre:left true:left 2379/11700\n",
      "tensor([ 0.3292, -0.1827])\n",
      "pre:left true:left 2380/11700\n",
      "tensor([-0.1094,  0.1262])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1401_0_1557_20200412_120921450.jpg\n",
      "pre:right true:left 2381/11700\n",
      "tensor([-0.1998,  0.2239])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左514_0_514_20200412_110901907_5.jpg\n",
      "pre:right true:left 2382/11700\n",
      "tensor([ 0.2859, -0.3012])\n",
      "pre:left true:left 2383/11700\n",
      "tensor([ 0.3033, -0.2155])\n",
      "pre:left true:left 2384/11700\n",
      "tensor([ 0.8097, -0.9339])\n",
      "pre:left true:left 2385/11700\n",
      "tensor([ 0.3622, -0.3042])\n",
      "pre:left true:left 2386/11700\n",
      "tensor([ 1.4462, -1.3770])\n",
      "pre:left true:left 2387/11700\n",
      "tensor([ 0.2562, -0.4064])\n",
      "pre:left true:left 2388/11700\n",
      "tensor([ 0.4027, -0.4600])\n",
      "pre:left true:left 2389/11700\n",
      "tensor([-0.0039, -0.0605])\n",
      "pre:left true:left 2390/11700\n",
      "tensor([ 0.2027, -0.2843])\n",
      "pre:left true:left 2391/11700\n",
      "tensor([ 1.4415, -1.4425])\n",
      "pre:left true:left 2392/11700\n",
      "tensor([ 0.7538, -0.6875])\n",
      "pre:left true:left 2393/11700\n",
      "tensor([ 0.0919, -0.0049])\n",
      "pre:left true:left 2394/11700\n",
      "tensor([ 0.5498, -0.5767])\n",
      "pre:left true:left 2395/11700\n",
      "tensor([ 0.2931, -0.3383])\n",
      "pre:left true:left 2396/11700\n",
      "tensor([ 1.6528, -1.6826])\n",
      "pre:left true:left 2397/11700\n",
      "tensor([ 1.4514, -1.4399])\n",
      "pre:left true:left 2398/11700\n",
      "tensor([ 0.1634, -0.2268])\n",
      "pre:left true:left 2399/11700\n",
      "tensor([ 0.8125, -0.7369])\n",
      "pre:left true:left 2400/11700\n",
      "tensor([ 0.3128, -0.2799])\n",
      "pre:left true:left 2401/11700\n",
      "tensor([ 1.1404, -1.1555])\n",
      "pre:left true:left 2402/11700\n",
      "tensor([ 0.6360, -0.5493])\n",
      "pre:left true:left 2403/11700\n",
      "tensor([ 0.9873, -1.0016])\n",
      "pre:left true:left 2404/11700\n",
      "tensor([ 0.2288, -0.3229])\n",
      "pre:left true:left 2405/11700\n",
      "tensor([ 1.0723, -1.0517])\n",
      "pre:left true:left 2406/11700\n",
      "tensor([ 0.1447, -0.0660])\n",
      "pre:left true:left 2407/11700\n",
      "tensor([ 0.5464, -0.4244])\n",
      "pre:left true:left 2408/11700\n",
      "tensor([ 0.4704, -0.3861])\n",
      "pre:left true:left 2409/11700\n",
      "tensor([ 0.7551, -0.7428])\n",
      "pre:left true:left 2410/11700\n",
      "tensor([ 1.2696, -1.2255])\n",
      "pre:left true:left 2411/11700\n",
      "tensor([ 0.8804, -0.8982])\n",
      "pre:left true:left 2412/11700\n",
      "tensor([ 0.7807, -0.7176])\n",
      "pre:left true:left 2413/11700\n",
      "tensor([ 0.5772, -0.6188])\n",
      "pre:left true:left 2414/11700\n",
      "tensor([ 0.4702, -0.4032])\n",
      "pre:left true:left 2415/11700\n",
      "tensor([ 0.3961, -0.3640])\n",
      "pre:left true:left 2416/11700\n",
      "tensor([ 0.8997, -0.8987])\n",
      "pre:left true:left 2417/11700\n",
      "tensor([ 0.7053, -0.6809])\n",
      "pre:left true:left 2418/11700\n",
      "tensor([ 0.7316, -0.7428])\n",
      "pre:left true:left 2419/11700\n",
      "tensor([ 0.9334, -0.8497])\n",
      "pre:left true:left 2420/11700\n",
      "tensor([ 6.0827e-02, -5.4151e-05])\n",
      "pre:left true:left 2421/11700\n",
      "tensor([ 1.0280, -0.8511])\n",
      "pre:left true:left 2422/11700\n",
      "tensor([-0.0909,  0.0390])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左288_0_288_20200412_110339565_2.jpg\n",
      "pre:right true:left 2423/11700\n",
      "tensor([ 0.4798, -0.4075])\n",
      "pre:left true:left 2424/11700\n",
      "tensor([ 0.8086, -0.8491])\n",
      "pre:left true:left 2425/11700\n",
      "tensor([ 0.1064, -0.1911])\n",
      "pre:left true:left 2426/11700\n",
      "tensor([ 0.7052, -0.6701])\n",
      "pre:left true:left 2427/11700\n",
      "tensor([ 0.4334, -0.3927])\n",
      "pre:left true:left 2428/11700\n",
      "tensor([ 0.6141, -0.6450])\n",
      "pre:left true:left 2429/11700\n",
      "tensor([ 0.2362, -0.2727])\n",
      "pre:left true:left 2430/11700\n",
      "tensor([ 0.8063, -0.8255])\n",
      "pre:left true:left 2431/11700\n",
      "tensor([ 0.2187, -0.2380])\n",
      "pre:left true:left 2432/11700\n",
      "tensor([ 0.4340, -0.4054])\n",
      "pre:left true:left 2433/11700\n",
      "tensor([ 0.7983, -0.7380])\n",
      "pre:left true:left 2434/11700\n",
      "tensor([ 1.0647, -0.9722])\n",
      "pre:left true:left 2435/11700\n",
      "tensor([ 0.1874, -0.0939])\n",
      "pre:left true:left 2436/11700\n",
      "tensor([-0.0605,  0.0750])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左72_0_72_20200412_105831500_4.jpg\n",
      "pre:right true:left 2437/11700\n",
      "tensor([ 0.3720, -0.3606])\n",
      "pre:left true:left 2438/11700\n",
      "tensor([ 1.1154, -1.1040])\n",
      "pre:left true:left 2439/11700\n",
      "tensor([ 0.4922, -0.4548])\n",
      "pre:left true:left 2440/11700\n",
      "tensor([ 0.6456, -0.5621])\n",
      "pre:left true:left 2441/11700\n",
      "tensor([ 0.2893, -0.1627])\n",
      "pre:left true:left 2442/11700\n",
      "tensor([ 0.3630, -0.3326])\n",
      "pre:left true:left 2443/11700\n",
      "tensor([ 0.7774, -0.8145])\n",
      "pre:left true:left 2444/11700\n",
      "tensor([ 0.0861, -0.0914])\n",
      "pre:left true:left 2445/11700\n",
      "tensor([ 0.8803, -0.8757])\n",
      "pre:left true:left 2446/11700\n",
      "tensor([ 0.7515, -0.7743])\n",
      "pre:left true:left 2447/11700\n",
      "tensor([-0.5398,  0.5792])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左416_0_572_20200412_114757758_5.jpg\n",
      "pre:right true:left 2448/11700\n",
      "tensor([ 0.9383, -0.9776])\n",
      "pre:left true:left 2449/11700\n",
      "tensor([ 1.3769, -1.4045])\n",
      "pre:left true:left 2450/11700\n",
      "tensor([ 0.7963, -0.7460])\n",
      "pre:left true:left 2451/11700\n",
      "tensor([ 0.4570, -0.4252])\n",
      "pre:left true:left 2452/11700\n",
      "tensor([ 0.3046, -0.2803])\n",
      "pre:left true:left 2453/11700\n",
      "tensor([ 0.0950, -0.1609])\n",
      "pre:left true:left 2454/11700\n",
      "tensor([ 0.4591, -0.4185])\n",
      "pre:left true:left 2455/11700\n",
      "tensor([ 0.7052, -0.6733])\n",
      "pre:left true:left 2456/11700\n",
      "tensor([ 0.9886, -0.9162])\n",
      "pre:left true:left 2457/11700\n",
      "tensor([ 0.8157, -0.6857])\n",
      "pre:left true:left 2458/11700\n",
      "tensor([ 0.3888, -0.3467])\n",
      "pre:left true:left 2459/11700\n",
      "tensor([ 0.3330, -0.1871])\n",
      "pre:left true:left 2460/11700\n",
      "tensor([ 0.5316, -0.4927])\n",
      "pre:left true:left 2461/11700\n",
      "tensor([ 0.1607, -0.1270])\n",
      "pre:left true:left 2462/11700\n",
      "tensor([0.0875, 0.0648])\n",
      "pre:left true:left 2463/11700\n",
      "tensor([-0.1082,  0.0924])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1167_0_1167_20200412_112402315_1.jpg\n",
      "pre:right true:left 2464/11700\n",
      "tensor([ 0.3628, -0.2728])\n",
      "pre:left true:left 2465/11700\n",
      "tensor([ 0.1616, -0.2069])\n",
      "pre:left true:left 2466/11700\n",
      "tensor([ 0.6449, -0.6276])\n",
      "pre:left true:left 2467/11700\n",
      "tensor([-0.0563,  0.1151])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1206_0_1206_20200412_112453125_1.jpg\n",
      "pre:right true:left 2468/11700\n",
      "tensor([ 0.8611, -0.9084])\n",
      "pre:left true:left 2469/11700\n",
      "tensor([ 0.4795, -0.4803])\n",
      "pre:left true:left 2470/11700\n",
      "tensor([ 0.1081, -0.0511])\n",
      "pre:left true:left 2471/11700\n",
      "tensor([ 0.4419, -0.4511])\n",
      "pre:left true:left 2472/11700\n",
      "tensor([ 0.1074, -0.1850])\n",
      "pre:left true:left 2473/11700\n",
      "tensor([ 1.1952, -1.2310])\n",
      "pre:left true:left 2474/11700\n",
      "tensor([ 0.6367, -0.6121])\n",
      "pre:left true:left 2475/11700\n",
      "tensor([ 0.5574, -0.6322])\n",
      "pre:left true:left 2476/11700\n",
      "tensor([-0.0349,  0.0055])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左780_0_780_20200412_111521333_3.jpg\n",
      "pre:right true:left 2477/11700\n",
      "tensor([ 0.3672, -0.3667])\n",
      "pre:left true:left 2478/11700\n",
      "tensor([ 0.1430, -0.0697])\n",
      "pre:left true:left 2479/11700\n",
      "tensor([ 0.2484, -0.2509])\n",
      "pre:left true:left 2480/11700\n",
      "tensor([ 0.6472, -0.7166])\n",
      "pre:left true:left 2481/11700\n",
      "tensor([ 0.8358, -0.8784])\n",
      "pre:left true:left 2482/11700\n",
      "tensor([ 0.2786, -0.2689])\n",
      "pre:left true:left 2483/11700\n",
      "tensor([ 0.4442, -0.4391])\n",
      "pre:left true:left 2484/11700\n",
      "tensor([ 0.6399, -0.7378])\n",
      "pre:left true:left 2485/11700\n",
      "tensor([ 0.7476, -0.6704])\n",
      "pre:left true:left 2486/11700\n",
      "tensor([ 0.0850, -0.0587])\n",
      "pre:left true:left 2487/11700\n",
      "tensor([ 0.4874, -0.4786])\n",
      "pre:left true:left 2488/11700\n",
      "tensor([ 0.2071, -0.2862])\n",
      "pre:left true:left 2489/11700\n",
      "tensor([ 0.2614, -0.2722])\n",
      "pre:left true:left 2490/11700\n",
      "tensor([ 0.8953, -0.8902])\n",
      "pre:left true:left 2491/11700\n",
      "tensor([ 0.6929, -0.7120])\n",
      "pre:left true:left 2492/11700\n",
      "tensor([-0.0298,  0.0688])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左618_0_618_20200412_111130269_2.jpg\n",
      "pre:right true:left 2493/11700\n",
      "tensor([ 0.7417, -0.7648])\n",
      "pre:left true:left 2494/11700\n",
      "tensor([ 0.2413, -0.3606])\n",
      "pre:left true:left 2495/11700\n",
      "tensor([-0.1779,  0.1847])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1273_0_1273_20200412_112620448.jpg\n",
      "pre:right true:left 2496/11700\n",
      "tensor([ 0.6951, -0.6438])\n",
      "pre:left true:left 2497/11700\n",
      "tensor([ 0.1710, -0.0933])\n",
      "pre:left true:left 2498/11700\n",
      "tensor([ 0.3997, -0.4065])\n",
      "pre:left true:left 2499/11700\n",
      "tensor([ 0.6034, -0.6369])\n",
      "pre:left true:left 2500/11700\n",
      "tensor([-0.1411,  0.0393])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左469_0_469_20200412_110757725_2.jpg\n",
      "pre:right true:left 2501/11700\n",
      "tensor([ 0.2371, -0.2481])\n",
      "pre:left true:left 2502/11700\n",
      "tensor([ 0.8832, -0.8469])\n",
      "pre:left true:left 2503/11700\n",
      "tensor([ 0.3545, -0.2590])\n",
      "pre:left true:left 2504/11700\n",
      "tensor([ 1.4325, -1.4855])\n",
      "pre:left true:left 2505/11700\n",
      "tensor([ 0.0826, -0.0668])\n",
      "pre:left true:left 2506/11700\n",
      "tensor([-0.2100,  0.2267])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左307_0_463_20200412_114535722_8.jpg\n",
      "pre:right true:left 2507/11700\n",
      "tensor([ 0.8215, -0.6648])\n",
      "pre:left true:left 2508/11700\n",
      "tensor([ 0.0652, -0.0718])\n",
      "pre:left true:left 2509/11700\n",
      "tensor([ 0.5479, -0.5259])\n",
      "pre:left true:left 2510/11700\n",
      "tensor([ 0.2810, -0.2695])\n",
      "pre:left true:left 2511/11700\n",
      "tensor([-0.0928,  0.0634])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左981_0_981_20200412_111959966.jpg\n",
      "pre:right true:left 2512/11700\n",
      "tensor([ 0.9185, -0.9242])\n",
      "pre:left true:left 2513/11700\n",
      "tensor([ 0.8703, -0.8149])\n",
      "pre:left true:left 2514/11700\n",
      "tensor([0.0170, 0.0545])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左814_0_970_20200412_115636447_5.jpg\n",
      "pre:right true:left 2515/11700\n",
      "tensor([-0.1656,  0.1193])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左702_0_858_20200412_115410468_1.jpg\n",
      "pre:right true:left 2516/11700\n",
      "tensor([-0.4488,  0.4850])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1155_0_1311_20200412_120400838_2.jpg\n",
      "pre:right true:left 2517/11700\n",
      "tensor([ 0.5302, -0.5665])\n",
      "pre:left true:left 2518/11700\n",
      "tensor([-0.1245,  0.2323])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1592_0_1748_20200412_121330413_0.jpg\n",
      "pre:right true:left 2519/11700\n",
      "tensor([ 1.6401, -1.7446])\n",
      "pre:left true:left 2520/11700\n",
      "tensor([ 0.4153, -0.2695])\n",
      "pre:left true:left 2521/11700\n",
      "tensor([ 0.2580, -0.1500])\n",
      "pre:left true:left 2522/11700\n",
      "tensor([ 0.1848, -0.1328])\n",
      "pre:left true:left 2523/11700\n",
      "tensor([ 0.4395, -0.4828])\n",
      "pre:left true:left 2524/11700\n",
      "tensor([ 0.4860, -0.4576])\n",
      "pre:left true:left 2525/11700\n",
      "tensor([ 0.1866, -0.1645])\n",
      "pre:left true:left 2526/11700\n",
      "tensor([-0.3625,  0.3383])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左122_0_122_20200412_105942805_7.jpg\n",
      "pre:right true:left 2527/11700\n",
      "tensor([ 0.6520, -0.7054])\n",
      "pre:left true:left 2528/11700\n",
      "tensor([-0.4665,  0.4577])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左369_0_525_20200412_114656522_5.jpg\n",
      "pre:right true:left 2529/11700\n",
      "tensor([0.0234, 0.0035])\n",
      "pre:left true:left 2530/11700\n",
      "tensor([0.0489, 0.0082])\n",
      "pre:left true:left 2531/11700\n",
      "tensor([ 0.4752, -0.4900])\n",
      "pre:left true:left 2532/11700\n",
      "tensor([ 0.5303, -0.5664])\n",
      "pre:left true:left 2533/11700\n",
      "tensor([ 0.8451, -0.8133])\n",
      "pre:left true:left 2534/11700\n",
      "tensor([-0.2150,  0.3058])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左244_0_244_20200412_110236813_6.jpg\n",
      "pre:right true:left 2535/11700\n",
      "tensor([ 0.5796, -0.6200])\n",
      "pre:left true:left 2536/11700\n",
      "tensor([ 0.6632, -0.6429])\n",
      "pre:left true:left 2537/11700\n",
      "tensor([-0.2186,  0.1545])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左408_0_564_20200412_114747327_9.jpg\n",
      "pre:right true:left 2538/11700\n",
      "tensor([ 0.4698, -0.3570])\n",
      "pre:left true:left 2539/11700\n",
      "tensor([ 0.3544, -0.3480])\n",
      "pre:left true:left 2540/11700\n",
      "tensor([ 0.5206, -0.5160])\n",
      "pre:left true:left 2541/11700\n",
      "tensor([ 0.8239, -0.8259])\n",
      "pre:left true:left 2542/11700\n",
      "tensor([ 1.0508, -1.0423])\n",
      "pre:left true:left 2543/11700\n",
      "tensor([ 0.7731, -0.8032])\n",
      "pre:left true:left 2544/11700\n",
      "tensor([ 0.5985, -0.7078])\n",
      "pre:left true:left 2545/11700\n",
      "tensor([ 1.0053, -1.1014])\n",
      "pre:left true:left 2546/11700\n",
      "tensor([-0.0473, -0.0246])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1320_0_1320_20200412_112731601_2.jpg\n",
      "pre:right true:left 2547/11700\n",
      "tensor([ 0.9716, -1.0035])\n",
      "pre:left true:left 2548/11700\n",
      "tensor([ 0.6067, -0.5674])\n",
      "pre:left true:left 2549/11700\n",
      "tensor([ 0.2831, -0.3274])\n",
      "pre:left true:left 2550/11700\n",
      "tensor([ 1.3327, -1.2382])\n",
      "pre:left true:left 2551/11700\n",
      "tensor([ 1.1342, -1.0925])\n",
      "pre:left true:left 2552/11700\n",
      "tensor([ 1.3417, -1.2990])\n",
      "pre:left true:left 2553/11700\n",
      "tensor([ 1.1923, -1.1512])\n",
      "pre:left true:left 2554/11700\n",
      "tensor([-0.0476,  0.0762])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左983_0_983_20200412_112002564_2.jpg\n",
      "pre:right true:left 2555/11700\n",
      "tensor([ 0.4679, -0.4532])\n",
      "pre:left true:left 2556/11700\n",
      "tensor([-0.2825,  0.2186])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左339_0_495_20200412_114617420_1.jpg\n",
      "pre:right true:left 2557/11700\n",
      "tensor([ 0.3873, -0.2762])\n",
      "pre:left true:left 2558/11700\n",
      "tensor([-0.5542,  0.6325])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左755_0_911_20200412_115519560_8.jpg\n",
      "pre:right true:left 2559/11700\n",
      "tensor([ 1.1029, -1.1525])\n",
      "pre:left true:left 2560/11700\n",
      "tensor([-0.1074,  0.1446])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左351_0_507_20200412_114633054_10.jpg\n",
      "pre:right true:left 2561/11700\n",
      "tensor([ 0.5913, -0.5216])\n",
      "pre:left true:left 2562/11700\n",
      "tensor([ 0.5679, -0.5527])\n",
      "pre:left true:left 2563/11700\n",
      "tensor([ 0.6641, -0.7453])\n",
      "pre:left true:left 2564/11700\n",
      "tensor([ 0.2967, -0.2621])\n",
      "pre:left true:left 2565/11700\n",
      "tensor([ 0.6269, -0.7079])\n",
      "pre:left true:left 2566/11700\n",
      "tensor([ 0.5979, -0.5838])\n",
      "pre:left true:left 2567/11700\n",
      "tensor([-0.0248,  0.0121])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1597_0_1753_20200412_121336950_8.jpg\n",
      "pre:right true:left 2568/11700\n",
      "tensor([ 0.9730, -1.1400])\n",
      "pre:left true:left 2569/11700\n",
      "tensor([ 0.4457, -0.3874])\n",
      "pre:left true:left 2570/11700\n",
      "tensor([ 1.4472, -1.3742])\n",
      "pre:left true:left 2571/11700\n",
      "tensor([ 0.7006, -0.7279])\n",
      "pre:left true:left 2572/11700\n",
      "tensor([ 0.6467, -0.6100])\n",
      "pre:left true:left 2573/11700\n",
      "tensor([ 0.2496, -0.3212])\n",
      "pre:left true:left 2574/11700\n",
      "tensor([ 0.3043, -0.2890])\n",
      "pre:left true:left 2575/11700\n",
      "tensor([ 1.3935, -1.3706])\n",
      "pre:left true:left 2576/11700\n",
      "tensor([ 0.7337, -0.7543])\n",
      "pre:left true:left 2577/11700\n",
      "tensor([-0.4025,  0.4416])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左712_0_868_20200412_115423513_5.jpg\n",
      "pre:right true:left 2578/11700\n",
      "tensor([ 1.0405, -1.1202])\n",
      "pre:left true:left 2579/11700\n",
      "tensor([ 0.8866, -0.8861])\n",
      "pre:left true:left 2580/11700\n",
      "tensor([ 0.3046, -0.3199])\n",
      "pre:left true:left 2581/11700\n",
      "tensor([ 0.2724, -0.1985])\n",
      "pre:left true:left 2582/11700\n",
      "tensor([ 0.3064, -0.3696])\n",
      "pre:left true:left 2583/11700\n",
      "tensor([ 0.3391, -0.2351])\n",
      "pre:left true:left 2584/11700\n",
      "tensor([ 0.5711, -0.5786])\n",
      "pre:left true:left 2585/11700\n",
      "tensor([ 0.2666, -0.2603])\n",
      "pre:left true:left 2586/11700\n",
      "tensor([-0.4914,  0.5163])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左285_0_441_20200412_114507035_2.jpg\n",
      "pre:right true:left 2587/11700\n",
      "tensor([-0.0234,  0.0321])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1151_0_1307_20200412_120355647_7.jpg\n",
      "pre:right true:left 2588/11700\n",
      "tensor([ 0.5918, -0.6264])\n",
      "pre:left true:left 2589/11700\n",
      "tensor([ 0.4995, -0.4197])\n",
      "pre:left true:left 2590/11700\n",
      "tensor([-0.2481,  0.1961])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左93_0_93_20200412_105901450_5.jpg\n",
      "pre:right true:left 2591/11700\n",
      "tensor([ 0.6165, -0.6134])\n",
      "pre:left true:left 2592/11700\n",
      "tensor([ 0.4388, -0.4995])\n",
      "pre:left true:left 2593/11700\n",
      "tensor([ 0.2559, -0.3562])\n",
      "pre:left true:left 2594/11700\n",
      "tensor([ 0.1309, -0.0578])\n",
      "pre:left true:left 2595/11700\n",
      "tensor([ 1.2138, -1.1280])\n",
      "pre:left true:left 2596/11700\n",
      "tensor([ 0.3735, -0.4314])\n",
      "pre:left true:left 2597/11700\n",
      "tensor([ 0.5773, -0.5568])\n",
      "pre:left true:left 2598/11700\n",
      "tensor([ 0.4985, -0.5039])\n",
      "pre:left true:left 2599/11700\n",
      "tensor([ 0.2273, -0.2087])\n",
      "pre:left true:left 2600/11700\n",
      "tensor([ 1.1443, -1.0894])\n",
      "pre:left true:left 2601/11700\n",
      "tensor([-0.1530,  0.1007])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1264_0_1264_20200412_112608712_10.jpg\n",
      "pre:right true:left 2602/11700\n",
      "tensor([ 0.3776, -0.3758])\n",
      "pre:left true:left 2603/11700\n",
      "tensor([ 0.7224, -0.7620])\n",
      "pre:left true:left 2604/11700\n",
      "tensor([ 0.6186, -0.5683])\n",
      "pre:left true:left 2605/11700\n",
      "tensor([ 0.2416, -0.1732])\n",
      "pre:left true:left 2606/11700\n",
      "tensor([ 0.2763, -0.3151])\n",
      "pre:left true:left 2607/11700\n",
      "tensor([ 0.4864, -0.4291])\n",
      "pre:left true:left 2608/11700\n",
      "tensor([ 0.8624, -0.9099])\n",
      "pre:left true:left 2609/11700\n",
      "tensor([ 0.2694, -0.3451])\n",
      "pre:left true:left 2610/11700\n",
      "tensor([-0.1683,  0.1948])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左822_0_978_20200412_115646880_9.jpg\n",
      "pre:right true:left 2611/11700\n",
      "tensor([ 0.4075, -0.3723])\n",
      "pre:left true:left 2612/11700\n",
      "tensor([-0.2321,  0.2791])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左970_0_970_20200412_111945629_6.jpg\n",
      "pre:right true:left 2613/11700\n",
      "tensor([ 0.4631, -0.4091])\n",
      "pre:left true:left 2614/11700\n",
      "tensor([ 0.4656, -0.4855])\n",
      "pre:left true:left 2615/11700\n",
      "tensor([ 0.2313, -0.1686])\n",
      "pre:left true:left 2616/11700\n",
      "tensor([ 1.0315, -0.9957])\n",
      "pre:left true:left 2617/11700\n",
      "tensor([ 0.3680, -0.3889])\n",
      "pre:left true:left 2618/11700\n",
      "tensor([ 0.7681, -0.7891])\n",
      "pre:left true:left 2619/11700\n",
      "tensor([ 0.1479, -0.2003])\n",
      "pre:left true:left 2620/11700\n",
      "tensor([-0.0888,  0.0745])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左761_0_761_20200412_111454231_0.jpg\n",
      "pre:right true:left 2621/11700\n",
      "tensor([-0.1900,  0.3145])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1589_0_1745_20200412_121326516_9.jpg\n",
      "pre:right true:left 2622/11700\n",
      "tensor([ 0.8777, -0.8699])\n",
      "pre:left true:left 2623/11700\n",
      "tensor([ 0.6618, -0.7791])\n",
      "pre:left true:left 2624/11700\n",
      "tensor([ 0.3327, -0.3120])\n",
      "pre:left true:left 2625/11700\n",
      "tensor([-0.2053,  0.2153])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左551_0_707_20200412_115053685_9.jpg\n",
      "pre:right true:left 2626/11700\n",
      "tensor([ 0.6225, -0.6030])\n",
      "pre:left true:left 2627/11700\n",
      "tensor([ 0.4497, -0.5169])\n",
      "pre:left true:left 2628/11700\n",
      "tensor([ 0.9364, -0.9398])\n",
      "pre:left true:left 2629/11700\n",
      "tensor([ 1.2029, -1.0891])\n",
      "pre:left true:left 2630/11700\n",
      "tensor([-0.1817,  0.2924])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1291_0_1291_20200412_112643889_1.jpg\n",
      "pre:right true:left 2631/11700\n",
      "tensor([ 0.2265, -0.1188])\n",
      "pre:left true:left 2632/11700\n",
      "tensor([ 0.0323, -0.0642])\n",
      "pre:left true:left 2633/11700\n",
      "tensor([ 0.2557, -0.3639])\n",
      "pre:left true:left 2634/11700\n",
      "tensor([-0.3644,  0.2868])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1592_0_1748_20200412_121330413_8.jpg\n",
      "pre:right true:left 2635/11700\n",
      "tensor([-0.0197,  0.1747])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左193_0_349_20200412_114307177_7.jpg\n",
      "pre:right true:left 2636/11700\n",
      "tensor([ 1.5194, -1.6079])\n",
      "pre:left true:left 2637/11700\n",
      "tensor([0.0503, 0.0816])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左976_0_976_20200412_111953440_1.jpg\n",
      "pre:right true:left 2638/11700\n",
      "tensor([ 0.9396, -0.8688])\n",
      "pre:left true:left 2639/11700\n",
      "tensor([ 0.6491, -0.6267])\n",
      "pre:left true:left 2640/11700\n",
      "tensor([-0.0107, -0.0546])\n",
      "pre:left true:left 2641/11700\n",
      "tensor([ 0.9278, -0.9747])\n",
      "pre:left true:left 2642/11700\n",
      "tensor([ 0.9618, -0.9810])\n",
      "pre:left true:left 2643/11700\n",
      "tensor([ 0.8379, -0.8987])\n",
      "pre:left true:left 2644/11700\n",
      "tensor([ 0.3506, -0.3884])\n",
      "pre:left true:left 2645/11700\n",
      "tensor([ 0.1373, -0.0590])\n",
      "pre:left true:left 2646/11700\n",
      "tensor([ 0.7218, -0.7256])\n",
      "pre:left true:left 2647/11700\n",
      "tensor([ 0.9843, -0.8904])\n",
      "pre:left true:left 2648/11700\n",
      "tensor([-0.1775,  0.1601])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左326_0_482_20200412_114600486_6.jpg\n",
      "pre:right true:left 2649/11700\n",
      "tensor([ 0.9111, -0.9354])\n",
      "pre:left true:left 2650/11700\n",
      "tensor([ 0.0844, -0.0236])\n",
      "pre:left true:left 2651/11700\n",
      "tensor([-0.1575,  0.1949])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左159_0_315_20200412_114222876_6.jpg\n",
      "pre:right true:left 2652/11700\n",
      "tensor([ 0.1415, -0.2189])\n",
      "pre:left true:left 2653/11700\n",
      "tensor([ 0.7047, -0.7477])\n",
      "pre:left true:left 2654/11700\n",
      "tensor([ 0.5437, -0.4933])\n",
      "pre:left true:left 2655/11700\n",
      "tensor([ 1.3077, -1.2295])\n",
      "pre:left true:left 2656/11700\n",
      "tensor([ 0.7200, -0.5999])\n",
      "pre:left true:left 2657/11700\n",
      "tensor([ 0.8521, -0.8049])\n",
      "pre:left true:left 2658/11700\n",
      "tensor([ 1.1136, -1.1635])\n",
      "pre:left true:left 2659/11700\n",
      "tensor([ 0.9149, -0.9618])\n",
      "pre:left true:left 2660/11700\n",
      "tensor([ 0.3740, -0.3991])\n",
      "pre:left true:left 2661/11700\n",
      "tensor([ 0.3527, -0.3414])\n",
      "pre:left true:left 2662/11700\n",
      "tensor([ 0.9283, -0.8962])\n",
      "pre:left true:left 2663/11700\n",
      "tensor([ 0.6930, -0.7013])\n",
      "pre:left true:left 2664/11700\n",
      "tensor([ 0.8714, -0.7532])\n",
      "pre:left true:left 2665/11700\n",
      "tensor([-0.3435,  0.4785])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左550_0_706_20200412_115052381_9.jpg\n",
      "pre:right true:left 2666/11700\n",
      "tensor([ 0.5702, -0.4628])\n",
      "pre:left true:left 2667/11700\n",
      "tensor([-0.3587,  0.3298])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左515_0_671_20200412_115006770_3.jpg\n",
      "pre:right true:left 2668/11700\n",
      "tensor([ 1.5720, -1.5192])\n",
      "pre:left true:left 2669/11700\n",
      "tensor([ 0.3642, -0.3517])\n",
      "pre:left true:left 2670/11700\n",
      "tensor([ 0.5214, -0.5024])\n",
      "pre:left true:left 2671/11700\n",
      "tensor([ 1.0340, -1.1872])\n",
      "pre:left true:left 2672/11700\n",
      "tensor([ 0.6077, -0.5775])\n",
      "pre:left true:left 2673/11700\n",
      "tensor([ 0.8497, -0.7797])\n",
      "pre:left true:left 2674/11700\n",
      "tensor([ 0.8746, -0.8403])\n",
      "pre:left true:left 2675/11700\n",
      "tensor([ 0.1781, -0.1507])\n",
      "pre:left true:left 2676/11700\n",
      "tensor([0.1438, 0.0216])\n",
      "pre:left true:left 2677/11700\n",
      "tensor([ 0.4429, -0.5121])\n",
      "pre:left true:left 2678/11700\n",
      "tensor([ 0.5391, -0.4678])\n",
      "pre:left true:left 2679/11700\n",
      "tensor([ 0.1929, -0.2002])\n",
      "pre:left true:left 2680/11700\n",
      "tensor([ 0.5078, -0.6349])\n",
      "pre:left true:left 2681/11700\n",
      "tensor([ 0.4921, -0.5008])\n",
      "pre:left true:left 2682/11700\n",
      "tensor([ 0.3351, -0.3725])\n",
      "pre:left true:left 2683/11700\n",
      "tensor([ 0.3984, -0.3750])\n",
      "pre:left true:left 2684/11700\n",
      "tensor([ 0.2778, -0.3175])\n",
      "pre:left true:left 2685/11700\n",
      "tensor([ 0.1717, -0.0802])\n",
      "pre:left true:left 2686/11700\n",
      "tensor([ 1.0906, -1.0025])\n",
      "pre:left true:left 2687/11700\n",
      "tensor([ 0.0282, -0.0333])\n",
      "pre:left true:left 2688/11700\n",
      "tensor([ 0.4406, -0.4459])\n",
      "pre:left true:left 2689/11700\n",
      "tensor([ 0.2728, -0.2833])\n",
      "pre:left true:left 2690/11700\n",
      "tensor([ 0.2206, -0.2608])\n",
      "pre:left true:left 2691/11700\n",
      "tensor([ 0.9688, -0.8217])\n",
      "pre:left true:left 2692/11700\n",
      "tensor([-0.0734,  0.0503])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左421_0_577_20200412_114804268_9.jpg\n",
      "pre:right true:left 2693/11700\n",
      "tensor([-0.1314,  0.1608])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左752_0_752_20200412_111441398_6.jpg\n",
      "pre:right true:left 2694/11700\n",
      "tensor([ 0.1933, -0.2585])\n",
      "pre:left true:left 2695/11700\n",
      "tensor([-0.0871,  0.1970])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1592_0_1748_20200412_121330413.jpg\n",
      "pre:right true:left 2696/11700\n",
      "tensor([ 0.0813, -0.0485])\n",
      "pre:left true:left 2697/11700\n",
      "tensor([ 1.0798, -1.0743])\n",
      "pre:left true:left 2698/11700\n",
      "tensor([ 0.1782, -0.1058])\n",
      "pre:left true:left 2699/11700\n",
      "tensor([-0.0169, -0.0592])\n",
      "pre:left true:left 2700/11700\n",
      "tensor([ 0.2008, -0.1960])\n",
      "pre:left true:left 2701/11700\n",
      "tensor([ 0.3316, -0.2842])\n",
      "pre:left true:left 2702/11700\n",
      "tensor([ 1.2390, -1.2429])\n",
      "pre:left true:left 2703/11700\n",
      "tensor([0.1219, 0.0125])\n",
      "pre:left true:left 2704/11700\n",
      "tensor([ 0.7791, -0.7722])\n",
      "pre:left true:left 2705/11700\n",
      "tensor([ 0.4364, -0.4998])\n",
      "pre:left true:left 2706/11700\n",
      "tensor([ 0.6566, -0.6394])\n",
      "pre:left true:left 2707/11700\n",
      "tensor([ 0.2944, -0.2645])\n",
      "pre:left true:left 2708/11700\n",
      "tensor([ 0.1300, -0.0837])\n",
      "pre:left true:left 2709/11700\n",
      "tensor([-0.3108,  0.3109])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左312_0_468_20200412_114542241_1.jpg\n",
      "pre:right true:left 2710/11700\n",
      "tensor([ 0.8049, -0.7434])\n",
      "pre:left true:left 2711/11700\n",
      "tensor([ 0.5904, -0.5485])\n",
      "pre:left true:left 2712/11700\n",
      "tensor([ 0.6111, -0.6241])\n",
      "pre:left true:left 2713/11700\n",
      "tensor([ 1.1951, -1.1564])\n",
      "pre:left true:left 2714/11700\n",
      "tensor([ 0.2348, -0.0926])\n",
      "pre:left true:left 2715/11700\n",
      "tensor([ 0.1060, -0.1009])\n",
      "pre:left true:left 2716/11700\n",
      "tensor([ 0.1947, -0.1717])\n",
      "pre:left true:left 2717/11700\n",
      "tensor([0.0141, 0.0236])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左440_0_440_20200412_110716364_9.jpg\n",
      "pre:right true:left 2718/11700\n",
      "tensor([ 0.6933, -0.6470])\n",
      "pre:left true:left 2719/11700\n",
      "tensor([ 0.8944, -0.8789])\n",
      "pre:left true:left 2720/11700\n",
      "tensor([ 0.1689, -0.1917])\n",
      "pre:left true:left 2721/11700\n",
      "tensor([ 0.9509, -0.8502])\n",
      "pre:left true:left 2722/11700\n",
      "tensor([ 0.1406, -0.1513])\n",
      "pre:left true:left 2723/11700\n",
      "tensor([ 0.4461, -0.4418])\n",
      "pre:left true:left 2724/11700\n",
      "tensor([ 0.1227, -0.0929])\n",
      "pre:left true:left 2725/11700\n",
      "tensor([ 0.1936, -0.2306])\n",
      "pre:left true:left 2726/11700\n",
      "tensor([ 0.5254, -0.4775])\n",
      "pre:left true:left 2727/11700\n",
      "tensor([ 0.1729, -0.2619])\n",
      "pre:left true:left 2728/11700\n",
      "tensor([-0.2608,  0.2295])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左474_0_630_20200412_114913342_1.jpg\n",
      "pre:right true:left 2729/11700\n",
      "tensor([ 0.0244, -0.1183])\n",
      "pre:left true:left 2730/11700\n",
      "tensor([ 0.3139, -0.3896])\n",
      "pre:left true:left 2731/11700\n",
      "tensor([ 1.4364, -1.4610])\n",
      "pre:left true:left 2732/11700\n",
      "tensor([ 1.2979, -1.2003])\n",
      "pre:left true:left 2733/11700\n",
      "tensor([ 0.9740, -1.0330])\n",
      "pre:left true:left 2734/11700\n",
      "tensor([ 0.7109, -0.7904])\n",
      "pre:left true:left 2735/11700\n",
      "tensor([ 0.4121, -0.3464])\n",
      "pre:left true:left 2736/11700\n",
      "tensor([ 0.6470, -0.7842])\n",
      "pre:left true:left 2737/11700\n",
      "tensor([ 0.5108, -0.5449])\n",
      "pre:left true:left 2738/11700\n",
      "tensor([ 0.3218, -0.3228])\n",
      "pre:left true:left 2739/11700\n",
      "tensor([ 0.0132, -0.0158])\n",
      "pre:left true:left 2740/11700\n",
      "tensor([ 1.5752, -1.6234])\n",
      "pre:left true:left 2741/11700\n",
      "tensor([ 0.6741, -0.7305])\n",
      "pre:left true:left 2742/11700\n",
      "tensor([ 0.4547, -0.4463])\n",
      "pre:left true:left 2743/11700\n",
      "tensor([ 0.5924, -0.5880])\n",
      "pre:left true:left 2744/11700\n",
      "tensor([ 0.8317, -0.8079])\n",
      "pre:left true:left 2745/11700\n",
      "tensor([ 1.4101, -1.4835])\n",
      "pre:left true:left 2746/11700\n",
      "tensor([ 1.2262, -1.1326])\n",
      "pre:left true:left 2747/11700\n",
      "tensor([ 0.2032, -0.2029])\n",
      "pre:left true:left 2748/11700\n",
      "tensor([-0.0705,  0.1616])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左585_0_741_20200412_115137994_3.jpg\n",
      "pre:right true:left 2749/11700\n",
      "tensor([ 0.8164, -0.8364])\n",
      "pre:left true:left 2750/11700\n",
      "tensor([ 1.1014, -1.0544])\n",
      "pre:left true:left 2751/11700\n",
      "tensor([ 0.5924, -0.5859])\n",
      "pre:left true:left 2752/11700\n",
      "tensor([ 0.5788, -0.6179])\n",
      "pre:left true:left 2753/11700\n",
      "tensor([ 0.4199, -0.4629])\n",
      "pre:left true:left 2754/11700\n",
      "tensor([0.0057, 0.0156])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左152_0_152_20200412_110025594.jpg\n",
      "pre:right true:left 2755/11700\n",
      "tensor([ 0.2269, -0.3445])\n",
      "pre:left true:left 2756/11700\n",
      "tensor([ 0.5481, -0.5045])\n",
      "pre:left true:left 2757/11700\n",
      "tensor([ 0.0879, -0.0089])\n",
      "pre:left true:left 2758/11700\n",
      "tensor([ 1.0404, -1.0002])\n",
      "pre:left true:left 2759/11700\n",
      "tensor([ 0.0621, -0.0277])\n",
      "pre:left true:left 2760/11700\n",
      "tensor([ 0.2413, -0.2335])\n",
      "pre:left true:left 2761/11700\n",
      "tensor([ 0.1068, -0.1427])\n",
      "pre:left true:left 2762/11700\n",
      "tensor([ 0.1736, -0.1009])\n",
      "pre:left true:left 2763/11700\n",
      "tensor([ 0.1957, -0.1877])\n",
      "pre:left true:left 2764/11700\n",
      "tensor([ 1.0983, -1.0017])\n",
      "pre:left true:left 2765/11700\n",
      "tensor([ 0.1180, -0.0969])\n",
      "pre:left true:left 2766/11700\n",
      "tensor([0.0110, 0.0471])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1112_0_1268_20200412_120304819_0.jpg\n",
      "pre:right true:left 2767/11700\n",
      "tensor([ 0.4852, -0.4978])\n",
      "pre:left true:left 2768/11700\n",
      "tensor([ 0.4639, -0.4112])\n",
      "pre:left true:left 2769/11700\n",
      "tensor([ 0.1180, -0.1928])\n",
      "pre:left true:left 2770/11700\n",
      "tensor([ 1.7244, -1.7805])\n",
      "pre:left true:left 2771/11700\n",
      "tensor([ 0.7036, -0.8391])\n",
      "pre:left true:left 2772/11700\n",
      "tensor([ 0.1971, -0.1152])\n",
      "pre:left true:left 2773/11700\n",
      "tensor([ 1.0528, -0.9549])\n",
      "pre:left true:left 2774/11700\n",
      "tensor([-0.2130,  0.3015])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左292_0_292_20200412_110345275_4.jpg\n",
      "pre:right true:left 2775/11700\n",
      "tensor([ 0.4236, -0.4043])\n",
      "pre:left true:left 2776/11700\n",
      "tensor([ 0.1488, -0.0893])\n",
      "pre:left true:left 2777/11700\n",
      "tensor([ 1.0185, -1.0456])\n",
      "pre:left true:left 2778/11700\n",
      "tensor([ 0.3444, -0.3166])\n",
      "pre:left true:left 2779/11700\n",
      "tensor([ 1.2707, -1.1735])\n",
      "pre:left true:left 2780/11700\n",
      "tensor([ 1.2092, -1.2509])\n",
      "pre:left true:left 2781/11700\n",
      "tensor([ 0.1490, -0.2285])\n",
      "pre:left true:left 2782/11700\n",
      "tensor([ 1.4056, -1.4607])\n",
      "pre:left true:left 2783/11700\n",
      "tensor([ 0.4187, -0.3371])\n",
      "pre:left true:left 2784/11700\n",
      "tensor([ 0.5105, -0.5158])\n",
      "pre:left true:left 2785/11700\n",
      "tensor([ 1.0800, -1.0422])\n",
      "pre:left true:left 2786/11700\n",
      "tensor([ 1.4543, -1.3084])\n",
      "pre:left true:left 2787/11700\n",
      "tensor([ 0.4916, -0.4642])\n",
      "pre:left true:left 2788/11700\n",
      "tensor([-0.4833,  0.6180])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1133_0_1289_20200412_120332193_5.jpg\n",
      "pre:right true:left 2789/11700\n",
      "tensor([ 0.8150, -0.7713])\n",
      "pre:left true:left 2790/11700\n",
      "tensor([ 0.0079, -0.0062])\n",
      "pre:left true:left 2791/11700\n",
      "tensor([ 0.3071, -0.2683])\n",
      "pre:left true:left 2792/11700\n",
      "tensor([ 0.7749, -0.6792])\n",
      "pre:left true:left 2793/11700\n",
      "tensor([ 0.8243, -0.9199])\n",
      "pre:left true:left 2794/11700\n",
      "tensor([ 0.4430, -0.4282])\n",
      "pre:left true:left 2795/11700\n",
      "tensor([ 0.0871, -0.0861])\n",
      "pre:left true:left 2796/11700\n",
      "tensor([ 1.9879, -2.0088])\n",
      "pre:left true:left 2797/11700\n",
      "tensor([ 1.3194, -1.3794])\n",
      "pre:left true:left 2798/11700\n",
      "tensor([ 0.5400, -0.4870])\n",
      "pre:left true:left 2799/11700\n",
      "tensor([ 1.0221, -0.9907])\n",
      "pre:left true:left 2800/11700\n",
      "tensor([ 0.5412, -0.4527])\n",
      "pre:left true:left 2801/11700\n",
      "tensor([0.0945, 0.0312])\n",
      "pre:left true:left 2802/11700\n",
      "tensor([ 0.6088, -0.5447])\n",
      "pre:left true:left 2803/11700\n",
      "tensor([ 0.5769, -0.5658])\n",
      "pre:left true:left 2804/11700\n",
      "tensor([ 0.4339, -0.4147])\n",
      "pre:left true:left 2805/11700\n",
      "tensor([ 0.6212, -0.6408])\n",
      "pre:left true:left 2806/11700\n",
      "tensor([ 0.2322, -0.2054])\n",
      "pre:left true:left 2807/11700\n",
      "tensor([ 0.2299, -0.2095])\n",
      "pre:left true:left 2808/11700\n",
      "tensor([ 0.6845, -0.6717])\n",
      "pre:left true:left 2809/11700\n",
      "tensor([ 0.4886, -0.5206])\n",
      "pre:left true:left 2810/11700\n",
      "tensor([ 0.6842, -0.7475])\n",
      "pre:left true:left 2811/11700\n",
      "tensor([ 0.1503, -0.2343])\n",
      "pre:left true:left 2812/11700\n",
      "tensor([ 0.7994, -0.8466])\n",
      "pre:left true:left 2813/11700\n",
      "tensor([-0.3246,  0.2685])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左381_0_381_20200412_110552198.jpg\n",
      "pre:right true:left 2814/11700\n",
      "tensor([ 0.6162, -0.5915])\n",
      "pre:left true:left 2815/11700\n",
      "tensor([-0.0480,  0.0150])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左587_0_743_20200412_115140615_6.jpg\n",
      "pre:right true:left 2816/11700\n",
      "tensor([ 0.3474, -0.4269])\n",
      "pre:left true:left 2817/11700\n",
      "tensor([ 1.0465, -0.8760])\n",
      "pre:left true:left 2818/11700\n",
      "tensor([ 0.2532, -0.2971])\n",
      "pre:left true:left 2819/11700\n",
      "tensor([ 0.5176, -0.4476])\n",
      "pre:left true:left 2820/11700\n",
      "tensor([ 0.2955, -0.3652])\n",
      "pre:left true:left 2821/11700\n",
      "tensor([ 0.6796, -0.6605])\n",
      "pre:left true:left 2822/11700\n",
      "tensor([ 0.3436, -0.2549])\n",
      "pre:left true:left 2823/11700\n",
      "tensor([ 0.6329, -0.6304])\n",
      "pre:left true:left 2824/11700\n",
      "tensor([ 0.0175, -0.0476])\n",
      "pre:left true:left 2825/11700\n",
      "tensor([ 1.1477, -1.1024])\n",
      "pre:left true:left 2826/11700\n",
      "tensor([ 0.5939, -0.5495])\n",
      "pre:left true:left 2827/11700\n",
      "tensor([ 0.6016, -0.5395])\n",
      "pre:left true:left 2828/11700\n",
      "tensor([ 0.4552, -0.5093])\n",
      "pre:left true:left 2829/11700\n",
      "tensor([ 0.7835, -0.7823])\n",
      "pre:left true:left 2830/11700\n",
      "tensor([ 0.8640, -0.9434])\n",
      "pre:left true:left 2831/11700\n",
      "tensor([-0.4357,  0.4478])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1273_0_1273_20200412_112620448_9.jpg\n",
      "pre:right true:left 2832/11700\n",
      "tensor([ 0.4716, -0.4151])\n",
      "pre:left true:left 2833/11700\n",
      "tensor([ 0.7799, -0.7915])\n",
      "pre:left true:left 2834/11700\n",
      "tensor([ 1.1585, -1.1378])\n",
      "pre:left true:left 2835/11700\n",
      "tensor([ 0.9013, -0.9056])\n",
      "pre:left true:left 2836/11700\n",
      "tensor([ 1.6505, -1.5497])\n",
      "pre:left true:left 2837/11700\n",
      "tensor([ 0.1049, -0.0357])\n",
      "pre:left true:left 2838/11700\n",
      "tensor([ 0.6148, -0.6281])\n",
      "pre:left true:left 2839/11700\n",
      "tensor([-1.3805,  1.4773])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左423_0_579_20200412_114806868_6.jpg\n",
      "pre:right true:left 2840/11700\n",
      "tensor([ 0.8659, -0.8119])\n",
      "pre:left true:left 2841/11700\n",
      "tensor([ 0.5716, -0.5863])\n",
      "pre:left true:left 2842/11700\n",
      "tensor([-0.3041,  0.3252])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左625_0_781_20200412_115230120_5.jpg\n",
      "pre:right true:left 2843/11700\n",
      "tensor([ 0.8508, -0.8152])\n",
      "pre:left true:left 2844/11700\n",
      "tensor([-0.0146,  0.0401])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1448_0_1604_20200412_121022709_0.jpg\n",
      "pre:right true:left 2845/11700\n",
      "tensor([-0.9634,  1.0470])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左804_0_804_20200412_111555570.jpg\n",
      "pre:right true:left 2846/11700\n",
      "tensor([ 0.4745, -0.3840])\n",
      "pre:left true:left 2847/11700\n",
      "tensor([-0.0734,  0.0464])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左159_0_315_20200412_114222876_5.jpg\n",
      "pre:right true:left 2848/11700\n",
      "tensor([ 0.5748, -0.5469])\n",
      "pre:left true:left 2849/11700\n",
      "tensor([ 1.1974, -1.2759])\n",
      "pre:left true:left 2850/11700\n",
      "tensor([ 0.8749, -0.9686])\n",
      "pre:left true:left 2851/11700\n",
      "tensor([ 1.0221, -0.9907])\n",
      "pre:left true:left 2852/11700\n",
      "tensor([ 0.8918, -0.8337])\n",
      "pre:left true:left 2853/11700\n",
      "tensor([ 0.2815, -0.2763])\n",
      "pre:left true:left 2854/11700\n",
      "tensor([-0.3000,  0.3577])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左454_0_610_20200412_114847282_4.jpg\n",
      "pre:right true:left 2855/11700\n",
      "tensor([ 2.0298, -2.0067])\n",
      "pre:left true:left 2856/11700\n",
      "tensor([ 0.5234, -0.5090])\n",
      "pre:left true:left 2857/11700\n",
      "tensor([ 0.4167, -0.3129])\n",
      "pre:left true:left 2858/11700\n",
      "tensor([ 0.3293, -0.2492])\n",
      "pre:left true:left 2859/11700\n",
      "tensor([-0.4988,  0.4437])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左733_0_733_20200412_111414310_3.jpg\n",
      "pre:right true:left 2860/11700\n",
      "tensor([ 0.4313, -0.4363])\n",
      "pre:left true:left 2861/11700\n",
      "tensor([ 0.1720, -0.1852])\n",
      "pre:left true:left 2862/11700\n",
      "tensor([ 0.3861, -0.4246])\n",
      "pre:left true:left 2863/11700\n",
      "tensor([ 0.0830, -0.0533])\n",
      "pre:left true:left 2864/11700\n",
      "tensor([ 0.3110, -0.2840])\n",
      "pre:left true:left 2865/11700\n",
      "tensor([-0.1604,  0.2697])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1061_0_1061_20200412_112144181_8.jpg\n",
      "pre:right true:left 2866/11700\n",
      "tensor([0.1418, 0.0252])\n",
      "pre:left true:left 2867/11700\n",
      "tensor([-0.0094,  0.0547])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左647_0_803_20200412_115258799_10.jpg\n",
      "pre:right true:left 2868/11700\n",
      "tensor([ 0.8070, -0.7877])\n",
      "pre:left true:left 2869/11700\n",
      "tensor([ 0.2893, -0.2676])\n",
      "pre:left true:left 2870/11700\n",
      "tensor([ 0.2468, -0.2252])\n",
      "pre:left true:left 2871/11700\n",
      "tensor([ 0.4059, -0.4375])\n",
      "pre:left true:left 2872/11700\n",
      "tensor([ 0.0787, -0.0468])\n",
      "pre:left true:left 2873/11700\n",
      "tensor([ 1.1247, -1.0768])\n",
      "pre:left true:left 2874/11700\n",
      "tensor([ 0.4153, -0.2626])\n",
      "pre:left true:left 2875/11700\n",
      "tensor([ 0.3116, -0.3033])\n",
      "pre:left true:left 2876/11700\n",
      "tensor([ 1.2229, -1.2915])\n",
      "pre:left true:left 2877/11700\n",
      "tensor([-0.1605,  0.2293])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1608_0_1764_20200412_121351283_2.jpg\n",
      "pre:right true:left 2878/11700\n",
      "tensor([ 0.4536, -0.4961])\n",
      "pre:left true:left 2879/11700\n",
      "tensor([ 0.5488, -0.5333])\n",
      "pre:left true:left 2880/11700\n",
      "tensor([ 0.1040, -0.1165])\n",
      "pre:left true:left 2881/11700\n",
      "tensor([ 0.8191, -0.8316])\n",
      "pre:left true:left 2882/11700\n",
      "tensor([ 0.2846, -0.0977])\n",
      "pre:left true:left 2883/11700\n",
      "tensor([ 0.0005, -0.0423])\n",
      "pre:left true:left 2884/11700\n",
      "tensor([ 0.4429, -0.4718])\n",
      "pre:left true:left 2885/11700\n",
      "tensor([ 0.5597, -0.6307])\n",
      "pre:left true:left 2886/11700\n",
      "tensor([ 0.7855, -0.8307])\n",
      "pre:left true:left 2887/11700\n",
      "tensor([ 0.1540, -0.1564])\n",
      "pre:left true:left 2888/11700\n",
      "tensor([ 0.2470, -0.2095])\n",
      "pre:left true:left 2889/11700\n",
      "tensor([ 1.4233, -1.3772])\n",
      "pre:left true:left 2890/11700\n",
      "tensor([ 0.7311, -0.7723])\n",
      "pre:left true:left 2891/11700\n",
      "tensor([ 0.2355, -0.2332])\n",
      "pre:left true:left 2892/11700\n",
      "tensor([ 1.3777, -1.3705])\n",
      "pre:left true:left 2893/11700\n",
      "tensor([ 0.1899, -0.1682])\n",
      "pre:left true:left 2894/11700\n",
      "tensor([ 1.0366, -0.9930])\n",
      "pre:left true:left 2895/11700\n",
      "tensor([ 0.5067, -0.4908])\n",
      "pre:left true:left 2896/11700\n",
      "tensor([ 0.6244, -0.5563])\n",
      "pre:left true:left 2897/11700\n",
      "tensor([ 1.0943, -1.1293])\n",
      "pre:left true:left 2898/11700\n",
      "tensor([ 0.6788, -0.6483])\n",
      "pre:left true:left 2899/11700\n",
      "tensor([ 0.6551, -0.5562])\n",
      "pre:left true:left 2900/11700\n",
      "tensor([ 0.5679, -0.5102])\n",
      "pre:left true:left 2901/11700\n",
      "tensor([ 1.1291, -1.1711])\n",
      "pre:left true:left 2902/11700\n",
      "tensor([ 0.5399, -0.5141])\n",
      "pre:left true:left 2903/11700\n",
      "tensor([-0.0057,  0.1604])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左881_0_881_20200412_111745390_1.jpg\n",
      "pre:right true:left 2904/11700\n",
      "tensor([ 0.5566, -0.5951])\n",
      "pre:left true:left 2905/11700\n",
      "tensor([ 0.4346, -0.3914])\n",
      "pre:left true:left 2906/11700\n",
      "tensor([ 0.9423, -0.9303])\n",
      "pre:left true:left 2907/11700\n",
      "tensor([ 0.6978, -0.6007])\n",
      "pre:left true:left 2908/11700\n",
      "tensor([-0.9570,  0.9377])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左708_0_708_20200412_111338627_3.jpg\n",
      "pre:right true:left 2909/11700\n",
      "tensor([ 0.3674, -0.3299])\n",
      "pre:left true:left 2910/11700\n",
      "tensor([ 0.4639, -0.5214])\n",
      "pre:left true:left 2911/11700\n",
      "tensor([ 0.9512, -1.0173])\n",
      "pre:left true:left 2912/11700\n",
      "tensor([ 0.7977, -0.8799])\n",
      "pre:left true:left 2913/11700\n",
      "tensor([ 0.1616, -0.1888])\n",
      "pre:left true:left 2914/11700\n",
      "tensor([ 1.7621, -1.7133])\n",
      "pre:left true:left 2915/11700\n",
      "tensor([ 0.4797, -0.5172])\n",
      "pre:left true:left 2916/11700\n",
      "tensor([ 0.5408, -0.5173])\n",
      "pre:left true:left 2917/11700\n",
      "tensor([0.0195, 0.0200])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左698_0_854_20200412_115405273_10.jpg\n",
      "pre:right true:left 2918/11700\n",
      "tensor([ 1.0076, -0.9553])\n",
      "pre:left true:left 2919/11700\n",
      "tensor([ 0.0085, -0.0573])\n",
      "pre:left true:left 2920/11700\n",
      "tensor([-0.2540,  0.2976])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左888_0_888_20200412_111755369_9.jpg\n",
      "pre:right true:left 2921/11700\n",
      "tensor([ 0.6056, -0.5901])\n",
      "pre:left true:left 2922/11700\n",
      "tensor([ 0.7025, -0.6503])\n",
      "pre:left true:left 2923/11700\n",
      "tensor([ 0.5538, -0.5025])\n",
      "pre:left true:left 2924/11700\n",
      "tensor([-0.1549,  0.2235])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左617_0_617_20200412_111128829_0.jpg\n",
      "pre:right true:left 2925/11700\n",
      "tensor([ 0.5754, -0.5858])\n",
      "pre:left true:left 2926/11700\n",
      "tensor([ 1.1936, -1.1809])\n",
      "pre:left true:left 2927/11700\n",
      "tensor([-0.0331,  0.0322])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左156_0_156_20200412_110031305_10.jpg\n",
      "pre:right true:left 2928/11700\n",
      "tensor([ 0.5780, -0.5297])\n",
      "pre:left true:left 2929/11700\n",
      "tensor([ 0.3271, -0.2494])\n",
      "pre:left true:left 2930/11700\n",
      "tensor([ 0.2035, -0.1591])\n",
      "pre:left true:left 2931/11700\n",
      "tensor([ 0.8727, -0.7892])\n",
      "pre:left true:left 2932/11700\n",
      "tensor([ 0.1961, -0.1181])\n",
      "pre:left true:left 2933/11700\n",
      "tensor([ 0.2131, -0.2019])\n",
      "pre:left true:left 2934/11700\n",
      "tensor([-0.6705,  0.7629])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左83_0_239_20200412_114043836_3.jpg\n",
      "pre:right true:left 2935/11700\n",
      "tensor([-0.0557,  0.0912])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左741_0_741_20200412_111425707_0.jpg\n",
      "pre:right true:left 2936/11700\n",
      "tensor([ 0.1473, -0.2128])\n",
      "pre:left true:left 2937/11700\n",
      "tensor([ 0.4738, -0.4877])\n",
      "pre:left true:left 2938/11700\n",
      "tensor([ 1.0188, -1.0088])\n",
      "pre:left true:left 2939/11700\n",
      "tensor([ 1.0142, -0.8272])\n",
      "pre:left true:left 2940/11700\n",
      "tensor([ 1.2176, -1.2166])\n",
      "pre:left true:left 2941/11700\n",
      "tensor([ 0.6956, -0.7602])\n",
      "pre:left true:left 2942/11700\n",
      "tensor([ 0.4805, -0.4665])\n",
      "pre:left true:left 2943/11700\n",
      "tensor([ 0.6794, -0.6447])\n",
      "pre:left true:left 2944/11700\n",
      "tensor([ 1.3027, -1.2756])\n",
      "pre:left true:left 2945/11700\n",
      "tensor([-0.1701,  0.1617])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左712_0_868_20200412_115423513_8.jpg\n",
      "pre:right true:left 2946/11700\n",
      "tensor([ 0.7391, -0.5990])\n",
      "pre:left true:left 2947/11700\n",
      "tensor([-0.2164,  0.3132])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左808_0_808_20200412_111601263_9.jpg\n",
      "pre:right true:left 2948/11700\n",
      "tensor([ 0.0673, -0.0362])\n",
      "pre:left true:left 2949/11700\n",
      "tensor([-0.1246,  0.2210])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左357_0_357_20200412_110517970_4.jpg\n",
      "pre:right true:left 2950/11700\n",
      "tensor([ 0.7767, -0.7495])\n",
      "pre:left true:left 2951/11700\n",
      "tensor([ 0.5568, -0.5414])\n",
      "pre:left true:left 2952/11700\n",
      "tensor([ 0.9090, -0.8671])\n",
      "pre:left true:left 2953/11700\n",
      "tensor([ 1.4479, -1.4064])\n",
      "pre:left true:left 2954/11700\n",
      "tensor([ 0.4131, -0.3697])\n",
      "pre:left true:left 2955/11700\n",
      "tensor([ 0.5812, -0.5559])\n",
      "pre:left true:left 2956/11700\n",
      "tensor([ 0.7473, -0.8018])\n",
      "pre:left true:left 2957/11700\n",
      "tensor([ 0.4060, -0.4479])\n",
      "pre:left true:left 2958/11700\n",
      "tensor([ 0.9740, -0.9022])\n",
      "pre:left true:left 2959/11700\n",
      "tensor([ 0.3174, -0.4111])\n",
      "pre:left true:left 2960/11700\n",
      "tensor([ 0.9743, -1.0413])\n",
      "pre:left true:left 2961/11700\n",
      "tensor([ 1.0837, -1.0853])\n",
      "pre:left true:left 2962/11700\n",
      "tensor([ 1.1150, -1.1563])\n",
      "pre:left true:left 2963/11700\n",
      "tensor([ 0.9422, -0.9234])\n",
      "pre:left true:left 2964/11700\n",
      "tensor([ 0.2695, -0.2567])\n",
      "pre:left true:left 2965/11700\n",
      "tensor([ 0.3034, -0.2897])\n",
      "pre:left true:left 2966/11700\n",
      "tensor([ 0.8220, -0.7580])\n",
      "pre:left true:left 2967/11700\n",
      "tensor([ 0.1429, -0.1769])\n",
      "pre:left true:left 2968/11700\n",
      "tensor([ 0.9261, -0.8837])\n",
      "pre:left true:left 2969/11700\n",
      "tensor([-0.0773,  0.1570])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左471_0_471_20200412_110800583_9.jpg\n",
      "pre:right true:left 2970/11700\n",
      "tensor([ 0.3989, -0.3972])\n",
      "pre:left true:left 2971/11700\n",
      "tensor([ 0.5848, -0.5928])\n",
      "pre:left true:left 2972/11700\n",
      "tensor([ 0.7287, -0.8182])\n",
      "pre:left true:left 2973/11700\n",
      "tensor([0.0428, 0.0082])\n",
      "pre:left true:left 2974/11700\n",
      "tensor([ 0.4594, -0.4237])\n",
      "pre:left true:left 2975/11700\n",
      "tensor([ 0.9910, -0.9879])\n",
      "pre:left true:left 2976/11700\n",
      "tensor([ 0.1620, -0.1382])\n",
      "pre:left true:left 2977/11700\n",
      "tensor([ 0.0715, -0.0559])\n",
      "pre:left true:left 2978/11700\n",
      "tensor([-0.5409,  0.5977])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左608_0_764_20200412_115207969_9.jpg\n",
      "pre:right true:left 2979/11700\n",
      "tensor([ 0.5985, -0.6651])\n",
      "pre:left true:left 2980/11700\n",
      "tensor([ 0.3123, -0.2763])\n",
      "pre:left true:left 2981/11700\n",
      "tensor([ 0.8630, -0.8756])\n",
      "pre:left true:left 2982/11700\n",
      "tensor([ 0.6051, -0.6195])\n",
      "pre:left true:left 2983/11700\n",
      "tensor([ 0.7448, -0.7104])\n",
      "pre:left true:left 2984/11700\n",
      "tensor([ 0.1848, -0.1338])\n",
      "pre:left true:left 2985/11700\n",
      "tensor([ 0.4694, -0.5436])\n",
      "pre:left true:left 2986/11700\n",
      "tensor([ 0.6799, -0.8138])\n",
      "pre:left true:left 2987/11700\n",
      "tensor([ 1.2152, -1.2884])\n",
      "pre:left true:left 2988/11700\n",
      "tensor([-0.0027,  0.1011])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1134_0_1134_20200412_112319312_4.jpg\n",
      "pre:right true:left 2989/11700\n",
      "tensor([ 0.6194, -0.6835])\n",
      "pre:left true:left 2990/11700\n",
      "tensor([ 0.5607, -0.4572])\n",
      "pre:left true:left 2991/11700\n",
      "tensor([ 0.4225, -0.3623])\n",
      "pre:left true:left 2992/11700\n",
      "tensor([ 0.4334, -0.3564])\n",
      "pre:left true:left 2993/11700\n",
      "tensor([ 0.4758, -0.5128])\n",
      "pre:left true:left 2994/11700\n",
      "tensor([ 1.2018, -1.2341])\n",
      "pre:left true:left 2995/11700\n",
      "tensor([ 0.6370, -0.6475])\n",
      "pre:left true:left 2996/11700\n",
      "tensor([ 0.1439, -0.1991])\n",
      "pre:left true:left 2997/11700\n",
      "tensor([ 1.0576, -1.0280])\n",
      "pre:left true:left 2998/11700\n",
      "tensor([ 0.2383, -0.1738])\n",
      "pre:left true:left 2999/11700\n",
      "tensor([ 2.0298, -2.0067])\n",
      "pre:left true:left 3000/11700\n",
      "tensor([ 0.7721, -0.7818])\n",
      "pre:left true:left 3001/11700\n",
      "tensor([ 0.1365, -0.0727])\n",
      "pre:left true:left 3002/11700\n",
      "tensor([ 0.5040, -0.4366])\n",
      "pre:left true:left 3003/11700\n",
      "tensor([ 1.1203, -1.2052])\n",
      "pre:left true:left 3004/11700\n",
      "tensor([ 1.0718, -1.1573])\n",
      "pre:left true:left 3005/11700\n",
      "tensor([-0.1499,  0.0887])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1046_0_1046_20200412_112124639.jpg\n",
      "pre:right true:left 3006/11700\n",
      "tensor([ 1.2940, -1.2930])\n",
      "pre:left true:left 3007/11700\n",
      "tensor([ 1.0210, -0.9350])\n",
      "pre:left true:left 3008/11700\n",
      "tensor([ 0.9364, -1.0010])\n",
      "pre:left true:left 3009/11700\n",
      "tensor([ 0.9836, -0.9656])\n",
      "pre:left true:left 3010/11700\n",
      "tensor([ 0.8907, -0.9308])\n",
      "pre:left true:left 3011/11700\n",
      "tensor([ 0.5501, -0.5143])\n",
      "pre:left true:left 3012/11700\n",
      "tensor([-0.1432,  0.2074])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左807_0_963_20200412_115627339.jpg\n",
      "pre:right true:left 3013/11700\n",
      "tensor([-0.0464,  0.0321])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左617_0_617_20200412_111128829_4.jpg\n",
      "pre:right true:left 3014/11700\n",
      "tensor([ 0.6619, -0.6773])\n",
      "pre:left true:left 3015/11700\n",
      "tensor([-0.1256,  0.1701])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左475_0_475_20200412_110806277_2.jpg\n",
      "pre:right true:left 3016/11700\n",
      "tensor([ 0.8251, -0.7591])\n",
      "pre:left true:left 3017/11700\n",
      "tensor([ 0.4123, -0.4321])\n",
      "pre:left true:left 3018/11700\n",
      "tensor([ 0.0979, -0.0789])\n",
      "pre:left true:left 3019/11700\n",
      "tensor([ 0.1832, -0.0534])\n",
      "pre:left true:left 3020/11700\n",
      "tensor([ 0.2159, -0.1985])\n",
      "pre:left true:left 3021/11700\n",
      "tensor([ 0.7846, -0.7639])\n",
      "pre:left true:left 3022/11700\n",
      "tensor([ 0.1135, -0.0393])\n",
      "pre:left true:left 3023/11700\n",
      "tensor([ 0.8680, -0.7776])\n",
      "pre:left true:left 3024/11700\n",
      "tensor([ 1.4303, -1.4393])\n",
      "pre:left true:left 3025/11700\n",
      "tensor([ 0.7412, -0.6543])\n",
      "pre:left true:left 3026/11700\n",
      "tensor([ 1.2182, -1.3074])\n",
      "pre:left true:left 3027/11700\n",
      "tensor([ 0.5543, -0.4995])\n",
      "pre:left true:left 3028/11700\n",
      "tensor([ 0.1459, -0.0217])\n",
      "pre:left true:left 3029/11700\n",
      "tensor([-0.0960,  0.1785])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左743_0_899_20200412_115503912_6.jpg\n",
      "pre:right true:left 3030/11700\n",
      "tensor([ 0.3793, -0.3450])\n",
      "pre:left true:left 3031/11700\n",
      "tensor([ 1.0017, -0.9561])\n",
      "pre:left true:left 3032/11700\n",
      "tensor([ 1.4098, -1.4688])\n",
      "pre:left true:left 3033/11700\n",
      "tensor([ 0.0315, -0.0711])\n",
      "pre:left true:left 3034/11700\n",
      "tensor([ 0.5693, -0.5050])\n",
      "pre:left true:left 3035/11700\n",
      "tensor([ 0.9628, -0.9409])\n",
      "pre:left true:left 3036/11700\n",
      "tensor([0.0420, 0.0858])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左658_0_814_20200412_115313134_10.jpg\n",
      "pre:right true:left 3037/11700\n",
      "tensor([ 1.0673, -1.1064])\n",
      "pre:left true:left 3038/11700\n",
      "tensor([-0.0939,  0.2395])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1573_0_1729_20200412_121305657_8.jpg\n",
      "pre:right true:left 3039/11700\n",
      "tensor([ 0.1559, -0.1698])\n",
      "pre:left true:left 3040/11700\n",
      "tensor([ 0.2466, -0.2480])\n",
      "pre:left true:left 3041/11700\n",
      "tensor([-0.1083,  0.2124])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左853_0_1009_20200412_115727284_9.jpg\n",
      "pre:right true:left 3042/11700\n",
      "tensor([ 0.6299, -0.6029])\n",
      "pre:left true:left 3043/11700\n",
      "tensor([ 1.0007, -0.9538])\n",
      "pre:left true:left 3044/11700\n",
      "tensor([ 1.3512, -1.4457])\n",
      "pre:left true:left 3045/11700\n",
      "tensor([ 0.6229, -0.4739])\n",
      "pre:left true:left 3046/11700\n",
      "tensor([ 0.4849, -0.4144])\n",
      "pre:left true:left 3047/11700\n",
      "tensor([ 0.6848, -0.6898])\n",
      "pre:left true:left 3048/11700\n",
      "tensor([-0.3277,  0.3293])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1110_0_1266_20200412_120302191_9.jpg\n",
      "pre:right true:left 3049/11700\n",
      "tensor([ 0.6317, -0.7635])\n",
      "pre:left true:left 3050/11700\n",
      "tensor([ 0.3547, -0.1860])\n",
      "pre:left true:left 3051/11700\n",
      "tensor([-0.2071,  0.2316])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1116_0_1116_20200412_112255854_4.jpg\n",
      "pre:right true:left 3052/11700\n",
      "tensor([ 0.2503, -0.1826])\n",
      "pre:left true:left 3053/11700\n",
      "tensor([ 0.7588, -0.6227])\n",
      "pre:left true:left 3054/11700\n",
      "tensor([ 0.7418, -0.7173])\n",
      "pre:left true:left 3055/11700\n",
      "tensor([ 0.7099, -0.6429])\n",
      "pre:left true:left 3056/11700\n",
      "tensor([ 0.2613, -0.2324])\n",
      "pre:left true:left 3057/11700\n",
      "tensor([ 0.4395, -0.3877])\n",
      "pre:left true:left 3058/11700\n",
      "tensor([0.0247, 0.0511])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左789_0_945_20200412_115603865_8.jpg\n",
      "pre:right true:left 3059/11700\n",
      "tensor([ 0.9552, -0.9679])\n",
      "pre:left true:left 3060/11700\n",
      "tensor([-0.1257,  0.0696])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左625_0_781_20200412_115230120_3.jpg\n",
      "pre:right true:left 3061/11700\n",
      "tensor([ 0.6730, -0.6859])\n",
      "pre:left true:left 3062/11700\n",
      "tensor([ 0.4894, -0.5721])\n",
      "pre:left true:left 3063/11700\n",
      "tensor([ 0.1500, -0.1273])\n",
      "pre:left true:left 3064/11700\n",
      "tensor([ 0.2510, -0.1433])\n",
      "pre:left true:left 3065/11700\n",
      "tensor([ 0.4180, -0.4787])\n",
      "pre:left true:left 3066/11700\n",
      "tensor([ 0.1722, -0.0800])\n",
      "pre:left true:left 3067/11700\n",
      "tensor([0.0062, 0.0458])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1169_0_1169_20200412_112404918_3.jpg\n",
      "pre:right true:left 3068/11700\n",
      "tensor([-0.1892,  0.1951])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左984_0_984_20200412_112003866_0.jpg\n",
      "pre:right true:left 3069/11700\n",
      "tensor([ 0.8680, -0.8744])\n",
      "pre:left true:left 3070/11700\n",
      "tensor([ 0.2351, -0.1622])\n",
      "pre:left true:left 3071/11700\n",
      "tensor([ 0.7864, -0.7770])\n",
      "pre:left true:left 3072/11700\n",
      "tensor([ 0.4773, -0.4966])\n",
      "pre:left true:left 3073/11700\n",
      "tensor([ 0.0777, -0.0316])\n",
      "pre:left true:left 3074/11700\n",
      "tensor([ 0.5137, -0.5561])\n",
      "pre:left true:left 3075/11700\n",
      "tensor([ 1.1448, -1.0858])\n",
      "pre:left true:left 3076/11700\n",
      "tensor([ 0.1878, -0.2044])\n",
      "pre:left true:left 3077/11700\n",
      "tensor([ 0.1998, -0.1229])\n",
      "pre:left true:left 3078/11700\n",
      "tensor([ 0.4860, -0.5055])\n",
      "pre:left true:left 3079/11700\n",
      "tensor([ 0.3341, -0.3142])\n",
      "pre:left true:left 3080/11700\n",
      "tensor([ 1.0153, -1.0611])\n",
      "pre:left true:left 3081/11700\n",
      "tensor([ 1.5531, -1.5745])\n",
      "pre:left true:left 3082/11700\n",
      "tensor([ 0.7081, -0.7584])\n",
      "pre:left true:left 3083/11700\n",
      "tensor([ 0.6675, -0.6238])\n",
      "pre:left true:left 3084/11700\n",
      "tensor([ 0.1552, -0.2417])\n",
      "pre:left true:left 3085/11700\n",
      "tensor([ 0.8779, -0.8482])\n",
      "pre:left true:left 3086/11700\n",
      "tensor([ 1.5258, -1.4582])\n",
      "pre:left true:left 3087/11700\n",
      "tensor([-0.1665,  0.1530])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左703_0_859_20200412_115411771_10.jpg\n",
      "pre:right true:left 3088/11700\n",
      "tensor([ 0.4185, -0.4482])\n",
      "pre:left true:left 3089/11700\n",
      "tensor([ 0.9402, -0.8340])\n",
      "pre:left true:left 3090/11700\n",
      "tensor([ 0.0803, -0.1324])\n",
      "pre:left true:left 3091/11700\n",
      "tensor([ 0.7812, -0.7418])\n",
      "pre:left true:left 3092/11700\n",
      "tensor([ 0.5847, -0.5125])\n",
      "pre:left true:left 3093/11700\n",
      "tensor([ 0.8484, -0.7898])\n",
      "pre:left true:left 3094/11700\n",
      "tensor([ 0.3395, -0.2738])\n",
      "pre:left true:left 3095/11700\n",
      "tensor([ 0.2336, -0.2873])\n",
      "pre:left true:left 3096/11700\n",
      "tensor([ 0.9892, -0.9892])\n",
      "pre:left true:left 3097/11700\n",
      "tensor([ 0.1912, -0.1245])\n",
      "pre:left true:left 3098/11700\n",
      "tensor([-0.1047,  0.1658])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左637_0_793_20200412_115245771.jpg\n",
      "pre:right true:left 3099/11700\n",
      "tensor([ 0.9432, -0.9327])\n",
      "pre:left true:left 3100/11700\n",
      "tensor([ 1.4862, -1.4982])\n",
      "pre:left true:left 3101/11700\n",
      "tensor([ 0.4337, -0.4144])\n",
      "pre:left true:left 3102/11700\n",
      "tensor([ 1.2474, -1.2688])\n",
      "pre:left true:left 3103/11700\n",
      "tensor([ 0.5066, -0.4556])\n",
      "pre:left true:left 3104/11700\n",
      "tensor([ 0.8559, -0.8695])\n",
      "pre:left true:left 3105/11700\n",
      "tensor([ 1.1070, -1.1460])\n",
      "pre:left true:left 3106/11700\n",
      "tensor([ 0.3885, -0.4587])\n",
      "pre:left true:left 3107/11700\n",
      "tensor([ 0.4617, -0.4779])\n",
      "pre:left true:left 3108/11700\n",
      "tensor([ 1.5915, -1.7238])\n",
      "pre:left true:left 3109/11700\n",
      "tensor([ 0.8642, -0.9553])\n",
      "pre:left true:left 3110/11700\n",
      "tensor([ 0.5823, -0.5907])\n",
      "pre:left true:left 3111/11700\n",
      "tensor([ 0.3959, -0.3326])\n",
      "pre:left true:left 3112/11700\n",
      "tensor([ 0.7158, -0.7735])\n",
      "pre:left true:left 3113/11700\n",
      "tensor([-0.2296,  0.1717])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左797_0_953_20200412_115614298_0.jpg\n",
      "pre:right true:left 3114/11700\n",
      "tensor([ 0.6227, -0.5400])\n",
      "pre:left true:left 3115/11700\n",
      "tensor([ 0.3894, -0.4682])\n",
      "pre:left true:left 3116/11700\n",
      "tensor([ 0.9161, -0.9919])\n",
      "pre:left true:left 3117/11700\n",
      "tensor([ 1.0976, -1.0626])\n",
      "pre:left true:left 3118/11700\n",
      "tensor([-0.0446, -0.0071])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左96_0_252_20200412_114100770_0.jpg\n",
      "pre:right true:left 3119/11700\n",
      "tensor([ 1.3176, -1.2596])\n",
      "pre:left true:left 3120/11700\n",
      "tensor([ 0.3543, -0.3805])\n",
      "pre:left true:left 3121/11700\n",
      "tensor([-0.6149,  0.7020])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左820_0_976_20200412_115644262_6.jpg\n",
      "pre:right true:left 3122/11700\n",
      "tensor([0.0240, 0.0481])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左737_0_893_20200412_115456089_1.jpg\n",
      "pre:right true:left 3123/11700\n",
      "tensor([-0.1651,  0.2056])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左592_0_592_20200412_111053164_2.jpg\n",
      "pre:right true:left 3124/11700\n",
      "tensor([ 0.0179, -0.0334])\n",
      "pre:left true:left 3125/11700\n",
      "tensor([ 0.9968, -1.0116])\n",
      "pre:left true:left 3126/11700\n",
      "tensor([ 0.1384, -0.1443])\n",
      "pre:left true:left 3127/11700\n",
      "tensor([ 0.8443, -0.8538])\n",
      "pre:left true:left 3128/11700\n",
      "tensor([ 0.3427, -0.3038])\n",
      "pre:left true:left 3129/11700\n",
      "tensor([ 1.4970, -1.4259])\n",
      "pre:left true:left 3130/11700\n",
      "tensor([ 1.5600, -1.6599])\n",
      "pre:left true:left 3131/11700\n",
      "tensor([ 1.9831, -2.0195])\n",
      "pre:left true:left 3132/11700\n",
      "tensor([ 1.4048, -1.4855])\n",
      "pre:left true:left 3133/11700\n",
      "tensor([ 0.1146, -0.1373])\n",
      "pre:left true:left 3134/11700\n",
      "tensor([ 1.0876, -1.1314])\n",
      "pre:left true:left 3135/11700\n",
      "tensor([-0.3306,  0.4285])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左519_0_675_20200412_115011993.jpg\n",
      "pre:right true:left 3136/11700\n",
      "tensor([ 0.9952, -0.9325])\n",
      "pre:left true:left 3137/11700\n",
      "tensor([ 0.7331, -0.7777])\n",
      "pre:left true:left 3138/11700\n",
      "tensor([ 0.7693, -0.7169])\n",
      "pre:left true:left 3139/11700\n",
      "tensor([ 0.4013, -0.4138])\n",
      "pre:left true:left 3140/11700\n",
      "tensor([ 0.5043, -0.4422])\n",
      "pre:left true:left 3141/11700\n",
      "tensor([ 1.1012, -1.1681])\n",
      "pre:left true:left 3142/11700\n",
      "tensor([ 0.1170, -0.1051])\n",
      "pre:left true:left 3143/11700\n",
      "tensor([ 1.1739, -1.2434])\n",
      "pre:left true:left 3144/11700\n",
      "tensor([ 1.8186, -1.8814])\n",
      "pre:left true:left 3145/11700\n",
      "tensor([ 1.3524, -1.3199])\n",
      "pre:left true:left 3146/11700\n",
      "tensor([ 0.1600, -0.1623])\n",
      "pre:left true:left 3147/11700\n",
      "tensor([-0.1216,  0.0958])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左699_0_855_20200412_115406565_9.jpg\n",
      "pre:right true:left 3148/11700\n",
      "tensor([ 0.0620, -0.0474])\n",
      "pre:left true:left 3149/11700\n",
      "tensor([ 0.3620, -0.3534])\n",
      "pre:left true:left 3150/11700\n",
      "tensor([ 0.2577, -0.2366])\n",
      "pre:left true:left 3151/11700\n",
      "tensor([ 0.8467, -0.8691])\n",
      "pre:left true:left 3152/11700\n",
      "tensor([ 0.3847, -0.4406])\n",
      "pre:left true:left 3153/11700\n",
      "tensor([ 0.7915, -0.7234])\n",
      "pre:left true:left 3154/11700\n",
      "tensor([ 0.6224, -0.6499])\n",
      "pre:left true:left 3155/11700\n",
      "tensor([ 0.8456, -0.7261])\n",
      "pre:left true:left 3156/11700\n",
      "tensor([ 0.8489, -0.8201])\n",
      "pre:left true:left 3157/11700\n",
      "tensor([-0.6938,  0.6334])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左457_0_613_20200412_114851184_3.jpg\n",
      "pre:right true:left 3158/11700\n",
      "tensor([ 0.3041, -0.3015])\n",
      "pre:left true:left 3159/11700\n",
      "tensor([-0.0514,  0.1001])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左116_0_116_20200412_105934251_1.jpg\n",
      "pre:right true:left 3160/11700\n",
      "tensor([ 0.3959, -0.3403])\n",
      "pre:left true:left 3161/11700\n",
      "tensor([ 0.5499, -0.5525])\n",
      "pre:left true:left 3162/11700\n",
      "tensor([ 0.1600, -0.1488])\n",
      "pre:left true:left 3163/11700\n",
      "tensor([ 0.6883, -0.6885])\n",
      "pre:left true:left 3164/11700\n",
      "tensor([ 1.4422, -1.4645])\n",
      "pre:left true:left 3165/11700\n",
      "tensor([ 1.1255, -1.1180])\n",
      "pre:left true:left 3166/11700\n",
      "tensor([ 0.5775, -0.5956])\n",
      "pre:left true:left 3167/11700\n",
      "tensor([ 0.7297, -0.7987])\n",
      "pre:left true:left 3168/11700\n",
      "tensor([ 0.2191, -0.0985])\n",
      "pre:left true:left 3169/11700\n",
      "tensor([-0.0905,  0.0853])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左751_0_907_20200412_115514344_2.jpg\n",
      "pre:right true:left 3170/11700\n",
      "tensor([ 0.6447, -0.6305])\n",
      "pre:left true:left 3171/11700\n",
      "tensor([ 0.6214, -0.5749])\n",
      "pre:left true:left 3172/11700\n",
      "tensor([ 0.5681, -0.5801])\n",
      "pre:left true:left 3173/11700\n",
      "tensor([ 0.2581, -0.1918])\n",
      "pre:left true:left 3174/11700\n",
      "tensor([ 0.6978, -0.7741])\n",
      "pre:left true:left 3175/11700\n",
      "tensor([ 0.8089, -0.7601])\n",
      "pre:left true:left 3176/11700\n",
      "tensor([ 0.7825, -0.8045])\n",
      "pre:left true:left 3177/11700\n",
      "tensor([ 0.6475, -0.5942])\n",
      "pre:left true:left 3178/11700\n",
      "tensor([ 0.5024, -0.4359])\n",
      "pre:left true:left 3179/11700\n",
      "tensor([ 0.5402, -0.4886])\n",
      "pre:left true:left 3180/11700\n",
      "tensor([ 0.4537, -0.4477])\n",
      "pre:left true:left 3181/11700\n",
      "tensor([ 0.1801, -0.1484])\n",
      "pre:left true:left 3182/11700\n",
      "tensor([ 0.6815, -0.6390])\n",
      "pre:left true:left 3183/11700\n",
      "tensor([-0.2462,  0.2689])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左344_0_500_20200412_114623927_9.jpg\n",
      "pre:right true:left 3184/11700\n",
      "tensor([ 0.1823, -0.1414])\n",
      "pre:left true:left 3185/11700\n",
      "tensor([ 0.3350, -0.4077])\n",
      "pre:left true:left 3186/11700\n",
      "tensor([ 0.7830, -0.7364])\n",
      "pre:left true:left 3187/11700\n",
      "tensor([ 0.7115, -0.6857])\n",
      "pre:left true:left 3188/11700\n",
      "tensor([-0.8573,  0.7711])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左616_0_772_20200412_115218396_3.jpg\n",
      "pre:right true:left 3189/11700\n",
      "tensor([ 0.1508, -0.1286])\n",
      "pre:left true:left 3190/11700\n",
      "tensor([ 0.2861, -0.3191])\n",
      "pre:left true:left 3191/11700\n",
      "tensor([ 0.6200, -0.6745])\n",
      "pre:left true:left 3192/11700\n",
      "tensor([ 0.7694, -0.8683])\n",
      "pre:left true:left 3193/11700\n",
      "tensor([ 0.0072, -0.0266])\n",
      "pre:left true:left 3194/11700\n",
      "tensor([ 0.7684, -0.7487])\n",
      "pre:left true:left 3195/11700\n",
      "tensor([ 0.4242, -0.4301])\n",
      "pre:left true:left 3196/11700\n",
      "tensor([ 0.5635, -0.5423])\n",
      "pre:left true:left 3197/11700\n",
      "tensor([ 0.8715, -0.7781])\n",
      "pre:left true:left 3198/11700\n",
      "tensor([-0.0693,  0.1048])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左269_0_425_20200412_114446204_3.jpg\n",
      "pre:right true:left 3199/11700\n",
      "tensor([ 0.7446, -0.7565])\n",
      "pre:left true:left 3200/11700\n",
      "tensor([0.0864, 0.0376])\n",
      "pre:left true:left 3201/11700\n",
      "tensor([0.0441, 0.0794])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左340_0_496_20200412_114618732_4.jpg\n",
      "pre:right true:left 3202/11700\n",
      "tensor([ 0.1318, -0.0260])\n",
      "pre:left true:left 3203/11700\n",
      "tensor([-0.0561,  0.0402])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左515_0_515_20200412_110903344_5.jpg\n",
      "pre:right true:left 3204/11700\n",
      "tensor([ 1.0738, -1.1183])\n",
      "pre:left true:left 3205/11700\n",
      "tensor([ 0.8930, -0.9198])\n",
      "pre:left true:left 3206/11700\n",
      "tensor([ 0.7799, -0.8462])\n",
      "pre:left true:left 3207/11700\n",
      "tensor([ 0.2915, -0.2504])\n",
      "pre:left true:left 3208/11700\n",
      "tensor([ 0.8248, -0.8651])\n",
      "pre:left true:left 3209/11700\n",
      "tensor([ 1.6287, -1.7014])\n",
      "pre:left true:left 3210/11700\n",
      "tensor([ 0.2274, -0.2317])\n",
      "pre:left true:left 3211/11700\n",
      "tensor([ 0.8432, -0.8311])\n",
      "pre:left true:left 3212/11700\n",
      "tensor([ 0.5834, -0.6055])\n",
      "pre:left true:left 3213/11700\n",
      "tensor([ 1.2314, -1.2194])\n",
      "pre:left true:left 3214/11700\n",
      "tensor([ 0.5643, -0.6006])\n",
      "pre:left true:left 3215/11700\n",
      "tensor([ 0.4600, -0.4782])\n",
      "pre:left true:left 3216/11700\n",
      "tensor([ 0.1826, -0.2492])\n",
      "pre:left true:left 3217/11700\n",
      "tensor([ 0.4005, -0.3030])\n",
      "pre:left true:left 3218/11700\n",
      "tensor([ 0.3507, -0.3061])\n",
      "pre:left true:left 3219/11700\n",
      "tensor([ 0.7507, -0.7319])\n",
      "pre:left true:left 3220/11700\n",
      "tensor([ 1.0427, -1.1137])\n",
      "pre:left true:left 3221/11700\n",
      "tensor([ 0.2614, -0.2627])\n",
      "pre:left true:left 3222/11700\n",
      "tensor([ 0.6427, -0.6492])\n",
      "pre:left true:left 3223/11700\n",
      "tensor([ 0.2029, -0.0847])\n",
      "pre:left true:left 3224/11700\n",
      "tensor([ 1.1337, -1.1444])\n",
      "pre:left true:left 3225/11700\n",
      "tensor([ 0.7618, -0.7508])\n",
      "pre:left true:left 3226/11700\n",
      "tensor([ 0.3190, -0.3105])\n",
      "pre:left true:left 3227/11700\n",
      "tensor([-1.2190,  1.2258])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左431_0_587_20200412_114817293_2.jpg\n",
      "pre:right true:left 3228/11700\n",
      "tensor([ 0.7321, -0.7355])\n",
      "pre:left true:left 3229/11700\n",
      "tensor([ 0.5418, -0.5743])\n",
      "pre:left true:left 3230/11700\n",
      "tensor([ 0.0889, -0.0316])\n",
      "pre:left true:left 3231/11700\n",
      "tensor([ 0.6994, -0.7535])\n",
      "pre:left true:left 3232/11700\n",
      "tensor([ 0.4466, -0.4042])\n",
      "pre:left true:left 3233/11700\n",
      "tensor([ 1.1049, -1.1710])\n",
      "pre:left true:left 3234/11700\n",
      "tensor([-0.0522,  0.1742])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1116_0_1116_20200412_112255854_2.jpg\n",
      "pre:right true:left 3235/11700\n",
      "tensor([ 1.7566, -1.8245])\n",
      "pre:left true:left 3236/11700\n",
      "tensor([ 0.1690, -0.0466])\n",
      "pre:left true:left 3237/11700\n",
      "tensor([ 0.5852, -0.5133])\n",
      "pre:left true:left 3238/11700\n",
      "tensor([ 0.5456, -0.6537])\n",
      "pre:left true:left 3239/11700\n",
      "tensor([ 0.1260, -0.0614])\n",
      "pre:left true:left 3240/11700\n",
      "tensor([ 0.9493, -0.7882])\n",
      "pre:left true:left 3241/11700\n",
      "tensor([ 0.8255, -0.7230])\n",
      "pre:left true:left 3242/11700\n",
      "tensor([ 0.8111, -0.7963])\n",
      "pre:left true:left 3243/11700\n",
      "tensor([ 0.1749, -0.1965])\n",
      "pre:left true:left 3244/11700\n",
      "tensor([ 0.5253, -0.5185])\n",
      "pre:left true:left 3245/11700\n",
      "tensor([ 0.4967, -0.4621])\n",
      "pre:left true:left 3246/11700\n",
      "tensor([ 0.8763, -0.8959])\n",
      "pre:left true:left 3247/11700\n",
      "tensor([-0.0971,  0.2566])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左774_0_774_20200412_111512774_9.jpg\n",
      "pre:right true:left 3248/11700\n",
      "tensor([-0.1715,  0.1691])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1608_0_1764_20200412_121351283_1.jpg\n",
      "pre:right true:left 3249/11700\n",
      "tensor([ 0.0683, -0.0756])\n",
      "pre:left true:left 3250/11700\n",
      "tensor([ 0.4020, -0.4103])\n",
      "pre:left true:left 3251/11700\n",
      "tensor([ 0.1950, -0.2122])\n",
      "pre:left true:left 3252/11700\n",
      "tensor([ 0.4783, -0.4031])\n",
      "pre:left true:left 3253/11700\n",
      "tensor([ 1.7129, -1.7097])\n",
      "pre:left true:left 3254/11700\n",
      "tensor([-0.4663,  0.3951])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1283_0_1283_20200412_112633476_4.jpg\n",
      "pre:right true:left 3255/11700\n",
      "tensor([ 0.8120, -0.8404])\n",
      "pre:left true:left 3256/11700\n",
      "tensor([ 0.7493, -0.7695])\n",
      "pre:left true:left 3257/11700\n",
      "tensor([ 0.4880, -0.4300])\n",
      "pre:left true:left 3258/11700\n",
      "tensor([-0.1512,  0.0673])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左175_0_175_20200412_110058390_2.jpg\n",
      "pre:right true:left 3259/11700\n",
      "tensor([ 0.5062, -0.4992])\n",
      "pre:left true:left 3260/11700\n",
      "tensor([ 0.7940, -0.8556])\n",
      "pre:left true:left 3261/11700\n",
      "tensor([ 0.2967, -0.3204])\n",
      "pre:left true:left 3262/11700\n",
      "tensor([ 0.1435, -0.1133])\n",
      "pre:left true:left 3263/11700\n",
      "tensor([ 0.5596, -0.6460])\n",
      "pre:left true:left 3264/11700\n",
      "tensor([ 0.6902, -0.6239])\n",
      "pre:left true:left 3265/11700\n",
      "tensor([ 0.3857, -0.3874])\n",
      "pre:left true:left 3266/11700\n",
      "tensor([ 0.1559, -0.1698])\n",
      "pre:left true:left 3267/11700\n",
      "tensor([ 0.2315, -0.2688])\n",
      "pre:left true:left 3268/11700\n",
      "tensor([ 0.5575, -0.4943])\n",
      "pre:left true:left 3269/11700\n",
      "tensor([ 0.9321, -0.9238])\n",
      "pre:left true:left 3270/11700\n",
      "tensor([ 0.2879, -0.2019])\n",
      "pre:left true:left 3271/11700\n",
      "tensor([ 0.6320, -0.6261])\n",
      "pre:left true:left 3272/11700\n",
      "tensor([ 0.3827, -0.4149])\n",
      "pre:left true:left 3273/11700\n",
      "tensor([ 0.3304, -0.3861])\n",
      "pre:left true:left 3274/11700\n",
      "tensor([ 0.8945, -0.8564])\n",
      "pre:left true:left 3275/11700\n",
      "tensor([ 0.2318, -0.2861])\n",
      "pre:left true:left 3276/11700\n",
      "tensor([ 0.3860, -0.3690])\n",
      "pre:left true:left 3277/11700\n",
      "tensor([-0.7740,  0.7504])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1152_0_1308_20200412_120356950_0.jpg\n",
      "pre:right true:left 3278/11700\n",
      "tensor([ 1.2705, -1.2746])\n",
      "pre:left true:left 3279/11700\n",
      "tensor([ 0.4570, -0.4827])\n",
      "pre:left true:left 3280/11700\n",
      "tensor([ 1.0299, -0.9587])\n",
      "pre:left true:left 3281/11700\n",
      "tensor([ 0.7535, -0.6910])\n",
      "pre:left true:left 3282/11700\n",
      "tensor([-0.2448,  0.2574])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左696_0_852_20200412_115402654_5.jpg\n",
      "pre:right true:left 3283/11700\n",
      "tensor([-0.1401,  0.1496])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左822_0_978_20200412_115646880_0.jpg\n",
      "pre:right true:left 3284/11700\n",
      "tensor([ 0.4400, -0.4895])\n",
      "pre:left true:left 3285/11700\n",
      "tensor([ 0.1599, -0.0476])\n",
      "pre:left true:left 3286/11700\n",
      "tensor([ 0.5798, -0.5057])\n",
      "pre:left true:left 3287/11700\n",
      "tensor([ 0.8555, -0.7486])\n",
      "pre:left true:left 3288/11700\n",
      "tensor([ 0.2933, -0.2252])\n",
      "pre:left true:left 3289/11700\n",
      "tensor([ 1.0692, -1.0339])\n",
      "pre:left true:left 3290/11700\n",
      "tensor([ 0.2305, -0.2462])\n",
      "pre:left true:left 3291/11700\n",
      "tensor([ 0.1514, -0.1857])\n",
      "pre:left true:left 3292/11700\n",
      "tensor([ 0.5657, -0.6030])\n",
      "pre:left true:left 3293/11700\n",
      "tensor([-0.3071,  0.3656])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左175_0_331_20200412_114243715_9.jpg\n",
      "pre:right true:left 3294/11700\n",
      "tensor([ 0.9232, -0.9260])\n",
      "pre:left true:left 3295/11700\n",
      "tensor([ 0.3428, -0.2849])\n",
      "pre:left true:left 3296/11700\n",
      "tensor([ 1.0659, -1.1179])\n",
      "pre:left true:left 3297/11700\n",
      "tensor([-0.1348,  0.0599])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左769_0_769_20200412_111505661_7.jpg\n",
      "pre:right true:left 3298/11700\n",
      "tensor([ 0.5129, -0.3728])\n",
      "pre:left true:left 3299/11700\n",
      "tensor([ 0.5355, -0.5630])\n",
      "pre:left true:left 3300/11700\n",
      "tensor([ 0.8525, -0.9318])\n",
      "pre:left true:left 3301/11700\n",
      "tensor([ 0.7325, -0.7618])\n",
      "pre:left true:left 3302/11700\n",
      "tensor([ 0.5787, -0.6417])\n",
      "pre:left true:left 3303/11700\n",
      "tensor([ 0.2078, -0.1603])\n",
      "pre:left true:left 3304/11700\n",
      "tensor([ 1.0450, -0.9865])\n",
      "pre:left true:left 3305/11700\n",
      "tensor([ 0.9111, -0.9354])\n",
      "pre:left true:left 3306/11700\n",
      "tensor([ 0.2837, -0.1755])\n",
      "pre:left true:left 3307/11700\n",
      "tensor([ 0.3709, -0.2668])\n",
      "pre:left true:left 3308/11700\n",
      "tensor([ 1.3461, -1.4025])\n",
      "pre:left true:left 3309/11700\n",
      "tensor([ 0.2668, -0.2886])\n",
      "pre:left true:left 3310/11700\n",
      "tensor([ 1.1201, -1.0917])\n",
      "pre:left true:left 3311/11700\n",
      "tensor([-0.3012,  0.3032])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左802_0_958_20200412_115620819_10.jpg\n",
      "pre:right true:left 3312/11700\n",
      "tensor([-0.0659,  0.1014])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左374_0_374_20200412_110542219_7.jpg\n",
      "pre:right true:left 3313/11700\n",
      "tensor([ 0.6489, -0.6916])\n",
      "pre:left true:left 3314/11700\n",
      "tensor([ 0.2222, -0.2283])\n",
      "pre:left true:left 3315/11700\n",
      "tensor([ 0.4101, -0.3862])\n",
      "pre:left true:left 3316/11700\n",
      "tensor([ 0.3551, -0.3182])\n",
      "pre:left true:left 3317/11700\n",
      "tensor([ 1.4384, -1.4562])\n",
      "pre:left true:left 3318/11700\n",
      "tensor([ 0.9693, -1.0321])\n",
      "pre:left true:left 3319/11700\n",
      "tensor([ 0.8566, -0.8818])\n",
      "pre:left true:left 3320/11700\n",
      "tensor([ 1.7451, -1.7740])\n",
      "pre:left true:left 3321/11700\n",
      "tensor([ 0.3262, -0.2825])\n",
      "pre:left true:left 3322/11700\n",
      "tensor([ 0.7463, -0.6226])\n",
      "pre:left true:left 3323/11700\n",
      "tensor([ 0.1087, -0.1036])\n",
      "pre:left true:left 3324/11700\n",
      "tensor([ 0.5241, -0.4985])\n",
      "pre:left true:left 3325/11700\n",
      "tensor([ 0.8405, -0.8722])\n",
      "pre:left true:left 3326/11700\n",
      "tensor([-0.5020,  0.5429])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左921_0_921_20200412_111841785_9.jpg\n",
      "pre:right true:left 3327/11700\n",
      "tensor([ 0.2612, -0.1503])\n",
      "pre:left true:left 3328/11700\n",
      "tensor([ 0.5856, -0.5319])\n",
      "pre:left true:left 3329/11700\n",
      "tensor([-1.4041,  1.5003])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左637_0_793_20200412_115245771_5.jpg\n",
      "pre:right true:left 3330/11700\n",
      "tensor([ 0.5410, -0.6141])\n",
      "pre:left true:left 3331/11700\n",
      "tensor([ 0.7343, -0.7053])\n",
      "pre:left true:left 3332/11700\n",
      "tensor([ 0.3556, -0.2896])\n",
      "pre:left true:left 3333/11700\n",
      "tensor([-0.4558,  0.4636])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左736_0_892_20200412_115454791_1.jpg\n",
      "pre:right true:left 3334/11700\n",
      "tensor([ 0.5711, -0.5085])\n",
      "pre:left true:left 3335/11700\n",
      "tensor([ 1.1765, -1.1761])\n",
      "pre:left true:left 3336/11700\n",
      "tensor([ 0.3851, -0.3498])\n",
      "pre:left true:left 3337/11700\n",
      "tensor([ 0.3474, -0.2704])\n",
      "pre:left true:left 3338/11700\n",
      "tensor([ 1.1132, -1.0290])\n",
      "pre:left true:left 3339/11700\n",
      "tensor([ 0.1910, -0.1206])\n",
      "pre:left true:left 3340/11700\n",
      "tensor([ 0.7862, -0.8551])\n",
      "pre:left true:left 3341/11700\n",
      "tensor([-0.2809,  0.2461])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左503_0_503_20200412_110846221_9.jpg\n",
      "pre:right true:left 3342/11700\n",
      "tensor([ 0.2715, -0.2281])\n",
      "pre:left true:left 3343/11700\n",
      "tensor([ 0.5412, -0.5744])\n",
      "pre:left true:left 3344/11700\n",
      "tensor([ 1.4733, -1.4652])\n",
      "pre:left true:left 3345/11700\n",
      "tensor([ 0.6126, -0.6659])\n",
      "pre:left true:left 3346/11700\n",
      "tensor([ 0.0798, -0.1378])\n",
      "pre:left true:left 3347/11700\n",
      "tensor([ 0.1119, -0.1196])\n",
      "pre:left true:left 3348/11700\n",
      "tensor([-0.0313,  0.0456])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左534_0_690_20200412_115031527.jpg\n",
      "pre:right true:left 3349/11700\n",
      "tensor([ 0.5707, -0.6007])\n",
      "pre:left true:left 3350/11700\n",
      "tensor([ 0.5979, -0.5678])\n",
      "pre:left true:left 3351/11700\n",
      "tensor([ 0.3951, -0.4354])\n",
      "pre:left true:left 3352/11700\n",
      "tensor([ 1.1941, -1.2077])\n",
      "pre:left true:left 3353/11700\n",
      "tensor([ 0.9885, -0.9680])\n",
      "pre:left true:left 3354/11700\n",
      "tensor([ 0.2086, -0.1224])\n",
      "pre:left true:left 3355/11700\n",
      "tensor([ 0.4168, -0.5016])\n",
      "pre:left true:left 3356/11700\n",
      "tensor([ 0.0494, -0.1128])\n",
      "pre:left true:left 3357/11700\n",
      "tensor([ 0.7162, -0.6390])\n",
      "pre:left true:left 3358/11700\n",
      "tensor([ 0.4455, -0.4864])\n",
      "pre:left true:left 3359/11700\n",
      "tensor([ 1.1423, -1.2173])\n",
      "pre:left true:left 3360/11700\n",
      "tensor([ 0.0295, -0.0544])\n",
      "pre:left true:left 3361/11700\n",
      "tensor([ 0.0676, -0.0638])\n",
      "pre:left true:left 3362/11700\n",
      "tensor([ 0.4201, -0.4491])\n",
      "pre:left true:left 3363/11700\n",
      "tensor([ 0.7684, -0.7236])\n",
      "pre:left true:left 3364/11700\n",
      "tensor([ 0.0457, -0.0629])\n",
      "pre:left true:left 3365/11700\n",
      "tensor([ 0.1340, -0.2163])\n",
      "pre:left true:left 3366/11700\n",
      "tensor([ 0.7466, -0.7946])\n",
      "pre:left true:left 3367/11700\n",
      "tensor([ 0.8795, -0.8873])\n",
      "pre:left true:left 3368/11700\n",
      "tensor([ 0.4101, -0.4208])\n",
      "pre:left true:left 3369/11700\n",
      "tensor([ 0.2908, -0.4177])\n",
      "pre:left true:left 3370/11700\n",
      "tensor([ 0.2879, -0.4099])\n",
      "pre:left true:left 3371/11700\n",
      "tensor([ 0.5917, -0.6603])\n",
      "pre:left true:left 3372/11700\n",
      "tensor([0.0887, 0.0275])\n",
      "pre:left true:left 3373/11700\n",
      "tensor([ 0.6572, -0.5837])\n",
      "pre:left true:left 3374/11700\n",
      "tensor([ 0.6135, -0.6104])\n",
      "pre:left true:left 3375/11700\n",
      "tensor([ 0.5878, -0.5434])\n",
      "pre:left true:left 3376/11700\n",
      "tensor([-0.3940,  0.3891])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左799_0_955_20200412_115616893_4.jpg\n",
      "pre:right true:left 3377/11700\n",
      "tensor([ 1.2038, -1.1710])\n",
      "pre:left true:left 3378/11700\n",
      "tensor([-0.2674,  0.2081])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1218_0_1218_20200412_112508762_2.jpg\n",
      "pre:right true:left 3379/11700\n",
      "tensor([ 0.5983, -0.5595])\n",
      "pre:left true:left 3380/11700\n",
      "tensor([ 0.3897, -0.3829])\n",
      "pre:left true:left 3381/11700\n",
      "tensor([ 0.9146, -0.8572])\n",
      "pre:left true:left 3382/11700\n",
      "tensor([ 0.2261, -0.2186])\n",
      "pre:left true:left 3383/11700\n",
      "tensor([ 0.8138, -0.7095])\n",
      "pre:left true:left 3384/11700\n",
      "tensor([ 0.3951, -0.2835])\n",
      "pre:left true:left 3385/11700\n",
      "tensor([ 0.2497, -0.1592])\n",
      "pre:left true:left 3386/11700\n",
      "tensor([ 0.3732, -0.3578])\n",
      "pre:left true:left 3387/11700\n",
      "tensor([ 0.5402, -0.5381])\n",
      "pre:left true:left 3388/11700\n",
      "tensor([ 0.1329, -0.1258])\n",
      "pre:left true:left 3389/11700\n",
      "tensor([ 0.7328, -0.7909])\n",
      "pre:left true:left 3390/11700\n",
      "tensor([ 0.1044, -0.2153])\n",
      "pre:left true:left 3391/11700\n",
      "tensor([-0.3542,  0.4779])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左266_0_422_20200412_114442302_7.jpg\n",
      "pre:right true:left 3392/11700\n",
      "tensor([ 0.0128, -0.0979])\n",
      "pre:left true:left 3393/11700\n",
      "tensor([ 0.2717, -0.1944])\n",
      "pre:left true:left 3394/11700\n",
      "tensor([ 1.9533, -1.9581])\n",
      "pre:left true:left 3395/11700\n",
      "tensor([ 0.6662, -0.6122])\n",
      "pre:left true:left 3396/11700\n",
      "tensor([ 0.3748, -0.3808])\n",
      "pre:left true:left 3397/11700\n",
      "tensor([ 0.6326, -0.5231])\n",
      "pre:left true:left 3398/11700\n",
      "tensor([ 0.2590, -0.2280])\n",
      "pre:left true:left 3399/11700\n",
      "tensor([ 0.3439, -0.3473])\n",
      "pre:left true:left 3400/11700\n",
      "tensor([ 0.3596, -0.3838])\n",
      "pre:left true:left 3401/11700\n",
      "tensor([ 1.7104, -1.8366])\n",
      "pre:left true:left 3402/11700\n",
      "tensor([-0.1051,  0.0699])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左385_0_541_20200412_114717362.jpg\n",
      "pre:right true:left 3403/11700\n",
      "tensor([ 0.7432, -0.7889])\n",
      "pre:left true:left 3404/11700\n",
      "tensor([ 0.1023, -0.0586])\n",
      "pre:left true:left 3405/11700\n",
      "tensor([ 0.6085, -0.6044])\n",
      "pre:left true:left 3406/11700\n",
      "tensor([ 0.9006, -0.9184])\n",
      "pre:left true:left 3407/11700\n",
      "tensor([-0.1424,  0.2350])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左583_0_583_20200412_111040345_1.jpg\n",
      "pre:right true:left 3408/11700\n",
      "tensor([ 0.2935, -0.1921])\n",
      "pre:left true:left 3409/11700\n",
      "tensor([ 1.0544, -1.0686])\n",
      "pre:left true:left 3410/11700\n",
      "tensor([ 0.6562, -0.5363])\n",
      "pre:left true:left 3411/11700\n",
      "tensor([ 0.4757, -0.3568])\n",
      "pre:left true:left 3412/11700\n",
      "tensor([ 0.6839, -0.6369])\n",
      "pre:left true:left 3413/11700\n",
      "tensor([ 0.7869, -0.8032])\n",
      "pre:left true:left 3414/11700\n",
      "tensor([ 0.7846, -0.7752])\n",
      "pre:left true:left 3415/11700\n",
      "tensor([ 0.3728, -0.2633])\n",
      "pre:left true:left 3416/11700\n",
      "tensor([ 0.6039, -0.5465])\n",
      "pre:left true:left 3417/11700\n",
      "tensor([ 0.1023, -0.0822])\n",
      "pre:left true:left 3418/11700\n",
      "tensor([ 0.4455, -0.4864])\n",
      "pre:left true:left 3419/11700\n",
      "tensor([ 0.8048, -0.7752])\n",
      "pre:left true:left 3420/11700\n",
      "tensor([ 0.3699, -0.3956])\n",
      "pre:left true:left 3421/11700\n",
      "tensor([ 0.7969, -0.8259])\n",
      "pre:left true:left 3422/11700\n",
      "tensor([ 0.5408, -0.6098])\n",
      "pre:left true:left 3423/11700\n",
      "tensor([ 0.4350, -0.3600])\n",
      "pre:left true:left 3424/11700\n",
      "tensor([ 0.4427, -0.4858])\n",
      "pre:left true:left 3425/11700\n",
      "tensor([ 0.7287, -0.6254])\n",
      "pre:left true:left 3426/11700\n",
      "tensor([ 0.7846, -0.7639])\n",
      "pre:left true:left 3427/11700\n",
      "tensor([ 0.5699, -0.5989])\n",
      "pre:left true:left 3428/11700\n",
      "tensor([ 0.4162, -0.3970])\n",
      "pre:left true:left 3429/11700\n",
      "tensor([0.0656, 0.0160])\n",
      "pre:left true:left 3430/11700\n",
      "tensor([-0.0125,  0.1702])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左773_0_773_20200412_111511346_1.jpg\n",
      "pre:right true:left 3431/11700\n",
      "tensor([ 0.5616, -0.6418])\n",
      "pre:left true:left 3432/11700\n",
      "tensor([ 0.9877, -0.9376])\n",
      "pre:left true:left 3433/11700\n",
      "tensor([ 0.1121, -0.1769])\n",
      "pre:left true:left 3434/11700\n",
      "tensor([ 1.3157, -1.3442])\n",
      "pre:left true:left 3435/11700\n",
      "tensor([ 0.2428, -0.1738])\n",
      "pre:left true:left 3436/11700\n",
      "tensor([ 0.3341, -0.3720])\n",
      "pre:left true:left 3437/11700\n",
      "tensor([ 0.7461, -0.7600])\n",
      "pre:left true:left 3438/11700\n",
      "tensor([-0.0706,  0.1075])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左457_0_613_20200412_114851184_1.jpg\n",
      "pre:right true:left 3439/11700\n",
      "tensor([ 0.1445, -0.1289])\n",
      "pre:left true:left 3440/11700\n",
      "tensor([ 0.3484, -0.3672])\n",
      "pre:left true:left 3441/11700\n",
      "tensor([ 0.1336, -0.0665])\n",
      "pre:left true:left 3442/11700\n",
      "tensor([ 0.1948, -0.1993])\n",
      "pre:left true:left 3443/11700\n",
      "tensor([-0.0355,  0.0225])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左494_0_650_20200412_114939397_7.jpg\n",
      "pre:right true:left 3444/11700\n",
      "tensor([ 0.3460, -0.4051])\n",
      "pre:left true:left 3445/11700\n",
      "tensor([0.0627, 0.0301])\n",
      "pre:left true:left 3446/11700\n",
      "tensor([-0.2375,  0.3158])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左792_0_792_20200412_111538448_6.jpg\n",
      "pre:right true:left 3447/11700\n",
      "tensor([ 1.3729, -1.3436])\n",
      "pre:left true:left 3448/11700\n",
      "tensor([-0.7650,  0.9079])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左330_0_486_20200412_114605706_9.jpg\n",
      "pre:right true:left 3449/11700\n",
      "tensor([ 0.3900, -0.2627])\n",
      "pre:left true:left 3450/11700\n",
      "tensor([ 0.1912, -0.2089])\n",
      "pre:left true:left 3451/11700\n",
      "tensor([ 0.6860, -0.6500])\n",
      "pre:left true:left 3452/11700\n",
      "tensor([ 0.9421, -1.0247])\n",
      "pre:left true:left 3453/11700\n",
      "tensor([ 0.9410, -0.9248])\n",
      "pre:left true:left 3454/11700\n",
      "tensor([ 0.1618, -0.1759])\n",
      "pre:left true:left 3455/11700\n",
      "tensor([ 1.2568, -1.2416])\n",
      "pre:left true:left 3456/11700\n",
      "tensor([ 1.9308, -1.9403])\n",
      "pre:left true:left 3457/11700\n",
      "tensor([ 0.5703, -0.5192])\n",
      "pre:left true:left 3458/11700\n",
      "tensor([ 0.5061, -0.4520])\n",
      "pre:left true:left 3459/11700\n",
      "tensor([ 0.3533, -0.3336])\n",
      "pre:left true:left 3460/11700\n",
      "tensor([ 0.9607, -0.8984])\n",
      "pre:left true:left 3461/11700\n",
      "tensor([ 0.4012, -0.4766])\n",
      "pre:left true:left 3462/11700\n",
      "tensor([ 0.8875, -0.8598])\n",
      "pre:left true:left 3463/11700\n",
      "tensor([ 0.2555, -0.3165])\n",
      "pre:left true:left 3464/11700\n",
      "tensor([ 1.6153, -1.6596])\n",
      "pre:left true:left 3465/11700\n",
      "tensor([-0.0272,  0.1265])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左813_0_969_20200412_115635143_4.jpg\n",
      "pre:right true:left 3466/11700\n",
      "tensor([ 0.5087, -0.4648])\n",
      "pre:left true:left 3467/11700\n",
      "tensor([ 0.8553, -0.7769])\n",
      "pre:left true:left 3468/11700\n",
      "tensor([ 0.4680, -0.5448])\n",
      "pre:left true:left 3469/11700\n",
      "tensor([ 0.2231, -0.0791])\n",
      "pre:left true:left 3470/11700\n",
      "tensor([ 2.5625, -2.5297])\n",
      "pre:left true:left 3471/11700\n",
      "tensor([ 1.1733, -1.2431])\n",
      "pre:left true:left 3472/11700\n",
      "tensor([ 0.1956, -0.2249])\n",
      "pre:left true:left 3473/11700\n",
      "tensor([ 0.3032, -0.3387])\n",
      "pre:left true:left 3474/11700\n",
      "tensor([ 1.2346, -1.1573])\n",
      "pre:left true:left 3475/11700\n",
      "tensor([ 0.0833, -0.0665])\n",
      "pre:left true:left 3476/11700\n",
      "tensor([ 1.5190, -1.5094])\n",
      "pre:left true:left 3477/11700\n",
      "tensor([ 0.1839, -0.0980])\n",
      "pre:left true:left 3478/11700\n",
      "tensor([ 1.1165, -1.2019])\n",
      "pre:left true:left 3479/11700\n",
      "tensor([-0.0582,  0.0405])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左166_0_166_20200412_110045563_4.jpg\n",
      "pre:right true:left 3480/11700\n",
      "tensor([ 0.0895, -0.0103])\n",
      "pre:left true:left 3481/11700\n",
      "tensor([ 0.2668, -0.3024])\n",
      "pre:left true:left 3482/11700\n",
      "tensor([ 0.2419, -0.1660])\n",
      "pre:left true:left 3483/11700\n",
      "tensor([ 0.3229, -0.3083])\n",
      "pre:left true:left 3484/11700\n",
      "tensor([ 0.4206, -0.3192])\n",
      "pre:left true:left 3485/11700\n",
      "tensor([ 1.0239, -0.9731])\n",
      "pre:left true:left 3486/11700\n",
      "tensor([ 0.9459, -0.9239])\n",
      "pre:left true:left 3487/11700\n",
      "tensor([ 0.9645, -1.0120])\n",
      "pre:left true:left 3488/11700\n",
      "tensor([ 0.3830, -0.3215])\n",
      "pre:left true:left 3489/11700\n",
      "tensor([ 0.6425, -0.5868])\n",
      "pre:left true:left 3490/11700\n",
      "tensor([ 0.1808, -0.0555])\n",
      "pre:left true:left 3491/11700\n",
      "tensor([-0.4220,  0.3802])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左842_0_998_20200412_115712939_10.jpg\n",
      "pre:right true:left 3492/11700\n",
      "tensor([ 0.6688, -0.5863])\n",
      "pre:left true:left 3493/11700\n",
      "tensor([-0.3194,  0.4090])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左822_0_978_20200412_115646880_10.jpg\n",
      "pre:right true:left 3494/11700\n",
      "tensor([ 1.0754, -0.9523])\n",
      "pre:left true:left 3495/11700\n",
      "tensor([-0.4003,  0.4438])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左905_0_905_20200412_111819617_0.jpg\n",
      "pre:right true:left 3496/11700\n",
      "tensor([ 1.0390, -1.0891])\n",
      "pre:left true:left 3497/11700\n",
      "tensor([ 0.5091, -0.4221])\n",
      "pre:left true:left 3498/11700\n",
      "tensor([ 0.6064, -0.4513])\n",
      "pre:left true:left 3499/11700\n",
      "tensor([ 0.0282, -0.0837])\n",
      "pre:left true:left 3500/11700\n",
      "tensor([ 0.7782, -0.7118])\n",
      "pre:left true:left 3501/11700\n",
      "tensor([ 0.6234, -0.5572])\n",
      "pre:left true:left 3502/11700\n",
      "tensor([ 0.4097, -0.4719])\n",
      "pre:left true:left 3503/11700\n",
      "tensor([-0.2890,  0.3238])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左512_0_512_20200412_110859050_1.jpg\n",
      "pre:right true:left 3504/11700\n",
      "tensor([-0.1949,  0.3421])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左503_0_659_20200412_114951128_0.jpg\n",
      "pre:right true:left 3505/11700\n",
      "tensor([ 0.4350, -0.3939])\n",
      "pre:left true:left 3506/11700\n",
      "tensor([ 0.7821, -0.7750])\n",
      "pre:left true:left 3507/11700\n",
      "tensor([ 0.7196, -0.6985])\n",
      "pre:left true:left 3508/11700\n",
      "tensor([ 0.9654, -0.9644])\n",
      "pre:left true:left 3509/11700\n",
      "tensor([ 0.7867, -0.8196])\n",
      "pre:left true:left 3510/11700\n",
      "tensor([ 0.6013, -0.5472])\n",
      "pre:left true:left 3511/11700\n",
      "tensor([ 0.8634, -0.8174])\n",
      "pre:left true:left 3512/11700\n",
      "tensor([ 0.5488, -0.5876])\n",
      "pre:left true:left 3513/11700\n",
      "tensor([ 0.1664, -0.1613])\n",
      "pre:left true:left 3514/11700\n",
      "tensor([ 0.1609, -0.0100])\n",
      "pre:left true:left 3515/11700\n",
      "tensor([ 0.6863, -0.6667])\n",
      "pre:left true:left 3516/11700\n",
      "tensor([ 1.1133, -1.1136])\n",
      "pre:left true:left 3517/11700\n",
      "tensor([-0.0625,  0.1091])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左657_0_657_20200412_111225902_3.jpg\n",
      "pre:right true:left 3518/11700\n",
      "tensor([ 0.5927, -0.6032])\n",
      "pre:left true:left 3519/11700\n",
      "tensor([ 0.9536, -0.9543])\n",
      "pre:left true:left 3520/11700\n",
      "tensor([ 0.7262, -0.6778])\n",
      "pre:left true:left 3521/11700\n",
      "tensor([ 0.7632, -0.6739])\n",
      "pre:left true:left 3522/11700\n",
      "tensor([ 0.6000, -0.5435])\n",
      "pre:left true:left 3523/11700\n",
      "tensor([ 1.2396, -1.1614])\n",
      "pre:left true:left 3524/11700\n",
      "tensor([ 0.9880, -0.9690])\n",
      "pre:left true:left 3525/11700\n",
      "tensor([ 0.5721, -0.6589])\n",
      "pre:left true:left 3526/11700\n",
      "tensor([ 0.6532, -0.6462])\n",
      "pre:left true:left 3527/11700\n",
      "tensor([ 0.7027, -0.7750])\n",
      "pre:left true:left 3528/11700\n",
      "tensor([ 0.1826, -0.0700])\n",
      "pre:left true:left 3529/11700\n",
      "tensor([ 1.1501, -1.1751])\n",
      "pre:left true:left 3530/11700\n",
      "tensor([ 0.1544, -0.1726])\n",
      "pre:left true:left 3531/11700\n",
      "tensor([ 0.0624, -0.0093])\n",
      "pre:left true:left 3532/11700\n",
      "tensor([ 0.3100, -0.2914])\n",
      "pre:left true:left 3533/11700\n",
      "tensor([ 0.5042, -0.4911])\n",
      "pre:left true:left 3534/11700\n",
      "tensor([ 1.4512, -1.4801])\n",
      "pre:left true:left 3535/11700\n",
      "tensor([ 0.4865, -0.4264])\n",
      "pre:left true:left 3536/11700\n",
      "tensor([ 0.2417, -0.2480])\n",
      "pre:left true:left 3537/11700\n",
      "tensor([ 0.6090, -0.6341])\n",
      "pre:left true:left 3538/11700\n",
      "tensor([-0.0568,  0.0859])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左799_0_799_20200412_111548441.jpg\n",
      "pre:right true:left 3539/11700\n",
      "tensor([ 0.9459, -1.0379])\n",
      "pre:left true:left 3540/11700\n",
      "tensor([ 0.3058, -0.3162])\n",
      "pre:left true:left 3541/11700\n",
      "tensor([ 0.9821, -0.9255])\n",
      "pre:left true:left 3542/11700\n",
      "tensor([-0.1069,  0.0530])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左845_0_845_20200412_111654048_2.jpg\n",
      "pre:right true:left 3543/11700\n",
      "tensor([ 1.6319, -1.6059])\n",
      "pre:left true:left 3544/11700\n",
      "tensor([ 0.4941, -0.5520])\n",
      "pre:left true:left 3545/11700\n",
      "tensor([-0.3654,  0.3170])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左510_0_666_20200412_115000244_5.jpg\n",
      "pre:right true:left 3546/11700\n",
      "tensor([ 0.7091, -0.8118])\n",
      "pre:left true:left 3547/11700\n",
      "tensor([ 0.8410, -0.8646])\n",
      "pre:left true:left 3548/11700\n",
      "tensor([ 0.5684, -0.4177])\n",
      "pre:left true:left 3549/11700\n",
      "tensor([ 0.8148, -0.7984])\n",
      "pre:left true:left 3550/11700\n",
      "tensor([ 1.4413, -1.5194])\n",
      "pre:left true:left 3551/11700\n",
      "tensor([ 0.6370, -0.6475])\n",
      "pre:left true:left 3552/11700\n",
      "tensor([ 1.1913, -1.2506])\n",
      "pre:left true:left 3553/11700\n",
      "tensor([ 0.8204, -0.8004])\n",
      "pre:left true:left 3554/11700\n",
      "tensor([ 0.7140, -0.6406])\n",
      "pre:left true:left 3555/11700\n",
      "tensor([ 0.7986, -0.7721])\n",
      "pre:left true:left 3556/11700\n",
      "tensor([ 0.6697, -0.6930])\n",
      "pre:left true:left 3557/11700\n",
      "tensor([ 0.6263, -0.6291])\n",
      "pre:left true:left 3558/11700\n",
      "tensor([ 0.4411, -0.4297])\n",
      "pre:left true:left 3559/11700\n",
      "tensor([ 0.9646, -0.9722])\n",
      "pre:left true:left 3560/11700\n",
      "tensor([ 0.3573, -0.3445])\n",
      "pre:left true:left 3561/11700\n",
      "tensor([ 0.7562, -0.6559])\n",
      "pre:left true:left 3562/11700\n",
      "tensor([ 1.3702, -1.3754])\n",
      "pre:left true:left 3563/11700\n",
      "tensor([ 0.3373, -0.3742])\n",
      "pre:left true:left 3564/11700\n",
      "tensor([-0.2753,  0.2265])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左413_0_569_20200412_114753840_6.jpg\n",
      "pre:right true:left 3565/11700\n",
      "tensor([ 0.7743, -0.6960])\n",
      "pre:left true:left 3566/11700\n",
      "tensor([ 0.3626, -0.2702])\n",
      "pre:left true:left 3567/11700\n",
      "tensor([ 0.4506, -0.5180])\n",
      "pre:left true:left 3568/11700\n",
      "tensor([ 0.0325, -0.0076])\n",
      "pre:left true:left 3569/11700\n",
      "tensor([ 0.8963, -0.8369])\n",
      "pre:left true:left 3570/11700\n",
      "tensor([ 1.1842, -1.1895])\n",
      "pre:left true:left 3571/11700\n",
      "tensor([ 0.2788, -0.2857])\n",
      "pre:left true:left 3572/11700\n",
      "tensor([ 0.6692, -0.7115])\n",
      "pre:left true:left 3573/11700\n",
      "tensor([ 0.3902, -0.3114])\n",
      "pre:left true:left 3574/11700\n",
      "tensor([ 1.0453, -0.9794])\n",
      "pre:left true:left 3575/11700\n",
      "tensor([ 1.2117, -1.2749])\n",
      "pre:left true:left 3576/11700\n",
      "tensor([ 1.1237, -1.0174])\n",
      "pre:left true:left 3577/11700\n",
      "tensor([ 0.3876, -0.3878])\n",
      "pre:left true:left 3578/11700\n",
      "tensor([ 0.6696, -0.6639])\n",
      "pre:left true:left 3579/11700\n",
      "tensor([ 1.4380, -1.5054])\n",
      "pre:left true:left 3580/11700\n",
      "tensor([ 1.0685, -1.0010])\n",
      "pre:left true:left 3581/11700\n",
      "tensor([ 0.5690, -0.5158])\n",
      "pre:left true:left 3582/11700\n",
      "tensor([-0.5236,  0.5548])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左159_0_159_20200412_110035581.jpg\n",
      "pre:right true:left 3583/11700\n",
      "tensor([ 1.6442, -1.7327])\n",
      "pre:left true:left 3584/11700\n",
      "tensor([ 0.6253, -0.5866])\n",
      "pre:left true:left 3585/11700\n",
      "tensor([ 0.5434, -0.6569])\n",
      "pre:left true:left 3586/11700\n",
      "tensor([ 1.1962, -1.0641])\n",
      "pre:left true:left 3587/11700\n",
      "tensor([ 1.0556, -0.9958])\n",
      "pre:left true:left 3588/11700\n",
      "tensor([ 0.7288, -0.7586])\n",
      "pre:left true:left 3589/11700\n",
      "tensor([ 0.3082, -0.3702])\n",
      "pre:left true:left 3590/11700\n",
      "tensor([-0.5038,  0.4974])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左805_0_961_20200412_115624729_6.jpg\n",
      "pre:right true:left 3591/11700\n",
      "tensor([ 0.6537, -0.5758])\n",
      "pre:left true:left 3592/11700\n",
      "tensor([ 0.7044, -0.6615])\n",
      "pre:left true:left 3593/11700\n",
      "tensor([ 1.3253, -1.3695])\n",
      "pre:left true:left 3594/11700\n",
      "tensor([ 0.2243, -0.1864])\n",
      "pre:left true:left 3595/11700\n",
      "tensor([ 1.0596, -1.1058])\n",
      "pre:left true:left 3596/11700\n",
      "tensor([ 0.5089, -0.4672])\n",
      "pre:left true:left 3597/11700\n",
      "tensor([-0.3047,  0.4294])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左258_0_414_20200412_114431875_2.jpg\n",
      "pre:right true:left 3598/11700\n",
      "tensor([ 0.7488, -0.7452])\n",
      "pre:left true:left 3599/11700\n",
      "tensor([ 0.6232, -0.6509])\n",
      "pre:left true:left 3600/11700\n",
      "tensor([ 0.5302, -0.3993])\n",
      "pre:left true:left 3601/11700\n",
      "tensor([ 0.0872, -0.0316])\n",
      "pre:left true:left 3602/11700\n",
      "tensor([ 0.3671, -0.4530])\n",
      "pre:left true:left 3603/11700\n",
      "tensor([ 1.3888, -1.2547])\n",
      "pre:left true:left 3604/11700\n",
      "tensor([-0.0290,  0.1288])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左490_0_646_20200412_114934188_9.jpg\n",
      "pre:right true:left 3605/11700\n",
      "tensor([ 0.2177, -0.0952])\n",
      "pre:left true:left 3606/11700\n",
      "tensor([-0.0842,  0.0121])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左846_0_846_20200412_111655478_2.jpg\n",
      "pre:right true:left 3607/11700\n",
      "tensor([ 0.0460, -0.0404])\n",
      "pre:left true:left 3608/11700\n",
      "tensor([ 0.4547, -0.5131])\n",
      "pre:left true:left 3609/11700\n",
      "tensor([ 0.1759, -0.0921])\n",
      "pre:left true:left 3610/11700\n",
      "tensor([0.0054, 0.0855])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左451_0_451_20200412_110732049_0.jpg\n",
      "pre:right true:left 3611/11700\n",
      "tensor([-0.3250,  0.3965])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左85_0_85_20200412_105850041_6.jpg\n",
      "pre:right true:left 3612/11700\n",
      "tensor([ 0.7185, -0.8118])\n",
      "pre:left true:left 3613/11700\n",
      "tensor([ 0.7854, -0.8201])\n",
      "pre:left true:left 3614/11700\n",
      "tensor([ 0.3030, -0.2814])\n",
      "pre:left true:left 3615/11700\n",
      "tensor([ 1.1978, -1.1448])\n",
      "pre:left true:left 3616/11700\n",
      "tensor([ 0.0541, -0.0255])\n",
      "pre:left true:left 3617/11700\n",
      "tensor([-0.4160,  0.5455])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左793_0_949_20200412_115609081_8.jpg\n",
      "pre:right true:left 3618/11700\n",
      "tensor([ 0.0771, -0.0671])\n",
      "pre:left true:left 3619/11700\n",
      "tensor([ 0.9261, -0.8888])\n",
      "pre:left true:left 3620/11700\n",
      "tensor([ 1.0306, -1.0802])\n",
      "pre:left true:left 3621/11700\n",
      "tensor([ 0.6102, -0.6097])\n",
      "pre:left true:left 3622/11700\n",
      "tensor([ 2.0883, -2.1109])\n",
      "pre:left true:left 3623/11700\n",
      "tensor([ 0.0760, -0.1183])\n",
      "pre:left true:left 3624/11700\n",
      "tensor([ 0.4181, -0.4286])\n",
      "pre:left true:left 3625/11700\n",
      "tensor([ 0.0977, -0.0373])\n",
      "pre:left true:left 3626/11700\n",
      "tensor([ 0.7608, -0.8197])\n",
      "pre:left true:left 3627/11700\n",
      "tensor([ 0.3296, -0.2646])\n",
      "pre:left true:left 3628/11700\n",
      "tensor([ 0.7041, -0.5220])\n",
      "pre:left true:left 3629/11700\n",
      "tensor([ 1.7842, -1.8477])\n",
      "pre:left true:left 3630/11700\n",
      "tensor([ 0.6326, -0.5231])\n",
      "pre:left true:left 3631/11700\n",
      "tensor([-0.1084,  0.1958])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左524_0_680_20200412_115018501_2.jpg\n",
      "pre:right true:left 3632/11700\n",
      "tensor([ 1.2486, -1.2107])\n",
      "pre:left true:left 3633/11700\n",
      "tensor([ 0.8216, -0.7618])\n",
      "pre:left true:left 3634/11700\n",
      "tensor([ 0.6074, -0.6017])\n",
      "pre:left true:left 3635/11700\n",
      "tensor([ 0.7894, -0.7332])\n",
      "pre:left true:left 3636/11700\n",
      "tensor([ 0.7493, -0.6412])\n",
      "pre:left true:left 3637/11700\n",
      "tensor([-1.0487,  1.2076])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左888_0_888_20200412_111755369_5.jpg\n",
      "pre:right true:left 3638/11700\n",
      "tensor([ 0.4067, -0.3611])\n",
      "pre:left true:left 3639/11700\n",
      "tensor([ 0.6082, -0.4354])\n",
      "pre:left true:left 3640/11700\n",
      "tensor([ 0.6281, -0.5537])\n",
      "pre:left true:left 3641/11700\n",
      "tensor([ 0.6595, -0.6751])\n",
      "pre:left true:left 3642/11700\n",
      "tensor([ 0.4966, -0.2866])\n",
      "pre:left true:left 3643/11700\n",
      "tensor([ 0.0811, -0.0165])\n",
      "pre:left true:left 3644/11700\n",
      "tensor([-0.0773,  0.0805])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1555_0_1711_20200412_121242195_5.jpg\n",
      "pre:right true:left 3645/11700\n",
      "tensor([ 0.9094, -0.7860])\n",
      "pre:left true:left 3646/11700\n",
      "tensor([ 0.4112, -0.4132])\n",
      "pre:left true:left 3647/11700\n",
      "tensor([ 0.4878, -0.4472])\n",
      "pre:left true:left 3648/11700\n",
      "tensor([ 0.4810, -0.4330])\n",
      "pre:left true:left 3649/11700\n",
      "tensor([ 0.5701, -0.6463])\n",
      "pre:left true:left 3650/11700\n",
      "tensor([-0.3212,  0.3411])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1202_0_1202_20200412_112447915_6.jpg\n",
      "pre:right true:left 3651/11700\n",
      "tensor([ 0.2273, -0.2946])\n",
      "pre:left true:left 3652/11700\n",
      "tensor([-0.1001,  0.2771])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左594_0_750_20200412_115149717_2.jpg\n",
      "pre:right true:left 3653/11700\n",
      "tensor([ 0.5918, -0.6645])\n",
      "pre:left true:left 3654/11700\n",
      "tensor([ 0.7330, -0.7623])\n",
      "pre:left true:left 3655/11700\n",
      "tensor([ 0.3531, -0.3234])\n",
      "pre:left true:left 3656/11700\n",
      "tensor([ 0.1080, -0.1120])\n",
      "pre:left true:left 3657/11700\n",
      "tensor([ 0.9808, -0.9923])\n",
      "pre:left true:left 3658/11700\n",
      "tensor([-0.4288,  0.2890])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左849_0_849_20200412_111659750_3.jpg\n",
      "pre:right true:left 3659/11700\n",
      "tensor([ 0.8270, -0.8222])\n",
      "pre:left true:left 3660/11700\n",
      "tensor([ 0.2391, -0.0872])\n",
      "pre:left true:left 3661/11700\n",
      "tensor([ 0.1504, -0.1204])\n",
      "pre:left true:left 3662/11700\n",
      "tensor([ 0.7273, -0.7066])\n",
      "pre:left true:left 3663/11700\n",
      "tensor([ 1.5921, -1.5521])\n",
      "pre:left true:left 3664/11700\n",
      "tensor([ 0.5159, -0.5212])\n",
      "pre:left true:left 3665/11700\n",
      "tensor([ 0.5469, -0.4992])\n",
      "pre:left true:left 3666/11700\n",
      "tensor([0.0539, 0.0669])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左202_0_358_20200412_114318899_2.jpg\n",
      "pre:right true:left 3667/11700\n",
      "tensor([ 0.7841, -0.8032])\n",
      "pre:left true:left 3668/11700\n",
      "tensor([ 0.2902, -0.2110])\n",
      "pre:left true:left 3669/11700\n",
      "tensor([-0.0267,  0.0039])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左797_0_953_20200412_115614298_3.jpg\n",
      "pre:right true:left 3670/11700\n",
      "tensor([-0.5703,  0.6023])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左393_0_549_20200412_114727767_3.jpg\n",
      "pre:right true:left 3671/11700\n",
      "tensor([ 0.9675, -0.9153])\n",
      "pre:left true:left 3672/11700\n",
      "tensor([ 1.0009, -0.9967])\n",
      "pre:left true:left 3673/11700\n",
      "tensor([ 0.6443, -0.6512])\n",
      "pre:left true:left 3674/11700\n",
      "tensor([ 0.4258, -0.3830])\n",
      "pre:left true:left 3675/11700\n",
      "tensor([ 0.1244, -0.2259])\n",
      "pre:left true:left 3676/11700\n",
      "tensor([ 0.8882, -0.9392])\n",
      "pre:left true:left 3677/11700\n",
      "tensor([-0.3648,  0.3581])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左703_0_859_20200412_115411771_9.jpg\n",
      "pre:right true:left 3678/11700\n",
      "tensor([0.0031, 0.0393])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左735_0_735_20200412_111417157_3.jpg\n",
      "pre:right true:left 3679/11700\n",
      "tensor([ 0.2822, -0.1612])\n",
      "pre:left true:left 3680/11700\n",
      "tensor([ 0.3428, -0.3833])\n",
      "pre:left true:left 3681/11700\n",
      "tensor([ 1.0270, -1.0121])\n",
      "pre:left true:left 3682/11700\n",
      "tensor([ 0.3593, -0.3538])\n",
      "pre:left true:left 3683/11700\n",
      "tensor([ 1.2269, -1.1878])\n",
      "pre:left true:left 3684/11700\n",
      "tensor([ 0.2753, -0.3175])\n",
      "pre:left true:left 3685/11700\n",
      "tensor([ 1.2380, -1.2531])\n",
      "pre:left true:left 3686/11700\n",
      "tensor([ 0.3375, -0.3505])\n",
      "pre:left true:left 3687/11700\n",
      "tensor([ 1.1061, -1.0740])\n",
      "pre:left true:left 3688/11700\n",
      "tensor([ 0.8852, -0.8185])\n",
      "pre:left true:left 3689/11700\n",
      "tensor([ 0.0414, -0.1068])\n",
      "pre:left true:left 3690/11700\n",
      "tensor([ 0.0924, -0.0027])\n",
      "pre:left true:left 3691/11700\n",
      "tensor([ 0.1670, -0.0881])\n",
      "pre:left true:left 3692/11700\n",
      "tensor([ 0.8047, -0.9045])\n",
      "pre:left true:left 3693/11700\n",
      "tensor([ 0.1251, -0.0791])\n",
      "pre:left true:left 3694/11700\n",
      "tensor([ 0.5685, -0.5424])\n",
      "pre:left true:left 3695/11700\n",
      "tensor([ 0.9008, -0.9279])\n",
      "pre:left true:left 3696/11700\n",
      "tensor([ 0.8886, -0.9168])\n",
      "pre:left true:left 3697/11700\n",
      "tensor([ 0.6682, -0.6882])\n",
      "pre:left true:left 3698/11700\n",
      "tensor([-0.8700,  0.8977])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1481_0_1637_20200412_121105731_7.jpg\n",
      "pre:right true:left 3699/11700\n",
      "tensor([ 0.4561, -0.3645])\n",
      "pre:left true:left 3700/11700\n",
      "tensor([ 0.8919, -0.8811])\n",
      "pre:left true:left 3701/11700\n",
      "tensor([ 1.0124, -0.9946])\n",
      "pre:left true:left 3702/11700\n",
      "tensor([ 0.5962, -0.6061])\n",
      "pre:left true:left 3703/11700\n",
      "tensor([ 0.2575, -0.1947])\n",
      "pre:left true:left 3704/11700\n",
      "tensor([ 0.2587, -0.2983])\n",
      "pre:left true:left 3705/11700\n",
      "tensor([ 1.3350, -1.2448])\n",
      "pre:left true:left 3706/11700\n",
      "tensor([ 0.2156, -0.2727])\n",
      "pre:left true:left 3707/11700\n",
      "tensor([ 0.6222, -0.6820])\n",
      "pre:left true:left 3708/11700\n",
      "tensor([ 0.5115, -0.5335])\n",
      "pre:left true:left 3709/11700\n",
      "tensor([ 0.5665, -0.5997])\n",
      "pre:left true:left 3710/11700\n",
      "tensor([-0.0811, -0.0614])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1526_0_1682_20200412_121204399_4.jpg\n",
      "pre:right true:left 3711/11700\n",
      "tensor([-0.7419,  0.7537])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左957_0_957_20200412_111928680_4.jpg\n",
      "pre:right true:left 3712/11700\n",
      "tensor([ 0.6750, -0.6078])\n",
      "pre:left true:left 3713/11700\n",
      "tensor([ 1.5965, -1.6666])\n",
      "pre:left true:left 3714/11700\n",
      "tensor([ 0.7369, -0.7510])\n",
      "pre:left true:left 3715/11700\n",
      "tensor([0.0678, 0.0305])\n",
      "pre:left true:left 3716/11700\n",
      "tensor([-0.1802,  0.3443])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左835_0_835_20200412_111639789_9.jpg\n",
      "pre:right true:left 3717/11700\n",
      "tensor([ 0.4334, -0.4063])\n",
      "pre:left true:left 3718/11700\n",
      "tensor([ 0.8479, -0.8810])\n",
      "pre:left true:left 3719/11700\n",
      "tensor([ 0.5634, -0.4836])\n",
      "pre:left true:left 3720/11700\n",
      "tensor([ 0.9607, -0.8427])\n",
      "pre:left true:left 3721/11700\n",
      "tensor([ 0.7497, -0.7415])\n",
      "pre:left true:left 3722/11700\n",
      "tensor([ 0.2633, -0.3149])\n",
      "pre:left true:left 3723/11700\n",
      "tensor([ 0.7604, -0.7447])\n",
      "pre:left true:left 3724/11700\n",
      "tensor([ 0.2202, -0.2893])\n",
      "pre:left true:left 3725/11700\n",
      "tensor([-0.9751,  0.8926])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1264_0_1264_20200412_112608712_9.jpg\n",
      "pre:right true:left 3726/11700\n",
      "tensor([ 0.6924, -0.6084])\n",
      "pre:left true:left 3727/11700\n",
      "tensor([ 0.8443, -0.8254])\n",
      "pre:left true:left 3728/11700\n",
      "tensor([ 0.4606, -0.3968])\n",
      "pre:left true:left 3729/11700\n",
      "tensor([ 0.5435, -0.6594])\n",
      "pre:left true:left 3730/11700\n",
      "tensor([ 0.2590, -0.1814])\n",
      "pre:left true:left 3731/11700\n",
      "tensor([ 0.4939, -0.4530])\n",
      "pre:left true:left 3732/11700\n",
      "tensor([ 0.2558, -0.2062])\n",
      "pre:left true:left 3733/11700\n",
      "tensor([ 0.5953, -0.5659])\n",
      "pre:left true:left 3734/11700\n",
      "tensor([ 1.3794, -1.2006])\n",
      "pre:left true:left 3735/11700\n",
      "tensor([ 0.4258, -0.4129])\n",
      "pre:left true:left 3736/11700\n",
      "tensor([ 0.7279, -0.7359])\n",
      "pre:left true:left 3737/11700\n",
      "tensor([ 1.4556, -1.4673])\n",
      "pre:left true:left 3738/11700\n",
      "tensor([ 0.3697, -0.2997])\n",
      "pre:left true:left 3739/11700\n",
      "tensor([ 0.1933, -0.2585])\n",
      "pre:left true:left 3740/11700\n",
      "tensor([ 0.6276, -0.6274])\n",
      "pre:left true:left 3741/11700\n",
      "tensor([ 0.6622, -0.7088])\n",
      "pre:left true:left 3742/11700\n",
      "tensor([-0.1301,  0.1946])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1350_0_1506_20200412_120814979_3.jpg\n",
      "pre:right true:left 3743/11700\n",
      "tensor([ 0.6860, -0.6500])\n",
      "pre:left true:left 3744/11700\n",
      "tensor([ 0.4940, -0.4342])\n",
      "pre:left true:left 3745/11700\n",
      "tensor([ 0.6241, -0.6329])\n",
      "pre:left true:left 3746/11700\n",
      "tensor([ 0.2245, -0.2077])\n",
      "pre:left true:left 3747/11700\n",
      "tensor([ 0.0364, -0.0987])\n",
      "pre:left true:left 3748/11700\n",
      "tensor([ 1.2628, -1.1360])\n",
      "pre:left true:left 3749/11700\n",
      "tensor([ 0.2731, -0.1889])\n",
      "pre:left true:left 3750/11700\n",
      "tensor([ 0.3187, -0.2889])\n",
      "pre:left true:left 3751/11700\n",
      "tensor([ 0.2713, -0.2007])\n",
      "pre:left true:left 3752/11700\n",
      "tensor([ 0.3027, -0.2677])\n",
      "pre:left true:left 3753/11700\n",
      "tensor([ 0.3600, -0.4065])\n",
      "pre:left true:left 3754/11700\n",
      "tensor([ 0.1349, -0.1032])\n",
      "pre:left true:left 3755/11700\n",
      "tensor([ 0.7923, -0.6867])\n",
      "pre:left true:left 3756/11700\n",
      "tensor([ 0.3070, -0.2838])\n",
      "pre:left true:left 3757/11700\n",
      "tensor([ 0.3715, -0.4370])\n",
      "pre:left true:left 3758/11700\n",
      "tensor([ 0.3090, -0.2338])\n",
      "pre:left true:left 3759/11700\n",
      "tensor([ 0.7036, -0.6669])\n",
      "pre:left true:left 3760/11700\n",
      "tensor([ 0.9125, -0.8895])\n",
      "pre:left true:left 3761/11700\n",
      "tensor([ 0.1811, -0.1488])\n",
      "pre:left true:left 3762/11700\n",
      "tensor([ 0.8326, -0.7358])\n",
      "pre:left true:left 3763/11700\n",
      "tensor([ 0.3225, -0.3077])\n",
      "pre:left true:left 3764/11700\n",
      "tensor([-0.2230,  0.2143])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左85_0_85_20200412_105850041_1.jpg\n",
      "pre:right true:left 3765/11700\n",
      "tensor([ 0.5627, -0.5653])\n",
      "pre:left true:left 3766/11700\n",
      "tensor([ 1.4487, -1.5254])\n",
      "pre:left true:left 3767/11700\n",
      "tensor([ 0.8485, -0.8614])\n",
      "pre:left true:left 3768/11700\n",
      "tensor([-0.1049,  0.0574])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左552_0_552_20200412_110956125_0.jpg\n",
      "pre:right true:left 3769/11700\n",
      "tensor([ 0.8661, -0.8892])\n",
      "pre:left true:left 3770/11700\n",
      "tensor([ 0.0356, -0.0206])\n",
      "pre:left true:left 3771/11700\n",
      "tensor([ 0.2164, -0.1771])\n",
      "pre:left true:left 3772/11700\n",
      "tensor([ 0.9636, -1.0481])\n",
      "pre:left true:left 3773/11700\n",
      "tensor([-0.1930,  0.1800])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1608_0_1764_20200412_121351283_9.jpg\n",
      "pre:right true:left 3774/11700\n",
      "tensor([ 0.1848, -0.1431])\n",
      "pre:left true:left 3775/11700\n",
      "tensor([ 0.7345, -0.7364])\n",
      "pre:left true:left 3776/11700\n",
      "tensor([ 0.0802, -0.0465])\n",
      "pre:left true:left 3777/11700\n",
      "tensor([ 0.5425, -0.5905])\n",
      "pre:left true:left 3778/11700\n",
      "tensor([ 1.3342, -1.3678])\n",
      "pre:left true:left 3779/11700\n",
      "tensor([ 0.8629, -0.7528])\n",
      "pre:left true:left 3780/11700\n",
      "tensor([-0.0902,  0.0778])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左535_0_535_20200412_110931848_8.jpg\n",
      "pre:right true:left 3781/11700\n",
      "tensor([-0.0898,  0.0527])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1086_0_1086_20200412_112216750_2.jpg\n",
      "pre:right true:left 3782/11700\n",
      "tensor([ 0.9691, -1.0046])\n",
      "pre:left true:left 3783/11700\n",
      "tensor([ 0.4579, -0.4482])\n",
      "pre:left true:left 3784/11700\n",
      "tensor([ 1.3971, -1.4134])\n",
      "pre:left true:left 3785/11700\n",
      "tensor([ 0.1581, -0.1917])\n",
      "pre:left true:left 3786/11700\n",
      "tensor([-0.2645,  0.2294])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左436_0_436_20200412_110710654_2.jpg\n",
      "pre:right true:left 3787/11700\n",
      "tensor([ 1.3835, -1.4694])\n",
      "pre:left true:left 3788/11700\n",
      "tensor([ 0.5336, -0.5444])\n",
      "pre:left true:left 3789/11700\n",
      "tensor([ 1.0629, -1.0323])\n",
      "pre:left true:left 3790/11700\n",
      "tensor([-0.4542,  0.4422])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左699_0_855_20200412_115406565.jpg\n",
      "pre:right true:left 3791/11700\n",
      "tensor([ 1.1441, -1.1707])\n",
      "pre:left true:left 3792/11700\n",
      "tensor([ 1.2676, -1.3301])\n",
      "pre:left true:left 3793/11700\n",
      "tensor([ 0.4378, -0.4312])\n",
      "pre:left true:left 3794/11700\n",
      "tensor([ 1.0359, -0.9448])\n",
      "pre:left true:left 3795/11700\n",
      "tensor([ 0.3288, -0.3268])\n",
      "pre:left true:left 3796/11700\n",
      "tensor([ 0.3321, -0.3617])\n",
      "pre:left true:left 3797/11700\n",
      "tensor([ 0.3754, -0.3525])\n",
      "pre:left true:left 3798/11700\n",
      "tensor([ 0.0833, -0.0173])\n",
      "pre:left true:left 3799/11700\n",
      "tensor([ 0.3453, -0.3273])\n",
      "pre:left true:left 3800/11700\n",
      "tensor([ 1.1134, -1.1150])\n",
      "pre:left true:left 3801/11700\n",
      "tensor([ 1.1982, -1.2428])\n",
      "pre:left true:left 3802/11700\n",
      "tensor([ 0.2635, -0.2633])\n",
      "pre:left true:left 3803/11700\n",
      "tensor([ 0.9329, -0.9193])\n",
      "pre:left true:left 3804/11700\n",
      "tensor([ 0.3686, -0.4260])\n",
      "pre:left true:left 3805/11700\n",
      "tensor([ 0.8557, -0.8448])\n",
      "pre:left true:left 3806/11700\n",
      "tensor([ 0.6382, -0.7116])\n",
      "pre:left true:left 3807/11700\n",
      "tensor([ 0.4135, -0.3751])\n",
      "pre:left true:left 3808/11700\n",
      "tensor([-0.3342,  0.5019])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左643_0_799_20200412_115253573.jpg\n",
      "pre:right true:left 3809/11700\n",
      "tensor([ 0.3805, -0.4439])\n",
      "pre:left true:left 3810/11700\n",
      "tensor([ 0.3354, -0.3437])\n",
      "pre:left true:left 3811/11700\n",
      "tensor([ 0.2384, -0.2614])\n",
      "pre:left true:left 3812/11700\n",
      "tensor([ 1.2972, -1.3604])\n",
      "pre:left true:left 3813/11700\n",
      "tensor([ 0.0867, -0.0141])\n",
      "pre:left true:left 3814/11700\n",
      "tensor([ 0.1509, -0.1083])\n",
      "pre:left true:left 3815/11700\n",
      "tensor([ 0.4918, -0.4366])\n",
      "pre:left true:left 3816/11700\n",
      "tensor([ 0.6652, -0.6811])\n",
      "pre:left true:left 3817/11700\n",
      "tensor([ 0.3681, -0.4021])\n",
      "pre:left true:left 3818/11700\n",
      "tensor([ 0.5052, -0.4594])\n",
      "pre:left true:left 3819/11700\n",
      "tensor([ 1.5957, -1.6448])\n",
      "pre:left true:left 3820/11700\n",
      "tensor([ 0.5555, -0.4818])\n",
      "pre:left true:left 3821/11700\n",
      "tensor([ 0.7820, -0.7005])\n",
      "pre:left true:left 3822/11700\n",
      "tensor([-0.0678,  0.0516])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1113_0_1269_20200412_120306104_9.jpg\n",
      "pre:right true:left 3823/11700\n",
      "tensor([ 0.7276, -0.7702])\n",
      "pre:left true:left 3824/11700\n",
      "tensor([ 0.3749, -0.3973])\n",
      "pre:left true:left 3825/11700\n",
      "tensor([ 0.8249, -0.7202])\n",
      "pre:left true:left 3826/11700\n",
      "tensor([ 1.1039, -1.0543])\n",
      "pre:left true:left 3827/11700\n",
      "tensor([ 0.7764, -0.7050])\n",
      "pre:left true:left 3828/11700\n",
      "tensor([ 0.4981, -0.5145])\n",
      "pre:left true:left 3829/11700\n",
      "tensor([ 0.9204, -0.9596])\n",
      "pre:left true:left 3830/11700\n",
      "tensor([ 1.1067, -1.1161])\n",
      "pre:left true:left 3831/11700\n",
      "tensor([ 1.2324, -1.2007])\n",
      "pre:left true:left 3832/11700\n",
      "tensor([ 1.6993, -1.7511])\n",
      "pre:left true:left 3833/11700\n",
      "tensor([ 0.5347, -0.5250])\n",
      "pre:left true:left 3834/11700\n",
      "tensor([ 0.2598, -0.2521])\n",
      "pre:left true:left 3835/11700\n",
      "tensor([ 0.5704, -0.5907])\n",
      "pre:left true:left 3836/11700\n",
      "tensor([ 0.4869, -0.4829])\n",
      "pre:left true:left 3837/11700\n",
      "tensor([ 1.1231, -1.0923])\n",
      "pre:left true:left 3838/11700\n",
      "tensor([ 0.1180, -0.0969])\n",
      "pre:left true:left 3839/11700\n",
      "tensor([ 0.7280, -0.6866])\n",
      "pre:left true:left 3840/11700\n",
      "tensor([-0.0862,  0.2987])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左457_0_613_20200412_114851184_5.jpg\n",
      "pre:right true:left 3841/11700\n",
      "tensor([ 0.7555, -0.7373])\n",
      "pre:left true:left 3842/11700\n",
      "tensor([ 0.8638, -0.9333])\n",
      "pre:left true:left 3843/11700\n",
      "tensor([-0.1150,  0.1804])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1362_0_1518_20200412_120830617_2.jpg\n",
      "pre:right true:left 3844/11700\n",
      "tensor([ 0.8864, -0.7328])\n",
      "pre:left true:left 3845/11700\n",
      "tensor([ 0.5523, -0.6014])\n",
      "pre:left true:left 3846/11700\n",
      "tensor([ 1.0323, -0.9789])\n",
      "pre:left true:left 3847/11700\n",
      "tensor([ 0.0072, -0.0590])\n",
      "pre:left true:left 3848/11700\n",
      "tensor([0.0210, 0.0617])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左405_0_561_20200412_114743435_5.jpg\n",
      "pre:right true:left 3849/11700\n",
      "tensor([ 0.4374, -0.4966])\n",
      "pre:left true:left 3850/11700\n",
      "tensor([ 0.7646, -0.8158])\n",
      "pre:left true:left 3851/11700\n",
      "tensor([ 0.6681, -0.5656])\n",
      "pre:left true:left 3852/11700\n",
      "tensor([ 0.0341, -0.0009])\n",
      "pre:left true:left 3853/11700\n",
      "tensor([ 0.4339, -0.4486])\n",
      "pre:left true:left 3854/11700\n",
      "tensor([ 0.5874, -0.5936])\n",
      "pre:left true:left 3855/11700\n",
      "tensor([ 0.6009, -0.6198])\n",
      "pre:left true:left 3856/11700\n",
      "tensor([ 0.6723, -0.6249])\n",
      "pre:left true:left 3857/11700\n",
      "tensor([ 0.1290, -0.1858])\n",
      "pre:left true:left 3858/11700\n",
      "tensor([-0.0025,  0.0057])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左623_0_623_20200412_111137396_5.jpg\n",
      "pre:right true:left 3859/11700\n",
      "tensor([ 0.2506, -0.2337])\n",
      "pre:left true:left 3860/11700\n",
      "tensor([ 0.6662, -0.6705])\n",
      "pre:left true:left 3861/11700\n",
      "tensor([-0.3297,  0.2811])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左659_0_815_20200412_115314448_7.jpg\n",
      "pre:right true:left 3862/11700\n",
      "tensor([ 0.9093, -0.8156])\n",
      "pre:left true:left 3863/11700\n",
      "tensor([ 0.7365, -0.6165])\n",
      "pre:left true:left 3864/11700\n",
      "tensor([ 1.6382, -1.7911])\n",
      "pre:left true:left 3865/11700\n",
      "tensor([ 0.7913, -0.7726])\n",
      "pre:left true:left 3866/11700\n",
      "tensor([-0.1341,  0.2558])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左607_0_763_20200412_115206661_6.jpg\n",
      "pre:right true:left 3867/11700\n",
      "tensor([ 0.6701, -0.7002])\n",
      "pre:left true:left 3868/11700\n",
      "tensor([ 0.6227, -0.5955])\n",
      "pre:left true:left 3869/11700\n",
      "tensor([ 1.0256, -1.0444])\n",
      "pre:left true:left 3870/11700\n",
      "tensor([ 0.6656, -0.6064])\n",
      "pre:left true:left 3871/11700\n",
      "tensor([ 0.3730, -0.4972])\n",
      "pre:left true:left 3872/11700\n",
      "tensor([ 1.0231, -1.0567])\n",
      "pre:left true:left 3873/11700\n",
      "tensor([ 1.3161, -1.3027])\n",
      "pre:left true:left 3874/11700\n",
      "tensor([ 1.0316, -1.0663])\n",
      "pre:left true:left 3875/11700\n",
      "tensor([ 0.7831, -0.7877])\n",
      "pre:left true:left 3876/11700\n",
      "tensor([ 0.7486, -0.8148])\n",
      "pre:left true:left 3877/11700\n",
      "tensor([ 0.6699, -0.7349])\n",
      "pre:left true:left 3878/11700\n",
      "tensor([ 1.9974, -2.0440])\n",
      "pre:left true:left 3879/11700\n",
      "tensor([-0.4438,  0.4913])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左783_0_783_20200412_111525607_6.jpg\n",
      "pre:right true:left 3880/11700\n",
      "tensor([ 0.0237, -0.0556])\n",
      "pre:left true:left 3881/11700\n",
      "tensor([ 1.0146, -1.0966])\n",
      "pre:left true:left 3882/11700\n",
      "tensor([ 0.5553, -0.5717])\n",
      "pre:left true:left 3883/11700\n",
      "tensor([-0.4103,  0.5590])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左881_0_881_20200412_111745390_3.jpg\n",
      "pre:right true:left 3884/11700\n",
      "tensor([ 1.0971, -1.0669])\n",
      "pre:left true:left 3885/11700\n",
      "tensor([ 0.5365, -0.5568])\n",
      "pre:left true:left 3886/11700\n",
      "tensor([-0.0247,  0.0240])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左531_0_687_20200412_115027615_7.jpg\n",
      "pre:right true:left 3887/11700\n",
      "tensor([ 0.1823, -0.2170])\n",
      "pre:left true:left 3888/11700\n",
      "tensor([ 0.3754, -0.3238])\n",
      "pre:left true:left 3889/11700\n",
      "tensor([-0.0274,  0.1516])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左852_0_852_20200412_111704019_1.jpg\n",
      "pre:right true:left 3890/11700\n",
      "tensor([ 0.7117, -0.6534])\n",
      "pre:left true:left 3891/11700\n",
      "tensor([ 0.5984, -0.4273])\n",
      "pre:left true:left 3892/11700\n",
      "tensor([ 0.6753, -0.6676])\n",
      "pre:left true:left 3893/11700\n",
      "tensor([ 0.3665, -0.2640])\n",
      "pre:left true:left 3894/11700\n",
      "tensor([ 0.4913, -0.4727])\n",
      "pre:left true:left 3895/11700\n",
      "tensor([ 1.1867, -1.2685])\n",
      "pre:left true:left 3896/11700\n",
      "tensor([ 0.0576, -0.0738])\n",
      "pre:left true:left 3897/11700\n",
      "tensor([ 0.3617, -0.4559])\n",
      "pre:left true:left 3898/11700\n",
      "tensor([ 0.7611, -0.6338])\n",
      "pre:left true:left 3899/11700\n",
      "tensor([ 1.2968, -1.3284])\n",
      "pre:left true:left 3900/11700\n",
      "tensor([ 0.9811, -1.0299])\n",
      "pre:left true:left 3901/11700\n",
      "tensor([ 0.8188, -0.8446])\n",
      "pre:left true:left 3902/11700\n",
      "tensor([ 0.6859, -0.6685])\n",
      "pre:left true:left 3903/11700\n",
      "tensor([ 0.2206, -0.1531])\n",
      "pre:left true:left 3904/11700\n",
      "tensor([ 0.7238, -0.6058])\n",
      "pre:left true:left 3905/11700\n",
      "tensor([ 0.4413, -0.4867])\n",
      "pre:left true:left 3906/11700\n",
      "tensor([ 0.3685, -0.3172])\n",
      "pre:left true:left 3907/11700\n",
      "tensor([ 0.5425, -0.5513])\n",
      "pre:left true:left 3908/11700\n",
      "tensor([ 0.4778, -0.4687])\n",
      "pre:left true:left 3909/11700\n",
      "tensor([ 0.7814, -0.7935])\n",
      "pre:left true:left 3910/11700\n",
      "tensor([ 0.8791, -0.8336])\n",
      "pre:left true:left 3911/11700\n",
      "tensor([ 1.3581, -1.2947])\n",
      "pre:left true:left 3912/11700\n",
      "tensor([ 0.2897, -0.3022])\n",
      "pre:left true:left 3913/11700\n",
      "tensor([ 0.2991, -0.3114])\n",
      "pre:left true:left 3914/11700\n",
      "tensor([ 0.9209, -0.9537])\n",
      "pre:left true:left 3915/11700\n",
      "tensor([ 0.5077, -0.6145])\n",
      "pre:left true:left 3916/11700\n",
      "tensor([ 0.7255, -0.6356])\n",
      "pre:left true:left 3917/11700\n",
      "tensor([ 0.9324, -0.8364])\n",
      "pre:left true:left 3918/11700\n",
      "tensor([-0.0326, -0.0288])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左534_0_534_20200412_110930432_6.jpg\n",
      "pre:right true:left 3919/11700\n",
      "tensor([ 0.7058, -0.7313])\n",
      "pre:left true:left 3920/11700\n",
      "tensor([ 0.6311, -0.6372])\n",
      "pre:left true:left 3921/11700\n",
      "tensor([ 0.8960, -0.9073])\n",
      "pre:left true:left 3922/11700\n",
      "tensor([ 0.7174, -0.6071])\n",
      "pre:left true:left 3923/11700\n",
      "tensor([ 0.1843, -0.2529])\n",
      "pre:left true:left 3924/11700\n",
      "tensor([ 1.1227, -1.0511])\n",
      "pre:left true:left 3925/11700\n",
      "tensor([0.0142, 0.0287])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左187_0_187_20200412_110115520_6.jpg\n",
      "pre:right true:left 3926/11700\n",
      "tensor([ 0.1799, -0.1567])\n",
      "pre:left true:left 3927/11700\n",
      "tensor([ 1.2071, -1.1987])\n",
      "pre:left true:left 3928/11700\n",
      "tensor([ 1.2641, -1.1602])\n",
      "pre:left true:left 3929/11700\n",
      "tensor([ 0.7183, -0.6630])\n",
      "pre:left true:left 3930/11700\n",
      "tensor([ 1.1256, -1.1452])\n",
      "pre:left true:left 3931/11700\n",
      "tensor([ 0.4897, -0.4945])\n",
      "pre:left true:left 3932/11700\n",
      "tensor([ 0.9967, -1.0621])\n",
      "pre:left true:left 3933/11700\n",
      "tensor([ 0.4103, -0.4451])\n",
      "pre:left true:left 3934/11700\n",
      "tensor([ 0.4036, -0.2847])\n",
      "pre:left true:left 3935/11700\n",
      "tensor([-0.1389,  0.2307])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左291_0_447_20200412_114514872_8.jpg\n",
      "pre:right true:left 3936/11700\n",
      "tensor([ 0.2583, -0.1772])\n",
      "pre:left true:left 3937/11700\n",
      "tensor([ 0.7969, -0.8280])\n",
      "pre:left true:left 3938/11700\n",
      "tensor([ 0.8271, -0.8463])\n",
      "pre:left true:left 3939/11700\n",
      "tensor([ 0.4667, -0.3705])\n",
      "pre:left true:left 3940/11700\n",
      "tensor([ 0.2913, -0.2493])\n",
      "pre:left true:left 3941/11700\n",
      "tensor([ 0.4491, -0.4229])\n",
      "pre:left true:left 3942/11700\n",
      "tensor([ 0.6151, -0.6200])\n",
      "pre:left true:left 3943/11700\n",
      "tensor([ 0.1828, -0.2216])\n",
      "pre:left true:left 3944/11700\n",
      "tensor([ 0.1725, -0.0868])\n",
      "pre:left true:left 3945/11700\n",
      "tensor([ 0.3606, -0.3968])\n",
      "pre:left true:left 3946/11700\n",
      "tensor([ 0.4733, -0.4166])\n",
      "pre:left true:left 3947/11700\n",
      "tensor([ 0.7154, -0.7960])\n",
      "pre:left true:left 3948/11700\n",
      "tensor([ 0.6673, -0.7304])\n",
      "pre:left true:left 3949/11700\n",
      "tensor([-0.0192, -0.0361])\n",
      "pre:left true:left 3950/11700\n",
      "tensor([ 1.5571, -1.4935])\n",
      "pre:left true:left 3951/11700\n",
      "tensor([ 0.7986, -0.7090])\n",
      "pre:left true:left 3952/11700\n",
      "tensor([ 0.6373, -0.7497])\n",
      "pre:left true:left 3953/11700\n",
      "tensor([ 1.1723, -1.1294])\n",
      "pre:left true:left 3954/11700\n",
      "tensor([ 0.1123, -0.1339])\n",
      "pre:left true:left 3955/11700\n",
      "tensor([-0.2468,  0.2733])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1397_0_1553_20200412_120916230_8.jpg\n",
      "pre:right true:left 3956/11700\n",
      "tensor([ 1.1149, -1.0482])\n",
      "pre:left true:left 3957/11700\n",
      "tensor([ 0.7492, -0.8020])\n",
      "pre:left true:left 3958/11700\n",
      "tensor([ 0.8418, -0.8520])\n",
      "pre:left true:left 3959/11700\n",
      "tensor([ 0.7846, -0.7969])\n",
      "pre:left true:left 3960/11700\n",
      "tensor([ 0.8951, -0.8553])\n",
      "pre:left true:left 3961/11700\n",
      "tensor([ 0.4643, -0.4339])\n",
      "pre:left true:left 3962/11700\n",
      "tensor([ 0.5178, -0.5188])\n",
      "pre:left true:left 3963/11700\n",
      "tensor([ 1.0065, -1.0919])\n",
      "pre:left true:left 3964/11700\n",
      "tensor([-0.2128,  0.3579])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左393_0_393_20200412_110609318.jpg\n",
      "pre:right true:left 3965/11700\n",
      "tensor([ 0.6895, -0.7250])\n",
      "pre:left true:left 3966/11700\n",
      "tensor([ 0.2393, -0.2109])\n",
      "pre:left true:left 3967/11700\n",
      "tensor([ 0.4766, -0.4387])\n",
      "pre:left true:left 3968/11700\n",
      "tensor([-0.1875,  0.2143])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1270_0_1426_20200412_120630738_6.jpg\n",
      "pre:right true:left 3969/11700\n",
      "tensor([ 0.9040, -0.8738])\n",
      "pre:left true:left 3970/11700\n",
      "tensor([ 0.5330, -0.4752])\n",
      "pre:left true:left 3971/11700\n",
      "tensor([ 0.1261, -0.1973])\n",
      "pre:left true:left 3972/11700\n",
      "tensor([ 1.1030, -1.0374])\n",
      "pre:left true:left 3973/11700\n",
      "tensor([ 0.6035, -0.5733])\n",
      "pre:left true:left 3974/11700\n",
      "tensor([ 0.1870, -0.0911])\n",
      "pre:left true:left 3975/11700\n",
      "tensor([ 0.2843, -0.2266])\n",
      "pre:left true:left 3976/11700\n",
      "tensor([ 1.4212, -1.3338])\n",
      "pre:left true:left 3977/11700\n",
      "tensor([ 1.2238, -1.1793])\n",
      "pre:left true:left 3978/11700\n",
      "tensor([ 1.0193, -1.0462])\n",
      "pre:left true:left 3979/11700\n",
      "tensor([-0.5123,  0.5503])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左567_0_723_20200412_115114530_0.jpg\n",
      "pre:right true:left 3980/11700\n",
      "tensor([ 0.7195, -0.7225])\n",
      "pre:left true:left 3981/11700\n",
      "tensor([ 0.7617, -0.7729])\n",
      "pre:left true:left 3982/11700\n",
      "tensor([-0.1296,  0.2572])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左277_0_277_20200412_110323869.jpg\n",
      "pre:right true:left 3983/11700\n",
      "tensor([-0.1516,  0.2275])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左308_0_464_20200412_114537015_1.jpg\n",
      "pre:right true:left 3984/11700\n",
      "tensor([ 0.5689, -0.6419])\n",
      "pre:left true:left 3985/11700\n",
      "tensor([-0.1093,  0.1052])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左498_0_498_20200412_110839077_2.jpg\n",
      "pre:right true:left 3986/11700\n",
      "tensor([ 0.9497, -0.9988])\n",
      "pre:left true:left 3987/11700\n",
      "tensor([ 0.2404, -0.2585])\n",
      "pre:left true:left 3988/11700\n",
      "tensor([ 0.4041, -0.4134])\n",
      "pre:left true:left 3989/11700\n",
      "tensor([ 0.7360, -0.8010])\n",
      "pre:left true:left 3990/11700\n",
      "tensor([ 0.6034, -0.6532])\n",
      "pre:left true:left 3991/11700\n",
      "tensor([ 0.4367, -0.3910])\n",
      "pre:left true:left 3992/11700\n",
      "tensor([-0.1244,  0.1401])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左837_0_837_20200412_111642640_2.jpg\n",
      "pre:right true:left 3993/11700\n",
      "tensor([-0.4094,  0.3388])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1236_0_1236_20200412_112532214_8.jpg\n",
      "pre:right true:left 3994/11700\n",
      "tensor([ 0.3676, -0.3120])\n",
      "pre:left true:left 3995/11700\n",
      "tensor([ 0.7516, -0.7297])\n",
      "pre:left true:left 3996/11700\n",
      "tensor([ 0.3153, -0.2920])\n",
      "pre:left true:left 3997/11700\n",
      "tensor([ 0.6439, -0.6497])\n",
      "pre:left true:left 3998/11700\n",
      "tensor([ 0.8675, -0.8071])\n",
      "pre:left true:left 3999/11700\n",
      "tensor([ 0.6380, -0.6850])\n",
      "pre:left true:left 4000/11700\n",
      "tensor([-0.1608,  0.0494])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1196_0_1196_20200412_112440097_10.jpg\n",
      "pre:right true:left 4001/11700\n",
      "tensor([ 0.7647, -0.7857])\n",
      "pre:left true:left 4002/11700\n",
      "tensor([ 0.6332, -0.6876])\n",
      "pre:left true:left 4003/11700\n",
      "tensor([-0.0368,  0.1820])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1556_0_1712_20200412_121243498_0.jpg\n",
      "pre:right true:left 4004/11700\n",
      "tensor([ 0.4048, -0.3201])\n",
      "pre:left true:left 4005/11700\n",
      "tensor([-0.1227,  0.1525])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左456_0_456_20200412_110739162_10.jpg\n",
      "pre:right true:left 4006/11700\n",
      "tensor([ 0.1784, -0.2197])\n",
      "pre:left true:left 4007/11700\n",
      "tensor([ 0.7046, -0.7423])\n",
      "pre:left true:left 4008/11700\n",
      "tensor([ 0.9218, -0.9712])\n",
      "pre:left true:left 4009/11700\n",
      "tensor([ 1.1248, -1.1667])\n",
      "pre:left true:left 4010/11700\n",
      "tensor([ 0.5904, -0.5586])\n",
      "pre:left true:left 4011/11700\n",
      "tensor([ 0.7876, -0.7039])\n",
      "pre:left true:left 4012/11700\n",
      "tensor([ 0.8661, -0.9664])\n",
      "pre:left true:left 4013/11700\n",
      "tensor([ 0.9645, -0.9032])\n",
      "pre:left true:left 4014/11700\n",
      "tensor([ 0.9821, -0.9022])\n",
      "pre:left true:left 4015/11700\n",
      "tensor([-0.1053,  0.1229])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1319_0_1319_20200412_112730298_2.jpg\n",
      "pre:right true:left 4016/11700\n",
      "tensor([ 0.0861, -0.0763])\n",
      "pre:left true:left 4017/11700\n",
      "tensor([ 0.4119, -0.5138])\n",
      "pre:left true:left 4018/11700\n",
      "tensor([ 0.0355, -0.0976])\n",
      "pre:left true:left 4019/11700\n",
      "tensor([ 0.6061, -0.5898])\n",
      "pre:left true:left 4020/11700\n",
      "tensor([ 0.5330, -0.4855])\n",
      "pre:left true:left 4021/11700\n",
      "tensor([ 0.1696, -0.0932])\n",
      "pre:left true:left 4022/11700\n",
      "tensor([-0.0244,  0.1580])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左671_0_671_20200412_111245857_8.jpg\n",
      "pre:right true:left 4023/11700\n",
      "tensor([ 0.8988, -0.8301])\n",
      "pre:left true:left 4024/11700\n",
      "tensor([ 0.5751, -0.6367])\n",
      "pre:left true:left 4025/11700\n",
      "tensor([-0.5038,  0.5835])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1481_0_1637_20200412_121105731_9.jpg\n",
      "pre:right true:left 4026/11700\n",
      "tensor([ 0.4834, -0.5738])\n",
      "pre:left true:left 4027/11700\n",
      "tensor([ 0.5618, -0.5785])\n",
      "pre:left true:left 4028/11700\n",
      "tensor([ 0.4083, -0.3849])\n",
      "pre:left true:left 4029/11700\n",
      "tensor([-0.0551,  0.1857])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左567_0_723_20200412_115114530_3.jpg\n",
      "pre:right true:left 4030/11700\n",
      "tensor([ 0.4587, -0.5121])\n",
      "pre:left true:left 4031/11700\n",
      "tensor([ 0.6469, -0.6247])\n",
      "pre:left true:left 4032/11700\n",
      "tensor([ 0.7518, -0.6489])\n",
      "pre:left true:left 4033/11700\n",
      "tensor([ 0.2817, -0.3648])\n",
      "pre:left true:left 4034/11700\n",
      "tensor([ 0.1782, -0.1660])\n",
      "pre:left true:left 4035/11700\n",
      "tensor([ 0.4188, -0.3670])\n",
      "pre:left true:left 4036/11700\n",
      "tensor([ 0.3827, -0.3724])\n",
      "pre:left true:left 4037/11700\n",
      "tensor([ 1.1324, -1.0578])\n",
      "pre:left true:left 4038/11700\n",
      "tensor([-0.3830,  0.4580])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1139_0_1139_20200412_112325821_9.jpg\n",
      "pre:right true:left 4039/11700\n",
      "tensor([ 0.9196, -0.9342])\n",
      "pre:left true:left 4040/11700\n",
      "tensor([ 0.5925, -0.4465])\n",
      "pre:left true:left 4041/11700\n",
      "tensor([-0.6691,  0.6938])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左356_0_356_20200412_110516529_5.jpg\n",
      "pre:right true:left 4042/11700\n",
      "tensor([ 0.8033, -0.7304])\n",
      "pre:left true:left 4043/11700\n",
      "tensor([ 0.6409, -0.6619])\n",
      "pre:left true:left 4044/11700\n",
      "tensor([ 1.1331, -1.1656])\n",
      "pre:left true:left 4045/11700\n",
      "tensor([-0.5352,  0.6025])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左223_0_223_20200412_110206863_10.jpg\n",
      "pre:right true:left 4046/11700\n",
      "tensor([ 1.0119, -0.9395])\n",
      "pre:left true:left 4047/11700\n",
      "tensor([ 1.3777, -1.3200])\n",
      "pre:left true:left 4048/11700\n",
      "tensor([ 0.2946, -0.2595])\n",
      "pre:left true:left 4049/11700\n",
      "tensor([ 1.0729, -1.0167])\n",
      "pre:left true:left 4050/11700\n",
      "tensor([ 0.3255, -0.3638])\n",
      "pre:left true:left 4051/11700\n",
      "tensor([ 0.6996, -0.7819])\n",
      "pre:left true:left 4052/11700\n",
      "tensor([ 0.7331, -0.7348])\n",
      "pre:left true:left 4053/11700\n",
      "tensor([-0.1907,  0.2327])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左472_0_628_20200412_114910718_7.jpg\n",
      "pre:right true:left 4054/11700\n",
      "tensor([ 0.8791, -0.8188])\n",
      "pre:left true:left 4055/11700\n",
      "tensor([ 0.9398, -0.9353])\n",
      "pre:left true:left 4056/11700\n",
      "tensor([ 0.9773, -0.9716])\n",
      "pre:left true:left 4057/11700\n",
      "tensor([ 0.3466, -0.1907])\n",
      "pre:left true:left 4058/11700\n",
      "tensor([ 1.2650, -1.2306])\n",
      "pre:left true:left 4059/11700\n",
      "tensor([ 0.2948, -0.3203])\n",
      "pre:left true:left 4060/11700\n",
      "tensor([ 0.7834, -0.7905])\n",
      "pre:left true:left 4061/11700\n",
      "tensor([ 0.7077, -0.7666])\n",
      "pre:left true:left 4062/11700\n",
      "tensor([ 0.6542, -0.5846])\n",
      "pre:left true:left 4063/11700\n",
      "tensor([ 0.6195, -0.5221])\n",
      "pre:left true:left 4064/11700\n",
      "tensor([ 0.7011, -0.6834])\n",
      "pre:left true:left 4065/11700\n",
      "tensor([ 0.3431, -0.3254])\n",
      "pre:left true:left 4066/11700\n",
      "tensor([ 0.8370, -0.8771])\n",
      "pre:left true:left 4067/11700\n",
      "tensor([ 0.3994, -0.3713])\n",
      "pre:left true:left 4068/11700\n",
      "tensor([ 0.1732, -0.1228])\n",
      "pre:left true:left 4069/11700\n",
      "tensor([ 0.3098, -0.2954])\n",
      "pre:left true:left 4070/11700\n",
      "tensor([ 0.2219, -0.1983])\n",
      "pre:left true:left 4071/11700\n",
      "tensor([ 0.7331, -0.6402])\n",
      "pre:left true:left 4072/11700\n",
      "tensor([ 0.3476, -0.3069])\n",
      "pre:left true:left 4073/11700\n",
      "tensor([ 0.7366, -0.7491])\n",
      "pre:left true:left 4074/11700\n",
      "tensor([ 0.5821, -0.5584])\n",
      "pre:left true:left 4075/11700\n",
      "tensor([ 0.5401, -0.4979])\n",
      "pre:left true:left 4076/11700\n",
      "tensor([ 0.3831, -0.3704])\n",
      "pre:left true:left 4077/11700\n",
      "tensor([ 1.1116, -1.1297])\n",
      "pre:left true:left 4078/11700\n",
      "tensor([ 0.8884, -0.9209])\n",
      "pre:left true:left 4079/11700\n",
      "tensor([ 0.3993, -0.4184])\n",
      "pre:left true:left 4080/11700\n",
      "tensor([ 0.7572, -0.6508])\n",
      "pre:left true:left 4081/11700\n",
      "tensor([-0.0135,  0.0764])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左594_0_750_20200412_115149717_7.jpg\n",
      "pre:right true:left 4082/11700\n",
      "tensor([ 1.3486, -1.3801])\n",
      "pre:left true:left 4083/11700\n",
      "tensor([ 0.1355, -0.1065])\n",
      "pre:left true:left 4084/11700\n",
      "tensor([ 0.8175, -0.8042])\n",
      "pre:left true:left 4085/11700\n",
      "tensor([ 0.6562, -0.7095])\n",
      "pre:left true:left 4086/11700\n",
      "tensor([ 0.5943, -0.6767])\n",
      "pre:left true:left 4087/11700\n",
      "tensor([ 0.8987, -0.7878])\n",
      "pre:left true:left 4088/11700\n",
      "tensor([ 0.8296, -0.8359])\n",
      "pre:left true:left 4089/11700\n",
      "tensor([ 0.8165, -0.8282])\n",
      "pre:left true:left 4090/11700\n",
      "tensor([ 0.6382, -0.7116])\n",
      "pre:left true:left 4091/11700\n",
      "tensor([ 0.7419, -0.7826])\n",
      "pre:left true:left 4092/11700\n",
      "tensor([ 0.2397, -0.1820])\n",
      "pre:left true:left 4093/11700\n",
      "tensor([ 0.2459, -0.2526])\n",
      "pre:left true:left 4094/11700\n",
      "tensor([-0.0105,  0.0805])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左606_0_762_20200412_115205352_1.jpg\n",
      "pre:right true:left 4095/11700\n",
      "tensor([ 0.4214, -0.3953])\n",
      "pre:left true:left 4096/11700\n",
      "tensor([ 1.0432, -1.0639])\n",
      "pre:left true:left 4097/11700\n",
      "tensor([-0.0082, -0.0441])\n",
      "pre:left true:left 4098/11700\n",
      "tensor([ 0.6712, -0.6384])\n",
      "pre:left true:left 4099/11700\n",
      "tensor([0.0761, 0.0418])\n",
      "pre:left true:left 4100/11700\n",
      "tensor([ 0.4557, -0.5144])\n",
      "pre:left true:left 4101/11700\n",
      "tensor([-0.7545,  0.7260])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左510_0_666_20200412_115000244_4.jpg\n",
      "pre:right true:left 4102/11700\n",
      "tensor([ 0.5607, -0.5409])\n",
      "pre:left true:left 4103/11700\n",
      "tensor([ 1.9126, -1.6895])\n",
      "pre:left true:left 4104/11700\n",
      "tensor([ 0.5835, -0.6437])\n",
      "pre:left true:left 4105/11700\n",
      "tensor([ 0.7534, -0.6935])\n",
      "pre:left true:left 4106/11700\n",
      "tensor([ 0.3723, -0.3980])\n",
      "pre:left true:left 4107/11700\n",
      "tensor([ 0.8718, -0.8046])\n",
      "pre:left true:left 4108/11700\n",
      "tensor([ 0.9151, -0.9139])\n",
      "pre:left true:left 4109/11700\n",
      "tensor([ 1.1742, -1.1828])\n",
      "pre:left true:left 4110/11700\n",
      "tensor([ 1.1182, -1.1220])\n",
      "pre:left true:left 4111/11700\n",
      "tensor([ 0.1426, -0.1107])\n",
      "pre:left true:left 4112/11700\n",
      "tensor([ 1.5961, -1.6417])\n",
      "pre:left true:left 4113/11700\n",
      "tensor([-0.3247,  0.2286])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左646_0_802_20200412_115257490_6.jpg\n",
      "pre:right true:left 4114/11700\n",
      "tensor([ 0.7057, -0.7531])\n",
      "pre:left true:left 4115/11700\n",
      "tensor([ 0.5886, -0.5885])\n",
      "pre:left true:left 4116/11700\n",
      "tensor([ 0.7358, -0.6968])\n",
      "pre:left true:left 4117/11700\n",
      "tensor([ 0.4428, -0.4712])\n",
      "pre:left true:left 4118/11700\n",
      "tensor([ 0.4129, -0.4041])\n",
      "pre:left true:left 4119/11700\n",
      "tensor([ 0.3880, -0.4889])\n",
      "pre:left true:left 4120/11700\n",
      "tensor([ 0.2265, -0.2913])\n",
      "pre:left true:left 4121/11700\n",
      "tensor([ 0.6877, -0.7081])\n",
      "pre:left true:left 4122/11700\n",
      "tensor([ 0.0484, -0.0554])\n",
      "pre:left true:left 4123/11700\n",
      "tensor([ 0.9509, -0.8761])\n",
      "pre:left true:left 4124/11700\n",
      "tensor([ 0.1670, -0.1409])\n",
      "pre:left true:left 4125/11700\n",
      "tensor([ 0.2246, -0.1201])\n",
      "pre:left true:left 4126/11700\n",
      "tensor([ 0.7259, -0.7162])\n",
      "pre:left true:left 4127/11700\n",
      "tensor([ 0.4405, -0.4288])\n",
      "pre:left true:left 4128/11700\n",
      "tensor([-0.0786,  0.0339])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左305_0_461_20200412_114533116_2.jpg\n",
      "pre:right true:left 4129/11700\n",
      "tensor([ 1.3571, -1.2576])\n",
      "pre:left true:left 4130/11700\n",
      "tensor([ 0.1774, -0.2605])\n",
      "pre:left true:left 4131/11700\n",
      "tensor([ 0.2949, -0.2848])\n",
      "pre:left true:left 4132/11700\n",
      "tensor([ 1.4548, -1.4460])\n",
      "pre:left true:left 4133/11700\n",
      "tensor([-0.2318,  0.2335])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1595_0_1751_20200412_121334340_10.jpg\n",
      "pre:right true:left 4134/11700\n",
      "tensor([ 0.0858, -0.0479])\n",
      "pre:left true:left 4135/11700\n",
      "tensor([ 0.7281, -0.7061])\n",
      "pre:left true:left 4136/11700\n",
      "tensor([-0.1328,  0.2963])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左312_0_312_20200412_110413788_9.jpg\n",
      "pre:right true:left 4137/11700\n",
      "tensor([ 0.6170, -0.5100])\n",
      "pre:left true:left 4138/11700\n",
      "tensor([ 0.5691, -0.6402])\n",
      "pre:left true:left 4139/11700\n",
      "tensor([ 0.9283, -0.8363])\n",
      "pre:left true:left 4140/11700\n",
      "tensor([ 0.2952, -0.3284])\n",
      "pre:left true:left 4141/11700\n",
      "tensor([ 0.2497, -0.1818])\n",
      "pre:left true:left 4142/11700\n",
      "tensor([ 0.8562, -0.8049])\n",
      "pre:left true:left 4143/11700\n",
      "tensor([ 0.3730, -0.3071])\n",
      "pre:left true:left 4144/11700\n",
      "tensor([-0.2651,  0.2261])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左784_0_940_20200412_115557343_1.jpg\n",
      "pre:right true:left 4145/11700\n",
      "tensor([ 0.9967, -1.0621])\n",
      "pre:left true:left 4146/11700\n",
      "tensor([ 0.6241, -0.6779])\n",
      "pre:left true:left 4147/11700\n",
      "tensor([ 0.3682, -0.4244])\n",
      "pre:left true:left 4148/11700\n",
      "tensor([ 0.4057, -0.3580])\n",
      "pre:left true:left 4149/11700\n",
      "tensor([ 0.4099, -0.4982])\n",
      "pre:left true:left 4150/11700\n",
      "tensor([ 0.4730, -0.4124])\n",
      "pre:left true:left 4151/11700\n",
      "tensor([ 0.7272, -0.7465])\n",
      "pre:left true:left 4152/11700\n",
      "tensor([ 0.6665, -0.7296])\n",
      "pre:left true:left 4153/11700\n",
      "tensor([ 1.0573, -1.1516])\n",
      "pre:left true:left 4154/11700\n",
      "tensor([ 0.0027, -0.0303])\n",
      "pre:left true:left 4155/11700\n",
      "tensor([-0.3806,  0.4045])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左893_0_1049_20200412_115819396_0.jpg\n",
      "pre:right true:left 4156/11700\n",
      "tensor([ 0.7507, -0.7180])\n",
      "pre:left true:left 4157/11700\n",
      "tensor([-0.4643,  0.4265])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左600_0_756_20200412_115157535_0.jpg\n",
      "pre:right true:left 4158/11700\n",
      "tensor([ 0.2291, -0.1876])\n",
      "pre:left true:left 4159/11700\n",
      "tensor([ 0.3900, -0.2627])\n",
      "pre:left true:left 4160/11700\n",
      "tensor([ 0.5409, -0.5300])\n",
      "pre:left true:left 4161/11700\n",
      "tensor([ 0.7724, -0.8063])\n",
      "pre:left true:left 4162/11700\n",
      "tensor([ 0.8952, -0.9549])\n",
      "pre:left true:left 4163/11700\n",
      "tensor([ 1.0183, -1.0141])\n",
      "pre:left true:left 4164/11700\n",
      "tensor([ 0.6444, -0.5641])\n",
      "pre:left true:left 4165/11700\n",
      "tensor([ 0.7389, -0.6555])\n",
      "pre:left true:left 4166/11700\n",
      "tensor([ 0.3503, -0.4023])\n",
      "pre:left true:left 4167/11700\n",
      "tensor([ 0.6115, -0.7668])\n",
      "pre:left true:left 4168/11700\n",
      "tensor([ 0.3426, -0.3346])\n",
      "pre:left true:left 4169/11700\n",
      "tensor([ 0.5611, -0.5486])\n",
      "pre:left true:left 4170/11700\n",
      "tensor([ 0.9143, -0.8751])\n",
      "pre:left true:left 4171/11700\n",
      "tensor([-0.1223,  0.1422])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左429_0_585_20200412_114814696_4.jpg\n",
      "pre:right true:left 4172/11700\n",
      "tensor([ 0.2531, -0.2175])\n",
      "pre:left true:left 4173/11700\n",
      "tensor([ 0.6373, -0.7497])\n",
      "pre:left true:left 4174/11700\n",
      "tensor([-0.0019, -0.0150])\n",
      "pre:left true:left 4175/11700\n",
      "tensor([ 0.5910, -0.6553])\n",
      "pre:left true:left 4176/11700\n",
      "tensor([ 0.9437, -0.9248])\n",
      "pre:left true:left 4177/11700\n",
      "tensor([ 0.0168, -0.0753])\n",
      "pre:left true:left 4178/11700\n",
      "tensor([ 0.9095, -1.0057])\n",
      "pre:left true:left 4179/11700\n",
      "tensor([ 0.5745, -0.5545])\n",
      "pre:left true:left 4180/11700\n",
      "tensor([ 0.7170, -0.7111])\n",
      "pre:left true:left 4181/11700\n",
      "tensor([ 1.2175, -1.2029])\n",
      "pre:left true:left 4182/11700\n",
      "tensor([ 0.8522, -0.7057])\n",
      "pre:left true:left 4183/11700\n",
      "tensor([-0.1004,  0.1962])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左891_0_891_20200412_111759650_0.jpg\n",
      "pre:right true:left 4184/11700\n",
      "tensor([ 0.6471, -0.5544])\n",
      "pre:left true:left 4185/11700\n",
      "tensor([ 0.3656, -0.4352])\n",
      "pre:left true:left 4186/11700\n",
      "tensor([ 0.6520, -0.6524])\n",
      "pre:left true:left 4187/11700\n",
      "tensor([ 0.3593, -0.3392])\n",
      "pre:left true:left 4188/11700\n",
      "tensor([ 1.2119, -1.2638])\n",
      "pre:left true:left 4189/11700\n",
      "tensor([ 1.0737, -1.0095])\n",
      "pre:left true:left 4190/11700\n",
      "tensor([ 0.8871, -0.9361])\n",
      "pre:left true:left 4191/11700\n",
      "tensor([ 0.1933, -0.2288])\n",
      "pre:left true:left 4192/11700\n",
      "tensor([ 0.5028, -0.4888])\n",
      "pre:left true:left 4193/11700\n",
      "tensor([ 1.2307, -1.1904])\n",
      "pre:left true:left 4194/11700\n",
      "tensor([ 0.6463, -0.6734])\n",
      "pre:left true:left 4195/11700\n",
      "tensor([ 0.8037, -0.8210])\n",
      "pre:left true:left 4196/11700\n",
      "tensor([-0.3336,  0.2504])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左833_0_989_20200412_115701218_4.jpg\n",
      "pre:right true:left 4197/11700\n",
      "tensor([ 1.0405, -1.1202])\n",
      "pre:left true:left 4198/11700\n",
      "tensor([ 0.1432, -0.0664])\n",
      "pre:left true:left 4199/11700\n",
      "tensor([ 0.3217, -0.2672])\n",
      "pre:left true:left 4200/11700\n",
      "tensor([-0.5505,  0.6212])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左544_0_544_20200412_110944711_10.jpg\n",
      "pre:right true:left 4201/11700\n",
      "tensor([ 0.6465, -0.6424])\n",
      "pre:left true:left 4202/11700\n",
      "tensor([ 0.5245, -0.5114])\n",
      "pre:left true:left 4203/11700\n",
      "tensor([ 0.5116, -0.5561])\n",
      "pre:left true:left 4204/11700\n",
      "tensor([ 0.1773, -0.0968])\n",
      "pre:left true:left 4205/11700\n",
      "tensor([ 0.2876, -0.2543])\n",
      "pre:left true:left 4206/11700\n",
      "tensor([ 1.3840, -1.2017])\n",
      "pre:left true:left 4207/11700\n",
      "tensor([ 1.4355, -1.4053])\n",
      "pre:left true:left 4208/11700\n",
      "tensor([ 0.1902, -0.1744])\n",
      "pre:left true:left 4209/11700\n",
      "tensor([ 0.5488, -0.4943])\n",
      "pre:left true:left 4210/11700\n",
      "tensor([ 0.3904, -0.3504])\n",
      "pre:left true:left 4211/11700\n",
      "tensor([ 0.7560, -0.5528])\n",
      "pre:left true:left 4212/11700\n",
      "tensor([ 0.3749, -0.3181])\n",
      "pre:left true:left 4213/11700\n",
      "tensor([ 0.2669, -0.2112])\n",
      "pre:left true:left 4214/11700\n",
      "tensor([ 1.0871, -1.0520])\n",
      "pre:left true:left 4215/11700\n",
      "tensor([ 0.7820, -0.8234])\n",
      "pre:left true:left 4216/11700\n",
      "tensor([ 0.3403, -0.3136])\n",
      "pre:left true:left 4217/11700\n",
      "tensor([ 0.8066, -0.8740])\n",
      "pre:left true:left 4218/11700\n",
      "tensor([ 1.3105, -1.2787])\n",
      "pre:left true:left 4219/11700\n",
      "tensor([ 1.4373, -1.3437])\n",
      "pre:left true:left 4220/11700\n",
      "tensor([ 0.9172, -0.9683])\n",
      "pre:left true:left 4221/11700\n",
      "tensor([ 0.5680, -0.5929])\n",
      "pre:left true:left 4222/11700\n",
      "tensor([-0.3171,  0.3746])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左845_0_845_20200412_111654048_9.jpg\n",
      "pre:right true:left 4223/11700\n",
      "tensor([-0.6942,  0.6898])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左270_0_426_20200412_114447496_3.jpg\n",
      "pre:right true:left 4224/11700\n",
      "tensor([ 0.1043, -0.0177])\n",
      "pre:left true:left 4225/11700\n",
      "tensor([ 0.6504, -0.6735])\n",
      "pre:left true:left 4226/11700\n",
      "tensor([ 1.0585, -1.0417])\n",
      "pre:left true:left 4227/11700\n",
      "tensor([ 1.0063, -0.9880])\n",
      "pre:left true:left 4228/11700\n",
      "tensor([ 0.7724, -0.7133])\n",
      "pre:left true:left 4229/11700\n",
      "tensor([ 0.5311, -0.5393])\n",
      "pre:left true:left 4230/11700\n",
      "tensor([ 0.8005, -0.8212])\n",
      "pre:left true:left 4231/11700\n",
      "tensor([-0.0667,  0.1370])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左759_0_915_20200412_115524760_10.jpg\n",
      "pre:right true:left 4232/11700\n",
      "tensor([ 1.1582, -1.1954])\n",
      "pre:left true:left 4233/11700\n",
      "tensor([ 0.3396, -0.2718])\n",
      "pre:left true:left 4234/11700\n",
      "tensor([-0.4219,  0.3868])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左990_0_990_20200412_112011687_4.jpg\n",
      "pre:right true:left 4235/11700\n",
      "tensor([ 0.4729, -0.4234])\n",
      "pre:left true:left 4236/11700\n",
      "tensor([ 0.4953, -0.4074])\n",
      "pre:left true:left 4237/11700\n",
      "tensor([ 0.1987, -0.2278])\n",
      "pre:left true:left 4238/11700\n",
      "tensor([ 0.4798, -0.4864])\n",
      "pre:left true:left 4239/11700\n",
      "tensor([ 0.8254, -0.8412])\n",
      "pre:left true:left 4240/11700\n",
      "tensor([ 0.6879, -0.7193])\n",
      "pre:left true:left 4241/11700\n",
      "tensor([ 0.7595, -0.8438])\n",
      "pre:left true:left 4242/11700\n",
      "tensor([ 0.4560, -0.4679])\n",
      "pre:left true:left 4243/11700\n",
      "tensor([ 0.5450, -0.3935])\n",
      "pre:left true:left 4244/11700\n",
      "tensor([ 0.3230, -0.3337])\n",
      "pre:left true:left 4245/11700\n",
      "tensor([-0.2480,  0.3007])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左708_0_708_20200412_111338627.jpg\n",
      "pre:right true:left 4246/11700\n",
      "tensor([ 0.1700, -0.1540])\n",
      "pre:left true:left 4247/11700\n",
      "tensor([ 0.6188, -0.7184])\n",
      "pre:left true:left 4248/11700\n",
      "tensor([ 0.3805, -0.2376])\n",
      "pre:left true:left 4249/11700\n",
      "tensor([0.0188, 0.0772])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左523_0_679_20200412_115017198_4.jpg\n",
      "pre:right true:left 4250/11700\n",
      "tensor([ 0.2630, -0.2168])\n",
      "pre:left true:left 4251/11700\n",
      "tensor([ 0.4774, -0.5094])\n",
      "pre:left true:left 4252/11700\n",
      "tensor([ 1.4994, -1.5191])\n",
      "pre:left true:left 4253/11700\n",
      "tensor([ 1.3087, -1.2660])\n",
      "pre:left true:left 4254/11700\n",
      "tensor([ 0.4537, -0.4644])\n",
      "pre:left true:left 4255/11700\n",
      "tensor([ 0.5777, -0.6298])\n",
      "pre:left true:left 4256/11700\n",
      "tensor([ 0.8187, -0.7789])\n",
      "pre:left true:left 4257/11700\n",
      "tensor([ 1.2205, -1.2859])\n",
      "pre:left true:left 4258/11700\n",
      "tensor([ 0.6913, -0.5839])\n",
      "pre:left true:left 4259/11700\n",
      "tensor([ 0.7632, -0.7955])\n",
      "pre:left true:left 4260/11700\n",
      "tensor([-0.0142,  0.0753])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左402_0_402_20200412_110622150_7.jpg\n",
      "pre:right true:left 4261/11700\n",
      "tensor([-0.0026,  0.0952])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左720_0_720_20200412_111355758_10.jpg\n",
      "pre:right true:left 4262/11700\n",
      "tensor([ 0.8313, -0.7702])\n",
      "pre:left true:left 4263/11700\n",
      "tensor([ 0.5037, -0.3881])\n",
      "pre:left true:left 4264/11700\n",
      "tensor([ 0.6516, -0.6271])\n",
      "pre:left true:left 4265/11700\n",
      "tensor([ 1.0741, -1.0599])\n",
      "pre:left true:left 4266/11700\n",
      "tensor([-0.2833,  0.2849])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左888_0_888_20200412_111755369_0.jpg\n",
      "pre:right true:left 4267/11700\n",
      "tensor([ 0.1654, -0.2334])\n",
      "pre:left true:left 4268/11700\n",
      "tensor([ 0.8988, -0.9200])\n",
      "pre:left true:left 4269/11700\n",
      "tensor([ 0.7077, -0.6709])\n",
      "pre:left true:left 4270/11700\n",
      "tensor([ 0.5066, -0.4935])\n",
      "pre:left true:left 4271/11700\n",
      "tensor([ 0.3924, -0.3717])\n",
      "pre:left true:left 4272/11700\n",
      "tensor([ 0.4818, -0.5813])\n",
      "pre:left true:left 4273/11700\n",
      "tensor([ 1.2079, -1.1910])\n",
      "pre:left true:left 4274/11700\n",
      "tensor([ 0.9315, -1.0337])\n",
      "pre:left true:left 4275/11700\n",
      "tensor([ 0.1870, -0.0911])\n",
      "pre:left true:left 4276/11700\n",
      "tensor([-0.0832,  0.0890])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左919_0_919_20200412_111839183_7.jpg\n",
      "pre:right true:left 4277/11700\n",
      "tensor([ 1.3527, -1.3787])\n",
      "pre:left true:left 4278/11700\n",
      "tensor([ 0.5776, -0.4663])\n",
      "pre:left true:left 4279/11700\n",
      "tensor([ 1.6378, -1.6163])\n",
      "pre:left true:left 4280/11700\n",
      "tensor([ 0.9339, -0.9056])\n",
      "pre:left true:left 4281/11700\n",
      "tensor([ 0.4170, -0.2649])\n",
      "pre:left true:left 4282/11700\n",
      "tensor([ 0.9507, -0.9595])\n",
      "pre:left true:left 4283/11700\n",
      "tensor([ 0.9233, -0.9244])\n",
      "pre:left true:left 4284/11700\n",
      "tensor([ 1.0083, -1.0511])\n",
      "pre:left true:left 4285/11700\n",
      "tensor([ 0.1947, -0.2403])\n",
      "pre:left true:left 4286/11700\n",
      "tensor([ 0.1895, -0.2506])\n",
      "pre:left true:left 4287/11700\n",
      "tensor([-0.0168,  0.1633])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左169_0_325_20200412_114235899_9.jpg\n",
      "pre:right true:left 4288/11700\n",
      "tensor([ 0.3847, -0.2796])\n",
      "pre:left true:left 4289/11700\n",
      "tensor([-0.1871,  0.1767])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左484_0_640_20200412_114926355_1.jpg\n",
      "pre:right true:left 4290/11700\n",
      "tensor([ 0.6251, -0.6452])\n",
      "pre:left true:left 4291/11700\n",
      "tensor([ 0.0599, -0.0456])\n",
      "pre:left true:left 4292/11700\n",
      "tensor([ 0.7892, -0.8812])\n",
      "pre:left true:left 4293/11700\n",
      "tensor([ 0.7142, -0.7056])\n",
      "pre:left true:left 4294/11700\n",
      "tensor([ 0.4922, -0.3847])\n",
      "pre:left true:left 4295/11700\n",
      "tensor([ 0.6912, -0.7539])\n",
      "pre:left true:left 4296/11700\n",
      "tensor([ 1.1240, -1.1219])\n",
      "pre:left true:left 4297/11700\n",
      "tensor([ 0.3867, -0.3448])\n",
      "pre:left true:left 4298/11700\n",
      "tensor([ 0.6658, -0.5847])\n",
      "pre:left true:left 4299/11700\n",
      "tensor([ 0.5509, -0.6041])\n",
      "pre:left true:left 4300/11700\n",
      "tensor([ 0.2206, -0.2368])\n",
      "pre:left true:left 4301/11700\n",
      "tensor([ 0.2940, -0.3261])\n",
      "pre:left true:left 4302/11700\n",
      "tensor([ 1.2242, -1.3093])\n",
      "pre:left true:left 4303/11700\n",
      "tensor([ 0.4304, -0.3795])\n",
      "pre:left true:left 4304/11700\n",
      "tensor([-0.5049,  0.4836])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左888_0_888_20200412_111755369_10.jpg\n",
      "pre:right true:left 4305/11700\n",
      "tensor([ 1.1328, -1.2468])\n",
      "pre:left true:left 4306/11700\n",
      "tensor([ 0.5487, -0.4279])\n",
      "pre:left true:left 4307/11700\n",
      "tensor([ 0.4507, -0.3819])\n",
      "pre:left true:left 4308/11700\n",
      "tensor([-0.0037, -0.0875])\n",
      "pre:left true:left 4309/11700\n",
      "tensor([ 0.4544, -0.4649])\n",
      "pre:left true:left 4310/11700\n",
      "tensor([ 0.2388, -0.1945])\n",
      "pre:left true:left 4311/11700\n",
      "tensor([ 0.8506, -0.7712])\n",
      "pre:left true:left 4312/11700\n",
      "tensor([ 1.0279, -1.1242])\n",
      "pre:left true:left 4313/11700\n",
      "tensor([ 0.5962, -0.6704])\n",
      "pre:left true:left 4314/11700\n",
      "tensor([ 0.0185, -0.0095])\n",
      "pre:left true:left 4315/11700\n",
      "tensor([ 0.5073, -0.5285])\n",
      "pre:left true:left 4316/11700\n",
      "tensor([ 0.7195, -0.6785])\n",
      "pre:left true:left 4317/11700\n",
      "tensor([ 0.6045, -0.5803])\n",
      "pre:left true:left 4318/11700\n",
      "tensor([ 1.3535, -1.3515])\n",
      "pre:left true:left 4319/11700\n",
      "tensor([ 0.1631, -0.2214])\n",
      "pre:left true:left 4320/11700\n",
      "tensor([ 0.2520, -0.2270])\n",
      "pre:left true:left 4321/11700\n",
      "tensor([ 0.1240, -0.0967])\n",
      "pre:left true:left 4322/11700\n",
      "tensor([ 1.7277, -1.8327])\n",
      "pre:left true:left 4323/11700\n",
      "tensor([ 0.9189, -0.9508])\n",
      "pre:left true:left 4324/11700\n",
      "tensor([-0.1608,  0.1907])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/右1009_0_1009_20200412_112036432_1.jpg\n",
      "pre:right true:left 4325/11700\n",
      "tensor([ 0.6334, -0.5131])\n",
      "pre:left true:left 4326/11700\n",
      "tensor([ 0.6284, -0.5572])\n",
      "pre:left true:left 4327/11700\n",
      "tensor([ 0.3946, -0.4126])\n",
      "pre:left true:left 4328/11700\n",
      "tensor([ 0.4477, -0.4399])\n",
      "pre:left true:left 4329/11700\n",
      "tensor([ 1.2337, -1.1643])\n",
      "pre:left true:left 4330/11700\n",
      "tensor([ 0.2615, -0.2891])\n",
      "pre:left true:left 4331/11700\n",
      "tensor([ 0.7252, -0.6956])\n",
      "pre:left true:left 4332/11700\n",
      "tensor([ 0.6117, -0.5085])\n",
      "pre:left true:left 4333/11700\n",
      "tensor([ 0.0787, -0.0238])\n",
      "pre:left true:left 4334/11700\n",
      "tensor([ 0.4399, -0.4175])\n",
      "pre:left true:left 4335/11700\n",
      "tensor([-0.1157,  0.1454])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左270_0_426_20200412_114447496_7.jpg\n",
      "pre:right true:left 4336/11700\n",
      "tensor([ 0.5014, -0.5533])\n",
      "pre:left true:left 4337/11700\n",
      "tensor([ 1.2145, -1.2142])\n",
      "pre:left true:left 4338/11700\n",
      "tensor([ 0.8708, -0.8758])\n",
      "pre:left true:left 4339/11700\n",
      "tensor([ 0.3254, -0.2592])\n",
      "pre:left true:left 4340/11700\n",
      "tensor([ 0.3192, -0.3172])\n",
      "pre:left true:left 4341/11700\n",
      "tensor([ 1.1751, -1.1024])\n",
      "pre:left true:left 4342/11700\n",
      "tensor([ 0.8525, -0.8619])\n",
      "pre:left true:left 4343/11700\n",
      "tensor([ 0.4707, -0.4583])\n",
      "pre:left true:left 4344/11700\n",
      "tensor([ 0.9804, -0.9519])\n",
      "pre:left true:left 4345/11700\n",
      "tensor([ 0.9526, -0.8823])\n",
      "pre:left true:left 4346/11700\n",
      "tensor([ 0.1382, -0.1377])\n",
      "pre:left true:left 4347/11700\n",
      "tensor([ 0.9044, -0.9505])\n",
      "pre:left true:left 4348/11700\n",
      "tensor([ 0.7098, -0.6463])\n",
      "pre:left true:left 4349/11700\n",
      "tensor([ 0.8398, -0.8346])\n",
      "pre:left true:left 4350/11700\n",
      "tensor([ 0.6071, -0.6751])\n",
      "pre:left true:left 4351/11700\n",
      "tensor([ 1.3643, -1.4011])\n",
      "pre:left true:left 4352/11700\n",
      "tensor([ 0.5498, -0.5405])\n",
      "pre:left true:left 4353/11700\n",
      "tensor([ 0.3803, -0.4594])\n",
      "pre:left true:left 4354/11700\n",
      "tensor([ 0.8622, -0.9103])\n",
      "pre:left true:left 4355/11700\n",
      "tensor([ 1.3969, -1.5120])\n",
      "pre:left true:left 4356/11700\n",
      "tensor([ 0.8168, -0.8159])\n",
      "pre:left true:left 4357/11700\n",
      "tensor([ 0.4536, -0.3899])\n",
      "pre:left true:left 4358/11700\n",
      "tensor([ 0.6272, -0.6452])\n",
      "pre:left true:left 4359/11700\n",
      "tensor([ 0.7597, -0.7276])\n",
      "pre:left true:left 4360/11700\n",
      "tensor([ 0.1057, -0.1616])\n",
      "pre:left true:left 4361/11700\n",
      "tensor([ 0.6995, -0.6747])\n",
      "pre:left true:left 4362/11700\n",
      "tensor([ 1.4848, -1.4506])\n",
      "pre:left true:left 4363/11700\n",
      "tensor([ 0.3513, -0.3191])\n",
      "pre:left true:left 4364/11700\n",
      "tensor([ 1.3208, -1.3144])\n",
      "pre:left true:left 4365/11700\n",
      "tensor([ 0.8864, -0.7509])\n",
      "pre:left true:left 4366/11700\n",
      "tensor([ 0.9935, -1.0085])\n",
      "pre:left true:left 4367/11700\n",
      "tensor([ 0.9515, -0.8699])\n",
      "pre:left true:left 4368/11700\n",
      "tensor([ 0.3282, -0.3343])\n",
      "pre:left true:left 4369/11700\n",
      "tensor([ 0.4450, -0.3246])\n",
      "pre:left true:left 4370/11700\n",
      "tensor([ 0.9611, -0.9845])\n",
      "pre:left true:left 4371/11700\n",
      "tensor([ 0.6299, -0.6029])\n",
      "pre:left true:left 4372/11700\n",
      "tensor([ 0.4806, -0.3664])\n",
      "pre:left true:left 4373/11700\n",
      "tensor([ 0.4917, -0.3884])\n",
      "pre:left true:left 4374/11700\n",
      "tensor([ 0.0776, -0.0630])\n",
      "pre:left true:left 4375/11700\n",
      "tensor([ 0.3535, -0.3857])\n",
      "pre:left true:left 4376/11700\n",
      "tensor([ 0.8857, -0.8467])\n",
      "pre:left true:left 4377/11700\n",
      "tensor([ 0.9641, -0.8232])\n",
      "pre:left true:left 4378/11700\n",
      "tensor([ 0.0808, -0.1655])\n",
      "pre:left true:left 4379/11700\n",
      "tensor([ 0.7022, -0.7273])\n",
      "pre:left true:left 4380/11700\n",
      "tensor([-0.2027,  0.1450])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左68_0_68_20200412_105825772_3.jpg\n",
      "pre:right true:left 4381/11700\n",
      "tensor([ 1.0450, -0.9391])\n",
      "pre:left true:left 4382/11700\n",
      "tensor([ 0.4529, -0.3135])\n",
      "pre:left true:left 4383/11700\n",
      "tensor([ 0.3037, -0.2665])\n",
      "pre:left true:left 4384/11700\n",
      "tensor([-0.3062,  0.4860])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左226_0_382_20200412_114350157.jpg\n",
      "pre:right true:left 4385/11700\n",
      "tensor([ 0.4323, -0.3292])\n",
      "pre:left true:left 4386/11700\n",
      "tensor([ 1.2584, -1.3229])\n",
      "pre:left true:left 4387/11700\n",
      "tensor([ 0.4333, -0.3968])\n",
      "pre:left true:left 4388/11700\n",
      "tensor([ 0.0700, -0.0938])\n",
      "pre:left true:left 4389/11700\n",
      "tensor([ 0.7778, -0.8038])\n",
      "pre:left true:left 4390/11700\n",
      "tensor([ 0.2662, -0.3250])\n",
      "pre:left true:left 4391/11700\n",
      "tensor([ 0.2452, -0.2372])\n",
      "pre:left true:left 4392/11700\n",
      "tensor([ 1.1029, -1.1525])\n",
      "pre:left true:left 4393/11700\n",
      "tensor([ 1.3291, -1.2961])\n",
      "pre:left true:left 4394/11700\n",
      "tensor([ 1.0154, -0.9193])\n",
      "pre:left true:left 4395/11700\n",
      "tensor([ 0.9411, -0.8547])\n",
      "pre:left true:left 4396/11700\n",
      "tensor([ 0.3389, -0.3198])\n",
      "pre:left true:left 4397/11700\n",
      "tensor([ 0.2211, -0.2706])\n",
      "pre:left true:left 4398/11700\n",
      "tensor([ 1.2568, -1.2416])\n",
      "pre:left true:left 4399/11700\n",
      "tensor([ 0.8207, -0.8665])\n",
      "pre:left true:left 4400/11700\n",
      "tensor([ 0.8872, -0.9193])\n",
      "pre:left true:left 4401/11700\n",
      "tensor([-0.4368,  0.5111])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左985_0_985_20200412_112005188_10.jpg\n",
      "pre:right true:left 4402/11700\n",
      "tensor([ 0.5397, -0.4741])\n",
      "pre:left true:left 4403/11700\n",
      "tensor([ 0.9453, -0.9567])\n",
      "pre:left true:left 4404/11700\n",
      "tensor([-0.8766,  0.8701])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1556_0_1712_20200412_121243498_3.jpg\n",
      "pre:right true:left 4405/11700\n",
      "tensor([ 1.1078, -1.1264])\n",
      "pre:left true:left 4406/11700\n",
      "tensor([ 0.5631, -0.5801])\n",
      "pre:left true:left 4407/11700\n",
      "tensor([ 0.0924, -0.0844])\n",
      "pre:left true:left 4408/11700\n",
      "tensor([ 1.6177, -1.6854])\n",
      "pre:left true:left 4409/11700\n",
      "tensor([ 1.0142, -1.0642])\n",
      "pre:left true:left 4410/11700\n",
      "tensor([ 0.9548, -0.9539])\n",
      "pre:left true:left 4411/11700\n",
      "tensor([ 0.3340, -0.2900])\n",
      "pre:left true:left 4412/11700\n",
      "tensor([ 0.4027, -0.4220])\n",
      "pre:left true:left 4413/11700\n",
      "tensor([ 0.6445, -0.6225])\n",
      "pre:left true:left 4414/11700\n",
      "tensor([ 0.2969, -0.3725])\n",
      "pre:left true:left 4415/11700\n",
      "tensor([ 0.7498, -0.7365])\n",
      "pre:left true:left 4416/11700\n",
      "tensor([ 0.7365, -0.8258])\n",
      "pre:left true:left 4417/11700\n",
      "tensor([ 0.3515, -0.3608])\n",
      "pre:left true:left 4418/11700\n",
      "tensor([ 1.1376, -1.1975])\n",
      "pre:left true:left 4419/11700\n",
      "tensor([ 0.9423, -0.9312])\n",
      "pre:left true:left 4420/11700\n",
      "tensor([ 1.2833, -1.1965])\n",
      "pre:left true:left 4421/11700\n",
      "tensor([ 0.7470, -0.7878])\n",
      "pre:left true:left 4422/11700\n",
      "tensor([ 0.6120, -0.6534])\n",
      "pre:left true:left 4423/11700\n",
      "tensor([ 0.5770, -0.5669])\n",
      "pre:left true:left 4424/11700\n",
      "tensor([ 0.5792, -0.5753])\n",
      "pre:left true:left 4425/11700\n",
      "tensor([ 0.5731, -0.6804])\n",
      "pre:left true:left 4426/11700\n",
      "tensor([ 0.2163, -0.1910])\n",
      "pre:left true:left 4427/11700\n",
      "tensor([ 0.7121, -0.6529])\n",
      "pre:left true:left 4428/11700\n",
      "tensor([ 0.4850, -0.4777])\n",
      "pre:left true:left 4429/11700\n",
      "tensor([ 0.3773, -0.3733])\n",
      "pre:left true:left 4430/11700\n",
      "tensor([ 0.1948, -0.1944])\n",
      "pre:left true:left 4431/11700\n",
      "tensor([ 0.4383, -0.4220])\n",
      "pre:left true:left 4432/11700\n",
      "tensor([ 0.3079, -0.4090])\n",
      "pre:left true:left 4433/11700\n",
      "tensor([ 0.5253, -0.4591])\n",
      "pre:left true:left 4434/11700\n",
      "tensor([ 1.2815, -1.3405])\n",
      "pre:left true:left 4435/11700\n",
      "tensor([ 0.3947, -0.4611])\n",
      "pre:left true:left 4436/11700\n",
      "tensor([ 0.4719, -0.4302])\n",
      "pre:left true:left 4437/11700\n",
      "tensor([ 0.2565, -0.2306])\n",
      "pre:left true:left 4438/11700\n",
      "tensor([ 0.7332, -0.7188])\n",
      "pre:left true:left 4439/11700\n",
      "tensor([ 0.0200, -0.0160])\n",
      "pre:left true:left 4440/11700\n",
      "tensor([ 0.9416, -0.9205])\n",
      "pre:left true:left 4441/11700\n",
      "tensor([ 0.5198, -0.4807])\n",
      "pre:left true:left 4442/11700\n",
      "tensor([ 1.0025, -0.9566])\n",
      "pre:left true:left 4443/11700\n",
      "tensor([ 0.7368, -0.7210])\n",
      "pre:left true:left 4444/11700\n",
      "tensor([ 1.2733, -1.2285])\n",
      "pre:left true:left 4445/11700\n",
      "tensor([ 1.2763, -1.2267])\n",
      "pre:left true:left 4446/11700\n",
      "tensor([ 0.5388, -0.4501])\n",
      "pre:left true:left 4447/11700\n",
      "tensor([ 0.3155, -0.2697])\n",
      "pre:left true:left 4448/11700\n",
      "tensor([ 0.9488, -0.9102])\n",
      "pre:left true:left 4449/11700\n",
      "tensor([ 0.3481, -0.2834])\n",
      "pre:left true:left 4450/11700\n",
      "tensor([ 0.3966, -0.3545])\n",
      "pre:left true:left 4451/11700\n",
      "tensor([ 0.9638, -0.9477])\n",
      "pre:left true:left 4452/11700\n",
      "tensor([-0.0284,  0.0045])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左742_0_742_20200412_111427140.jpg\n",
      "pre:right true:left 4453/11700\n",
      "tensor([ 0.4222, -0.5365])\n",
      "pre:left true:left 4454/11700\n",
      "tensor([ 0.7355, -0.7887])\n",
      "pre:left true:left 4455/11700\n",
      "tensor([ 0.3710, -0.3149])\n",
      "pre:left true:left 4456/11700\n",
      "tensor([-0.0568,  0.0859])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左799_0_799_20200412_111548441_10.jpg\n",
      "pre:right true:left 4457/11700\n",
      "tensor([ 0.4691, -0.3262])\n",
      "pre:left true:left 4458/11700\n",
      "tensor([ 0.2820, -0.2440])\n",
      "pre:left true:left 4459/11700\n",
      "tensor([ 0.4148, -0.4404])\n",
      "pre:left true:left 4460/11700\n",
      "tensor([ 0.8195, -0.7766])\n",
      "pre:left true:left 4461/11700\n",
      "tensor([ 0.1467, -0.1773])\n",
      "pre:left true:left 4462/11700\n",
      "tensor([-0.7941,  0.6890])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左351_0_507_20200412_114633054_3.jpg\n",
      "pre:right true:left 4463/11700\n",
      "tensor([ 1.3272, -1.2953])\n",
      "pre:left true:left 4464/11700\n",
      "tensor([ 0.8504, -0.8439])\n",
      "pre:left true:left 4465/11700\n",
      "tensor([ 0.5783, -0.6335])\n",
      "pre:left true:left 4466/11700\n",
      "tensor([ 0.4446, -0.3327])\n",
      "pre:left true:left 4467/11700\n",
      "tensor([ 1.1015, -1.1388])\n",
      "pre:left true:left 4468/11700\n",
      "tensor([ 0.6057, -0.6165])\n",
      "pre:left true:left 4469/11700\n",
      "tensor([ 0.8079, -0.8844])\n",
      "pre:left true:left 4470/11700\n",
      "tensor([ 0.8077, -0.7172])\n",
      "pre:left true:left 4471/11700\n",
      "tensor([ 0.5220, -0.5176])\n",
      "pre:left true:left 4472/11700\n",
      "tensor([ 0.6755, -0.6199])\n",
      "pre:left true:left 4473/11700\n",
      "tensor([ 0.4496, -0.3702])\n",
      "pre:left true:left 4474/11700\n",
      "tensor([ 1.0761, -0.9933])\n",
      "pre:left true:left 4475/11700\n",
      "tensor([ 1.1312, -1.1944])\n",
      "pre:left true:left 4476/11700\n",
      "tensor([-0.5246,  0.5448])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左519_0_519_20200412_110909041_1.jpg\n",
      "pre:right true:left 4477/11700\n",
      "tensor([ 0.2414, -0.3345])\n",
      "pre:left true:left 4478/11700\n",
      "tensor([ 1.3769, -1.4045])\n",
      "pre:left true:left 4479/11700\n",
      "tensor([ 0.4371, -0.4143])\n",
      "pre:left true:left 4480/11700\n",
      "tensor([ 0.2936, -0.2028])\n",
      "pre:left true:left 4481/11700\n",
      "tensor([ 0.5410, -0.5545])\n",
      "pre:left true:left 4482/11700\n",
      "tensor([ 1.1245, -0.9626])\n",
      "pre:left true:left 4483/11700\n",
      "tensor([ 0.7404, -0.7017])\n",
      "pre:left true:left 4484/11700\n",
      "tensor([ 0.8571, -0.8901])\n",
      "pre:left true:left 4485/11700\n",
      "tensor([ 0.4662, -0.5050])\n",
      "pre:left true:left 4486/11700\n",
      "tensor([ 1.0667, -1.0633])\n",
      "pre:left true:left 4487/11700\n",
      "tensor([ 0.8191, -0.9235])\n",
      "pre:left true:left 4488/11700\n",
      "tensor([ 0.2069, -0.2346])\n",
      "pre:left true:left 4489/11700\n",
      "tensor([ 0.1634, -0.1065])\n",
      "pre:left true:left 4490/11700\n",
      "tensor([ 0.7078, -0.8080])\n",
      "pre:left true:left 4491/11700\n",
      "tensor([ 0.2881, -0.2380])\n",
      "pre:left true:left 4492/11700\n",
      "tensor([ 0.5932, -0.6403])\n",
      "pre:left true:left 4493/11700\n",
      "tensor([ 0.9773, -0.9335])\n",
      "pre:left true:left 4494/11700\n",
      "tensor([ 0.5001, -0.4885])\n",
      "pre:left true:left 4495/11700\n",
      "tensor([ 0.0767, -0.0260])\n",
      "pre:left true:left 4496/11700\n",
      "tensor([ 0.2898, -0.2815])\n",
      "pre:left true:left 4497/11700\n",
      "tensor([ 0.4524, -0.4703])\n",
      "pre:left true:left 4498/11700\n",
      "tensor([-0.5277,  0.5529])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左479_0_635_20200412_114919868_5.jpg\n",
      "pre:right true:left 4499/11700\n",
      "tensor([ 1.0849, -1.0688])\n",
      "pre:left true:left 4500/11700\n",
      "tensor([ 0.2024, -0.2636])\n",
      "pre:left true:left 4501/11700\n",
      "tensor([ 0.5570, -0.5605])\n",
      "pre:left true:left 4502/11700\n",
      "tensor([ 0.2401, -0.1965])\n",
      "pre:left true:left 4503/11700\n",
      "tensor([-0.0190,  0.0926])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左384_0_540_20200412_114716060_6.jpg\n",
      "pre:right true:left 4504/11700\n",
      "tensor([ 0.3476, -0.3143])\n",
      "pre:left true:left 4505/11700\n",
      "tensor([ 0.5636, -0.4638])\n",
      "pre:left true:left 4506/11700\n",
      "tensor([ 0.2215, -0.2352])\n",
      "pre:left true:left 4507/11700\n",
      "tensor([ 0.7001, -0.6724])\n",
      "pre:left true:left 4508/11700\n",
      "tensor([ 1.0260, -0.8785])\n",
      "pre:left true:left 4509/11700\n",
      "tensor([ 0.9846, -1.0393])\n",
      "pre:left true:left 4510/11700\n",
      "tensor([ 0.8239, -0.7562])\n",
      "pre:left true:left 4511/11700\n",
      "tensor([ 0.4682, -0.4374])\n",
      "pre:left true:left 4512/11700\n",
      "tensor([ 0.6713, -0.6674])\n",
      "pre:left true:left 4513/11700\n",
      "tensor([ 0.8240, -0.7907])\n",
      "pre:left true:left 4514/11700\n",
      "tensor([ 0.7314, -0.7496])\n",
      "pre:left true:left 4515/11700\n",
      "tensor([ 0.6834, -0.7310])\n",
      "pre:left true:left 4516/11700\n",
      "tensor([ 0.7127, -0.6990])\n",
      "pre:left true:left 4517/11700\n",
      "tensor([ 0.3088, -0.3309])\n",
      "pre:left true:left 4518/11700\n",
      "tensor([ 0.3793, -0.3450])\n",
      "pre:left true:left 4519/11700\n",
      "tensor([ 1.2795, -1.3594])\n",
      "pre:left true:left 4520/11700\n",
      "tensor([ 0.8070, -0.7877])\n",
      "pre:left true:left 4521/11700\n",
      "tensor([-0.5127,  0.5834])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1268_0_1424_20200412_120628117_9.jpg\n",
      "pre:right true:left 4522/11700\n",
      "tensor([ 0.7050, -0.5629])\n",
      "pre:left true:left 4523/11700\n",
      "tensor([ 1.0353, -0.9698])\n",
      "pre:left true:left 4524/11700\n",
      "tensor([ 0.3109, -0.3126])\n",
      "pre:left true:left 4525/11700\n",
      "tensor([ 1.2886, -1.2859])\n",
      "pre:left true:left 4526/11700\n",
      "tensor([ 0.7112, -0.6305])\n",
      "pre:left true:left 4527/11700\n",
      "tensor([ 0.4347, -0.3963])\n",
      "pre:left true:left 4528/11700\n",
      "tensor([ 0.2030, -0.2127])\n",
      "pre:left true:left 4529/11700\n",
      "tensor([ 0.2955, -0.3152])\n",
      "pre:left true:left 4530/11700\n",
      "tensor([ 0.9495, -1.0286])\n",
      "pre:left true:left 4531/11700\n",
      "tensor([ 0.6974, -0.7229])\n",
      "pre:left true:left 4532/11700\n",
      "tensor([ 0.7266, -0.4849])\n",
      "pre:left true:left 4533/11700\n",
      "tensor([ 0.2276, -0.2271])\n",
      "pre:left true:left 4534/11700\n",
      "tensor([-0.4079,  0.3120])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左495_0_651_20200412_114940709_10.jpg\n",
      "pre:right true:left 4535/11700\n",
      "tensor([ 0.0335, -0.0919])\n",
      "pre:left true:left 4536/11700\n",
      "tensor([ 0.6748, -0.6216])\n",
      "pre:left true:left 4537/11700\n",
      "tensor([ 0.5872, -0.6076])\n",
      "pre:left true:left 4538/11700\n",
      "tensor([ 1.2860, -1.3036])\n",
      "pre:left true:left 4539/11700\n",
      "tensor([ 0.6099, -0.5802])\n",
      "pre:left true:left 4540/11700\n",
      "tensor([ 1.0063, -0.9409])\n",
      "pre:left true:left 4541/11700\n",
      "tensor([-0.0066,  0.0249])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左296_0_296_20200412_110350973_2.jpg\n",
      "pre:right true:left 4542/11700\n",
      "tensor([ 0.7684, -0.7588])\n",
      "pre:left true:left 4543/11700\n",
      "tensor([ 0.7264, -0.7554])\n",
      "pre:left true:left 4544/11700\n",
      "tensor([ 0.6248, -0.6783])\n",
      "pre:left true:left 4545/11700\n",
      "tensor([ 0.8299, -0.8271])\n",
      "pre:left true:left 4546/11700\n",
      "tensor([ 1.2174, -1.1993])\n",
      "pre:left true:left 4547/11700\n",
      "tensor([ 0.5237, -0.5482])\n",
      "pre:left true:left 4548/11700\n",
      "tensor([ 0.0473, -0.0078])\n",
      "pre:left true:left 4549/11700\n",
      "tensor([-0.6041,  0.5587])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1200_0_1200_20200412_112445301_0.jpg\n",
      "pre:right true:left 4550/11700\n",
      "tensor([ 0.5071, -0.5445])\n",
      "pre:left true:left 4551/11700\n",
      "tensor([ 0.8430, -0.9117])\n",
      "pre:left true:left 4552/11700\n",
      "tensor([-0.2103,  0.1587])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左193_0_193_20200412_110124081_0.jpg\n",
      "pre:right true:left 4553/11700\n",
      "tensor([ 0.3878, -0.2854])\n",
      "pre:left true:left 4554/11700\n",
      "tensor([ 0.6012, -0.5255])\n",
      "pre:left true:left 4555/11700\n",
      "tensor([ 0.6895, -0.5654])\n",
      "pre:left true:left 4556/11700\n",
      "tensor([ 0.2375, -0.1895])\n",
      "pre:left true:left 4557/11700\n",
      "tensor([ 0.7088, -0.8382])\n",
      "pre:left true:left 4558/11700\n",
      "tensor([ 0.2920, -0.2793])\n",
      "pre:left true:left 4559/11700\n",
      "tensor([ 0.9325, -0.9308])\n",
      "pre:left true:left 4560/11700\n",
      "tensor([ 0.4618, -0.3883])\n",
      "pre:left true:left 4561/11700\n",
      "tensor([ 0.5425, -0.5685])\n",
      "pre:left true:left 4562/11700\n",
      "tensor([ 0.7298, -0.6976])\n",
      "pre:left true:left 4563/11700\n",
      "tensor([ 1.1736, -1.2125])\n",
      "pre:left true:left 4564/11700\n",
      "tensor([ 0.7550, -0.7289])\n",
      "pre:left true:left 4565/11700\n",
      "tensor([-0.2899,  0.3260])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左798_0_954_20200412_115615583_7.jpg\n",
      "pre:right true:left 4566/11700\n",
      "tensor([ 1.6479, -1.6811])\n",
      "pre:left true:left 4567/11700\n",
      "tensor([ 0.7237, -0.6660])\n",
      "pre:left true:left 4568/11700\n",
      "tensor([ 1.7270, -1.6507])\n",
      "pre:left true:left 4569/11700\n",
      "tensor([ 0.2214, -0.1759])\n",
      "pre:left true:left 4570/11700\n",
      "tensor([-0.0104,  0.0691])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左480_0_636_20200412_114921166_1.jpg\n",
      "pre:right true:left 4571/11700\n",
      "tensor([ 0.7757, -0.7410])\n",
      "pre:left true:left 4572/11700\n",
      "tensor([ 0.8953, -0.8907])\n",
      "pre:left true:left 4573/11700\n",
      "tensor([-0.1260,  0.2243])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左991_0_991_20200412_112012994_4.jpg\n",
      "pre:right true:left 4574/11700\n",
      "tensor([-0.2456,  0.2533])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左839_0_839_20200412_111645484_8.jpg\n",
      "pre:right true:left 4575/11700\n",
      "tensor([-0.0931,  0.1301])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左307_0_463_20200412_114535722_4.jpg\n",
      "pre:right true:left 4576/11700\n",
      "tensor([ 0.8593, -0.7802])\n",
      "pre:left true:left 4577/11700\n",
      "tensor([ 0.9654, -0.8787])\n",
      "pre:left true:left 4578/11700\n",
      "tensor([-0.5468,  0.5007])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左65_0_65_20200412_105821839_3.jpg\n",
      "pre:right true:left 4579/11700\n",
      "tensor([ 0.3193, -0.2342])\n",
      "pre:left true:left 4580/11700\n",
      "tensor([ 0.5426, -0.5331])\n",
      "pre:left true:left 4581/11700\n",
      "tensor([-0.1309,  0.1209])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左609_0_765_20200412_115209260_6.jpg\n",
      "pre:right true:left 4582/11700\n",
      "tensor([-1.2779,  1.2551])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左423_0_579_20200412_114806868_1.jpg\n",
      "pre:right true:left 4583/11700\n",
      "tensor([ 1.7717, -1.7880])\n",
      "pre:left true:left 4584/11700\n",
      "tensor([ 0.3296, -0.3016])\n",
      "pre:left true:left 4585/11700\n",
      "tensor([ 1.9926, -2.1304])\n",
      "pre:left true:left 4586/11700\n",
      "tensor([ 1.5020, -1.5746])\n",
      "pre:left true:left 4587/11700\n",
      "tensor([ 0.4671, -0.4627])\n",
      "pre:left true:left 4588/11700\n",
      "tensor([ 0.2947, -0.2786])\n",
      "pre:left true:left 4589/11700\n",
      "tensor([ 0.3083, -0.2974])\n",
      "pre:left true:left 4590/11700\n",
      "tensor([-0.2881,  0.3969])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1081_0_1081_20200412_112210244_9.jpg\n",
      "pre:right true:left 4591/11700\n",
      "tensor([ 0.2246, -0.1201])\n",
      "pre:left true:left 4592/11700\n",
      "tensor([ 0.7960, -0.8169])\n",
      "pre:left true:left 4593/11700\n",
      "tensor([-0.1964,  0.2010])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左416_0_572_20200412_114757758_0.jpg\n",
      "pre:right true:left 4594/11700\n",
      "tensor([-0.0244,  0.0951])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左151_0_151_20200412_110024176_3.jpg\n",
      "pre:right true:left 4595/11700\n",
      "tensor([ 0.3936, -0.3453])\n",
      "pre:left true:left 4596/11700\n",
      "tensor([ 0.6858, -0.6221])\n",
      "pre:left true:left 4597/11700\n",
      "tensor([ 0.3419, -0.4320])\n",
      "pre:left true:left 4598/11700\n",
      "tensor([ 0.2234, -0.2581])\n",
      "pre:left true:left 4599/11700\n",
      "tensor([ 0.1803, -0.2826])\n",
      "pre:left true:left 4600/11700\n",
      "tensor([ 0.9548, -0.9733])\n",
      "pre:left true:left 4601/11700\n",
      "tensor([-0.6455,  0.7302])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左339_0_339_20200412_110452288_9.jpg\n",
      "pre:right true:left 4602/11700\n",
      "tensor([ 0.9519, -0.8933])\n",
      "pre:left true:left 4603/11700\n",
      "tensor([ 0.4126, -0.3558])\n",
      "pre:left true:left 4604/11700\n",
      "tensor([ 0.3814, -0.4067])\n",
      "pre:left true:left 4605/11700\n",
      "tensor([ 0.0496, -0.0287])\n",
      "pre:left true:left 4606/11700\n",
      "tensor([ 0.8759, -0.8765])\n",
      "pre:left true:left 4607/11700\n",
      "tensor([ 0.2925, -0.3313])\n",
      "pre:left true:left 4608/11700\n",
      "tensor([ 0.1171, -0.0509])\n",
      "pre:left true:left 4609/11700\n",
      "tensor([ 0.9324, -0.8364])\n",
      "pre:left true:left 4610/11700\n",
      "tensor([ 1.0945, -1.1143])\n",
      "pre:left true:left 4611/11700\n",
      "tensor([ 0.2515, -0.1807])\n",
      "pre:left true:left 4612/11700\n",
      "tensor([ 0.6783, -0.6838])\n",
      "pre:left true:left 4613/11700\n",
      "tensor([ 0.4510, -0.3546])\n",
      "pre:left true:left 4614/11700\n",
      "tensor([-0.7131,  0.7068])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左350_0_350_20200412_110507973_1.jpg\n",
      "pre:right true:left 4615/11700\n",
      "tensor([ 0.3824, -0.3650])\n",
      "pre:left true:left 4616/11700\n",
      "tensor([ 0.3111, -0.3041])\n",
      "pre:left true:left 4617/11700\n",
      "tensor([ 0.1245, -0.0770])\n",
      "pre:left true:left 4618/11700\n",
      "tensor([ 0.3953, -0.3292])\n",
      "pre:left true:left 4619/11700\n",
      "tensor([ 2.7032, -2.7515])\n",
      "pre:left true:left 4620/11700\n",
      "tensor([ 0.3696, -0.3077])\n",
      "pre:left true:left 4621/11700\n",
      "tensor([-0.4844,  0.4086])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左509_0_665_20200412_114958946_3.jpg\n",
      "pre:right true:left 4622/11700\n",
      "tensor([ 0.7024, -0.7292])\n",
      "pre:left true:left 4623/11700\n",
      "tensor([ 0.3512, -0.3352])\n",
      "pre:left true:left 4624/11700\n",
      "tensor([ 0.0636, -0.0062])\n",
      "pre:left true:left 4625/11700\n",
      "tensor([-0.0692,  0.0768])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1556_0_1712_20200412_121243498_4.jpg\n",
      "pre:right true:left 4626/11700\n",
      "tensor([ 0.1610, -0.2915])\n",
      "pre:left true:left 4627/11700\n",
      "tensor([ 0.6524, -0.5767])\n",
      "pre:left true:left 4628/11700\n",
      "tensor([ 0.1471, -0.1085])\n",
      "pre:left true:left 4629/11700\n",
      "tensor([ 0.6123, -0.5935])\n",
      "pre:left true:left 4630/11700\n",
      "tensor([ 0.6666, -0.6836])\n",
      "pre:left true:left 4631/11700\n",
      "tensor([ 0.8379, -0.8480])\n",
      "pre:left true:left 4632/11700\n",
      "tensor([ 0.4102, -0.4106])\n",
      "pre:left true:left 4633/11700\n",
      "tensor([ 0.4754, -0.4965])\n",
      "pre:left true:left 4634/11700\n",
      "tensor([ 1.4925, -1.5601])\n",
      "pre:left true:left 4635/11700\n",
      "tensor([-0.5218,  0.6645])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左393_0_393_20200412_110609318_5.jpg\n",
      "pre:right true:left 4636/11700\n",
      "tensor([ 0.4323, -0.3710])\n",
      "pre:left true:left 4637/11700\n",
      "tensor([ 0.4492, -0.4950])\n",
      "pre:left true:left 4638/11700\n",
      "tensor([ 0.2959, -0.3364])\n",
      "pre:left true:left 4639/11700\n",
      "tensor([ 0.6595, -0.6751])\n",
      "pre:left true:left 4640/11700\n",
      "tensor([ 0.0999, -0.1174])\n",
      "pre:left true:left 4641/11700\n",
      "tensor([ 1.4325, -1.4855])\n",
      "pre:left true:left 4642/11700\n",
      "tensor([ 0.0809, -0.0389])\n",
      "pre:left true:left 4643/11700\n",
      "tensor([ 1.0214, -0.9908])\n",
      "pre:left true:left 4644/11700\n",
      "tensor([ 1.1439, -1.0520])\n",
      "pre:left true:left 4645/11700\n",
      "tensor([ 0.2238, -0.2689])\n",
      "pre:left true:left 4646/11700\n",
      "tensor([ 1.2239, -1.1402])\n",
      "pre:left true:left 4647/11700\n",
      "tensor([ 0.7389, -0.6475])\n",
      "pre:left true:left 4648/11700\n",
      "tensor([ 0.6964, -0.7329])\n",
      "pre:left true:left 4649/11700\n",
      "tensor([ 0.2127, -0.1048])\n",
      "pre:left true:left 4650/11700\n",
      "tensor([-0.1731,  0.1379])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左429_0_585_20200412_114814696_7.jpg\n",
      "pre:right true:left 4651/11700\n",
      "tensor([0.0162, 0.0743])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左985_0_985_20200412_112005188_4.jpg\n",
      "pre:right true:left 4652/11700\n",
      "tensor([ 0.3770, -0.3740])\n",
      "pre:left true:left 4653/11700\n",
      "tensor([ 0.9536, -0.8396])\n",
      "pre:left true:left 4654/11700\n",
      "tensor([ 0.8062, -0.8588])\n",
      "pre:left true:left 4655/11700\n",
      "tensor([ 0.5267, -0.4995])\n",
      "pre:left true:left 4656/11700\n",
      "tensor([ 0.0820, -0.1117])\n",
      "pre:left true:left 4657/11700\n",
      "tensor([ 0.3918, -0.3440])\n",
      "pre:left true:left 4658/11700\n",
      "tensor([ 0.5542, -0.5332])\n",
      "pre:left true:left 4659/11700\n",
      "tensor([ 1.0187, -1.0413])\n",
      "pre:left true:left 4660/11700\n",
      "tensor([ 0.5582, -0.5924])\n",
      "pre:left true:left 4661/11700\n",
      "tensor([ 0.7762, -0.8067])\n",
      "pre:left true:left 4662/11700\n",
      "tensor([ 0.7110, -0.6832])\n",
      "pre:left true:left 4663/11700\n",
      "tensor([ 0.2275, -0.2909])\n",
      "pre:left true:left 4664/11700\n",
      "tensor([ 0.5890, -0.6377])\n",
      "pre:left true:left 4665/11700\n",
      "tensor([ 0.1079, -0.1758])\n",
      "pre:left true:left 4666/11700\n",
      "tensor([ 0.9550, -0.9916])\n",
      "pre:left true:left 4667/11700\n",
      "tensor([ 0.8359, -0.7714])\n",
      "pre:left true:left 4668/11700\n",
      "tensor([ 1.1583, -1.2271])\n",
      "pre:left true:left 4669/11700\n",
      "tensor([-0.0666,  0.1251])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左699_0_855_20200412_115406565_7.jpg\n",
      "pre:right true:left 4670/11700\n",
      "tensor([ 0.3261, -0.3918])\n",
      "pre:left true:left 4671/11700\n",
      "tensor([ 0.2101, -0.2299])\n",
      "pre:left true:left 4672/11700\n",
      "tensor([ 0.6662, -0.6518])\n",
      "pre:left true:left 4673/11700\n",
      "tensor([ 0.3306, -0.3092])\n",
      "pre:left true:left 4674/11700\n",
      "tensor([ 0.3200, -0.3091])\n",
      "pre:left true:left 4675/11700\n",
      "tensor([ 0.8618, -0.8024])\n",
      "pre:left true:left 4676/11700\n",
      "tensor([ 0.7501, -0.7936])\n",
      "pre:left true:left 4677/11700\n",
      "tensor([ 0.5054, -0.5823])\n",
      "pre:left true:left 4678/11700\n",
      "tensor([ 0.1955, -0.1975])\n",
      "pre:left true:left 4679/11700\n",
      "tensor([ 0.1166, -0.0350])\n",
      "pre:left true:left 4680/11700\n",
      "tensor([ 0.2259, -0.3280])\n",
      "pre:left true:left 4681/11700\n",
      "tensor([ 0.3727, -0.4196])\n",
      "pre:left true:left 4682/11700\n",
      "tensor([ 0.3372, -0.2881])\n",
      "pre:left true:left 4683/11700\n",
      "tensor([ 0.0802, -0.0961])\n",
      "pre:left true:left 4684/11700\n",
      "tensor([ 0.0552, -0.1670])\n",
      "pre:left true:left 4685/11700\n",
      "tensor([ 1.2823, -1.3301])\n",
      "pre:left true:left 4686/11700\n",
      "tensor([ 0.3852, -0.3225])\n",
      "pre:left true:left 4687/11700\n",
      "tensor([ 0.6978, -0.6992])\n",
      "pre:left true:left 4688/11700\n",
      "tensor([ 1.1978, -1.2606])\n",
      "pre:left true:left 4689/11700\n",
      "tensor([ 0.0950, -0.1609])\n",
      "pre:left true:left 4690/11700\n",
      "tensor([ 0.3138, -0.2514])\n",
      "pre:left true:left 4691/11700\n",
      "tensor([ 0.6130, -0.5444])\n",
      "pre:left true:left 4692/11700\n",
      "tensor([ 0.0503, -0.0998])\n",
      "pre:left true:left 4693/11700\n",
      "tensor([ 1.0035, -0.9445])\n",
      "pre:left true:left 4694/11700\n",
      "tensor([-0.2265,  0.1884])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左710_0_866_20200412_115420900_1.jpg\n",
      "pre:right true:left 4695/11700\n",
      "tensor([ 0.3822, -0.4340])\n",
      "pre:left true:left 4696/11700\n",
      "tensor([0.0656, 0.0160])\n",
      "pre:left true:left 4697/11700\n",
      "tensor([ 0.8006, -0.7816])\n",
      "pre:left true:left 4698/11700\n",
      "tensor([ 0.7552, -0.7847])\n",
      "pre:left true:left 4699/11700\n",
      "tensor([ 1.2224, -1.1818])\n",
      "pre:left true:left 4700/11700\n",
      "tensor([ 0.7981, -0.7224])\n",
      "pre:left true:left 4701/11700\n",
      "tensor([ 0.2127, -0.2896])\n",
      "pre:left true:left 4702/11700\n",
      "tensor([ 1.2168, -1.2288])\n",
      "pre:left true:left 4703/11700\n",
      "tensor([ 0.5800, -0.4904])\n",
      "pre:left true:left 4704/11700\n",
      "tensor([-0.1738,  0.1934])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左508_0_508_20200412_110853361_1.jpg\n",
      "pre:right true:left 4705/11700\n",
      "tensor([ 0.7190, -0.7658])\n",
      "pre:left true:left 4706/11700\n",
      "tensor([-0.0852,  0.2926])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左418_0_574_20200412_114800361_3.jpg\n",
      "pre:right true:left 4707/11700\n",
      "tensor([ 1.0219, -1.0378])\n",
      "pre:left true:left 4708/11700\n",
      "tensor([ 0.8475, -0.8372])\n",
      "pre:left true:left 4709/11700\n",
      "tensor([ 0.2391, -0.2777])\n",
      "pre:left true:left 4710/11700\n",
      "tensor([ 0.1876, -0.1413])\n",
      "pre:left true:left 4711/11700\n",
      "tensor([ 0.6864, -0.5809])\n",
      "pre:left true:left 4712/11700\n",
      "tensor([ 0.5376, -0.5195])\n",
      "pre:left true:left 4713/11700\n",
      "tensor([ 0.4594, -0.4601])\n",
      "pre:left true:left 4714/11700\n",
      "tensor([ 0.0498, -0.0442])\n",
      "pre:left true:left 4715/11700\n",
      "tensor([ 1.2093, -1.1528])\n",
      "pre:left true:left 4716/11700\n",
      "tensor([ 0.8421, -0.8165])\n",
      "pre:left true:left 4717/11700\n",
      "tensor([ 0.5463, -0.5138])\n",
      "pre:left true:left 4718/11700\n",
      "tensor([-0.4030,  0.2942])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左929_0_929_20200412_111852226_1.jpg\n",
      "pre:right true:left 4719/11700\n",
      "tensor([ 1.0369, -1.0313])\n",
      "pre:left true:left 4720/11700\n",
      "tensor([ 0.0408, -0.0090])\n",
      "pre:left true:left 4721/11700\n",
      "tensor([ 0.6581, -0.5690])\n",
      "pre:left true:left 4722/11700\n",
      "tensor([ 0.6530, -0.5889])\n",
      "pre:left true:left 4723/11700\n",
      "tensor([ 0.6197, -0.5359])\n",
      "pre:left true:left 4724/11700\n",
      "tensor([ 0.8276, -0.8743])\n",
      "pre:left true:left 4725/11700\n",
      "tensor([ 0.2842, -0.3007])\n",
      "pre:left true:left 4726/11700\n",
      "tensor([ 0.2764, -0.1736])\n",
      "pre:left true:left 4727/11700\n",
      "tensor([ 0.3917, -0.4667])\n",
      "pre:left true:left 4728/11700\n",
      "tensor([ 1.4191, -1.4955])\n",
      "pre:left true:left 4729/11700\n",
      "tensor([ 0.5053, -0.4536])\n",
      "pre:left true:left 4730/11700\n",
      "tensor([ 0.3436, -0.3043])\n",
      "pre:left true:left 4731/11700\n",
      "tensor([ 0.5449, -0.5620])\n",
      "pre:left true:left 4732/11700\n",
      "tensor([ 0.5370, -0.4360])\n",
      "pre:left true:left 4733/11700\n",
      "tensor([-0.1578,  0.2597])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左291_0_447_20200412_114514872_3.jpg\n",
      "pre:right true:left 4734/11700\n",
      "tensor([-0.0203, -0.0153])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左74_0_74_20200412_105834356_9.jpg\n",
      "pre:right true:left 4735/11700\n",
      "tensor([ 0.8057, -0.7651])\n",
      "pre:left true:left 4736/11700\n",
      "tensor([ 0.5104, -0.5200])\n",
      "pre:left true:left 4737/11700\n",
      "tensor([ 0.2986, -0.2907])\n",
      "pre:left true:left 4738/11700\n",
      "tensor([ 0.3382, -0.2017])\n",
      "pre:left true:left 4739/11700\n",
      "tensor([ 0.4061, -0.4541])\n",
      "pre:left true:left 4740/11700\n",
      "tensor([ 1.3058, -1.1847])\n",
      "pre:left true:left 4741/11700\n",
      "tensor([ 0.9141, -0.8893])\n",
      "pre:left true:left 4742/11700\n",
      "tensor([ 0.8778, -0.9647])\n",
      "pre:left true:left 4743/11700\n",
      "tensor([ 0.3310, -0.3244])\n",
      "pre:left true:left 4744/11700\n",
      "tensor([ 0.7128, -0.7823])\n",
      "pre:left true:left 4745/11700\n",
      "tensor([ 0.4818, -0.4238])\n",
      "pre:left true:left 4746/11700\n",
      "tensor([ 0.8489, -0.7668])\n",
      "pre:left true:left 4747/11700\n",
      "tensor([ 0.5276, -0.4541])\n",
      "pre:left true:left 4748/11700\n",
      "tensor([ 0.2209, -0.1363])\n",
      "pre:left true:left 4749/11700\n",
      "tensor([ 0.4208, -0.3654])\n",
      "pre:left true:left 4750/11700\n",
      "tensor([ 0.2711, -0.1249])\n",
      "pre:left true:left 4751/11700\n",
      "tensor([ 0.1698, -0.2043])\n",
      "pre:left true:left 4752/11700\n",
      "tensor([ 0.6167, -0.5424])\n",
      "pre:left true:left 4753/11700\n",
      "tensor([ 0.3510, -0.3720])\n",
      "pre:left true:left 4754/11700\n",
      "tensor([-0.3114,  0.3925])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左519_0_675_20200412_115011993_2.jpg\n",
      "pre:right true:left 4755/11700\n",
      "tensor([ 0.2019, -0.2141])\n",
      "pre:left true:left 4756/11700\n",
      "tensor([ 0.8064, -0.7692])\n",
      "pre:left true:left 4757/11700\n",
      "tensor([ 0.9738, -0.9900])\n",
      "pre:left true:left 4758/11700\n",
      "tensor([-0.9448,  1.1437])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左421_0_577_20200412_114804268_8.jpg\n",
      "pre:right true:left 4759/11700\n",
      "tensor([ 0.9996, -0.9524])\n",
      "pre:left true:left 4760/11700\n",
      "tensor([ 0.1295, -0.0753])\n",
      "pre:left true:left 4761/11700\n",
      "tensor([ 0.2332, -0.2302])\n",
      "pre:left true:left 4762/11700\n",
      "tensor([ 0.5295, -0.4073])\n",
      "pre:left true:left 4763/11700\n",
      "tensor([ 0.4858, -0.3414])\n",
      "pre:left true:left 4764/11700\n",
      "tensor([ 0.2893, -0.3009])\n",
      "pre:left true:left 4765/11700\n",
      "tensor([ 1.1368, -1.1255])\n",
      "pre:left true:left 4766/11700\n",
      "tensor([ 0.7178, -0.6710])\n",
      "pre:left true:left 4767/11700\n",
      "tensor([ 0.5443, -0.5308])\n",
      "pre:left true:left 4768/11700\n",
      "tensor([ 0.5387, -0.4116])\n",
      "pre:left true:left 4769/11700\n",
      "tensor([ 0.5594, -0.5143])\n",
      "pre:left true:left 4770/11700\n",
      "tensor([ 0.3948, -0.5061])\n",
      "pre:left true:left 4771/11700\n",
      "tensor([ 0.4056, -0.4878])\n",
      "pre:left true:left 4772/11700\n",
      "tensor([ 0.4326, -0.4890])\n",
      "pre:left true:left 4773/11700\n",
      "tensor([ 0.8266, -0.6975])\n",
      "pre:left true:left 4774/11700\n",
      "tensor([ 0.7298, -0.6594])\n",
      "pre:left true:left 4775/11700\n",
      "tensor([ 0.6871, -0.7221])\n",
      "pre:left true:left 4776/11700\n",
      "tensor([0.0863, 0.0012])\n",
      "pre:left true:left 4777/11700\n",
      "tensor([ 0.6955, -0.7751])\n",
      "pre:left true:left 4778/11700\n",
      "tensor([0.0077, 0.0273])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左542_0_698_20200412_115041962_2.jpg\n",
      "pre:right true:left 4779/11700\n",
      "tensor([ 0.8110, -0.7494])\n",
      "pre:left true:left 4780/11700\n",
      "tensor([ 0.5167, -0.4593])\n",
      "pre:left true:left 4781/11700\n",
      "tensor([-0.0479,  0.0016])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左329_0_329_20200412_110438029.jpg\n",
      "pre:right true:left 4782/11700\n",
      "tensor([ 0.6388, -0.5677])\n",
      "pre:left true:left 4783/11700\n",
      "tensor([ 0.1786, -0.0718])\n",
      "pre:left true:left 4784/11700\n",
      "tensor([ 1.1192, -1.1160])\n",
      "pre:left true:left 4785/11700\n",
      "tensor([-0.2863,  0.2160])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1291_0_1291_20200412_112643889_5.jpg\n",
      "pre:right true:left 4786/11700\n",
      "tensor([ 0.6326, -0.7192])\n",
      "pre:left true:left 4787/11700\n",
      "tensor([ 0.2297, -0.1969])\n",
      "pre:left true:left 4788/11700\n",
      "tensor([ 0.6158, -0.5925])\n",
      "pre:left true:left 4789/11700\n",
      "tensor([ 0.3240, -0.1950])\n",
      "pre:left true:left 4790/11700\n",
      "tensor([ 0.7295, -0.7993])\n",
      "pre:left true:left 4791/11700\n",
      "tensor([ 0.2983, -0.2927])\n",
      "pre:left true:left 4792/11700\n",
      "tensor([ 0.5430, -0.5668])\n",
      "pre:left true:left 4793/11700\n",
      "tensor([ 0.8916, -0.8924])\n",
      "pre:left true:left 4794/11700\n",
      "tensor([ 1.5584, -1.4028])\n",
      "pre:left true:left 4795/11700\n",
      "tensor([ 0.4117, -0.4699])\n",
      "pre:left true:left 4796/11700\n",
      "tensor([ 0.4852, -0.4542])\n",
      "pre:left true:left 4797/11700\n",
      "tensor([ 0.8433, -0.8311])\n",
      "pre:left true:left 4798/11700\n",
      "tensor([ 0.3523, -0.3946])\n",
      "pre:left true:left 4799/11700\n",
      "tensor([ 0.9370, -0.9511])\n",
      "pre:left true:left 4800/11700\n",
      "tensor([ 0.4805, -0.5352])\n",
      "pre:left true:left 4801/11700\n",
      "tensor([ 0.2640, -0.3368])\n",
      "pre:left true:left 4802/11700\n",
      "tensor([ 0.6658, -0.7342])\n",
      "pre:left true:left 4803/11700\n",
      "tensor([ 0.8192, -0.8308])\n",
      "pre:left true:left 4804/11700\n",
      "tensor([ 0.3713, -0.2517])\n",
      "pre:left true:left 4805/11700\n",
      "tensor([ 0.4503, -0.5403])\n",
      "pre:left true:left 4806/11700\n",
      "tensor([ 0.7195, -0.6999])\n",
      "pre:left true:left 4807/11700\n",
      "tensor([-0.4583,  0.4866])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1229_0_1229_20200412_112523087_3.jpg\n",
      "pre:right true:left 4808/11700\n",
      "tensor([ 0.3659, -0.3383])\n",
      "pre:left true:left 4809/11700\n",
      "tensor([ 0.4244, -0.3207])\n",
      "pre:left true:left 4810/11700\n",
      "tensor([-0.0429,  0.0215])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左877_0_877_20200412_111739699_7.jpg\n",
      "pre:right true:left 4811/11700\n",
      "tensor([ 0.2253, -0.2880])\n",
      "pre:left true:left 4812/11700\n",
      "tensor([ 1.1821, -1.1990])\n",
      "pre:left true:left 4813/11700\n",
      "tensor([ 0.6679, -0.5529])\n",
      "pre:left true:left 4814/11700\n",
      "tensor([-0.0085,  0.0871])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左348_0_348_20200412_110505133_0.jpg\n",
      "pre:right true:left 4815/11700\n",
      "tensor([ 1.1225, -1.0308])\n",
      "pre:left true:left 4816/11700\n",
      "tensor([ 0.2242, -0.2595])\n",
      "pre:left true:left 4817/11700\n",
      "tensor([ 0.2994, -0.2781])\n",
      "pre:left true:left 4818/11700\n",
      "tensor([ 0.5400, -0.6921])\n",
      "pre:left true:left 4819/11700\n",
      "tensor([ 0.6113, -0.6493])\n",
      "pre:left true:left 4820/11700\n",
      "tensor([-0.5240,  0.5407])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左817_0_817_20200412_111614098_9.jpg\n",
      "pre:right true:left 4821/11700\n",
      "tensor([-0.0062, -0.0144])\n",
      "pre:left true:left 4822/11700\n",
      "tensor([ 0.5443, -0.3568])\n",
      "pre:left true:left 4823/11700\n",
      "tensor([-0.5618,  0.6152])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左494_0_650_20200412_114939397_0.jpg\n",
      "pre:right true:left 4824/11700\n",
      "tensor([-0.1061,  0.0817])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左852_0_1008_20200412_115725981_2.jpg\n",
      "pre:right true:left 4825/11700\n",
      "tensor([ 0.8351, -0.8316])\n",
      "pre:left true:left 4826/11700\n",
      "tensor([ 0.8409, -0.7750])\n",
      "pre:left true:left 4827/11700\n",
      "tensor([ 0.6481, -0.6645])\n",
      "pre:left true:left 4828/11700\n",
      "tensor([ 1.2422, -1.1225])\n",
      "pre:left true:left 4829/11700\n",
      "tensor([ 0.9918, -0.9457])\n",
      "pre:left true:left 4830/11700\n",
      "tensor([ 0.3978, -0.3851])\n",
      "pre:left true:left 4831/11700\n",
      "tensor([ 0.6076, -0.5928])\n",
      "pre:left true:left 4832/11700\n",
      "tensor([ 0.0960, -0.0788])\n",
      "pre:left true:left 4833/11700\n",
      "tensor([ 0.7116, -0.6745])\n",
      "pre:left true:left 4834/11700\n",
      "tensor([ 0.9056, -0.8150])\n",
      "pre:left true:left 4835/11700\n",
      "tensor([ 1.4588, -1.3966])\n",
      "pre:left true:left 4836/11700\n",
      "tensor([ 0.7042, -0.7259])\n",
      "pre:left true:left 4837/11700\n",
      "tensor([ 0.8770, -0.8497])\n",
      "pre:left true:left 4838/11700\n",
      "tensor([ 0.8418, -0.8849])\n",
      "pre:left true:left 4839/11700\n",
      "tensor([ 0.2412, -0.2572])\n",
      "pre:left true:left 4840/11700\n",
      "tensor([ 0.5310, -0.4641])\n",
      "pre:left true:left 4841/11700\n",
      "tensor([ 0.0313, -0.0662])\n",
      "pre:left true:left 4842/11700\n",
      "tensor([ 0.6709, -0.6082])\n",
      "pre:left true:left 4843/11700\n",
      "tensor([ 0.0959, -0.0689])\n",
      "pre:left true:left 4844/11700\n",
      "tensor([ 1.2916, -1.2698])\n",
      "pre:left true:left 4845/11700\n",
      "tensor([ 0.3881, -0.3223])\n",
      "pre:left true:left 4846/11700\n",
      "tensor([-0.1120,  0.1022])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左791_0_947_20200412_115606477_7.jpg\n",
      "pre:right true:left 4847/11700\n",
      "tensor([-0.3765,  0.4863])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左563_0_719_20200412_115109319_4.jpg\n",
      "pre:right true:left 4848/11700\n",
      "tensor([-0.1051,  0.0699])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左385_0_541_20200412_114717362_10.jpg\n",
      "pre:right true:left 4849/11700\n",
      "tensor([ 0.0189, -0.0944])\n",
      "pre:left true:left 4850/11700\n",
      "tensor([-0.6464,  0.7076])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1172_0_1172_20200412_112408825_1.jpg\n",
      "pre:right true:left 4851/11700\n",
      "tensor([ 1.0992, -1.1793])\n",
      "pre:left true:left 4852/11700\n",
      "tensor([-0.0193,  0.0775])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1329_0_1329_20200412_112743331_9.jpg\n",
      "pre:right true:left 4853/11700\n",
      "tensor([ 0.4577, -0.4660])\n",
      "pre:left true:left 4854/11700\n",
      "tensor([ 0.4455, -0.3807])\n",
      "pre:left true:left 4855/11700\n",
      "tensor([ 0.1413, -0.0132])\n",
      "pre:left true:left 4856/11700\n",
      "tensor([ 1.0673, -1.0411])\n",
      "pre:left true:left 4857/11700\n",
      "tensor([ 0.2122, -0.1468])\n",
      "pre:left true:left 4858/11700\n",
      "tensor([ 0.5409, -0.4673])\n",
      "pre:left true:left 4859/11700\n",
      "tensor([ 0.2910, -0.2826])\n",
      "pre:left true:left 4860/11700\n",
      "tensor([ 0.6843, -0.7176])\n",
      "pre:left true:left 4861/11700\n",
      "tensor([ 0.6946, -0.6888])\n",
      "pre:left true:left 4862/11700\n",
      "tensor([ 0.9473, -0.8440])\n",
      "pre:left true:left 4863/11700\n",
      "tensor([ 0.5422, -0.4659])\n",
      "pre:left true:left 4864/11700\n",
      "tensor([-0.2971,  0.4229])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1114_0_1114_20200412_112253252_4.jpg\n",
      "pre:right true:left 4865/11700\n",
      "tensor([ 0.4424, -0.3269])\n",
      "pre:left true:left 4866/11700\n",
      "tensor([ 1.2858, -1.3544])\n",
      "pre:left true:left 4867/11700\n",
      "tensor([ 1.0022, -0.9377])\n",
      "pre:left true:left 4868/11700\n",
      "tensor([ 0.4332, -0.4720])\n",
      "pre:left true:left 4869/11700\n",
      "tensor([ 0.3745, -0.3688])\n",
      "pre:left true:left 4870/11700\n",
      "tensor([ 0.1880, -0.0607])\n",
      "pre:left true:left 4871/11700\n",
      "tensor([-0.2760,  0.2469])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左806_0_962_20200412_115626037_8.jpg\n",
      "pre:right true:left 4872/11700\n",
      "tensor([ 0.7579, -0.7649])\n",
      "pre:left true:left 4873/11700\n",
      "tensor([ 0.7535, -0.7441])\n",
      "pre:left true:left 4874/11700\n",
      "tensor([ 1.0278, -0.9904])\n",
      "pre:left true:left 4875/11700\n",
      "tensor([ 0.8699, -0.9047])\n",
      "pre:left true:left 4876/11700\n",
      "tensor([ 0.8271, -0.8409])\n",
      "pre:left true:left 4877/11700\n",
      "tensor([ 0.1645, -0.1917])\n",
      "pre:left true:left 4878/11700\n",
      "tensor([ 0.3268, -0.3036])\n",
      "pre:left true:left 4879/11700\n",
      "tensor([ 0.4132, -0.3813])\n",
      "pre:left true:left 4880/11700\n",
      "tensor([ 1.0225, -1.0204])\n",
      "pre:left true:left 4881/11700\n",
      "tensor([ 0.5286, -0.5193])\n",
      "pre:left true:left 4882/11700\n",
      "tensor([ 0.2532, -0.2971])\n",
      "pre:left true:left 4883/11700\n",
      "tensor([-0.0559, -0.0578])\n",
      "pre:left true:left 4884/11700\n",
      "tensor([ 0.4424, -0.4120])\n",
      "pre:left true:left 4885/11700\n",
      "tensor([-0.5107,  0.5012])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左967_0_967_20200412_111941711_5.jpg\n",
      "pre:right true:left 4886/11700\n",
      "tensor([ 0.7623, -0.8046])\n",
      "pre:left true:left 4887/11700\n",
      "tensor([-0.9416,  0.8422])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左446_0_602_20200412_114836836_5.jpg\n",
      "pre:right true:left 4888/11700\n",
      "tensor([ 0.2647, -0.2844])\n",
      "pre:left true:left 4889/11700\n",
      "tensor([ 0.2527, -0.2244])\n",
      "pre:left true:left 4890/11700\n",
      "tensor([ 1.2045, -1.1022])\n",
      "pre:left true:left 4891/11700\n",
      "tensor([ 0.5236, -0.5315])\n",
      "pre:left true:left 4892/11700\n",
      "tensor([ 0.3528, -0.3173])\n",
      "pre:left true:left 4893/11700\n",
      "tensor([ 0.4201, -0.4606])\n",
      "pre:left true:left 4894/11700\n",
      "tensor([ 0.8127, -0.6748])\n",
      "pre:left true:left 4895/11700\n",
      "tensor([ 0.6160, -0.6271])\n",
      "pre:left true:left 4896/11700\n",
      "tensor([ 0.1167, -0.0664])\n",
      "pre:left true:left 4897/11700\n",
      "tensor([ 0.8967, -0.8248])\n",
      "pre:left true:left 4898/11700\n",
      "tensor([ 0.9109, -0.8993])\n",
      "pre:left true:left 4899/11700\n",
      "tensor([ 0.9945, -1.0051])\n",
      "pre:left true:left 4900/11700\n",
      "tensor([ 0.0802, -0.0722])\n",
      "pre:left true:left 4901/11700\n",
      "tensor([ 0.6666, -0.6580])\n",
      "pre:left true:left 4902/11700\n",
      "tensor([ 0.3196, -0.3189])\n",
      "pre:left true:left 4903/11700\n",
      "tensor([ 0.8632, -0.8579])\n",
      "pre:left true:left 4904/11700\n",
      "tensor([ 0.1920, -0.1220])\n",
      "pre:left true:left 4905/11700\n",
      "tensor([ 1.3184, -1.2620])\n",
      "pre:left true:left 4906/11700\n",
      "tensor([ 0.2351, -0.2737])\n",
      "pre:left true:left 4907/11700\n",
      "tensor([ 0.2402, -0.3253])\n",
      "pre:left true:left 4908/11700\n",
      "tensor([-0.0923, -0.0138])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左532_0_688_20200412_115028919_5.jpg\n",
      "pre:right true:left 4909/11700\n",
      "tensor([ 1.2877, -1.2784])\n",
      "pre:left true:left 4910/11700\n",
      "tensor([-0.3012,  0.2603])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左853_0_1009_20200412_115727284_3.jpg\n",
      "pre:right true:left 4911/11700\n",
      "tensor([ 0.6350, -0.6769])\n",
      "pre:left true:left 4912/11700\n",
      "tensor([ 0.9524, -0.9589])\n",
      "pre:left true:left 4913/11700\n",
      "tensor([ 0.4693, -0.3628])\n",
      "pre:left true:left 4914/11700\n",
      "tensor([ 0.5508, -0.6414])\n",
      "pre:left true:left 4915/11700\n",
      "tensor([ 0.0064, -0.0555])\n",
      "pre:left true:left 4916/11700\n",
      "tensor([ 0.1339, -0.1325])\n",
      "pre:left true:left 4917/11700\n",
      "tensor([ 0.4829, -0.4773])\n",
      "pre:left true:left 4918/11700\n",
      "tensor([ 0.6837, -0.7009])\n",
      "pre:left true:left 4919/11700\n",
      "tensor([ 0.4667, -0.3090])\n",
      "pre:left true:left 4920/11700\n",
      "tensor([ 0.0762, -0.0624])\n",
      "pre:left true:left 4921/11700\n",
      "tensor([ 1.0574, -1.0041])\n",
      "pre:left true:left 4922/11700\n",
      "tensor([ 0.1995, -0.1924])\n",
      "pre:left true:left 4923/11700\n",
      "tensor([ 0.7401, -0.8366])\n",
      "pre:left true:left 4924/11700\n",
      "tensor([ 0.3566, -0.3927])\n",
      "pre:left true:left 4925/11700\n",
      "tensor([ 0.9625, -0.9091])\n",
      "pre:left true:left 4926/11700\n",
      "tensor([ 0.1417, -0.1738])\n",
      "pre:left true:left 4927/11700\n",
      "tensor([ 0.7578, -0.7218])\n",
      "pre:left true:left 4928/11700\n",
      "tensor([-0.0482, -0.0153])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左295_0_295_20200412_105529093_6.jpg\n",
      "pre:right true:left 4929/11700\n",
      "tensor([ 0.2332, -0.1612])\n",
      "pre:left true:left 4930/11700\n",
      "tensor([ 0.5890, -0.5190])\n",
      "pre:left true:left 4931/11700\n",
      "tensor([ 0.3208, -0.2712])\n",
      "pre:left true:left 4932/11700\n",
      "tensor([ 0.2326, -0.2849])\n",
      "pre:left true:left 4933/11700\n",
      "tensor([ 0.1736, -0.1743])\n",
      "pre:left true:left 4934/11700\n",
      "tensor([ 0.1406, -0.1762])\n",
      "pre:left true:left 4935/11700\n",
      "tensor([ 0.4579, -0.4041])\n",
      "pre:left true:left 4936/11700\n",
      "tensor([ 0.3836, -0.3858])\n",
      "pre:left true:left 4937/11700\n",
      "tensor([-0.0377,  0.0612])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1218_0_1218_20200412_112508762_9.jpg\n",
      "pre:right true:left 4938/11700\n",
      "tensor([ 0.2795, -0.3043])\n",
      "pre:left true:left 4939/11700\n",
      "tensor([ 0.4570, -0.5023])\n",
      "pre:left true:left 4940/11700\n",
      "tensor([ 0.2442, -0.2233])\n",
      "pre:left true:left 4941/11700\n",
      "tensor([ 1.2454, -1.2274])\n",
      "pre:left true:left 4942/11700\n",
      "tensor([ 0.4534, -0.4288])\n",
      "pre:left true:left 4943/11700\n",
      "tensor([ 0.5078, -0.4489])\n",
      "pre:left true:left 4944/11700\n",
      "tensor([ 0.4268, -0.3765])\n",
      "pre:left true:left 4945/11700\n",
      "tensor([ 0.9269, -0.8874])\n",
      "pre:left true:left 4946/11700\n",
      "tensor([ 0.2829, -0.2875])\n",
      "pre:left true:left 4947/11700\n",
      "tensor([ 1.2518, -1.2931])\n",
      "pre:left true:left 4948/11700\n",
      "tensor([ 1.1241, -0.9850])\n",
      "pre:left true:left 4949/11700\n",
      "tensor([ 0.1799, -0.1819])\n",
      "pre:left true:left 4950/11700\n",
      "tensor([ 0.4657, -0.5244])\n",
      "pre:left true:left 4951/11700\n",
      "tensor([-0.1593,  0.1112])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1617_0_1773_20200412_121402989_9.jpg\n",
      "pre:right true:left 4952/11700\n",
      "tensor([ 0.6975, -0.5895])\n",
      "pre:left true:left 4953/11700\n",
      "tensor([ 2.0054, -2.0065])\n",
      "pre:left true:left 4954/11700\n",
      "tensor([ 0.4550, -0.4378])\n",
      "pre:left true:left 4955/11700\n",
      "tensor([-1.2012,  1.3130])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左755_0_911_20200412_115519560_10.jpg\n",
      "pre:right true:left 4956/11700\n",
      "tensor([ 0.1095, -0.0466])\n",
      "pre:left true:left 4957/11700\n",
      "tensor([ 0.6719, -0.7286])\n",
      "pre:left true:left 4958/11700\n",
      "tensor([ 0.3355, -0.2961])\n",
      "pre:left true:left 4959/11700\n",
      "tensor([ 0.5226, -0.4873])\n",
      "pre:left true:left 4960/11700\n",
      "tensor([ 0.6936, -0.6635])\n",
      "pre:left true:left 4961/11700\n",
      "tensor([ 1.2629, -1.2533])\n",
      "pre:left true:left 4962/11700\n",
      "tensor([ 0.0594, -0.0515])\n",
      "pre:left true:left 4963/11700\n",
      "tensor([ 0.5191, -0.3918])\n",
      "pre:left true:left 4964/11700\n",
      "tensor([ 0.2273, -0.0758])\n",
      "pre:left true:left 4965/11700\n",
      "tensor([ 1.5357, -1.5584])\n",
      "pre:left true:left 4966/11700\n",
      "tensor([ 0.5024, -0.4803])\n",
      "pre:left true:left 4967/11700\n",
      "tensor([ 0.8588, -0.8735])\n",
      "pre:left true:left 4968/11700\n",
      "tensor([ 0.3856, -0.2222])\n",
      "pre:left true:left 4969/11700\n",
      "tensor([ 0.4201, -0.4606])\n",
      "pre:left true:left 4970/11700\n",
      "tensor([ 0.4789, -0.3867])\n",
      "pre:left true:left 4971/11700\n",
      "tensor([ 0.9263, -0.9722])\n",
      "pre:left true:left 4972/11700\n",
      "tensor([ 0.6388, -0.5689])\n",
      "pre:left true:left 4973/11700\n",
      "tensor([-0.1627,  0.1407])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左860_0_1016_20200412_115736393_4.jpg\n",
      "pre:right true:left 4974/11700\n",
      "tensor([ 0.8984, -0.8499])\n",
      "pre:left true:left 4975/11700\n",
      "tensor([ 1.3764, -1.4041])\n",
      "pre:left true:left 4976/11700\n",
      "tensor([-0.1298,  0.0956])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左367_0_523_20200412_114653912_6.jpg\n",
      "pre:right true:left 4977/11700\n",
      "tensor([ 0.2915, -0.1985])\n",
      "pre:left true:left 4978/11700\n",
      "tensor([ 1.0010, -1.0844])\n",
      "pre:left true:left 4979/11700\n",
      "tensor([ 0.1685, -0.1620])\n",
      "pre:left true:left 4980/11700\n",
      "tensor([-0.1628,  0.1986])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左720_0_720_20200412_111355758_3.jpg\n",
      "pre:right true:left 4981/11700\n",
      "tensor([ 0.9106, -0.8519])\n",
      "pre:left true:left 4982/11700\n",
      "tensor([ 1.0907, -1.0454])\n",
      "pre:left true:left 4983/11700\n",
      "tensor([ 0.0261, -0.0080])\n",
      "pre:left true:left 4984/11700\n",
      "tensor([ 0.2857, -0.2389])\n",
      "pre:left true:left 4985/11700\n",
      "tensor([ 1.0018, -1.0119])\n",
      "pre:left true:left 4986/11700\n",
      "tensor([ 0.9417, -0.9482])\n",
      "pre:left true:left 4987/11700\n",
      "tensor([ 0.8949, -0.9601])\n",
      "pre:left true:left 4988/11700\n",
      "tensor([ 1.1304, -1.1442])\n",
      "pre:left true:left 4989/11700\n",
      "tensor([ 0.0655, -0.1908])\n",
      "pre:left true:left 4990/11700\n",
      "tensor([ 0.0629, -0.0012])\n",
      "pre:left true:left 4991/11700\n",
      "tensor([ 0.3206, -0.3536])\n",
      "pre:left true:left 4992/11700\n",
      "tensor([ 0.9224, -0.9343])\n",
      "pre:left true:left 4993/11700\n",
      "tensor([ 0.6752, -0.5998])\n",
      "pre:left true:left 4994/11700\n",
      "tensor([ 0.5942, -0.5066])\n",
      "pre:left true:left 4995/11700\n",
      "tensor([ 0.9386, -0.9703])\n",
      "pre:left true:left 4996/11700\n",
      "tensor([ 0.2401, -0.1340])\n",
      "pre:left true:left 4997/11700\n",
      "tensor([ 0.9917, -0.8811])\n",
      "pre:left true:left 4998/11700\n",
      "tensor([ 1.1933, -1.1556])\n",
      "pre:left true:left 4999/11700\n",
      "tensor([ 0.2935, -0.2735])\n",
      "pre:left true:left 5000/11700\n",
      "tensor([ 0.4003, -0.2754])\n",
      "pre:left true:left 5001/11700\n",
      "tensor([-0.7283,  0.7450])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左768_0_924_20200412_115536520_5.jpg\n",
      "pre:right true:left 5002/11700\n",
      "tensor([ 0.4264, -0.4542])\n",
      "pre:left true:left 5003/11700\n",
      "tensor([ 0.5976, -0.6241])\n",
      "pre:left true:left 5004/11700\n",
      "tensor([ 0.0417, -0.0014])\n",
      "pre:left true:left 5005/11700\n",
      "tensor([ 0.1010, -0.1712])\n",
      "pre:left true:left 5006/11700\n",
      "tensor([ 0.4534, -0.4288])\n",
      "pre:left true:left 5007/11700\n",
      "tensor([0.0991, 0.0136])\n",
      "pre:left true:left 5008/11700\n",
      "tensor([ 1.3132, -1.3061])\n",
      "pre:left true:left 5009/11700\n",
      "tensor([ 0.3449, -0.1804])\n",
      "pre:left true:left 5010/11700\n",
      "tensor([ 0.6612, -0.6600])\n",
      "pre:left true:left 5011/11700\n",
      "tensor([-0.5659,  0.5754])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左614_0_770_20200412_115215786_2.jpg\n",
      "pre:right true:left 5012/11700\n",
      "tensor([ 0.3943, -0.3955])\n",
      "pre:left true:left 5013/11700\n",
      "tensor([ 0.8606, -0.9111])\n",
      "pre:left true:left 5014/11700\n",
      "tensor([ 0.6175, -0.6129])\n",
      "pre:left true:left 5015/11700\n",
      "tensor([ 1.3331, -1.4434])\n",
      "pre:left true:left 5016/11700\n",
      "tensor([ 0.6720, -0.6714])\n",
      "pre:left true:left 5017/11700\n",
      "tensor([ 0.6338, -0.6894])\n",
      "pre:left true:left 5018/11700\n",
      "tensor([ 1.7717, -1.7880])\n",
      "pre:left true:left 5019/11700\n",
      "tensor([ 0.9937, -1.0426])\n",
      "pre:left true:left 5020/11700\n",
      "tensor([-0.3840,  0.3047])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左72_0_72_20200412_105831500_5.jpg\n",
      "pre:right true:left 5021/11700\n",
      "tensor([ 0.5691, -0.5520])\n",
      "pre:left true:left 5022/11700\n",
      "tensor([ 0.6250, -0.6429])\n",
      "pre:left true:left 5023/11700\n",
      "tensor([ 0.3821, -0.3840])\n",
      "pre:left true:left 5024/11700\n",
      "tensor([-0.0354,  0.0450])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左337_0_493_20200412_114614825_6.jpg\n",
      "pre:right true:left 5025/11700\n",
      "tensor([ 0.5026, -0.5048])\n",
      "pre:left true:left 5026/11700\n",
      "tensor([ 1.4052, -1.4642])\n",
      "pre:left true:left 5027/11700\n",
      "tensor([-0.6918,  0.7755])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左96_0_252_20200412_114100770_4.jpg\n",
      "pre:right true:left 5028/11700\n",
      "tensor([ 0.0666, -0.0342])\n",
      "pre:left true:left 5029/11700\n",
      "tensor([ 1.0541, -1.1646])\n",
      "pre:left true:left 5030/11700\n",
      "tensor([ 0.2744, -0.2972])\n",
      "pre:left true:left 5031/11700\n",
      "tensor([ 0.7343, -0.8188])\n",
      "pre:left true:left 5032/11700\n",
      "tensor([ 0.6953, -0.6167])\n",
      "pre:left true:left 5033/11700\n",
      "tensor([ 0.8107, -0.8074])\n",
      "pre:left true:left 5034/11700\n",
      "tensor([ 0.8847, -0.8403])\n",
      "pre:left true:left 5035/11700\n",
      "tensor([ 0.7571, -0.7700])\n",
      "pre:left true:left 5036/11700\n",
      "tensor([ 0.2511, -0.1432])\n",
      "pre:left true:left 5037/11700\n",
      "tensor([-0.0800,  0.2454])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左777_0_933_20200412_115548226_4.jpg\n",
      "pre:right true:left 5038/11700\n",
      "tensor([ 0.4765, -0.3942])\n",
      "pre:left true:left 5039/11700\n",
      "tensor([ 0.6908, -0.6183])\n",
      "pre:left true:left 5040/11700\n",
      "tensor([ 0.4214, -0.3953])\n",
      "pre:left true:left 5041/11700\n",
      "tensor([ 0.4643, -0.3538])\n",
      "pre:left true:left 5042/11700\n",
      "tensor([-0.4067,  0.4608])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1101_0_1101_20200412_112236314_5.jpg\n",
      "pre:right true:left 5043/11700\n",
      "tensor([ 0.4935, -0.5655])\n",
      "pre:left true:left 5044/11700\n",
      "tensor([ 0.4230, -0.3644])\n",
      "pre:left true:left 5045/11700\n",
      "tensor([0.0385, 0.1364])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左550_0_706_20200412_115052381_5.jpg\n",
      "pre:right true:left 5046/11700\n",
      "tensor([-0.0744,  0.1033])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左768_0_768_20200412_111504208_7.jpg\n",
      "pre:right true:left 5047/11700\n",
      "tensor([ 0.7963, -0.5949])\n",
      "pre:left true:left 5048/11700\n",
      "tensor([ 0.8733, -0.8961])\n",
      "pre:left true:left 5049/11700\n",
      "tensor([ 0.6294, -0.6192])\n",
      "pre:left true:left 5050/11700\n",
      "tensor([ 0.7381, -0.7025])\n",
      "pre:left true:left 5051/11700\n",
      "tensor([ 0.6861, -0.6422])\n",
      "pre:left true:left 5052/11700\n",
      "tensor([ 0.6142, -0.6247])\n",
      "pre:left true:left 5053/11700\n",
      "tensor([ 0.5207, -0.4928])\n",
      "pre:left true:left 5054/11700\n",
      "tensor([ 0.3856, -0.2222])\n",
      "pre:left true:left 5055/11700\n",
      "tensor([ 0.2843, -0.3539])\n",
      "pre:left true:left 5056/11700\n",
      "tensor([ 0.4783, -0.5024])\n",
      "pre:left true:left 5057/11700\n",
      "tensor([ 0.5437, -0.5476])\n",
      "pre:left true:left 5058/11700\n",
      "tensor([ 0.3450, -0.2931])\n",
      "pre:left true:left 5059/11700\n",
      "tensor([-0.1556,  0.1811])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1517_0_1673_20200412_121152658_4.jpg\n",
      "pre:right true:left 5060/11700\n",
      "tensor([ 0.4765, -0.5874])\n",
      "pre:left true:left 5061/11700\n",
      "tensor([ 0.7770, -0.7694])\n",
      "pre:left true:left 5062/11700\n",
      "tensor([ 0.5686, -0.5974])\n",
      "pre:left true:left 5063/11700\n",
      "tensor([ 0.1797, -0.0774])\n",
      "pre:left true:left 5064/11700\n",
      "tensor([ 0.3501, -0.4101])\n",
      "pre:left true:left 5065/11700\n",
      "tensor([ 0.4711, -0.4391])\n",
      "pre:left true:left 5066/11700\n",
      "tensor([ 0.3161, -0.2188])\n",
      "pre:left true:left 5067/11700\n",
      "tensor([ 0.2142, -0.2047])\n",
      "pre:left true:left 5068/11700\n",
      "tensor([ 0.0609, -0.0876])\n",
      "pre:left true:left 5069/11700\n",
      "tensor([ 0.4860, -0.5055])\n",
      "pre:left true:left 5070/11700\n",
      "tensor([ 0.6277, -0.6124])\n",
      "pre:left true:left 5071/11700\n",
      "tensor([ 0.5553, -0.5083])\n",
      "pre:left true:left 5072/11700\n",
      "tensor([ 0.9900, -0.9147])\n",
      "pre:left true:left 5073/11700\n",
      "tensor([ 0.7969, -0.7578])\n",
      "pre:left true:left 5074/11700\n",
      "tensor([ 0.1538, -0.1418])\n",
      "pre:left true:left 5075/11700\n",
      "tensor([ 0.8270, -0.8938])\n",
      "pre:left true:left 5076/11700\n",
      "tensor([ 0.8141, -0.7310])\n",
      "pre:left true:left 5077/11700\n",
      "tensor([ 0.3720, -0.4146])\n",
      "pre:left true:left 5078/11700\n",
      "tensor([ 0.4939, -0.5320])\n",
      "pre:left true:left 5079/11700\n",
      "tensor([ 0.9687, -0.8122])\n",
      "pre:left true:left 5080/11700\n",
      "tensor([ 1.0143, -0.9575])\n",
      "pre:left true:left 5081/11700\n",
      "tensor([ 0.6605, -0.5461])\n",
      "pre:left true:left 5082/11700\n",
      "tensor([ 0.5493, -0.5568])\n",
      "pre:left true:left 5083/11700\n",
      "tensor([ 0.1477, -0.0769])\n",
      "pre:left true:left 5084/11700\n",
      "tensor([ 0.2285, -0.2195])\n",
      "pre:left true:left 5085/11700\n",
      "tensor([ 0.6776, -0.6627])\n",
      "pre:left true:left 5086/11700\n",
      "tensor([ 1.2379, -1.2706])\n",
      "pre:left true:left 5087/11700\n",
      "tensor([-0.2010,  0.2391])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左710_0_866_20200412_115420900_6.jpg\n",
      "pre:right true:left 5088/11700\n",
      "tensor([ 0.2334, -0.2279])\n",
      "pre:left true:left 5089/11700\n",
      "tensor([ 0.6210, -0.6036])\n",
      "pre:left true:left 5090/11700\n",
      "tensor([ 1.0210, -1.0296])\n",
      "pre:left true:left 5091/11700\n",
      "tensor([ 0.2380, -0.2656])\n",
      "pre:left true:left 5092/11700\n",
      "tensor([ 0.3471, -0.3078])\n",
      "pre:left true:left 5093/11700\n",
      "tensor([ 0.3818, -0.4545])\n",
      "pre:left true:left 5094/11700\n",
      "tensor([ 0.4627, -0.4543])\n",
      "pre:left true:left 5095/11700\n",
      "tensor([ 0.2844, -0.2977])\n",
      "pre:left true:left 5096/11700\n",
      "tensor([ 0.7268, -0.7329])\n",
      "pre:left true:left 5097/11700\n",
      "tensor([ 0.1067, -0.0788])\n",
      "pre:left true:left 5098/11700\n",
      "tensor([0.0587, 0.0049])\n",
      "pre:left true:left 5099/11700\n",
      "tensor([ 0.7337, -0.7117])\n",
      "pre:left true:left 5100/11700\n",
      "tensor([ 0.0361, -0.0797])\n",
      "pre:left true:left 5101/11700\n",
      "tensor([ 0.2225, -0.2688])\n",
      "pre:left true:left 5102/11700\n",
      "tensor([ 0.9728, -0.9340])\n",
      "pre:left true:left 5103/11700\n",
      "tensor([ 1.0970, -1.1753])\n",
      "pre:left true:left 5104/11700\n",
      "tensor([ 1.2681, -1.2787])\n",
      "pre:left true:left 5105/11700\n",
      "tensor([ 0.2622, -0.1697])\n",
      "pre:left true:left 5106/11700\n",
      "tensor([ 1.7661, -1.8513])\n",
      "pre:left true:left 5107/11700\n",
      "tensor([-0.0096, -0.0499])\n",
      "pre:left true:left 5108/11700\n",
      "tensor([ 0.7921, -0.7184])\n",
      "pre:left true:left 5109/11700\n",
      "tensor([ 0.5959, -0.6462])\n",
      "pre:left true:left 5110/11700\n",
      "tensor([ 0.3240, -0.3827])\n",
      "pre:left true:left 5111/11700\n",
      "tensor([ 0.6960, -0.6771])\n",
      "pre:left true:left 5112/11700\n",
      "tensor([ 0.2051, -0.2416])\n",
      "pre:left true:left 5113/11700\n",
      "tensor([ 0.3961, -0.3836])\n",
      "pre:left true:left 5114/11700\n",
      "tensor([ 0.9655, -0.8651])\n",
      "pre:left true:left 5115/11700\n",
      "tensor([ 0.7508, -0.7506])\n",
      "pre:left true:left 5116/11700\n",
      "tensor([ 0.4430, -0.4282])\n",
      "pre:left true:left 5117/11700\n",
      "tensor([ 0.5845, -0.5561])\n",
      "pre:left true:left 5118/11700\n",
      "tensor([ 0.8905, -0.8852])\n",
      "pre:left true:left 5119/11700\n",
      "tensor([ 0.4288, -0.3898])\n",
      "pre:left true:left 5120/11700\n",
      "tensor([ 0.7900, -0.8370])\n",
      "pre:left true:left 5121/11700\n",
      "tensor([-0.1060,  0.0673])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左675_0_831_20200412_115335288_0.jpg\n",
      "pre:right true:left 5122/11700\n",
      "tensor([ 1.1359, -1.1501])\n",
      "pre:left true:left 5123/11700\n",
      "tensor([ 1.5164, -1.4987])\n",
      "pre:left true:left 5124/11700\n",
      "tensor([ 0.4560, -0.3707])\n",
      "pre:left true:left 5125/11700\n",
      "tensor([ 0.5492, -0.5792])\n",
      "pre:left true:left 5126/11700\n",
      "tensor([ 0.5396, -0.4151])\n",
      "pre:left true:left 5127/11700\n",
      "tensor([ 0.1976, -0.2014])\n",
      "pre:left true:left 5128/11700\n",
      "tensor([ 0.6399, -0.6278])\n",
      "pre:left true:left 5129/11700\n",
      "tensor([ 0.8801, -0.8829])\n",
      "pre:left true:left 5130/11700\n",
      "tensor([ 0.6829, -0.6493])\n",
      "pre:left true:left 5131/11700\n",
      "tensor([ 0.9760, -0.9811])\n",
      "pre:left true:left 5132/11700\n",
      "tensor([ 0.7795, -0.6778])\n",
      "pre:left true:left 5133/11700\n",
      "tensor([-0.1621,  0.1696])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左261_0_261_20200412_110301071_8.jpg\n",
      "pre:right true:left 5134/11700\n",
      "tensor([ 0.4267, -0.4920])\n",
      "pre:left true:left 5135/11700\n",
      "tensor([-0.0318,  0.0238])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1291_0_1447_20200412_120658098_2.jpg\n",
      "pre:right true:left 5136/11700\n",
      "tensor([-0.5574,  0.6179])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左457_0_613_20200412_114851184_8.jpg\n",
      "pre:right true:left 5137/11700\n",
      "tensor([ 0.7943, -0.7337])\n",
      "pre:left true:left 5138/11700\n",
      "tensor([ 0.3215, -0.2722])\n",
      "pre:left true:left 5139/11700\n",
      "tensor([ 0.9524, -0.9530])\n",
      "pre:left true:left 5140/11700\n",
      "tensor([ 0.5164, -0.4876])\n",
      "pre:left true:left 5141/11700\n",
      "tensor([ 0.2643, -0.2053])\n",
      "pre:left true:left 5142/11700\n",
      "tensor([ 0.5205, -0.5515])\n",
      "pre:left true:left 5143/11700\n",
      "tensor([ 0.3746, -0.3952])\n",
      "pre:left true:left 5144/11700\n",
      "tensor([ 0.7708, -0.6973])\n",
      "pre:left true:left 5145/11700\n",
      "tensor([ 1.0540, -1.0490])\n",
      "pre:left true:left 5146/11700\n",
      "tensor([ 0.2523, -0.2776])\n",
      "pre:left true:left 5147/11700\n",
      "tensor([ 0.3862, -0.3233])\n",
      "pre:left true:left 5148/11700\n",
      "tensor([ 0.5629, -0.5579])\n",
      "pre:left true:left 5149/11700\n",
      "tensor([ 0.8616, -0.8731])\n",
      "pre:left true:left 5150/11700\n",
      "tensor([ 1.1042, -1.0734])\n",
      "pre:left true:left 5151/11700\n",
      "tensor([ 0.3727, -0.3014])\n",
      "pre:left true:left 5152/11700\n",
      "tensor([ 0.9234, -0.9380])\n",
      "pre:left true:left 5153/11700\n",
      "tensor([ 0.3895, -0.4439])\n",
      "pre:left true:left 5154/11700\n",
      "tensor([ 1.9577, -1.9540])\n",
      "pre:left true:left 5155/11700\n",
      "tensor([-0.0491,  0.0593])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1372_0_1528_20200412_120843645_8.jpg\n",
      "pre:right true:left 5156/11700\n",
      "tensor([ 0.8164, -0.8583])\n",
      "pre:left true:left 5157/11700\n",
      "tensor([ 0.7732, -0.6974])\n",
      "pre:left true:left 5158/11700\n",
      "tensor([ 0.6310, -0.5536])\n",
      "pre:left true:left 5159/11700\n",
      "tensor([ 0.4269, -0.3479])\n",
      "pre:left true:left 5160/11700\n",
      "tensor([ 0.5016, -0.4747])\n",
      "pre:left true:left 5161/11700\n",
      "tensor([ 0.9544, -0.9375])\n",
      "pre:left true:left 5162/11700\n",
      "tensor([ 0.8994, -0.9159])\n",
      "pre:left true:left 5163/11700\n",
      "tensor([-0.0308, -0.0420])\n",
      "pre:left true:left 5164/11700\n",
      "tensor([ 0.5082, -0.5553])\n",
      "pre:left true:left 5165/11700\n",
      "tensor([-0.4011,  0.4740])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1110_0_1266_20200412_120302191.jpg\n",
      "pre:right true:left 5166/11700\n",
      "tensor([ 0.0928, -0.0637])\n",
      "pre:left true:left 5167/11700\n",
      "tensor([ 0.3815, -0.3361])\n",
      "pre:left true:left 5168/11700\n",
      "tensor([ 0.7781, -0.7712])\n",
      "pre:left true:left 5169/11700\n",
      "tensor([ 0.8083, -0.8112])\n",
      "pre:left true:left 5170/11700\n",
      "tensor([-0.0698,  0.0994])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1507_0_1663_20200412_121139621_7.jpg\n",
      "pre:right true:left 5171/11700\n",
      "tensor([ 0.9546, -0.9410])\n",
      "pre:left true:left 5172/11700\n",
      "tensor([ 0.4484, -0.4725])\n",
      "pre:left true:left 5173/11700\n",
      "tensor([ 0.9991, -0.9208])\n",
      "pre:left true:left 5174/11700\n",
      "tensor([ 0.6244, -0.5451])\n",
      "pre:left true:left 5175/11700\n",
      "tensor([ 0.2182, -0.1621])\n",
      "pre:left true:left 5176/11700\n",
      "tensor([ 0.8679, -0.8858])\n",
      "pre:left true:left 5177/11700\n",
      "tensor([ 0.2911, -0.3183])\n",
      "pre:left true:left 5178/11700\n",
      "tensor([ 0.4693, -0.4224])\n",
      "pre:left true:left 5179/11700\n",
      "tensor([ 0.6084, -0.5579])\n",
      "pre:left true:left 5180/11700\n",
      "tensor([ 1.3674, -1.3723])\n",
      "pre:left true:left 5181/11700\n",
      "tensor([ 0.4622, -0.4379])\n",
      "pre:left true:left 5182/11700\n",
      "tensor([ 0.2882, -0.2101])\n",
      "pre:left true:left 5183/11700\n",
      "tensor([ 1.0169, -1.0609])\n",
      "pre:left true:left 5184/11700\n",
      "tensor([ 0.5113, -0.5437])\n",
      "pre:left true:left 5185/11700\n",
      "tensor([ 0.3616, -0.3003])\n",
      "pre:left true:left 5186/11700\n",
      "tensor([-0.5821,  0.6262])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左635_0_791_20200412_115243157_2.jpg\n",
      "pre:right true:left 5187/11700\n",
      "tensor([ 0.4105, -0.3983])\n",
      "pre:left true:left 5188/11700\n",
      "tensor([ 0.4556, -0.5354])\n",
      "pre:left true:left 5189/11700\n",
      "tensor([ 1.0474, -0.9768])\n",
      "pre:left true:left 5190/11700\n",
      "tensor([-0.6108,  0.6524])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左544_0_544_20200412_110944711_9.jpg\n",
      "pre:right true:left 5191/11700\n",
      "tensor([ 0.9234, -0.9820])\n",
      "pre:left true:left 5192/11700\n",
      "tensor([ 0.6216, -0.6002])\n",
      "pre:left true:left 5193/11700\n",
      "tensor([ 0.7723, -0.8116])\n",
      "pre:left true:left 5194/11700\n",
      "tensor([ 0.7025, -0.5917])\n",
      "pre:left true:left 5195/11700\n",
      "tensor([ 0.5783, -0.6047])\n",
      "pre:left true:left 5196/11700\n",
      "tensor([ 1.2397, -1.1482])\n",
      "pre:left true:left 5197/11700\n",
      "tensor([-0.2643,  0.2139])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左519_0_675_20200412_115011993_5.jpg\n",
      "pre:right true:left 5198/11700\n",
      "tensor([ 0.3109, -0.2625])\n",
      "pre:left true:left 5199/11700\n",
      "tensor([ 0.7720, -0.8719])\n",
      "pre:left true:left 5200/11700\n",
      "tensor([-0.2625,  0.2512])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左231_0_231_20200412_110218270_10.jpg\n",
      "pre:right true:left 5201/11700\n",
      "tensor([ 0.9238, -0.8189])\n",
      "pre:left true:left 5202/11700\n",
      "tensor([ 0.3546, -0.3422])\n",
      "pre:left true:left 5203/11700\n",
      "tensor([ 0.5165, -0.3928])\n",
      "pre:left true:left 5204/11700\n",
      "tensor([-0.2080,  0.1976])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1122_0_1122_20200412_112303666_1.jpg\n",
      "pre:right true:left 5205/11700\n",
      "tensor([ 0.2413, -0.1913])\n",
      "pre:left true:left 5206/11700\n",
      "tensor([ 0.1902, -0.1781])\n",
      "pre:left true:left 5207/11700\n",
      "tensor([ 0.6004, -0.5994])\n",
      "pre:left true:left 5208/11700\n",
      "tensor([ 1.1009, -0.9821])\n",
      "pre:left true:left 5209/11700\n",
      "tensor([-0.3867,  0.3924])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左612_0_612_20200412_111121701_9.jpg\n",
      "pre:right true:left 5210/11700\n",
      "tensor([-0.0238, -0.0544])\n",
      "pre:left true:left 5211/11700\n",
      "tensor([-0.0009,  0.0794])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左428_0_584_20200412_114813466_1.jpg\n",
      "pre:right true:left 5212/11700\n",
      "tensor([ 0.6145, -0.5631])\n",
      "pre:left true:left 5213/11700\n",
      "tensor([ 0.6401, -0.6402])\n",
      "pre:left true:left 5214/11700\n",
      "tensor([ 0.0109, -0.0474])\n",
      "pre:left true:left 5215/11700\n",
      "tensor([ 0.6155, -0.5575])\n",
      "pre:left true:left 5216/11700\n",
      "tensor([ 0.7987, -0.8550])\n",
      "pre:left true:left 5217/11700\n",
      "tensor([ 0.0900, -0.1379])\n",
      "pre:left true:left 5218/11700\n",
      "tensor([-0.0115,  0.0182])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左654_0_810_20200412_115307919_4.jpg\n",
      "pre:right true:left 5219/11700\n",
      "tensor([ 0.6855, -0.6811])\n",
      "pre:left true:left 5220/11700\n",
      "tensor([ 0.4257, -0.4581])\n",
      "pre:left true:left 5221/11700\n",
      "tensor([ 0.3628, -0.4336])\n",
      "pre:left true:left 5222/11700\n",
      "tensor([ 0.5425, -0.5303])\n",
      "pre:left true:left 5223/11700\n",
      "tensor([ 0.5555, -0.5346])\n",
      "pre:left true:left 5224/11700\n",
      "tensor([ 0.4018, -0.3402])\n",
      "pre:left true:left 5225/11700\n",
      "tensor([ 0.4555, -0.3889])\n",
      "pre:left true:left 5226/11700\n",
      "tensor([ 0.5068, -0.4877])\n",
      "pre:left true:left 5227/11700\n",
      "tensor([ 0.8145, -0.8782])\n",
      "pre:left true:left 5228/11700\n",
      "tensor([ 0.3663, -0.2407])\n",
      "pre:left true:left 5229/11700\n",
      "tensor([ 0.7056, -0.8195])\n",
      "pre:left true:left 5230/11700\n",
      "tensor([ 0.3622, -0.3246])\n",
      "pre:left true:left 5231/11700\n",
      "tensor([ 0.7254, -0.7561])\n",
      "pre:left true:left 5232/11700\n",
      "tensor([-0.3233,  0.3911])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1140_0_1140_20200412_112327126_8.jpg\n",
      "pre:right true:left 5233/11700\n",
      "tensor([ 0.4098, -0.3882])\n",
      "pre:left true:left 5234/11700\n",
      "tensor([-0.1440,  0.1019])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1134_0_1134_20200412_112319312_7.jpg\n",
      "pre:right true:left 5235/11700\n",
      "tensor([ 0.5342, -0.5747])\n",
      "pre:left true:left 5236/11700\n",
      "tensor([ 0.6069, -0.6733])\n",
      "pre:left true:left 5237/11700\n",
      "tensor([ 0.2450, -0.2023])\n",
      "pre:left true:left 5238/11700\n",
      "tensor([ 0.0508, -0.0538])\n",
      "pre:left true:left 5239/11700\n",
      "tensor([ 0.0824, -0.0220])\n",
      "pre:left true:left 5240/11700\n",
      "tensor([0.0086, 0.0421])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左917_0_917_20200412_111836594_4.jpg\n",
      "pre:right true:left 5241/11700\n",
      "tensor([ 0.7039, -0.7383])\n",
      "pre:left true:left 5242/11700\n",
      "tensor([ 0.6151, -0.6091])\n",
      "pre:left true:left 5243/11700\n",
      "tensor([ 0.6542, -0.7414])\n",
      "pre:left true:left 5244/11700\n",
      "tensor([ 0.8520, -0.8645])\n",
      "pre:left true:left 5245/11700\n",
      "tensor([-0.0578,  0.1349])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左127_0_127_20200412_105949944_0.jpg\n",
      "pre:right true:left 5246/11700\n",
      "tensor([ 0.1919, -0.2379])\n",
      "pre:left true:left 5247/11700\n",
      "tensor([-0.0757,  0.1014])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左386_0_386_20200412_110559320_3.jpg\n",
      "pre:right true:left 5248/11700\n",
      "tensor([ 0.5452, -0.5668])\n",
      "pre:left true:left 5249/11700\n",
      "tensor([ 0.4576, -0.3285])\n",
      "pre:left true:left 5250/11700\n",
      "tensor([ 0.6976, -0.6222])\n",
      "pre:left true:left 5251/11700\n",
      "tensor([ 0.3183, -0.3870])\n",
      "pre:left true:left 5252/11700\n",
      "tensor([ 0.3347, -0.2984])\n",
      "pre:left true:left 5253/11700\n",
      "tensor([ 0.8480, -0.8164])\n",
      "pre:left true:left 5254/11700\n",
      "tensor([ 1.0682, -1.0316])\n",
      "pre:left true:left 5255/11700\n",
      "tensor([ 0.2240, -0.2247])\n",
      "pre:left true:left 5256/11700\n",
      "tensor([ 1.4373, -1.3437])\n",
      "pre:left true:left 5257/11700\n",
      "tensor([ 2.0361, -2.1727])\n",
      "pre:left true:left 5258/11700\n",
      "tensor([ 0.0673, -0.1057])\n",
      "pre:left true:left 5259/11700\n",
      "tensor([ 0.7097, -0.7266])\n",
      "pre:left true:left 5260/11700\n",
      "tensor([ 0.6365, -0.5769])\n",
      "pre:left true:left 5261/11700\n",
      "tensor([ 0.6482, -0.6236])\n",
      "pre:left true:left 5262/11700\n",
      "tensor([ 0.7616, -0.7021])\n",
      "pre:left true:left 5263/11700\n",
      "tensor([ 0.1027, -0.0829])\n",
      "pre:left true:left 5264/11700\n",
      "tensor([ 0.6523, -0.7571])\n",
      "pre:left true:left 5265/11700\n",
      "tensor([0.0549, 0.0134])\n",
      "pre:left true:left 5266/11700\n",
      "tensor([ 0.5731, -0.6125])\n",
      "pre:left true:left 5267/11700\n",
      "tensor([ 0.4304, -0.3740])\n",
      "pre:left true:left 5268/11700\n",
      "tensor([ 0.9956, -1.0088])\n",
      "pre:left true:left 5269/11700\n",
      "tensor([ 0.1499, -0.1784])\n",
      "pre:left true:left 5270/11700\n",
      "tensor([ 0.9759, -0.9265])\n",
      "pre:left true:left 5271/11700\n",
      "tensor([ 1.0594, -1.0649])\n",
      "pre:left true:left 5272/11700\n",
      "tensor([-0.1364,  0.1335])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1257_0_1413_20200412_120613774_8.jpg\n",
      "pre:right true:left 5273/11700\n",
      "tensor([ 0.7273, -0.7066])\n",
      "pre:left true:left 5274/11700\n",
      "tensor([ 0.2973, -0.2322])\n",
      "pre:left true:left 5275/11700\n",
      "tensor([ 0.3875, -0.3578])\n",
      "pre:left true:left 5276/11700\n",
      "tensor([ 0.1914, -0.1864])\n",
      "pre:left true:left 5277/11700\n",
      "tensor([ 1.4342, -1.4569])\n",
      "pre:left true:left 5278/11700\n",
      "tensor([ 0.3796, -0.4135])\n",
      "pre:left true:left 5279/11700\n",
      "tensor([-0.3899,  0.4022])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左554_0_710_20200412_115057587_3.jpg\n",
      "pre:right true:left 5280/11700\n",
      "tensor([ 1.2590, -1.2757])\n",
      "pre:left true:left 5281/11700\n",
      "tensor([ 0.7502, -0.7903])\n",
      "pre:left true:left 5282/11700\n",
      "tensor([ 0.5067, -0.4463])\n",
      "pre:left true:left 5283/11700\n",
      "tensor([-0.0043, -0.0621])\n",
      "pre:left true:left 5284/11700\n",
      "tensor([ 0.4249, -0.4153])\n",
      "pre:left true:left 5285/11700\n",
      "tensor([ 0.5320, -0.5319])\n",
      "pre:left true:left 5286/11700\n",
      "tensor([-0.3017,  0.3200])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左736_0_736_20200412_111418571_9.jpg\n",
      "pre:right true:left 5287/11700\n",
      "tensor([ 0.8519, -0.8066])\n",
      "pre:left true:left 5288/11700\n",
      "tensor([ 0.0346, -0.0971])\n",
      "pre:left true:left 5289/11700\n",
      "tensor([ 0.4943, -0.4166])\n",
      "pre:left true:left 5290/11700\n",
      "tensor([ 0.5276, -0.4541])\n",
      "pre:left true:left 5291/11700\n",
      "tensor([-0.3945,  0.3800])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左393_0_549_20200412_114727767_8.jpg\n",
      "pre:right true:left 5292/11700\n",
      "tensor([-0.7236,  0.5925])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左618_0_618_20200412_111130269_9.jpg\n",
      "pre:right true:left 5293/11700\n",
      "tensor([ 0.5290, -0.5497])\n",
      "pre:left true:left 5294/11700\n",
      "tensor([ 0.4369, -0.4688])\n",
      "pre:left true:left 5295/11700\n",
      "tensor([ 0.5463, -0.4059])\n",
      "pre:left true:left 5296/11700\n",
      "tensor([0.0768, 0.0074])\n",
      "pre:left true:left 5297/11700\n",
      "tensor([ 0.2447, -0.0803])\n",
      "pre:left true:left 5298/11700\n",
      "tensor([ 0.6979, -0.6427])\n",
      "pre:left true:left 5299/11700\n",
      "tensor([ 1.0297, -0.9713])\n",
      "pre:left true:left 5300/11700\n",
      "tensor([ 0.8861, -0.9517])\n",
      "pre:left true:left 5301/11700\n",
      "tensor([ 0.5737, -0.5546])\n",
      "pre:left true:left 5302/11700\n",
      "tensor([ 0.4167, -0.3129])\n",
      "pre:left true:left 5303/11700\n",
      "tensor([ 1.0396, -0.9624])\n",
      "pre:left true:left 5304/11700\n",
      "tensor([ 0.2466, -0.2237])\n",
      "pre:left true:left 5305/11700\n",
      "tensor([ 0.3524, -0.2866])\n",
      "pre:left true:left 5306/11700\n",
      "tensor([ 0.7916, -0.7770])\n",
      "pre:left true:left 5307/11700\n",
      "tensor([ 1.1638, -1.0883])\n",
      "pre:left true:left 5308/11700\n",
      "tensor([ 1.0259, -0.9084])\n",
      "pre:left true:left 5309/11700\n",
      "tensor([ 0.7142, -0.6747])\n",
      "pre:left true:left 5310/11700\n",
      "tensor([ 0.7733, -0.6617])\n",
      "pre:left true:left 5311/11700\n",
      "tensor([ 0.7902, -0.7998])\n",
      "pre:left true:left 5312/11700\n",
      "tensor([ 0.2834, -0.3458])\n",
      "pre:left true:left 5313/11700\n",
      "tensor([-0.1008,  0.1805])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1401_0_1557_20200412_120921450_3.jpg\n",
      "pre:right true:left 5314/11700\n",
      "tensor([ 0.6347, -0.6336])\n",
      "pre:left true:left 5315/11700\n",
      "tensor([ 0.1400, -0.1844])\n",
      "pre:left true:left 5316/11700\n",
      "tensor([ 0.9747, -0.9550])\n",
      "pre:left true:left 5317/11700\n",
      "tensor([ 1.1100, -1.0910])\n",
      "pre:left true:left 5318/11700\n",
      "tensor([ 0.7924, -0.7916])\n",
      "pre:left true:left 5319/11700\n",
      "tensor([ 0.5938, -0.5913])\n",
      "pre:left true:left 5320/11700\n",
      "tensor([ 1.9135, -1.8725])\n",
      "pre:left true:left 5321/11700\n",
      "tensor([ 0.7890, -0.8153])\n",
      "pre:left true:left 5322/11700\n",
      "tensor([-0.1904,  0.2582])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1302_0_1458_20200412_120712431_0.jpg\n",
      "pre:right true:left 5323/11700\n",
      "tensor([ 0.9224, -0.8286])\n",
      "pre:left true:left 5324/11700\n",
      "tensor([ 0.6958, -0.6055])\n",
      "pre:left true:left 5325/11700\n",
      "tensor([ 0.0598, -0.0066])\n",
      "pre:left true:left 5326/11700\n",
      "tensor([ 0.1225, -0.0796])\n",
      "pre:left true:left 5327/11700\n",
      "tensor([ 0.6896, -0.7089])\n",
      "pre:left true:left 5328/11700\n",
      "tensor([0.1147, 0.1262])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1556_0_1712_20200412_121243498_2.jpg\n",
      "pre:right true:left 5329/11700\n",
      "tensor([ 1.0558, -1.0795])\n",
      "pre:left true:left 5330/11700\n",
      "tensor([ 1.3659, -1.3883])\n",
      "pre:left true:left 5331/11700\n",
      "tensor([-0.3282,  0.2769])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左751_0_751_20200412_111439952_4.jpg\n",
      "pre:right true:left 5332/11700\n",
      "tensor([-0.0416,  0.0363])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左306_0_306_20200412_105542285_4.jpg\n",
      "pre:right true:left 5333/11700\n",
      "tensor([ 1.2056, -1.2812])\n",
      "pre:left true:left 5334/11700\n",
      "tensor([ 0.0630, -0.0011])\n",
      "pre:left true:left 5335/11700\n",
      "tensor([ 0.7473, -0.7829])\n",
      "pre:left true:left 5336/11700\n",
      "tensor([ 0.6855, -0.7073])\n",
      "pre:left true:left 5337/11700\n",
      "tensor([ 0.8581, -0.9136])\n",
      "pre:left true:left 5338/11700\n",
      "tensor([ 0.2337, -0.2073])\n",
      "pre:left true:left 5339/11700\n",
      "tensor([ 0.4210, -0.3717])\n",
      "pre:left true:left 5340/11700\n",
      "tensor([ 0.1052, -0.1255])\n",
      "pre:left true:left 5341/11700\n",
      "tensor([ 0.2438, -0.1949])\n",
      "pre:left true:left 5342/11700\n",
      "tensor([ 0.8458, -0.8042])\n",
      "pre:left true:left 5343/11700\n",
      "tensor([ 1.4415, -1.4717])\n",
      "pre:left true:left 5344/11700\n",
      "tensor([ 0.5116, -0.5604])\n",
      "pre:left true:left 5345/11700\n",
      "tensor([ 1.0437, -0.9903])\n",
      "pre:left true:left 5346/11700\n",
      "tensor([ 0.8419, -0.8643])\n",
      "pre:left true:left 5347/11700\n",
      "tensor([ 0.4278, -0.4353])\n",
      "pre:left true:left 5348/11700\n",
      "tensor([ 0.9557, -0.9481])\n",
      "pre:left true:left 5349/11700\n",
      "tensor([-0.1834,  0.1398])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1308_0_1464_20200412_120720259_7.jpg\n",
      "pre:right true:left 5350/11700\n",
      "tensor([ 0.8236, -0.8247])\n",
      "pre:left true:left 5351/11700\n",
      "tensor([ 0.2047, -0.2372])\n",
      "pre:left true:left 5352/11700\n",
      "tensor([ 0.2557, -0.3165])\n",
      "pre:left true:left 5353/11700\n",
      "tensor([ 1.2282, -1.2693])\n",
      "pre:left true:left 5354/11700\n",
      "tensor([-0.1204,  0.0839])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左367_0_523_20200412_114653912_5.jpg\n",
      "pre:right true:left 5355/11700\n",
      "tensor([ 0.5428, -0.6489])\n",
      "pre:left true:left 5356/11700\n",
      "tensor([ 0.8829, -0.8091])\n",
      "pre:left true:left 5357/11700\n",
      "tensor([ 1.2842, -1.2267])\n",
      "pre:left true:left 5358/11700\n",
      "tensor([ 0.2144, -0.2901])\n",
      "pre:left true:left 5359/11700\n",
      "tensor([ 0.9318, -0.9017])\n",
      "pre:left true:left 5360/11700\n",
      "tensor([ 0.2317, -0.3363])\n",
      "pre:left true:left 5361/11700\n",
      "tensor([ 0.9463, -0.8933])\n",
      "pre:left true:left 5362/11700\n",
      "tensor([ 0.4519, -0.5167])\n",
      "pre:left true:left 5363/11700\n",
      "tensor([ 0.3919, -0.2996])\n",
      "pre:left true:left 5364/11700\n",
      "tensor([ 0.4682, -0.4060])\n",
      "pre:left true:left 5365/11700\n",
      "tensor([ 0.2583, -0.2382])\n",
      "pre:left true:left 5366/11700\n",
      "tensor([-0.0084, -0.0363])\n",
      "pre:left true:left 5367/11700\n",
      "tensor([ 1.1971, -1.2586])\n",
      "pre:left true:left 5368/11700\n",
      "tensor([ 1.0375, -0.9802])\n",
      "pre:left true:left 5369/11700\n",
      "tensor([ 0.5022, -0.5260])\n",
      "pre:left true:left 5370/11700\n",
      "tensor([ 0.9096, -0.8451])\n",
      "pre:left true:left 5371/11700\n",
      "tensor([ 0.3255, -0.2528])\n",
      "pre:left true:left 5372/11700\n",
      "tensor([ 0.3645, -0.2800])\n",
      "pre:left true:left 5373/11700\n",
      "tensor([ 0.2531, -0.2927])\n",
      "pre:left true:left 5374/11700\n",
      "tensor([ 0.9326, -0.9209])\n",
      "pre:left true:left 5375/11700\n",
      "tensor([ 0.0456, -0.0155])\n",
      "pre:left true:left 5376/11700\n",
      "tensor([ 0.5033, -0.5548])\n",
      "pre:left true:left 5377/11700\n",
      "tensor([ 0.2784, -0.3141])\n",
      "pre:left true:left 5378/11700\n",
      "tensor([ 0.4740, -0.4097])\n",
      "pre:left true:left 5379/11700\n",
      "tensor([ 1.1322, -1.0590])\n",
      "pre:left true:left 5380/11700\n",
      "tensor([ 0.5323, -0.5014])\n",
      "pre:left true:left 5381/11700\n",
      "tensor([ 0.9264, -0.8911])\n",
      "pre:left true:left 5382/11700\n",
      "tensor([ 0.2004, -0.1135])\n",
      "pre:left true:left 5383/11700\n",
      "tensor([ 1.3534, -1.2892])\n",
      "pre:left true:left 5384/11700\n",
      "tensor([-0.1849,  0.1720])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左367_0_523_20200412_114653912_8.jpg\n",
      "pre:right true:left 5385/11700\n",
      "tensor([ 0.7690, -0.7417])\n",
      "pre:left true:left 5386/11700\n",
      "tensor([ 1.3553, -1.3613])\n",
      "pre:left true:left 5387/11700\n",
      "tensor([-0.4274,  0.4364])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左498_0_498_20200412_110839077_1.jpg\n",
      "pre:right true:left 5388/11700\n",
      "tensor([ 0.0977, -0.1766])\n",
      "pre:left true:left 5389/11700\n",
      "tensor([ 1.3572, -1.4187])\n",
      "pre:left true:left 5390/11700\n",
      "tensor([ 0.6896, -0.6133])\n",
      "pre:left true:left 5391/11700\n",
      "tensor([-0.3951,  0.4039])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左282_0_438_20200412_114503138_3.jpg\n",
      "pre:right true:left 5392/11700\n",
      "tensor([ 0.0595, -0.0789])\n",
      "pre:left true:left 5393/11700\n",
      "tensor([ 0.0504, -0.0616])\n",
      "pre:left true:left 5394/11700\n",
      "tensor([ 0.5701, -0.6528])\n",
      "pre:left true:left 5395/11700\n",
      "tensor([ 0.7608, -0.7180])\n",
      "pre:left true:left 5396/11700\n",
      "tensor([ 1.1005, -1.0986])\n",
      "pre:left true:left 5397/11700\n",
      "tensor([ 0.2962, -0.2932])\n",
      "pre:left true:left 5398/11700\n",
      "tensor([ 0.3555, -0.2781])\n",
      "pre:left true:left 5399/11700\n",
      "tensor([ 0.9171, -0.9126])\n",
      "pre:left true:left 5400/11700\n",
      "tensor([-0.1643,  0.1533])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左130_0_130_20200412_105954227_8.jpg\n",
      "pre:right true:left 5401/11700\n",
      "tensor([ 0.2019, -0.2503])\n",
      "pre:left true:left 5402/11700\n",
      "tensor([ 0.1780, -0.1969])\n",
      "pre:left true:left 5403/11700\n",
      "tensor([-0.3801,  0.3934])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左580_0_736_20200412_115131473_9.jpg\n",
      "pre:right true:left 5404/11700\n",
      "tensor([ 0.6661, -0.7062])\n",
      "pre:left true:left 5405/11700\n",
      "tensor([ 1.0974, -1.1326])\n",
      "pre:left true:left 5406/11700\n",
      "tensor([-0.0891,  0.1249])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1241_0_1241_20200412_112538741_3.jpg\n",
      "pre:right true:left 5407/11700\n",
      "tensor([ 0.4249, -0.3496])\n",
      "pre:left true:left 5408/11700\n",
      "tensor([ 0.6701, -0.6084])\n",
      "pre:left true:left 5409/11700\n",
      "tensor([ 0.8205, -0.8241])\n",
      "pre:left true:left 5410/11700\n",
      "tensor([ 0.5242, -0.5215])\n",
      "pre:left true:left 5411/11700\n",
      "tensor([-0.2632,  0.3617])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左597_0_753_20200412_115153625_8.jpg\n",
      "pre:right true:left 5412/11700\n",
      "tensor([ 0.4400, -0.4491])\n",
      "pre:left true:left 5413/11700\n",
      "tensor([-0.2971,  0.3913])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左755_0_911_20200412_115519560_9.jpg\n",
      "pre:right true:left 5414/11700\n",
      "tensor([ 0.0349, -0.0173])\n",
      "pre:left true:left 5415/11700\n",
      "tensor([ 0.9851, -1.0503])\n",
      "pre:left true:left 5416/11700\n",
      "tensor([ 1.0495, -0.9881])\n",
      "pre:left true:left 5417/11700\n",
      "tensor([ 0.5146, -0.5195])\n",
      "pre:left true:left 5418/11700\n",
      "tensor([ 0.7307, -0.7208])\n",
      "pre:left true:left 5419/11700\n",
      "tensor([ 0.7236, -0.6222])\n",
      "pre:left true:left 5420/11700\n",
      "tensor([-0.2564,  0.1959])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左201_0_201_20200412_110135479_2.jpg\n",
      "pre:right true:left 5421/11700\n",
      "tensor([ 1.0600, -1.0249])\n",
      "pre:left true:left 5422/11700\n",
      "tensor([ 1.1754, -1.2044])\n",
      "pre:left true:left 5423/11700\n",
      "tensor([ 0.2908, -0.3361])\n",
      "pre:left true:left 5424/11700\n",
      "tensor([ 0.5631, -0.5801])\n",
      "pre:left true:left 5425/11700\n",
      "tensor([ 1.0330, -1.1414])\n",
      "pre:left true:left 5426/11700\n",
      "tensor([-0.5327,  0.5505])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1574_0_1730_20200412_121306937_0.jpg\n",
      "pre:right true:left 5427/11700\n",
      "tensor([ 0.6870, -0.7479])\n",
      "pre:left true:left 5428/11700\n",
      "tensor([ 1.2140, -1.1815])\n",
      "pre:left true:left 5429/11700\n",
      "tensor([-0.2125,  0.2478])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左847_0_847_20200412_111656901.jpg\n",
      "pre:right true:left 5430/11700\n",
      "tensor([ 0.4767, -0.4107])\n",
      "pre:left true:left 5431/11700\n",
      "tensor([ 1.0072, -1.0544])\n",
      "pre:left true:left 5432/11700\n",
      "tensor([ 0.4669, -0.3777])\n",
      "pre:left true:left 5433/11700\n",
      "tensor([ 0.2431, -0.2187])\n",
      "pre:left true:left 5434/11700\n",
      "tensor([ 0.3103, -0.3706])\n",
      "pre:left true:left 5435/11700\n",
      "tensor([ 1.0646, -1.0501])\n",
      "pre:left true:left 5436/11700\n",
      "tensor([ 0.3271, -0.3037])\n",
      "pre:left true:left 5437/11700\n",
      "tensor([ 0.5085, -0.4786])\n",
      "pre:left true:left 5438/11700\n",
      "tensor([ 0.7238, -0.7252])\n",
      "pre:left true:left 5439/11700\n",
      "tensor([ 0.2560, -0.1973])\n",
      "pre:left true:left 5440/11700\n",
      "tensor([ 0.1690, -0.0924])\n",
      "pre:left true:left 5441/11700\n",
      "tensor([ 0.9431, -0.8343])\n",
      "pre:left true:left 5442/11700\n",
      "tensor([ 0.2199, -0.2583])\n",
      "pre:left true:left 5443/11700\n",
      "tensor([ 0.6288, -0.5844])\n",
      "pre:left true:left 5444/11700\n",
      "tensor([ 1.0554, -1.1513])\n",
      "pre:left true:left 5445/11700\n",
      "tensor([ 0.9911, -0.9572])\n",
      "pre:left true:left 5446/11700\n",
      "tensor([-0.0343,  0.0425])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左703_0_859_20200412_115411771_0.jpg\n",
      "pre:right true:left 5447/11700\n",
      "tensor([ 0.0998, -0.0703])\n",
      "pre:left true:left 5448/11700\n",
      "tensor([ 0.7036, -0.6669])\n",
      "pre:left true:left 5449/11700\n",
      "tensor([ 0.2190, -0.1863])\n",
      "pre:left true:left 5450/11700\n",
      "tensor([ 0.4812, -0.4110])\n",
      "pre:left true:left 5451/11700\n",
      "tensor([-0.4668,  0.5407])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左403_0_403_20200412_110623586_5.jpg\n",
      "pre:right true:left 5452/11700\n",
      "tensor([ 0.3636, -0.4379])\n",
      "pre:left true:left 5453/11700\n",
      "tensor([ 0.6068, -0.5340])\n",
      "pre:left true:left 5454/11700\n",
      "tensor([ 1.4340, -1.4866])\n",
      "pre:left true:left 5455/11700\n",
      "tensor([ 0.2395, -0.1100])\n",
      "pre:left true:left 5456/11700\n",
      "tensor([ 0.9553, -0.9186])\n",
      "pre:left true:left 5457/11700\n",
      "tensor([ 0.8981, -0.8653])\n",
      "pre:left true:left 5458/11700\n",
      "tensor([ 0.9550, -1.0269])\n",
      "pre:left true:left 5459/11700\n",
      "tensor([ 0.1179, -0.1055])\n",
      "pre:left true:left 5460/11700\n",
      "tensor([ 0.2208, -0.2269])\n",
      "pre:left true:left 5461/11700\n",
      "tensor([ 0.4170, -0.4406])\n",
      "pre:left true:left 5462/11700\n",
      "tensor([ 0.2674, -0.3456])\n",
      "pre:left true:left 5463/11700\n",
      "tensor([ 0.2415, -0.3094])\n",
      "pre:left true:left 5464/11700\n",
      "tensor([0.0150, 0.0536])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1470_0_1626_20200412_121051395_1.jpg\n",
      "pre:right true:left 5465/11700\n",
      "tensor([-0.5569,  0.4901])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1324_0_1324_20200412_112736794.jpg\n",
      "pre:right true:left 5466/11700\n",
      "tensor([-0.0364,  0.0625])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左772_0_928_20200412_115541714_7.jpg\n",
      "pre:right true:left 5467/11700\n",
      "tensor([ 0.5265, -0.4665])\n",
      "pre:left true:left 5468/11700\n",
      "tensor([ 1.0503, -1.0548])\n",
      "pre:left true:left 5469/11700\n",
      "tensor([-0.0694,  0.1035])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左179_0_179_20200412_110104093_6.jpg\n",
      "pre:right true:left 5470/11700\n",
      "tensor([ 0.4591, -0.4966])\n",
      "pre:left true:left 5471/11700\n",
      "tensor([ 0.3183, -0.3082])\n",
      "pre:left true:left 5472/11700\n",
      "tensor([-0.1085,  0.2131])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左430_0_586_20200412_114815979_9.jpg\n",
      "pre:right true:left 5473/11700\n",
      "tensor([ 1.1331, -1.1656])\n",
      "pre:left true:left 5474/11700\n",
      "tensor([ 0.2918, -0.3110])\n",
      "pre:left true:left 5475/11700\n",
      "tensor([ 1.0512, -1.1109])\n",
      "pre:left true:left 5476/11700\n",
      "tensor([ 0.0442, -0.1506])\n",
      "pre:left true:left 5477/11700\n",
      "tensor([ 0.5287, -0.5634])\n",
      "pre:left true:left 5478/11700\n",
      "tensor([-0.6689,  0.6503])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1433_0_1589_20200412_121003157_1.jpg\n",
      "pre:right true:left 5479/11700\n",
      "tensor([ 0.3770, -0.4306])\n",
      "pre:left true:left 5480/11700\n",
      "tensor([ 0.3109, -0.3146])\n",
      "pre:left true:left 5481/11700\n",
      "tensor([ 0.4444, -0.4821])\n",
      "pre:left true:left 5482/11700\n",
      "tensor([ 0.9666, -0.8674])\n",
      "pre:left true:left 5483/11700\n",
      "tensor([ 0.5924, -0.5880])\n",
      "pre:left true:left 5484/11700\n",
      "tensor([ 0.8196, -0.8427])\n",
      "pre:left true:left 5485/11700\n",
      "tensor([ 0.8645, -0.9187])\n",
      "pre:left true:left 5486/11700\n",
      "tensor([-0.0953,  0.1316])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左477_0_477_20200412_110809150_1.jpg\n",
      "pre:right true:left 5487/11700\n",
      "tensor([-0.3635,  0.2952])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左675_0_675_20200412_111251560_4.jpg\n",
      "pre:right true:left 5488/11700\n",
      "tensor([ 0.8589, -0.8700])\n",
      "pre:left true:left 5489/11700\n",
      "tensor([ 0.2659, -0.1694])\n",
      "pre:left true:left 5490/11700\n",
      "tensor([ 1.2902, -1.2335])\n",
      "pre:left true:left 5491/11700\n",
      "tensor([ 0.3095, -0.3165])\n",
      "pre:left true:left 5492/11700\n",
      "tensor([ 0.1723, -0.1313])\n",
      "pre:left true:left 5493/11700\n",
      "tensor([ 0.1881, -0.2244])\n",
      "pre:left true:left 5494/11700\n",
      "tensor([ 0.4133, -0.4186])\n",
      "pre:left true:left 5495/11700\n",
      "tensor([-0.0795,  0.1146])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左645_0_645_20200412_111208780_9.jpg\n",
      "pre:right true:left 5496/11700\n",
      "tensor([ 1.0237, -1.0471])\n",
      "pre:left true:left 5497/11700\n",
      "tensor([-0.2357,  0.2853])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左491_0_647_20200412_114935493_4.jpg\n",
      "pre:right true:left 5498/11700\n",
      "tensor([-0.0016,  0.1088])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左959_0_959_20200412_111931300_10.jpg\n",
      "pre:right true:left 5499/11700\n",
      "tensor([0.0011, 0.1075])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左944_0_944_20200412_111911762_4.jpg\n",
      "pre:right true:left 5500/11700\n",
      "tensor([0.0446, 0.0248])\n",
      "pre:left true:left 5501/11700\n",
      "tensor([ 0.3772, -0.4334])\n",
      "pre:left true:left 5502/11700\n",
      "tensor([ 1.3215, -1.1942])\n",
      "pre:left true:left 5503/11700\n",
      "tensor([-0.0899,  0.0383])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左53_0_53_20200412_105807363_6.jpg\n",
      "pre:right true:left 5504/11700\n",
      "tensor([ 0.5700, -0.5551])\n",
      "pre:left true:left 5505/11700\n",
      "tensor([ 0.6077, -0.5310])\n",
      "pre:left true:left 5506/11700\n",
      "tensor([ 0.6617, -0.6477])\n",
      "pre:left true:left 5507/11700\n",
      "tensor([-0.4009,  0.3747])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1067_0_1067_20200412_112151999_3.jpg\n",
      "pre:right true:left 5508/11700\n",
      "tensor([ 1.7099, -1.7176])\n",
      "pre:left true:left 5509/11700\n",
      "tensor([ 0.3616, -0.3003])\n",
      "pre:left true:left 5510/11700\n",
      "tensor([-0.1172,  0.1337])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左594_0_750_20200412_115149717_3.jpg\n",
      "pre:right true:left 5511/11700\n",
      "tensor([-0.1490,  0.2101])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左430_0_430_20200412_110702096_2.jpg\n",
      "pre:right true:left 5512/11700\n",
      "tensor([ 0.5815, -0.4936])\n",
      "pre:left true:left 5513/11700\n",
      "tensor([ 0.1651, -0.0361])\n",
      "pre:left true:left 5514/11700\n",
      "tensor([ 0.4250, -0.4650])\n",
      "pre:left true:left 5515/11700\n",
      "tensor([ 0.1644, -0.1483])\n",
      "pre:left true:left 5516/11700\n",
      "tensor([ 0.4287, -0.5446])\n",
      "pre:left true:left 5517/11700\n",
      "tensor([-0.1637,  0.2886])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左587_0_743_20200412_115140615_8.jpg\n",
      "pre:right true:left 5518/11700\n",
      "tensor([ 0.4354, -0.4023])\n",
      "pre:left true:left 5519/11700\n",
      "tensor([ 0.8615, -0.8590])\n",
      "pre:left true:left 5520/11700\n",
      "tensor([-0.2209,  0.3135])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左159_0_159_20200412_110035581_7.jpg\n",
      "pre:right true:left 5521/11700\n",
      "tensor([ 0.6200, -0.4682])\n",
      "pre:left true:left 5522/11700\n",
      "tensor([ 0.4130, -0.3726])\n",
      "pre:left true:left 5523/11700\n",
      "tensor([ 0.4833, -0.4168])\n",
      "pre:left true:left 5524/11700\n",
      "tensor([ 0.3417, -0.3303])\n",
      "pre:left true:left 5525/11700\n",
      "tensor([ 0.7818, -0.7175])\n",
      "pre:left true:left 5526/11700\n",
      "tensor([ 0.5315, -0.5917])\n",
      "pre:left true:left 5527/11700\n",
      "tensor([ 0.8632, -0.8786])\n",
      "pre:left true:left 5528/11700\n",
      "tensor([ 0.1219, -0.2127])\n",
      "pre:left true:left 5529/11700\n",
      "tensor([ 0.6208, -0.5967])\n",
      "pre:left true:left 5530/11700\n",
      "tensor([-0.1148,  0.1605])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左485_0_641_20200412_114927678_0.jpg\n",
      "pre:right true:left 5531/11700\n",
      "tensor([ 2.1452, -2.2252])\n",
      "pre:left true:left 5532/11700\n",
      "tensor([ 1.0697, -1.0963])\n",
      "pre:left true:left 5533/11700\n",
      "tensor([-0.1683,  0.3057])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左601_0_757_20200412_115158849_1.jpg\n",
      "pre:right true:left 5534/11700\n",
      "tensor([ 0.8408, -0.8862])\n",
      "pre:left true:left 5535/11700\n",
      "tensor([-0.5964,  0.6247])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1333_0_1489_20200412_120752844_1.jpg\n",
      "pre:right true:left 5536/11700\n",
      "tensor([ 0.4561, -0.5365])\n",
      "pre:left true:left 5537/11700\n",
      "tensor([ 1.0803, -1.0059])\n",
      "pre:left true:left 5538/11700\n",
      "tensor([-0.0767, -0.0002])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左425_0_581_20200412_114809477_10.jpg\n",
      "pre:right true:left 5539/11700\n",
      "tensor([-0.0774,  0.1885])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左189_0_189_20200412_110118368_6.jpg\n",
      "pre:right true:left 5540/11700\n",
      "tensor([ 0.2445, -0.2240])\n",
      "pre:left true:left 5541/11700\n",
      "tensor([ 0.9714, -0.9762])\n",
      "pre:left true:left 5542/11700\n",
      "tensor([ 0.7037, -0.6624])\n",
      "pre:left true:left 5543/11700\n",
      "tensor([ 0.0892, -0.1461])\n",
      "pre:left true:left 5544/11700\n",
      "tensor([ 1.4161, -1.4180])\n",
      "pre:left true:left 5545/11700\n",
      "tensor([ 0.4341, -0.3565])\n",
      "pre:left true:left 5546/11700\n",
      "tensor([ 0.2328, -0.2413])\n",
      "pre:left true:left 5547/11700\n",
      "tensor([ 0.1366, -0.1953])\n",
      "pre:left true:left 5548/11700\n",
      "tensor([ 0.6399, -0.6234])\n",
      "pre:left true:left 5549/11700\n",
      "tensor([ 0.6652, -0.6797])\n",
      "pre:left true:left 5550/11700\n",
      "tensor([ 0.2699, -0.3065])\n",
      "pre:left true:left 5551/11700\n",
      "tensor([ 0.8683, -0.8214])\n",
      "pre:left true:left 5552/11700\n",
      "tensor([-0.1662,  0.2505])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1504_0_1660_20200412_121135709_1.jpg\n",
      "pre:right true:left 5553/11700\n",
      "tensor([ 0.4913, -0.3999])\n",
      "pre:left true:left 5554/11700\n",
      "tensor([ 0.5647, -0.5193])\n",
      "pre:left true:left 5555/11700\n",
      "tensor([-0.5147,  0.5603])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左407_0_407_20200412_110629294_4.jpg\n",
      "pre:right true:left 5556/11700\n",
      "tensor([0.0867, 0.0170])\n",
      "pre:left true:left 5557/11700\n",
      "tensor([-0.1766,  0.1812])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左314_0_470_20200412_114544844_9.jpg\n",
      "pre:right true:left 5558/11700\n",
      "tensor([ 0.7422, -0.7298])\n",
      "pre:left true:left 5559/11700\n",
      "tensor([ 0.2196, -0.2381])\n",
      "pre:left true:left 5560/11700\n",
      "tensor([-0.0602, -0.0274])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左955_0_955_20200412_111926089_0.jpg\n",
      "pre:right true:left 5561/11700\n",
      "tensor([ 0.1167, -0.1500])\n",
      "pre:left true:left 5562/11700\n",
      "tensor([ 0.5685, -0.5570])\n",
      "pre:left true:left 5563/11700\n",
      "tensor([ 0.6700, -0.7440])\n",
      "pre:left true:left 5564/11700\n",
      "tensor([-0.0785,  0.1906])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左260_0_260_20200412_110259633_3.jpg\n",
      "pre:right true:left 5565/11700\n",
      "tensor([ 0.9574, -0.9958])\n",
      "pre:left true:left 5566/11700\n",
      "tensor([ 0.5638, -0.4079])\n",
      "pre:left true:left 5567/11700\n",
      "tensor([ 1.2262, -1.1690])\n",
      "pre:left true:left 5568/11700\n",
      "tensor([ 0.5085, -0.4599])\n",
      "pre:left true:left 5569/11700\n",
      "tensor([ 0.0345, -0.0072])\n",
      "pre:left true:left 5570/11700\n",
      "tensor([ 0.8092, -0.8021])\n",
      "pre:left true:left 5571/11700\n",
      "tensor([-0.6707,  0.7160])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左857_0_1013_20200412_115732488_1.jpg\n",
      "pre:right true:left 5572/11700\n",
      "tensor([ 0.1120, -0.0712])\n",
      "pre:left true:left 5573/11700\n",
      "tensor([-0.6322,  0.7341])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左527_0_683_20200412_115022411_7.jpg\n",
      "pre:right true:left 5574/11700\n",
      "tensor([ 0.7295, -0.6212])\n",
      "pre:left true:left 5575/11700\n",
      "tensor([ 0.8780, -0.8087])\n",
      "pre:left true:left 5576/11700\n",
      "tensor([-0.4455,  0.3810])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左990_0_990_20200412_112011687_2.jpg\n",
      "pre:right true:left 5577/11700\n",
      "tensor([ 0.6932, -0.7583])\n",
      "pre:left true:left 5578/11700\n",
      "tensor([ 0.5379, -0.5407])\n",
      "pre:left true:left 5579/11700\n",
      "tensor([ 0.6582, -0.7293])\n",
      "pre:left true:left 5580/11700\n",
      "tensor([ 0.2459, -0.2654])\n",
      "pre:left true:left 5581/11700\n",
      "tensor([ 0.7375, -0.7124])\n",
      "pre:left true:left 5582/11700\n",
      "tensor([ 0.5413, -0.4805])\n",
      "pre:left true:left 5583/11700\n",
      "tensor([ 0.3855, -0.2976])\n",
      "pre:left true:left 5584/11700\n",
      "tensor([ 0.7709, -0.8111])\n",
      "pre:left true:left 5585/11700\n",
      "tensor([ 0.5164, -0.5863])\n",
      "pre:left true:left 5586/11700\n",
      "tensor([-0.0632,  0.0711])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1306_0_1306_20200412_112703459_6.jpg\n",
      "pre:right true:left 5587/11700\n",
      "tensor([ 0.7244, -0.6899])\n",
      "pre:left true:left 5588/11700\n",
      "tensor([-0.3324,  0.3996])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1589_0_1745_20200412_121326516_10.jpg\n",
      "pre:right true:left 5589/11700\n",
      "tensor([ 1.2993, -1.2275])\n",
      "pre:left true:left 5590/11700\n",
      "tensor([ 0.1543, -0.1840])\n",
      "pre:left true:left 5591/11700\n",
      "tensor([ 1.6466, -1.7308])\n",
      "pre:left true:left 5592/11700\n",
      "tensor([ 0.6670, -0.5423])\n",
      "pre:left true:left 5593/11700\n",
      "tensor([ 0.9203, -0.9067])\n",
      "pre:left true:left 5594/11700\n",
      "tensor([ 1.4321, -1.4500])\n",
      "pre:left true:left 5595/11700\n",
      "tensor([ 0.7048, -0.7853])\n",
      "pre:left true:left 5596/11700\n",
      "tensor([ 0.3262, -0.2940])\n",
      "pre:left true:left 5597/11700\n",
      "tensor([ 0.7729, -0.8038])\n",
      "pre:left true:left 5598/11700\n",
      "tensor([ 0.5596, -0.4367])\n",
      "pre:left true:left 5599/11700\n",
      "tensor([ 0.2632, -0.3105])\n",
      "pre:left true:left 5600/11700\n",
      "tensor([ 0.3985, -0.3451])\n",
      "pre:left true:left 5601/11700\n",
      "tensor([ 0.6389, -0.7416])\n",
      "pre:left true:left 5602/11700\n",
      "tensor([ 0.8676, -0.8417])\n",
      "pre:left true:left 5603/11700\n",
      "tensor([-0.1516,  0.2088])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左881_0_881_20200412_111745390_2.jpg\n",
      "pre:right true:left 5604/11700\n",
      "tensor([ 1.2354, -1.1825])\n",
      "pre:left true:left 5605/11700\n",
      "tensor([ 0.5076, -0.4728])\n",
      "pre:left true:left 5606/11700\n",
      "tensor([ 0.6133, -0.6539])\n",
      "pre:left true:left 5607/11700\n",
      "tensor([0.0299, 0.0136])\n",
      "pre:left true:left 5608/11700\n",
      "tensor([ 1.2896, -1.2914])\n",
      "pre:left true:left 5609/11700\n",
      "tensor([ 0.4043, -0.4194])\n",
      "pre:left true:left 5610/11700\n",
      "tensor([ 0.2613, -0.2264])\n",
      "pre:left true:left 5611/11700\n",
      "tensor([ 0.2638, -0.2727])\n",
      "pre:left true:left 5612/11700\n",
      "tensor([ 0.0538, -0.0849])\n",
      "pre:left true:left 5613/11700\n",
      "tensor([ 0.7127, -0.6908])\n",
      "pre:left true:left 5614/11700\n",
      "tensor([0.0167, 0.0186])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1046_0_1046_20200412_112124639_9.jpg\n",
      "pre:right true:left 5615/11700\n",
      "tensor([ 0.5267, -0.5521])\n",
      "pre:left true:left 5616/11700\n",
      "tensor([ 1.0685, -1.0769])\n",
      "pre:left true:left 5617/11700\n",
      "tensor([-0.3071,  0.2929])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左955_0_955_20200412_111926089_4.jpg\n",
      "pre:right true:left 5618/11700\n",
      "tensor([-0.1301,  0.2455])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左796_0_952_20200412_115612987_2.jpg\n",
      "pre:right true:left 5619/11700\n",
      "tensor([ 0.5802, -0.5138])\n",
      "pre:left true:left 5620/11700\n",
      "tensor([ 0.1144, -0.0822])\n",
      "pre:left true:left 5621/11700\n",
      "tensor([ 0.6148, -0.7035])\n",
      "pre:left true:left 5622/11700\n",
      "tensor([ 0.6018, -0.5554])\n",
      "pre:left true:left 5623/11700\n",
      "tensor([ 0.4561, -0.3843])\n",
      "pre:left true:left 5624/11700\n",
      "tensor([ 0.3989, -0.4473])\n",
      "pre:left true:left 5625/11700\n",
      "tensor([ 0.8659, -0.7848])\n",
      "pre:left true:left 5626/11700\n",
      "tensor([ 0.5178, -0.4385])\n",
      "pre:left true:left 5627/11700\n",
      "tensor([ 0.2280, -0.2707])\n",
      "pre:left true:left 5628/11700\n",
      "tensor([ 0.6616, -0.6396])\n",
      "pre:left true:left 5629/11700\n",
      "tensor([ 0.2894, -0.2925])\n",
      "pre:left true:left 5630/11700\n",
      "tensor([ 1.0391, -1.0950])\n",
      "pre:left true:left 5631/11700\n",
      "tensor([-0.0012,  0.1178])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左569_0_725_20200412_115117138_4.jpg\n",
      "pre:right true:left 5632/11700\n",
      "tensor([ 0.3684, -0.2777])\n",
      "pre:left true:left 5633/11700\n",
      "tensor([ 0.1846, -0.1177])\n",
      "pre:left true:left 5634/11700\n",
      "tensor([ 0.8688, -0.7909])\n",
      "pre:left true:left 5635/11700\n",
      "tensor([ 0.9334, -1.0001])\n",
      "pre:left true:left 5636/11700\n",
      "tensor([-0.0493,  0.0281])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1526_0_1682_20200412_121204399_0.jpg\n",
      "pre:right true:left 5637/11700\n",
      "tensor([-0.2453,  0.1231])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左330_0_486_20200412_114605706_4.jpg\n",
      "pre:right true:left 5638/11700\n",
      "tensor([ 0.7947, -0.7799])\n",
      "pre:left true:left 5639/11700\n",
      "tensor([ 1.3058, -1.1847])\n",
      "pre:left true:left 5640/11700\n",
      "tensor([ 0.5523, -0.5407])\n",
      "pre:left true:left 5641/11700\n",
      "tensor([ 0.1163, -0.0576])\n",
      "pre:left true:left 5642/11700\n",
      "tensor([ 1.6423, -1.6042])\n",
      "pre:left true:left 5643/11700\n",
      "tensor([-0.6164,  0.6412])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左493_0_493_20200412_110831962_3.jpg\n",
      "pre:right true:left 5644/11700\n",
      "tensor([ 1.0878, -1.1775])\n",
      "pre:left true:left 5645/11700\n",
      "tensor([ 0.0291, -0.0929])\n",
      "pre:left true:left 5646/11700\n",
      "tensor([ 0.5991, -0.5706])\n",
      "pre:left true:left 5647/11700\n",
      "tensor([-0.0941,  0.1587])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1332_0_1488_20200412_120751532_1.jpg\n",
      "pre:right true:left 5648/11700\n",
      "tensor([ 0.9754, -0.9279])\n",
      "pre:left true:left 5649/11700\n",
      "tensor([ 0.1476, -0.1190])\n",
      "pre:left true:left 5650/11700\n",
      "tensor([ 0.1971, -0.1390])\n",
      "pre:left true:left 5651/11700\n",
      "tensor([ 0.9489, -0.9815])\n",
      "pre:left true:left 5652/11700\n",
      "tensor([-0.2772,  0.3905])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1366_0_1522_20200412_120835827_4.jpg\n",
      "pre:right true:left 5653/11700\n",
      "tensor([ 0.2378, -0.2621])\n",
      "pre:left true:left 5654/11700\n",
      "tensor([ 0.5605, -0.4319])\n",
      "pre:left true:left 5655/11700\n",
      "tensor([-0.3059,  0.1752])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左797_0_953_20200412_115614298_10.jpg\n",
      "pre:right true:left 5656/11700\n",
      "tensor([-0.2630,  0.3077])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左635_0_791_20200412_115243157_1.jpg\n",
      "pre:right true:left 5657/11700\n",
      "tensor([ 0.2101, -0.2452])\n",
      "pre:left true:left 5658/11700\n",
      "tensor([ 0.1784, -0.1528])\n",
      "pre:left true:left 5659/11700\n",
      "tensor([ 0.4580, -0.4546])\n",
      "pre:left true:left 5660/11700\n",
      "tensor([ 0.2593, -0.2494])\n",
      "pre:left true:left 5661/11700\n",
      "tensor([ 1.1628, -1.1457])\n",
      "pre:left true:left 5662/11700\n",
      "tensor([ 0.8410, -0.9102])\n",
      "pre:left true:left 5663/11700\n",
      "tensor([-0.1826,  0.1977])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左778_0_778_20200412_111518473_5.jpg\n",
      "pre:right true:left 5664/11700\n",
      "tensor([ 0.6299, -0.6688])\n",
      "pre:left true:left 5665/11700\n",
      "tensor([ 0.4491, -0.5058])\n",
      "pre:left true:left 5666/11700\n",
      "tensor([ 0.6229, -0.5434])\n",
      "pre:left true:left 5667/11700\n",
      "tensor([ 0.0590, -0.0467])\n",
      "pre:left true:left 5668/11700\n",
      "tensor([ 0.5900, -0.6282])\n",
      "pre:left true:left 5669/11700\n",
      "tensor([-0.1073,  0.1786])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1440_0_1596_20200412_121012283_3.jpg\n",
      "pre:right true:left 5670/11700\n",
      "tensor([ 0.2149, -0.1510])\n",
      "pre:left true:left 5671/11700\n",
      "tensor([ 0.3835, -0.3426])\n",
      "pre:left true:left 5672/11700\n",
      "tensor([ 0.3499, -0.3476])\n",
      "pre:left true:left 5673/11700\n",
      "tensor([ 0.3681, -0.3776])\n",
      "pre:left true:left 5674/11700\n",
      "tensor([ 0.5862, -0.5611])\n",
      "pre:left true:left 5675/11700\n",
      "tensor([-0.4839,  0.4496])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1320_0_1320_20200412_112731601_0.jpg\n",
      "pre:right true:left 5676/11700\n",
      "tensor([ 0.9943, -1.0734])\n",
      "pre:left true:left 5677/11700\n",
      "tensor([ 0.4537, -0.4671])\n",
      "pre:left true:left 5678/11700\n",
      "tensor([ 0.2684, -0.2299])\n",
      "pre:left true:left 5679/11700\n",
      "tensor([ 0.8005, -0.7710])\n",
      "pre:left true:left 5680/11700\n",
      "tensor([ 0.8223, -0.8647])\n",
      "pre:left true:left 5681/11700\n",
      "tensor([ 0.6185, -0.6611])\n",
      "pre:left true:left 5682/11700\n",
      "tensor([ 1.0602, -1.1500])\n",
      "pre:left true:left 5683/11700\n",
      "tensor([ 0.7915, -0.7753])\n",
      "pre:left true:left 5684/11700\n",
      "tensor([ 0.7469, -0.7850])\n",
      "pre:left true:left 5685/11700\n",
      "tensor([ 0.8198, -0.7035])\n",
      "pre:left true:left 5686/11700\n",
      "tensor([ 0.4251, -0.3668])\n",
      "pre:left true:left 5687/11700\n",
      "tensor([ 0.6261, -0.5964])\n",
      "pre:left true:left 5688/11700\n",
      "tensor([ 0.9517, -0.9423])\n",
      "pre:left true:left 5689/11700\n",
      "tensor([ 0.5686, -0.5974])\n",
      "pre:left true:left 5690/11700\n",
      "tensor([ 0.5777, -0.5600])\n",
      "pre:left true:left 5691/11700\n",
      "tensor([ 0.9209, -0.9121])\n",
      "pre:left true:left 5692/11700\n",
      "tensor([ 0.2665, -0.2492])\n",
      "pre:left true:left 5693/11700\n",
      "tensor([ 1.1831, -1.1560])\n",
      "pre:left true:left 5694/11700\n",
      "tensor([ 1.3023, -1.2855])\n",
      "pre:left true:left 5695/11700\n",
      "tensor([ 0.8978, -0.8141])\n",
      "pre:left true:left 5696/11700\n",
      "tensor([ 0.1074, -0.0563])\n",
      "pre:left true:left 5697/11700\n",
      "tensor([ 0.3735, -0.2899])\n",
      "pre:left true:left 5698/11700\n",
      "tensor([ 0.5348, -0.5266])\n",
      "pre:left true:left 5699/11700\n",
      "tensor([-0.0633,  0.0689])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左198_0_198_20200412_110131204.jpg\n",
      "pre:right true:left 5700/11700\n",
      "tensor([ 0.3132, -0.2577])\n",
      "pre:left true:left 5701/11700\n",
      "tensor([ 1.1039, -1.1022])\n",
      "pre:left true:left 5702/11700\n",
      "tensor([ 0.3228, -0.4186])\n",
      "pre:left true:left 5703/11700\n",
      "tensor([ 0.6554, -0.6174])\n",
      "pre:left true:left 5704/11700\n",
      "tensor([ 0.2679, -0.3420])\n",
      "pre:left true:left 5705/11700\n",
      "tensor([-0.0024, -0.0917])\n",
      "pre:left true:left 5706/11700\n",
      "tensor([ 1.1900, -1.2674])\n",
      "pre:left true:left 5707/11700\n",
      "tensor([ 0.6284, -0.5794])\n",
      "pre:left true:left 5708/11700\n",
      "tensor([ 0.4104, -0.4682])\n",
      "pre:left true:left 5709/11700\n",
      "tensor([ 0.7500, -0.6977])\n",
      "pre:left true:left 5710/11700\n",
      "tensor([ 0.8128, -0.7888])\n",
      "pre:left true:left 5711/11700\n",
      "tensor([ 0.5044, -0.5125])\n",
      "pre:left true:left 5712/11700\n",
      "tensor([ 1.0938, -0.9830])\n",
      "pre:left true:left 5713/11700\n",
      "tensor([ 0.4067, -0.3611])\n",
      "pre:left true:left 5714/11700\n",
      "tensor([ 1.1397, -1.0552])\n",
      "pre:left true:left 5715/11700\n",
      "tensor([ 0.2171, -0.2384])\n",
      "pre:left true:left 5716/11700\n",
      "tensor([-0.0904,  0.0574])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左317_0_473_20200412_114548746_5.jpg\n",
      "pre:right true:left 5717/11700\n",
      "tensor([ 0.8560, -0.8591])\n",
      "pre:left true:left 5718/11700\n",
      "tensor([ 0.8663, -0.7547])\n",
      "pre:left true:left 5719/11700\n",
      "tensor([ 0.1315, -0.1703])\n",
      "pre:left true:left 5720/11700\n",
      "tensor([ 0.2356, -0.2103])\n",
      "pre:left true:left 5721/11700\n",
      "tensor([ 0.3860, -0.4147])\n",
      "pre:left true:left 5722/11700\n",
      "tensor([ 0.0524, -0.0291])\n",
      "pre:left true:left 5723/11700\n",
      "tensor([ 0.5820, -0.5307])\n",
      "pre:left true:left 5724/11700\n",
      "tensor([ 0.4750, -0.4952])\n",
      "pre:left true:left 5725/11700\n",
      "tensor([ 0.8972, -0.9067])\n",
      "pre:left true:left 5726/11700\n",
      "tensor([ 0.3581, -0.3253])\n",
      "pre:left true:left 5727/11700\n",
      "tensor([ 0.0589, -0.1426])\n",
      "pre:left true:left 5728/11700\n",
      "tensor([ 0.3762, -0.2927])\n",
      "pre:left true:left 5729/11700\n",
      "tensor([0.0652, 0.0356])\n",
      "pre:left true:left 5730/11700\n",
      "tensor([ 0.2899, -0.3598])\n",
      "pre:left true:left 5731/11700\n",
      "tensor([ 0.3576, -0.3213])\n",
      "pre:left true:left 5732/11700\n",
      "tensor([ 0.6083, -0.7364])\n",
      "pre:left true:left 5733/11700\n",
      "tensor([ 0.5896, -0.6333])\n",
      "pre:left true:left 5734/11700\n",
      "tensor([ 0.0770, -0.0089])\n",
      "pre:left true:left 5735/11700\n",
      "tensor([ 0.7612, -0.7939])\n",
      "pre:left true:left 5736/11700\n",
      "tensor([-0.4786,  0.5717])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1307_0_1307_20200412_112704754_0.jpg\n",
      "pre:right true:left 5737/11700\n",
      "tensor([ 0.8095, -0.7369])\n",
      "pre:left true:left 5738/11700\n",
      "tensor([ 0.4954, -0.3860])\n",
      "pre:left true:left 5739/11700\n",
      "tensor([ 1.1902, -1.1772])\n",
      "pre:left true:left 5740/11700\n",
      "tensor([ 0.1017, -0.1430])\n",
      "pre:left true:left 5741/11700\n",
      "tensor([ 0.7671, -0.6871])\n",
      "pre:left true:left 5742/11700\n",
      "tensor([ 0.0846, -0.0717])\n",
      "pre:left true:left 5743/11700\n",
      "tensor([ 0.8982, -0.8296])\n",
      "pre:left true:left 5744/11700\n",
      "tensor([ 0.3316, -0.3730])\n",
      "pre:left true:left 5745/11700\n",
      "tensor([ 0.5413, -0.5167])\n",
      "pre:left true:left 5746/11700\n",
      "tensor([ 0.7987, -0.7337])\n",
      "pre:left true:left 5747/11700\n",
      "tensor([ 1.0662, -1.1485])\n",
      "pre:left true:left 5748/11700\n",
      "tensor([ 0.3460, -0.3173])\n",
      "pre:left true:left 5749/11700\n",
      "tensor([ 0.5870, -0.4778])\n",
      "pre:left true:left 5750/11700\n",
      "tensor([ 0.4088, -0.3532])\n",
      "pre:left true:left 5751/11700\n",
      "tensor([ 0.8405, -0.8997])\n",
      "pre:left true:left 5752/11700\n",
      "tensor([ 0.6208, -0.5967])\n",
      "pre:left true:left 5753/11700\n",
      "tensor([-0.1994,  0.1707])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左474_0_630_20200412_114913342_2.jpg\n",
      "pre:right true:left 5754/11700\n",
      "tensor([ 0.4390, -0.3496])\n",
      "pre:left true:left 5755/11700\n",
      "tensor([ 0.7476, -0.6704])\n",
      "pre:left true:left 5756/11700\n",
      "tensor([ 0.4388, -0.3338])\n",
      "pre:left true:left 5757/11700\n",
      "tensor([ 1.1354, -1.0968])\n",
      "pre:left true:left 5758/11700\n",
      "tensor([ 0.1843, -0.2918])\n",
      "pre:left true:left 5759/11700\n",
      "tensor([-0.3069,  0.3937])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1597_0_1753_20200412_121336950_2.jpg\n",
      "pre:right true:left 5760/11700\n",
      "tensor([ 0.6641, -0.6698])\n",
      "pre:left true:left 5761/11700\n",
      "tensor([ 0.8795, -0.9329])\n",
      "pre:left true:left 5762/11700\n",
      "tensor([ 0.4625, -0.3949])\n",
      "pre:left true:left 5763/11700\n",
      "tensor([ 0.1537, -0.0349])\n",
      "pre:left true:left 5764/11700\n",
      "tensor([ 0.9907, -1.0010])\n",
      "pre:left true:left 5765/11700\n",
      "tensor([ 0.9294, -0.8635])\n",
      "pre:left true:left 5766/11700\n",
      "tensor([-0.2400,  0.3509])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左474_0_630_20200412_114913342_4.jpg\n",
      "pre:right true:left 5767/11700\n",
      "tensor([ 0.0730, -0.1051])\n",
      "pre:left true:left 5768/11700\n",
      "tensor([ 1.2599, -1.2723])\n",
      "pre:left true:left 5769/11700\n",
      "tensor([ 0.7345, -0.7262])\n",
      "pre:left true:left 5770/11700\n",
      "tensor([ 0.8838, -0.9134])\n",
      "pre:left true:left 5771/11700\n",
      "tensor([ 1.8700, -1.9047])\n",
      "pre:left true:left 5772/11700\n",
      "tensor([ 0.0930, -0.0959])\n",
      "pre:left true:left 5773/11700\n",
      "tensor([ 0.2863, -0.1805])\n",
      "pre:left true:left 5774/11700\n",
      "tensor([ 0.5039, -0.4917])\n",
      "pre:left true:left 5775/11700\n",
      "tensor([-0.0387,  0.1439])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左727_0_883_20200412_115443056_0.jpg\n",
      "pre:right true:left 5776/11700\n",
      "tensor([ 0.6186, -0.5610])\n",
      "pre:left true:left 5777/11700\n",
      "tensor([-0.2862,  0.3745])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左321_0_321_20200412_105600268_10.jpg\n",
      "pre:right true:left 5778/11700\n",
      "tensor([ 0.6476, -0.6330])\n",
      "pre:left true:left 5779/11700\n",
      "tensor([ 1.1662, -1.1645])\n",
      "pre:left true:left 5780/11700\n",
      "tensor([0.0351, 0.0703])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左375_0_531_20200412_114704342_7.jpg\n",
      "pre:right true:left 5781/11700\n",
      "tensor([ 0.5044, -0.4580])\n",
      "pre:left true:left 5782/11700\n",
      "tensor([ 0.4146, -0.3507])\n",
      "pre:left true:left 5783/11700\n",
      "tensor([-0.6871,  0.6583])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左531_0_687_20200412_115027615_9.jpg\n",
      "pre:right true:left 5784/11700\n",
      "tensor([-0.1298,  0.1743])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左387_0_543_20200412_114719968_10.jpg\n",
      "pre:right true:left 5785/11700\n",
      "tensor([ 0.3320, -0.3006])\n",
      "pre:left true:left 5786/11700\n",
      "tensor([ 0.4811, -0.4284])\n",
      "pre:left true:left 5787/11700\n",
      "tensor([ 0.6361, -0.6396])\n",
      "pre:left true:left 5788/11700\n",
      "tensor([-0.4447,  0.4979])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1537_0_1693_20200412_121218732_8.jpg\n",
      "pre:right true:left 5789/11700\n",
      "tensor([ 1.2966, -1.3331])\n",
      "pre:left true:left 5790/11700\n",
      "tensor([ 0.4899, -0.3954])\n",
      "pre:left true:left 5791/11700\n",
      "tensor([ 0.2251, -0.1481])\n",
      "pre:left true:left 5792/11700\n",
      "tensor([ 0.4825, -0.4291])\n",
      "pre:left true:left 5793/11700\n",
      "tensor([ 0.5913, -0.5216])\n",
      "pre:left true:left 5794/11700\n",
      "tensor([-0.1245,  0.0805])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左98_0_98_20200412_105908563_0.jpg\n",
      "pre:right true:left 5795/11700\n",
      "tensor([ 0.2317, -0.2185])\n",
      "pre:left true:left 5796/11700\n",
      "tensor([ 0.4883, -0.4524])\n",
      "pre:left true:left 5797/11700\n",
      "tensor([ 1.1935, -1.2119])\n",
      "pre:left true:left 5798/11700\n",
      "tensor([ 0.3935, -0.3000])\n",
      "pre:left true:left 5799/11700\n",
      "tensor([ 1.2957, -1.3582])\n",
      "pre:left true:left 5800/11700\n",
      "tensor([ 0.2707, -0.3164])\n",
      "pre:left true:left 5801/11700\n",
      "tensor([ 0.6432, -0.5591])\n",
      "pre:left true:left 5802/11700\n",
      "tensor([ 0.7859, -0.8499])\n",
      "pre:left true:left 5803/11700\n",
      "tensor([ 0.1241, -0.0687])\n",
      "pre:left true:left 5804/11700\n",
      "tensor([ 0.7058, -0.6700])\n",
      "pre:left true:left 5805/11700\n",
      "tensor([ 0.7440, -0.7278])\n",
      "pre:left true:left 5806/11700\n",
      "tensor([ 0.6802, -0.6900])\n",
      "pre:left true:left 5807/11700\n",
      "tensor([-0.0633,  0.0151])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左339_0_495_20200412_114617420_2.jpg\n",
      "pre:right true:left 5808/11700\n",
      "tensor([ 0.3680, -0.2159])\n",
      "pre:left true:left 5809/11700\n",
      "tensor([ 0.2167, -0.1392])\n",
      "pre:left true:left 5810/11700\n",
      "tensor([ 0.6154, -0.6798])\n",
      "pre:left true:left 5811/11700\n",
      "tensor([ 0.7194, -0.8239])\n",
      "pre:left true:left 5812/11700\n",
      "tensor([ 0.7628, -0.6744])\n",
      "pre:left true:left 5813/11700\n",
      "tensor([ 0.4555, -0.3889])\n",
      "pre:left true:left 5814/11700\n",
      "tensor([ 0.2159, -0.1729])\n",
      "pre:left true:left 5815/11700\n",
      "tensor([ 2.0134, -2.1549])\n",
      "pre:left true:left 5816/11700\n",
      "tensor([ 0.2910, -0.2826])\n",
      "pre:left true:left 5817/11700\n",
      "tensor([ 0.3238, -0.2943])\n",
      "pre:left true:left 5818/11700\n",
      "tensor([-0.4550,  0.4916])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左331_0_487_20200412_114606994_10.jpg\n",
      "pre:right true:left 5819/11700\n",
      "tensor([ 0.9805, -0.9785])\n",
      "pre:left true:left 5820/11700\n",
      "tensor([ 0.4424, -0.3269])\n",
      "pre:left true:left 5821/11700\n",
      "tensor([ 0.6456, -0.6667])\n",
      "pre:left true:left 5822/11700\n",
      "tensor([ 0.8074, -0.7668])\n",
      "pre:left true:left 5823/11700\n",
      "tensor([ 0.5690, -0.5158])\n",
      "pre:left true:left 5824/11700\n",
      "tensor([ 0.7942, -0.8462])\n",
      "pre:left true:left 5825/11700\n",
      "tensor([-0.6518,  0.7074])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左226_0_382_20200412_114350157_7.jpg\n",
      "pre:right true:left 5826/11700\n",
      "tensor([ 1.6322, -1.5755])\n",
      "pre:left true:left 5827/11700\n",
      "tensor([ 0.7332, -0.7858])\n",
      "pre:left true:left 5828/11700\n",
      "tensor([ 0.2087, -0.1954])\n",
      "pre:left true:left 5829/11700\n",
      "tensor([ 1.2452, -1.2788])\n",
      "pre:left true:left 5830/11700\n",
      "tensor([ 2.0699, -2.0545])\n",
      "pre:left true:left 5831/11700\n",
      "tensor([-0.1296,  0.2225])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1327_0_1483_20200412_120745025_4.jpg\n",
      "pre:right true:left 5832/11700\n",
      "tensor([ 0.4590, -0.4248])\n",
      "pre:left true:left 5833/11700\n",
      "tensor([ 0.7500, -0.6977])\n",
      "pre:left true:left 5834/11700\n",
      "tensor([-0.0958,  0.1945])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左485_0_641_20200412_114927678_3.jpg\n",
      "pre:right true:left 5835/11700\n",
      "tensor([ 0.5749, -0.5727])\n",
      "pre:left true:left 5836/11700\n",
      "tensor([ 0.9799, -0.9237])\n",
      "pre:left true:left 5837/11700\n",
      "tensor([ 0.7579, -0.7891])\n",
      "pre:left true:left 5838/11700\n",
      "tensor([ 0.6312, -0.5954])\n",
      "pre:left true:left 5839/11700\n",
      "tensor([ 0.4336, -0.4222])\n",
      "pre:left true:left 5840/11700\n",
      "tensor([ 0.3984, -0.3988])\n",
      "pre:left true:left 5841/11700\n",
      "tensor([ 0.8206, -0.9599])\n",
      "pre:left true:left 5842/11700\n",
      "tensor([-0.0106, -0.0163])\n",
      "pre:left true:left 5843/11700\n",
      "tensor([ 0.4921, -0.4569])\n",
      "pre:left true:left 5844/11700\n",
      "tensor([ 0.3173, -0.2919])\n",
      "pre:left true:left 5845/11700\n",
      "tensor([ 0.1495, -0.1403])\n",
      "pre:left true:left 5846/11700\n",
      "tensor([ 1.6584, -1.6392])\n",
      "pre:left true:left 5847/11700\n",
      "tensor([ 1.3732, -1.2725])\n",
      "pre:left true:left 5848/11700\n",
      "tensor([ 0.7641, -0.8890])\n",
      "pre:left true:left 5849/11700\n",
      "tensor([-0.0280, -0.0175])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1402_0_1558_20200412_120922756_3.jpg\n",
      "pre:right true:left 5850/11700\n",
      "tensor([ 0.5281, -0.5084])\n",
      "pre:left true:left 5851/11700\n",
      "tensor([ 0.3483, -0.2315])\n",
      "pre:left true:left 5852/11700\n",
      "tensor([ 0.7372, -0.7596])\n",
      "pre:left true:left 5853/11700\n",
      "tensor([ 0.8818, -0.9350])\n",
      "pre:left true:left 5854/11700\n",
      "tensor([ 0.1803, -0.1575])\n",
      "pre:left true:left 5855/11700\n",
      "tensor([ 0.3671, -0.3641])\n",
      "pre:left true:left 5856/11700\n",
      "tensor([-0.6520,  0.8423])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左566_0_722_20200412_115113231.jpg\n",
      "pre:right true:left 5857/11700\n",
      "tensor([ 0.0973, -0.1040])\n",
      "pre:left true:left 5858/11700\n",
      "tensor([ 0.2439, -0.2105])\n",
      "pre:left true:left 5859/11700\n",
      "tensor([-0.0004,  0.0403])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左558_0_714_20200412_115102802_7.jpg\n",
      "pre:right true:left 5860/11700\n",
      "tensor([ 0.1582, -0.1285])\n",
      "pre:left true:left 5861/11700\n",
      "tensor([-0.2312,  0.3255])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左837_0_837_20200412_111642640_0.jpg\n",
      "pre:right true:left 5862/11700\n",
      "tensor([ 0.8596, -0.8638])\n",
      "pre:left true:left 5863/11700\n",
      "tensor([ 0.2359, -0.2780])\n",
      "pre:left true:left 5864/11700\n",
      "tensor([ 1.4670, -1.4214])\n",
      "pre:left true:left 5865/11700\n",
      "tensor([ 0.5196, -0.4494])\n",
      "pre:left true:left 5866/11700\n",
      "tensor([ 0.4908, -0.3868])\n",
      "pre:left true:left 5867/11700\n",
      "tensor([ 0.1210, -0.0604])\n",
      "pre:left true:left 5868/11700\n",
      "tensor([ 0.2948, -0.3771])\n",
      "pre:left true:left 5869/11700\n",
      "tensor([-0.4059,  0.4380])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1297_0_1453_20200412_120705914_7.jpg\n",
      "pre:right true:left 5870/11700\n",
      "tensor([ 1.0839, -1.0655])\n",
      "pre:left true:left 5871/11700\n",
      "tensor([ 0.1521, -0.1181])\n",
      "pre:left true:left 5872/11700\n",
      "tensor([ 0.2936, -0.2299])\n",
      "pre:left true:left 5873/11700\n",
      "tensor([-0.1072,  0.0926])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1199_0_1199_20200412_112444000_5.jpg\n",
      "pre:right true:left 5874/11700\n",
      "tensor([ 0.7407, -0.7683])\n",
      "pre:left true:left 5875/11700\n",
      "tensor([ 0.3154, -0.3676])\n",
      "pre:left true:left 5876/11700\n",
      "tensor([ 1.7763, -1.8880])\n",
      "pre:left true:left 5877/11700\n",
      "tensor([ 0.6955, -0.6518])\n",
      "pre:left true:left 5878/11700\n",
      "tensor([ 0.2508, -0.1944])\n",
      "pre:left true:left 5879/11700\n",
      "tensor([ 0.7196, -0.6854])\n",
      "pre:left true:left 5880/11700\n",
      "tensor([ 0.6999, -0.6855])\n",
      "pre:left true:left 5881/11700\n",
      "tensor([ 0.9655, -0.8651])\n",
      "pre:left true:left 5882/11700\n",
      "tensor([ 0.6826, -0.6500])\n",
      "pre:left true:left 5883/11700\n",
      "tensor([-0.6449,  0.6789])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左430_0_430_20200412_110702096_4.jpg\n",
      "pre:right true:left 5884/11700\n",
      "tensor([-0.0310, -0.0146])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左422_0_578_20200412_114805569_2.jpg\n",
      "pre:right true:left 5885/11700\n",
      "tensor([ 0.5830, -0.5188])\n",
      "pre:left true:left 5886/11700\n",
      "tensor([ 0.9596, -0.9678])\n",
      "pre:left true:left 5887/11700\n",
      "tensor([ 0.1506, -0.1945])\n",
      "pre:left true:left 5888/11700\n",
      "tensor([ 0.2080, -0.0997])\n",
      "pre:left true:left 5889/11700\n",
      "tensor([ 0.6694, -0.6267])\n",
      "pre:left true:left 5890/11700\n",
      "tensor([ 0.2036, -0.2103])\n",
      "pre:left true:left 5891/11700\n",
      "tensor([ 0.4232, -0.4558])\n",
      "pre:left true:left 5892/11700\n",
      "tensor([ 0.3729, -0.2814])\n",
      "pre:left true:left 5893/11700\n",
      "tensor([ 0.5077, -0.5425])\n",
      "pre:left true:left 5894/11700\n",
      "tensor([ 0.4454, -0.3253])\n",
      "pre:left true:left 5895/11700\n",
      "tensor([ 0.3453, -0.3273])\n",
      "pre:left true:left 5896/11700\n",
      "tensor([-0.1034,  0.2307])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左772_0_928_20200412_115541714_5.jpg\n",
      "pre:right true:left 5897/11700\n",
      "tensor([-0.2423,  0.2849])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左306_0_462_20200412_114534417_9.jpg\n",
      "pre:right true:left 5898/11700\n",
      "tensor([ 0.4996, -0.4326])\n",
      "pre:left true:left 5899/11700\n",
      "tensor([ 0.6507, -0.6938])\n",
      "pre:left true:left 5900/11700\n",
      "tensor([ 0.2792, -0.2408])\n",
      "pre:left true:left 5901/11700\n",
      "tensor([ 1.0170, -0.9555])\n",
      "pre:left true:left 5902/11700\n",
      "tensor([ 0.3968, -0.2897])\n",
      "pre:left true:left 5903/11700\n",
      "tensor([ 1.4823, -1.4385])\n",
      "pre:left true:left 5904/11700\n",
      "tensor([ 0.2710, -0.3344])\n",
      "pre:left true:left 5905/11700\n",
      "tensor([ 0.8930, -1.0498])\n",
      "pre:left true:left 5906/11700\n",
      "tensor([-0.0247,  0.0088])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左420_0_576_20200412_114802970_6.jpg\n",
      "pre:right true:left 5907/11700\n",
      "tensor([ 0.6930, -0.7750])\n",
      "pre:left true:left 5908/11700\n",
      "tensor([0.0027, 0.0341])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左351_0_351_20200412_105636230_5.jpg\n",
      "pre:right true:left 5909/11700\n",
      "tensor([ 1.4403, -1.4737])\n",
      "pre:left true:left 5910/11700\n",
      "tensor([ 1.1525, -1.1809])\n",
      "pre:left true:left 5911/11700\n",
      "tensor([ 0.5214, -0.5087])\n",
      "pre:left true:left 5912/11700\n",
      "tensor([ 1.0317, -0.9420])\n",
      "pre:left true:left 5913/11700\n",
      "tensor([ 1.1617, -1.1948])\n",
      "pre:left true:left 5914/11700\n",
      "tensor([ 0.3162, -0.2789])\n",
      "pre:left true:left 5915/11700\n",
      "tensor([ 0.3784, -0.3904])\n",
      "pre:left true:left 5916/11700\n",
      "tensor([ 1.0405, -0.9521])\n",
      "pre:left true:left 5917/11700\n",
      "tensor([ 0.7015, -0.8097])\n",
      "pre:left true:left 5918/11700\n",
      "tensor([-0.0568,  0.0756])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左165_0_321_20200412_114230687_5.jpg\n",
      "pre:right true:left 5919/11700\n",
      "tensor([ 1.2452, -1.2788])\n",
      "pre:left true:left 5920/11700\n",
      "tensor([ 0.0628, -0.0893])\n",
      "pre:left true:left 5921/11700\n",
      "tensor([ 1.0859, -1.1521])\n",
      "pre:left true:left 5922/11700\n",
      "tensor([ 1.1500, -1.1128])\n",
      "pre:left true:left 5923/11700\n",
      "tensor([-0.3757,  0.3968])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左469_0_625_20200412_114906825_4.jpg\n",
      "pre:right true:left 5924/11700\n",
      "tensor([-0.0332,  0.0001])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左159_0_315_20200412_114222876_9.jpg\n",
      "pre:right true:left 5925/11700\n",
      "tensor([ 0.9469, -0.8814])\n",
      "pre:left true:left 5926/11700\n",
      "tensor([ 0.5194, -0.5716])\n",
      "pre:left true:left 5927/11700\n",
      "tensor([ 0.7424, -0.7799])\n",
      "pre:left true:left 5928/11700\n",
      "tensor([ 0.3687, -0.4451])\n",
      "pre:left true:left 5929/11700\n",
      "tensor([ 0.7552, -0.7847])\n",
      "pre:left true:left 5930/11700\n",
      "tensor([ 0.1487, -0.0904])\n",
      "pre:left true:left 5931/11700\n",
      "tensor([-0.0246,  0.0210])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左524_0_680_20200412_115018501_9.jpg\n",
      "pre:right true:left 5932/11700\n",
      "tensor([ 0.4989, -0.5169])\n",
      "pre:left true:left 5933/11700\n",
      "tensor([ 0.1175, -0.0851])\n",
      "pre:left true:left 5934/11700\n",
      "tensor([ 0.3895, -0.3684])\n",
      "pre:left true:left 5935/11700\n",
      "tensor([ 0.9050, -0.8375])\n",
      "pre:left true:left 5936/11700\n",
      "tensor([-0.3818,  0.3839])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左498_0_654_20200412_114944689_6.jpg\n",
      "pre:right true:left 5937/11700\n",
      "tensor([ 0.4019, -0.3396])\n",
      "pre:left true:left 5938/11700\n",
      "tensor([ 0.4810, -0.4932])\n",
      "pre:left true:left 5939/11700\n",
      "tensor([ 1.1123, -1.1475])\n",
      "pre:left true:left 5940/11700\n",
      "tensor([ 0.3735, -0.3887])\n",
      "pre:left true:left 5941/11700\n",
      "tensor([ 0.9298, -0.8869])\n",
      "pre:left true:left 5942/11700\n",
      "tensor([-0.3283,  0.3110])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左824_0_824_20200412_111624083_7.jpg\n",
      "pre:right true:left 5943/11700\n",
      "tensor([ 0.6905, -0.6909])\n",
      "pre:left true:left 5944/11700\n",
      "tensor([ 0.3637, -0.2759])\n",
      "pre:left true:left 5945/11700\n",
      "tensor([ 0.7024, -0.6839])\n",
      "pre:left true:left 5946/11700\n",
      "tensor([ 0.5704, -0.5907])\n",
      "pre:left true:left 5947/11700\n",
      "tensor([ 0.2276, -0.2176])\n",
      "pre:left true:left 5948/11700\n",
      "tensor([ 1.1288, -1.1519])\n",
      "pre:left true:left 5949/11700\n",
      "tensor([ 0.4966, -0.3603])\n",
      "pre:left true:left 5950/11700\n",
      "tensor([ 0.4248, -0.4542])\n",
      "pre:left true:left 5951/11700\n",
      "tensor([ 1.1105, -1.0061])\n",
      "pre:left true:left 5952/11700\n",
      "tensor([ 0.2044, -0.2330])\n",
      "pre:left true:left 5953/11700\n",
      "tensor([ 0.1487, -0.2111])\n",
      "pre:left true:left 5954/11700\n",
      "tensor([ 0.6573, -0.4649])\n",
      "pre:left true:left 5955/11700\n",
      "tensor([ 0.7825, -0.6402])\n",
      "pre:left true:left 5956/11700\n",
      "tensor([ 0.3012, -0.2559])\n",
      "pre:left true:left 5957/11700\n",
      "tensor([ 1.3252, -1.4921])\n",
      "pre:left true:left 5958/11700\n",
      "tensor([ 0.5564, -0.5609])\n",
      "pre:left true:left 5959/11700\n",
      "tensor([ 0.3310, -0.3278])\n",
      "pre:left true:left 5960/11700\n",
      "tensor([ 1.2682, -1.3821])\n",
      "pre:left true:left 5961/11700\n",
      "tensor([ 0.5404, -0.5158])\n",
      "pre:left true:left 5962/11700\n",
      "tensor([ 0.7303, -0.7417])\n",
      "pre:left true:left 5963/11700\n",
      "tensor([ 0.4921, -0.4304])\n",
      "pre:left true:left 5964/11700\n",
      "tensor([ 1.0563, -1.0631])\n",
      "pre:left true:left 5965/11700\n",
      "tensor([ 0.2099, -0.1693])\n",
      "pre:left true:left 5966/11700\n",
      "tensor([ 0.8878, -0.9801])\n",
      "pre:left true:left 5967/11700\n",
      "tensor([ 0.4992, -0.5213])\n",
      "pre:left true:left 5968/11700\n",
      "tensor([-0.1952,  0.1951])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左489_0_645_20200412_114932883_9.jpg\n",
      "pre:right true:left 5969/11700\n",
      "tensor([ 0.4148, -0.5084])\n",
      "pre:left true:left 5970/11700\n",
      "tensor([ 2.1534, -2.2448])\n",
      "pre:left true:left 5971/11700\n",
      "tensor([-0.5831,  0.5916])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1330_0_1486_20200412_120748944_1.jpg\n",
      "pre:right true:left 5972/11700\n",
      "tensor([ 1.0516, -1.0445])\n",
      "pre:left true:left 5973/11700\n",
      "tensor([ 0.6332, -0.4985])\n",
      "pre:left true:left 5974/11700\n",
      "tensor([ 0.4822, -0.4562])\n",
      "pre:left true:left 5975/11700\n",
      "tensor([ 0.3692, -0.3296])\n",
      "pre:left true:left 5976/11700\n",
      "tensor([ 0.5234, -0.5090])\n",
      "pre:left true:left 5977/11700\n",
      "tensor([ 0.6701, -0.5772])\n",
      "pre:left true:left 5978/11700\n",
      "tensor([ 1.0568, -0.9324])\n",
      "pre:left true:left 5979/11700\n",
      "tensor([ 0.5003, -0.5177])\n",
      "pre:left true:left 5980/11700\n",
      "tensor([ 0.1637, -0.2371])\n",
      "pre:left true:left 5981/11700\n",
      "tensor([ 0.7767, -0.8505])\n",
      "pre:left true:left 5982/11700\n",
      "tensor([ 0.0475, -0.0191])\n",
      "pre:left true:left 5983/11700\n",
      "tensor([ 1.0062, -0.7824])\n",
      "pre:left true:left 5984/11700\n",
      "tensor([ 0.5798, -0.6235])\n",
      "pre:left true:left 5985/11700\n",
      "tensor([ 0.6140, -0.5527])\n",
      "pre:left true:left 5986/11700\n",
      "tensor([ 0.1886, -0.1218])\n",
      "pre:left true:left 5987/11700\n",
      "tensor([ 0.3847, -0.3924])\n",
      "pre:left true:left 5988/11700\n",
      "tensor([ 1.0563, -1.0175])\n",
      "pre:left true:left 5989/11700\n",
      "tensor([ 0.4304, -0.3090])\n",
      "pre:left true:left 5990/11700\n",
      "tensor([-0.0927,  0.0403])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左689_0_689_20200412_111311531_10.jpg\n",
      "pre:right true:left 5991/11700\n",
      "tensor([ 0.6186, -0.5683])\n",
      "pre:left true:left 5992/11700\n",
      "tensor([ 0.8266, -0.6975])\n",
      "pre:left true:left 5993/11700\n",
      "tensor([ 0.8219, -0.8900])\n",
      "pre:left true:left 5994/11700\n",
      "tensor([ 0.8688, -0.8411])\n",
      "pre:left true:left 5995/11700\n",
      "tensor([ 0.6495, -0.6928])\n",
      "pre:left true:left 5996/11700\n",
      "tensor([ 0.6194, -0.5534])\n",
      "pre:left true:left 5997/11700\n",
      "tensor([ 0.8335, -0.7872])\n",
      "pre:left true:left 5998/11700\n",
      "tensor([ 0.1971, -0.1519])\n",
      "pre:left true:left 5999/11700\n",
      "tensor([ 0.7570, -0.7255])\n",
      "pre:left true:left 6000/11700\n",
      "tensor([ 0.4083, -0.4129])\n",
      "pre:left true:left 6001/11700\n",
      "tensor([ 0.1989, -0.1690])\n",
      "pre:left true:left 6002/11700\n",
      "tensor([-0.2828,  0.2502])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左601_0_757_20200412_115158849_8.jpg\n",
      "pre:right true:left 6003/11700\n",
      "tensor([ 0.8157, -0.7296])\n",
      "pre:left true:left 6004/11700\n",
      "tensor([ 0.0860, -0.0652])\n",
      "pre:left true:left 6005/11700\n",
      "tensor([ 0.2111, -0.1589])\n",
      "pre:left true:left 6006/11700\n",
      "tensor([-0.7639,  0.7560])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左375_0_531_20200412_114704342.jpg\n",
      "pre:right true:left 6007/11700\n",
      "tensor([-0.0308,  0.0503])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左655_0_655_20200412_111223032_8.jpg\n",
      "pre:right true:left 6008/11700\n",
      "tensor([ 0.4034, -0.4599])\n",
      "pre:left true:left 6009/11700\n",
      "tensor([ 1.0575, -1.1976])\n",
      "pre:left true:left 6010/11700\n",
      "tensor([ 0.4675, -0.4094])\n",
      "pre:left true:left 6011/11700\n",
      "tensor([ 0.9192, -1.0520])\n",
      "pre:left true:left 6012/11700\n",
      "tensor([ 0.3068, -0.4035])\n",
      "pre:left true:left 6013/11700\n",
      "tensor([ 0.5041, -0.5235])\n",
      "pre:left true:left 6014/11700\n",
      "tensor([ 0.1956, -0.2600])\n",
      "pre:left true:left 6015/11700\n",
      "tensor([-0.2249,  0.3199])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左835_0_991_20200412_115703810_0.jpg\n",
      "pre:right true:left 6016/11700\n",
      "tensor([ 0.3710, -0.3632])\n",
      "pre:left true:left 6017/11700\n",
      "tensor([ 0.3748, -0.4160])\n",
      "pre:left true:left 6018/11700\n",
      "tensor([ 0.0716, -0.1448])\n",
      "pre:left true:left 6019/11700\n",
      "tensor([ 1.1695, -1.0950])\n",
      "pre:left true:left 6020/11700\n",
      "tensor([ 1.0731, -0.9990])\n",
      "pre:left true:left 6021/11700\n",
      "tensor([ 0.1602, -0.1223])\n",
      "pre:left true:left 6022/11700\n",
      "tensor([ 0.3414, -0.4096])\n",
      "pre:left true:left 6023/11700\n",
      "tensor([ 0.1774, -0.2590])\n",
      "pre:left true:left 6024/11700\n",
      "tensor([ 0.7397, -0.7625])\n",
      "pre:left true:left 6025/11700\n",
      "tensor([-0.1124,  0.1056])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左685_0_841_20200412_115348326_0.jpg\n",
      "pre:right true:left 6026/11700\n",
      "tensor([ 0.4417, -0.4261])\n",
      "pre:left true:left 6027/11700\n",
      "tensor([ 1.5361, -1.5601])\n",
      "pre:left true:left 6028/11700\n",
      "tensor([ 0.1621, -0.2350])\n",
      "pre:left true:left 6029/11700\n",
      "tensor([ 0.4939, -0.5320])\n",
      "pre:left true:left 6030/11700\n",
      "tensor([ 0.1832, -0.1467])\n",
      "pre:left true:left 6031/11700\n",
      "tensor([ 0.5638, -0.5249])\n",
      "pre:left true:left 6032/11700\n",
      "tensor([ 0.4230, -0.3596])\n",
      "pre:left true:left 6033/11700\n",
      "tensor([ 0.3300, -0.3416])\n",
      "pre:left true:left 6034/11700\n",
      "tensor([ 0.1869, -0.1953])\n",
      "pre:left true:left 6035/11700\n",
      "tensor([ 0.3007, -0.2405])\n",
      "pre:left true:left 6036/11700\n",
      "tensor([ 0.5644, -0.5872])\n",
      "pre:left true:left 6037/11700\n",
      "tensor([ 0.6803, -0.6681])\n",
      "pre:left true:left 6038/11700\n",
      "tensor([ 0.2505, -0.2798])\n",
      "pre:left true:left 6039/11700\n",
      "tensor([ 0.5977, -0.5361])\n",
      "pre:left true:left 6040/11700\n",
      "tensor([-0.3632,  0.4030])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左995_0_1151_20200412_120032330_1.jpg\n",
      "pre:right true:left 6041/11700\n",
      "tensor([0.0040, 0.0153])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左617_0_773_20200412_115219705.jpg\n",
      "pre:right true:left 6042/11700\n",
      "tensor([ 0.6218, -0.5239])\n",
      "pre:left true:left 6043/11700\n",
      "tensor([ 0.1077, -0.0644])\n",
      "pre:left true:left 6044/11700\n",
      "tensor([-0.6008,  0.7339])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左661_0_661_20200412_111231607_3.jpg\n",
      "pre:right true:left 6045/11700\n",
      "tensor([ 0.6239, -0.5557])\n",
      "pre:left true:left 6046/11700\n",
      "tensor([ 0.3735, -0.4116])\n",
      "pre:left true:left 6047/11700\n",
      "tensor([ 0.4176, -0.5071])\n",
      "pre:left true:left 6048/11700\n",
      "tensor([ 1.3588, -1.4334])\n",
      "pre:left true:left 6049/11700\n",
      "tensor([ 0.8425, -0.9097])\n",
      "pre:left true:left 6050/11700\n",
      "tensor([ 0.3362, -0.4042])\n",
      "pre:left true:left 6051/11700\n",
      "tensor([ 0.0553, -0.0571])\n",
      "pre:left true:left 6052/11700\n",
      "tensor([ 0.9630, -0.8957])\n",
      "pre:left true:left 6053/11700\n",
      "tensor([-0.1265,  0.1048])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左981_0_981_20200412_111959966_5.jpg\n",
      "pre:right true:left 6054/11700\n",
      "tensor([ 0.2821, -0.3118])\n",
      "pre:left true:left 6055/11700\n",
      "tensor([ 0.5187, -0.5102])\n",
      "pre:left true:left 6056/11700\n",
      "tensor([ 0.3743, -0.2714])\n",
      "pre:left true:left 6057/11700\n",
      "tensor([ 0.9643, -1.0110])\n",
      "pre:left true:left 6058/11700\n",
      "tensor([ 0.5347, -0.5122])\n",
      "pre:left true:left 6059/11700\n",
      "tensor([ 0.6310, -0.6827])\n",
      "pre:left true:left 6060/11700\n",
      "tensor([ 0.6262, -0.6463])\n",
      "pre:left true:left 6061/11700\n",
      "tensor([ 0.9090, -0.9827])\n",
      "pre:left true:left 6062/11700\n",
      "tensor([ 1.0094, -1.1103])\n",
      "pre:left true:left 6063/11700\n",
      "tensor([ 0.0701, -0.0349])\n",
      "pre:left true:left 6064/11700\n",
      "tensor([-0.1176,  0.1371])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左706_0_706_20200412_111335772_0.jpg\n",
      "pre:right true:left 6065/11700\n",
      "tensor([ 0.3258, -0.2689])\n",
      "pre:left true:left 6066/11700\n",
      "tensor([ 0.5542, -0.5019])\n",
      "pre:left true:left 6067/11700\n",
      "tensor([ 0.7726, -0.7246])\n",
      "pre:left true:left 6068/11700\n",
      "tensor([ 0.7841, -0.7973])\n",
      "pre:left true:left 6069/11700\n",
      "tensor([ 0.6498, -0.7878])\n",
      "pre:left true:left 6070/11700\n",
      "tensor([ 0.4951, -0.5433])\n",
      "pre:left true:left 6071/11700\n",
      "tensor([ 0.7257, -0.5591])\n",
      "pre:left true:left 6072/11700\n",
      "tensor([-0.2695,  0.2574])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1133_0_1289_20200412_120332193_1.jpg\n",
      "pre:right true:left 6073/11700\n",
      "tensor([ 0.8106, -0.7491])\n",
      "pre:left true:left 6074/11700\n",
      "tensor([ 0.6804, -0.6643])\n",
      "pre:left true:left 6075/11700\n",
      "tensor([ 0.3841, -0.4405])\n",
      "pre:left true:left 6076/11700\n",
      "tensor([ 0.0298, -0.0836])\n",
      "pre:left true:left 6077/11700\n",
      "tensor([ 0.5732, -0.5660])\n",
      "pre:left true:left 6078/11700\n",
      "tensor([ 0.2504, -0.1927])\n",
      "pre:left true:left 6079/11700\n",
      "tensor([0.0832, 0.0211])\n",
      "pre:left true:left 6080/11700\n",
      "tensor([ 1.0198, -1.0406])\n",
      "pre:left true:left 6081/11700\n",
      "tensor([ 0.4867, -0.5331])\n",
      "pre:left true:left 6082/11700\n",
      "tensor([ 0.0949, -0.1201])\n",
      "pre:left true:left 6083/11700\n",
      "tensor([ 1.3635, -1.2742])\n",
      "pre:left true:left 6084/11700\n",
      "tensor([ 0.1403, -0.0863])\n",
      "pre:left true:left 6085/11700\n",
      "tensor([ 0.4878, -0.4478])\n",
      "pre:left true:left 6086/11700\n",
      "tensor([ 0.4306, -0.3873])\n",
      "pre:left true:left 6087/11700\n",
      "tensor([ 0.5872, -0.6008])\n",
      "pre:left true:left 6088/11700\n",
      "tensor([ 0.1073, -0.0512])\n",
      "pre:left true:left 6089/11700\n",
      "tensor([ 0.3780, -0.3631])\n",
      "pre:left true:left 6090/11700\n",
      "tensor([-0.1652,  0.1007])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左74_0_230_20200412_114032091_10.jpg\n",
      "pre:right true:left 6091/11700\n",
      "tensor([ 0.9749, -0.9863])\n",
      "pre:left true:left 6092/11700\n",
      "tensor([ 0.6506, -0.6225])\n",
      "pre:left true:left 6093/11700\n",
      "tensor([ 0.9768, -0.9636])\n",
      "pre:left true:left 6094/11700\n",
      "tensor([ 1.0033, -1.0098])\n",
      "pre:left true:left 6095/11700\n",
      "tensor([ 0.5287, -0.5587])\n",
      "pre:left true:left 6096/11700\n",
      "tensor([ 0.6684, -0.6619])\n",
      "pre:left true:left 6097/11700\n",
      "tensor([ 0.6052, -0.6307])\n",
      "pre:left true:left 6098/11700\n",
      "tensor([ 0.3505, -0.3935])\n",
      "pre:left true:left 6099/11700\n",
      "tensor([-0.0626,  0.0762])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1174_0_1174_20200412_112411433_0.jpg\n",
      "pre:right true:left 6100/11700\n",
      "tensor([ 0.9480, -0.9344])\n",
      "pre:left true:left 6101/11700\n",
      "tensor([ 0.3637, -0.2838])\n",
      "pre:left true:left 6102/11700\n",
      "tensor([ 0.2419, -0.1660])\n",
      "pre:left true:left 6103/11700\n",
      "tensor([ 0.1977, -0.1421])\n",
      "pre:left true:left 6104/11700\n",
      "tensor([ 0.7079, -0.7419])\n",
      "pre:left true:left 6105/11700\n",
      "tensor([ 0.9041, -0.9492])\n",
      "pre:left true:left 6106/11700\n",
      "tensor([ 0.6711, -0.6778])\n",
      "pre:left true:left 6107/11700\n",
      "tensor([ 0.4352, -0.3630])\n",
      "pre:left true:left 6108/11700\n",
      "tensor([ 0.2253, -0.1372])\n",
      "pre:left true:left 6109/11700\n",
      "tensor([ 0.9718, -0.9678])\n",
      "pre:left true:left 6110/11700\n",
      "tensor([-0.1588,  0.0477])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左584_0_740_20200412_115136688_1.jpg\n",
      "pre:right true:left 6111/11700\n",
      "tensor([ 0.5777, -0.5241])\n",
      "pre:left true:left 6112/11700\n",
      "tensor([ 0.3534, -0.4340])\n",
      "pre:left true:left 6113/11700\n",
      "tensor([ 0.5019, -0.4647])\n",
      "pre:left true:left 6114/11700\n",
      "tensor([ 1.1273, -1.2136])\n",
      "pre:left true:left 6115/11700\n",
      "tensor([ 1.1698, -1.1005])\n",
      "pre:left true:left 6116/11700\n",
      "tensor([ 0.3394, -0.2626])\n",
      "pre:left true:left 6117/11700\n",
      "tensor([-0.0674,  0.0269])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左456_0_612_20200412_114849884_7.jpg\n",
      "pre:right true:left 6118/11700\n",
      "tensor([ 0.6000, -0.5435])\n",
      "pre:left true:left 6119/11700\n",
      "tensor([ 0.3992, -0.4670])\n",
      "pre:left true:left 6120/11700\n",
      "tensor([ 0.1343, -0.0383])\n",
      "pre:left true:left 6121/11700\n",
      "tensor([-0.2694,  0.2472])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左657_0_813_20200412_115311824_3.jpg\n",
      "pre:right true:left 6122/11700\n",
      "tensor([ 0.6222, -0.6143])\n",
      "pre:left true:left 6123/11700\n",
      "tensor([ 0.6564, -0.6405])\n",
      "pre:left true:left 6124/11700\n",
      "tensor([ 0.9497, -1.0583])\n",
      "pre:left true:left 6125/11700\n",
      "tensor([ 1.1535, -1.1910])\n",
      "pre:left true:left 6126/11700\n",
      "tensor([ 0.8473, -0.8352])\n",
      "pre:left true:left 6127/11700\n",
      "tensor([ 0.7844, -0.7588])\n",
      "pre:left true:left 6128/11700\n",
      "tensor([ 0.0454, -0.0893])\n",
      "pre:left true:left 6129/11700\n",
      "tensor([ 0.3036, -0.2904])\n",
      "pre:left true:left 6130/11700\n",
      "tensor([ 0.9096, -0.9131])\n",
      "pre:left true:left 6131/11700\n",
      "tensor([ 1.1252, -1.2067])\n",
      "pre:left true:left 6132/11700\n",
      "tensor([ 0.4881, -0.4662])\n",
      "pre:left true:left 6133/11700\n",
      "tensor([-0.1279,  0.1008])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左565_0_721_20200412_115111921_0.jpg\n",
      "pre:right true:left 6134/11700\n",
      "tensor([ 0.0792, -0.0237])\n",
      "pre:left true:left 6135/11700\n",
      "tensor([ 0.9123, -0.8850])\n",
      "pre:left true:left 6136/11700\n",
      "tensor([ 0.8246, -0.8800])\n",
      "pre:left true:left 6137/11700\n",
      "tensor([ 1.2947, -1.1107])\n",
      "pre:left true:left 6138/11700\n",
      "tensor([ 1.5373, -1.6392])\n",
      "pre:left true:left 6139/11700\n",
      "tensor([ 0.6367, -0.6137])\n",
      "pre:left true:left 6140/11700\n",
      "tensor([ 0.6499, -0.7043])\n",
      "pre:left true:left 6141/11700\n",
      "tensor([-0.3207,  0.2634])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左811_0_811_20200412_111605535_4.jpg\n",
      "pre:right true:left 6142/11700\n",
      "tensor([ 1.0485, -1.1040])\n",
      "pre:left true:left 6143/11700\n",
      "tensor([ 1.5902, -1.5964])\n",
      "pre:left true:left 6144/11700\n",
      "tensor([ 0.4244, -0.3738])\n",
      "pre:left true:left 6145/11700\n",
      "tensor([ 0.9228, -0.9154])\n",
      "pre:left true:left 6146/11700\n",
      "tensor([-0.3625,  0.3385])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左528_0_528_20200412_110921885_10.jpg\n",
      "pre:right true:left 6147/11700\n",
      "tensor([ 0.9440, -1.0002])\n",
      "pre:left true:left 6148/11700\n",
      "tensor([-0.3090,  0.3606])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左558_0_714_20200412_115102802_3.jpg\n",
      "pre:right true:left 6149/11700\n",
      "tensor([-0.0175,  0.1521])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左156_0_156_20200412_110031305_1.jpg\n",
      "pre:right true:left 6150/11700\n",
      "tensor([ 0.3805, -0.4600])\n",
      "pre:left true:left 6151/11700\n",
      "tensor([-0.0196,  0.0165])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左844_0_1000_20200412_115715544.jpg\n",
      "pre:right true:left 6152/11700\n",
      "tensor([-0.0116,  0.0767])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左591_0_591_20200412_111051747.jpg\n",
      "pre:right true:left 6153/11700\n",
      "tensor([ 0.9501, -0.8072])\n",
      "pre:left true:left 6154/11700\n",
      "tensor([ 0.7252, -0.7244])\n",
      "pre:left true:left 6155/11700\n",
      "tensor([ 0.3378, -0.3054])\n",
      "pre:left true:left 6156/11700\n",
      "tensor([-0.0451, -0.0099])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左521_0_677_20200412_115014578_9.jpg\n",
      "pre:right true:left 6157/11700\n",
      "tensor([ 1.1161, -1.1515])\n",
      "pre:left true:left 6158/11700\n",
      "tensor([ 0.0135, -0.0479])\n",
      "pre:left true:left 6159/11700\n",
      "tensor([ 0.8596, -0.8638])\n",
      "pre:left true:left 6160/11700\n",
      "tensor([ 0.8966, -0.8703])\n",
      "pre:left true:left 6161/11700\n",
      "tensor([ 0.5034, -0.4424])\n",
      "pre:left true:left 6162/11700\n",
      "tensor([ 0.6651, -0.7084])\n",
      "pre:left true:left 6163/11700\n",
      "tensor([ 0.8107, -0.8301])\n",
      "pre:left true:left 6164/11700\n",
      "tensor([ 0.4438, -0.3003])\n",
      "pre:left true:left 6165/11700\n",
      "tensor([ 0.7952, -0.7734])\n",
      "pre:left true:left 6166/11700\n",
      "tensor([ 1.7262, -1.8102])\n",
      "pre:left true:left 6167/11700\n",
      "tensor([ 0.8566, -0.7508])\n",
      "pre:left true:left 6168/11700\n",
      "tensor([ 0.8473, -0.9696])\n",
      "pre:left true:left 6169/11700\n",
      "tensor([ 0.5107, -0.4148])\n",
      "pre:left true:left 6170/11700\n",
      "tensor([ 0.9808, -0.9363])\n",
      "pre:left true:left 6171/11700\n",
      "tensor([-0.2527,  0.3367])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左479_0_635_20200412_114919868_3.jpg\n",
      "pre:right true:left 6172/11700\n",
      "tensor([ 0.9309, -0.8384])\n",
      "pre:left true:left 6173/11700\n",
      "tensor([ 0.6993, -0.6223])\n",
      "pre:left true:left 6174/11700\n",
      "tensor([ 1.5809, -1.4732])\n",
      "pre:left true:left 6175/11700\n",
      "tensor([ 0.4274, -0.4241])\n",
      "pre:left true:left 6176/11700\n",
      "tensor([ 0.8732, -0.9373])\n",
      "pre:left true:left 6177/11700\n",
      "tensor([-0.0497,  0.0355])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左300_0_456_20200412_114526600_4.jpg\n",
      "pre:right true:left 6178/11700\n",
      "tensor([ 0.6817, -0.7909])\n",
      "pre:left true:left 6179/11700\n",
      "tensor([0.0590, 0.0248])\n",
      "pre:left true:left 6180/11700\n",
      "tensor([ 0.2521, -0.2894])\n",
      "pre:left true:left 6181/11700\n",
      "tensor([-0.3338,  0.3064])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左721_0_877_20200412_115435244_10.jpg\n",
      "pre:right true:left 6182/11700\n",
      "tensor([-0.5341,  0.5388])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左445_0_601_20200412_114835539_6.jpg\n",
      "pre:right true:left 6183/11700\n",
      "tensor([-0.1301,  0.0913])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左989_0_989_20200412_112010371_4.jpg\n",
      "pre:right true:left 6184/11700\n",
      "tensor([ 0.5860, -0.5222])\n",
      "pre:left true:left 6185/11700\n",
      "tensor([ 0.1859, -0.1890])\n",
      "pre:left true:left 6186/11700\n",
      "tensor([-0.1428,  0.1154])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左331_0_331_20200412_105612246_1.jpg\n",
      "pre:right true:left 6187/11700\n",
      "tensor([ 0.1906, -0.2323])\n",
      "pre:left true:left 6188/11700\n",
      "tensor([ 0.4114, -0.3903])\n",
      "pre:left true:left 6189/11700\n",
      "tensor([ 0.5836, -0.6082])\n",
      "pre:left true:left 6190/11700\n",
      "tensor([ 0.8873, -0.8653])\n",
      "pre:left true:left 6191/11700\n",
      "tensor([ 0.2686, -0.3473])\n",
      "pre:left true:left 6192/11700\n",
      "tensor([-0.2033,  0.3053])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左917_0_917_20200412_111836594_9.jpg\n",
      "pre:right true:left 6193/11700\n",
      "tensor([ 1.3014, -1.3347])\n",
      "pre:left true:left 6194/11700\n",
      "tensor([ 0.4000, -0.3564])\n",
      "pre:left true:left 6195/11700\n",
      "tensor([ 0.7678, -0.7210])\n",
      "pre:left true:left 6196/11700\n",
      "tensor([ 0.4964, -0.4577])\n",
      "pre:left true:left 6197/11700\n",
      "tensor([ 0.9929, -0.9798])\n",
      "pre:left true:left 6198/11700\n",
      "tensor([ 1.3675, -1.2729])\n",
      "pre:left true:left 6199/11700\n",
      "tensor([ 0.8674, -0.9212])\n",
      "pre:left true:left 6200/11700\n",
      "tensor([0.0908, 0.0155])\n",
      "pre:left true:left 6201/11700\n",
      "tensor([ 0.8806, -0.8432])\n",
      "pre:left true:left 6202/11700\n",
      "tensor([ 0.3478, -0.3768])\n",
      "pre:left true:left 6203/11700\n",
      "tensor([ 0.5323, -0.5431])\n",
      "pre:left true:left 6204/11700\n",
      "tensor([ 0.5695, -0.5262])\n",
      "pre:left true:left 6205/11700\n",
      "tensor([ 0.6442, -0.7015])\n",
      "pre:left true:left 6206/11700\n",
      "tensor([ 0.5265, -0.4665])\n",
      "pre:left true:left 6207/11700\n",
      "tensor([ 0.8263, -0.6880])\n",
      "pre:left true:left 6208/11700\n",
      "tensor([ 0.3224, -0.1447])\n",
      "pre:left true:left 6209/11700\n",
      "tensor([0.0304, 0.0043])\n",
      "pre:left true:left 6210/11700\n",
      "tensor([ 0.8007, -0.7577])\n",
      "pre:left true:left 6211/11700\n",
      "tensor([ 0.1173, -0.0315])\n",
      "pre:left true:left 6212/11700\n",
      "tensor([ 0.1116, -0.1186])\n",
      "pre:left true:left 6213/11700\n",
      "tensor([ 0.6349, -0.5457])\n",
      "pre:left true:left 6214/11700\n",
      "tensor([ 0.9158, -1.0355])\n",
      "pre:left true:left 6215/11700\n",
      "tensor([ 1.1988, -1.1661])\n",
      "pre:left true:left 6216/11700\n",
      "tensor([-0.1099,  0.2246])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左208_0_208_20200412_110145465_9.jpg\n",
      "pre:right true:left 6217/11700\n",
      "tensor([ 0.5704, -0.7199])\n",
      "pre:left true:left 6218/11700\n",
      "tensor([ 0.5385, -0.5745])\n",
      "pre:left true:left 6219/11700\n",
      "tensor([ 0.3080, -0.2569])\n",
      "pre:left true:left 6220/11700\n",
      "tensor([ 0.6058, -0.5383])\n",
      "pre:left true:left 6221/11700\n",
      "tensor([0.0657, 0.0133])\n",
      "pre:left true:left 6222/11700\n",
      "tensor([ 0.9014, -0.8072])\n",
      "pre:left true:left 6223/11700\n",
      "tensor([ 0.2278, -0.2461])\n",
      "pre:left true:left 6224/11700\n",
      "tensor([ 0.7132, -0.7410])\n",
      "pre:left true:left 6225/11700\n",
      "tensor([ 0.3863, -0.2711])\n",
      "pre:left true:left 6226/11700\n",
      "tensor([ 1.0493, -1.0450])\n",
      "pre:left true:left 6227/11700\n",
      "tensor([ 0.2236, -0.1291])\n",
      "pre:left true:left 6228/11700\n",
      "tensor([ 1.0752, -1.1480])\n",
      "pre:left true:left 6229/11700\n",
      "tensor([ 0.1880, -0.0605])\n",
      "pre:left true:left 6230/11700\n",
      "tensor([ 0.1754, -0.0607])\n",
      "pre:left true:left 6231/11700\n",
      "tensor([-0.1736,  0.2034])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左68_0_68_20200412_105825772_9.jpg\n",
      "pre:right true:left 6232/11700\n",
      "tensor([ 0.7153, -0.6761])\n",
      "pre:left true:left 6233/11700\n",
      "tensor([ 1.0206, -1.0664])\n",
      "pre:left true:left 6234/11700\n",
      "tensor([-1.1000,  1.1728])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左778_0_934_20200412_115549533_5.jpg\n",
      "pre:right true:left 6235/11700\n",
      "tensor([ 0.1021, -0.1078])\n",
      "pre:left true:left 6236/11700\n",
      "tensor([ 0.5960, -0.5623])\n",
      "pre:left true:left 6237/11700\n",
      "tensor([ 0.7064, -0.6748])\n",
      "pre:left true:left 6238/11700\n",
      "tensor([ 0.6645, -0.6268])\n",
      "pre:left true:left 6239/11700\n",
      "tensor([ 0.3701, -0.2306])\n",
      "pre:left true:left 6240/11700\n",
      "tensor([ 0.5443, -0.5046])\n",
      "pre:left true:left 6241/11700\n",
      "tensor([-0.1990,  0.2138])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左572_0_728_20200412_115121052_5.jpg\n",
      "pre:right true:left 6242/11700\n",
      "tensor([-0.0204,  0.1833])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1538_0_1694_20200412_121220028_1.jpg\n",
      "pre:right true:left 6243/11700\n",
      "tensor([ 0.2206, -0.3123])\n",
      "pre:left true:left 6244/11700\n",
      "tensor([ 0.0981, -0.1557])\n",
      "pre:left true:left 6245/11700\n",
      "tensor([ 0.5005, -0.4650])\n",
      "pre:left true:left 6246/11700\n",
      "tensor([ 0.5120, -0.5140])\n",
      "pre:left true:left 6247/11700\n",
      "tensor([ 0.3822, -0.4340])\n",
      "pre:left true:left 6248/11700\n",
      "tensor([ 0.4827, -0.4733])\n",
      "pre:left true:left 6249/11700\n",
      "tensor([ 0.6820, -0.6449])\n",
      "pre:left true:left 6250/11700\n",
      "tensor([ 0.8007, -0.8354])\n",
      "pre:left true:left 6251/11700\n",
      "tensor([ 0.3146, -0.2680])\n",
      "pre:left true:left 6252/11700\n",
      "tensor([-0.1957,  0.2306])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左357_0_357_20200412_110517970.jpg\n",
      "pre:right true:left 6253/11700\n",
      "tensor([ 1.2511, -1.0786])\n",
      "pre:left true:left 6254/11700\n",
      "tensor([ 0.9245, -0.9683])\n",
      "pre:left true:left 6255/11700\n",
      "tensor([ 0.6232, -0.5840])\n",
      "pre:left true:left 6256/11700\n",
      "tensor([-0.3446,  0.3472])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1512_0_1668_20200412_121146147_10.jpg\n",
      "pre:right true:left 6257/11700\n",
      "tensor([-0.2640,  0.2740])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左751_0_751_20200412_111439952_3.jpg\n",
      "pre:right true:left 6258/11700\n",
      "tensor([ 0.1999, -0.2441])\n",
      "pre:left true:left 6259/11700\n",
      "tensor([ 0.3060, -0.2932])\n",
      "pre:left true:left 6260/11700\n",
      "tensor([ 0.4623, -0.5115])\n",
      "pre:left true:left 6261/11700\n",
      "tensor([-0.2480,  0.3007])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左708_0_708_20200412_111338627_10.jpg\n",
      "pre:right true:left 6262/11700\n",
      "tensor([ 0.3636, -0.3820])\n",
      "pre:left true:left 6263/11700\n",
      "tensor([ 1.1994, -1.2067])\n",
      "pre:left true:left 6264/11700\n",
      "tensor([ 1.3655, -1.4411])\n",
      "pre:left true:left 6265/11700\n",
      "tensor([-0.0082,  0.1024])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1333_0_1333_20200412_112748533_6.jpg\n",
      "pre:right true:left 6266/11700\n",
      "tensor([ 0.6355, -0.6651])\n",
      "pre:left true:left 6267/11700\n",
      "tensor([ 0.2021, -0.1806])\n",
      "pre:left true:left 6268/11700\n",
      "tensor([ 0.7826, -0.7516])\n",
      "pre:left true:left 6269/11700\n",
      "tensor([ 0.5828, -0.5016])\n",
      "pre:left true:left 6270/11700\n",
      "tensor([ 0.4305, -0.4018])\n",
      "pre:left true:left 6271/11700\n",
      "tensor([ 1.2099, -1.2610])\n",
      "pre:left true:left 6272/11700\n",
      "tensor([ 1.3572, -1.4187])\n",
      "pre:left true:left 6273/11700\n",
      "tensor([ 0.7929, -0.8222])\n",
      "pre:left true:left 6274/11700\n",
      "tensor([ 0.3703, -0.1457])\n",
      "pre:left true:left 6275/11700\n",
      "tensor([ 0.8143, -0.7646])\n",
      "pre:left true:left 6276/11700\n",
      "tensor([ 0.6094, -0.5957])\n",
      "pre:left true:left 6277/11700\n",
      "tensor([ 0.0719, -0.0518])\n",
      "pre:left true:left 6278/11700\n",
      "tensor([ 0.3225, -0.1842])\n",
      "pre:left true:left 6279/11700\n",
      "tensor([ 0.3699, -0.5253])\n",
      "pre:left true:left 6280/11700\n",
      "tensor([ 0.5552, -0.4323])\n",
      "pre:left true:left 6281/11700\n",
      "tensor([ 0.5942, -0.5504])\n",
      "pre:left true:left 6282/11700\n",
      "tensor([ 0.6254, -0.5994])\n",
      "pre:left true:left 6283/11700\n",
      "tensor([ 1.0201, -0.9470])\n",
      "pre:left true:left 6284/11700\n",
      "tensor([-0.9049,  0.9112])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1433_0_1589_20200412_121003157_2.jpg\n",
      "pre:right true:left 6285/11700\n",
      "tensor([ 0.4109, -0.3619])\n",
      "pre:left true:left 6286/11700\n",
      "tensor([ 0.6498, -0.6353])\n",
      "pre:left true:left 6287/11700\n",
      "tensor([ 0.8776, -0.8838])\n",
      "pre:left true:left 6288/11700\n",
      "tensor([-0.5477,  0.5309])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左344_0_500_20200412_114623927_4.jpg\n",
      "pre:right true:left 6289/11700\n",
      "tensor([ 0.0906, -0.0770])\n",
      "pre:left true:left 6290/11700\n",
      "tensor([ 0.9739, -0.9516])\n",
      "pre:left true:left 6291/11700\n",
      "tensor([ 0.3151, -0.2915])\n",
      "pre:left true:left 6292/11700\n",
      "tensor([ 0.8755, -0.8569])\n",
      "pre:left true:left 6293/11700\n",
      "tensor([ 0.7551, -0.7145])\n",
      "pre:left true:left 6294/11700\n",
      "tensor([ 0.5339, -0.3996])\n",
      "pre:left true:left 6295/11700\n",
      "tensor([ 1.2119, -1.2284])\n",
      "pre:left true:left 6296/11700\n",
      "tensor([ 0.5000, -0.5338])\n",
      "pre:left true:left 6297/11700\n",
      "tensor([ 0.7894, -0.7443])\n",
      "pre:left true:left 6298/11700\n",
      "tensor([ 1.3502, -1.2714])\n",
      "pre:left true:left 6299/11700\n",
      "tensor([-0.1222,  0.1610])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左843_0_843_20200412_111651177_0.jpg\n",
      "pre:right true:left 6300/11700\n",
      "tensor([ 0.3753, -0.4025])\n",
      "pre:left true:left 6301/11700\n",
      "tensor([0.0339, 0.0081])\n",
      "pre:left true:left 6302/11700\n",
      "tensor([ 0.9205, -0.9670])\n",
      "pre:left true:left 6303/11700\n",
      "tensor([ 0.2686, -0.1978])\n",
      "pre:left true:left 6304/11700\n",
      "tensor([ 0.4077, -0.4295])\n",
      "pre:left true:left 6305/11700\n",
      "tensor([ 0.6744, -0.6053])\n",
      "pre:left true:left 6306/11700\n",
      "tensor([ 0.2551, -0.1193])\n",
      "pre:left true:left 6307/11700\n",
      "tensor([ 1.3201, -1.2178])\n",
      "pre:left true:left 6308/11700\n",
      "tensor([ 0.3587, -0.2763])\n",
      "pre:left true:left 6309/11700\n",
      "tensor([ 0.8110, -0.8178])\n",
      "pre:left true:left 6310/11700\n",
      "tensor([ 0.0632, -0.0879])\n",
      "pre:left true:left 6311/11700\n",
      "tensor([ 0.7515, -0.7743])\n",
      "pre:left true:left 6312/11700\n",
      "tensor([ 1.1627, -1.1312])\n",
      "pre:left true:left 6313/11700\n",
      "tensor([ 1.2708, -1.3743])\n",
      "pre:left true:left 6314/11700\n",
      "tensor([ 0.6701, -0.7022])\n",
      "pre:left true:left 6315/11700\n",
      "tensor([ 0.3120, -0.2713])\n",
      "pre:left true:left 6316/11700\n",
      "tensor([-0.0506,  0.0298])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左983_0_983_20200412_112002564_1.jpg\n",
      "pre:right true:left 6317/11700\n",
      "tensor([ 0.5302, -0.4673])\n",
      "pre:left true:left 6318/11700\n",
      "tensor([ 0.4087, -0.3561])\n",
      "pre:left true:left 6319/11700\n",
      "tensor([ 0.7743, -0.7116])\n",
      "pre:left true:left 6320/11700\n",
      "tensor([ 0.3415, -0.2988])\n",
      "pre:left true:left 6321/11700\n",
      "tensor([ 0.9152, -1.0381])\n",
      "pre:left true:left 6322/11700\n",
      "tensor([ 0.4729, -0.4234])\n",
      "pre:left true:left 6323/11700\n",
      "tensor([ 0.3105, -0.2462])\n",
      "pre:left true:left 6324/11700\n",
      "tensor([ 0.4091, -0.2185])\n",
      "pre:left true:left 6325/11700\n",
      "tensor([ 0.1139, -0.0554])\n",
      "pre:left true:left 6326/11700\n",
      "tensor([ 0.6349, -0.6477])\n",
      "pre:left true:left 6327/11700\n",
      "tensor([ 0.3976, -0.3465])\n",
      "pre:left true:left 6328/11700\n",
      "tensor([ 0.6352, -0.6585])\n",
      "pre:left true:left 6329/11700\n",
      "tensor([ 0.9055, -0.9145])\n",
      "pre:left true:left 6330/11700\n",
      "tensor([ 0.1567, -0.3015])\n",
      "pre:left true:left 6331/11700\n",
      "tensor([ 0.6272, -0.4790])\n",
      "pre:left true:left 6332/11700\n",
      "tensor([ 1.5809, -1.4732])\n",
      "pre:left true:left 6333/11700\n",
      "tensor([ 0.2606, -0.2766])\n",
      "pre:left true:left 6334/11700\n",
      "tensor([0.0565, 0.1191])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左679_0_835_20200412_115340501_7.jpg\n",
      "pre:right true:left 6335/11700\n",
      "tensor([ 0.7410, -0.6479])\n",
      "pre:left true:left 6336/11700\n",
      "tensor([ 1.5077, -1.4822])\n",
      "pre:left true:left 6337/11700\n",
      "tensor([ 0.2812, -0.2378])\n",
      "pre:left true:left 6338/11700\n",
      "tensor([ 0.8917, -0.8966])\n",
      "pre:left true:left 6339/11700\n",
      "tensor([-0.2833,  0.2332])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1122_0_1122_20200412_112303666_4.jpg\n",
      "pre:right true:left 6340/11700\n",
      "tensor([ 0.5690, -0.5336])\n",
      "pre:left true:left 6341/11700\n",
      "tensor([ 0.4449, -0.5152])\n",
      "pre:left true:left 6342/11700\n",
      "tensor([ 0.5932, -0.5993])\n",
      "pre:left true:left 6343/11700\n",
      "tensor([ 0.1151, -0.1604])\n",
      "pre:left true:left 6344/11700\n",
      "tensor([ 0.2767, -0.2022])\n",
      "pre:left true:left 6345/11700\n",
      "tensor([ 0.2628, -0.3041])\n",
      "pre:left true:left 6346/11700\n",
      "tensor([ 0.7238, -0.6058])\n",
      "pre:left true:left 6347/11700\n",
      "tensor([ 0.8619, -0.7524])\n",
      "pre:left true:left 6348/11700\n",
      "tensor([ 0.7257, -0.7073])\n",
      "pre:left true:left 6349/11700\n",
      "tensor([ 0.3826, -0.3780])\n",
      "pre:left true:left 6350/11700\n",
      "tensor([ 0.4412, -0.4616])\n",
      "pre:left true:left 6351/11700\n",
      "tensor([ 1.2351, -1.2215])\n",
      "pre:left true:left 6352/11700\n",
      "tensor([ 0.6126, -0.6238])\n",
      "pre:left true:left 6353/11700\n",
      "tensor([ 0.5697, -0.5548])\n",
      "pre:left true:left 6354/11700\n",
      "tensor([ 0.7578, -0.7218])\n",
      "pre:left true:left 6355/11700\n",
      "tensor([ 0.0305, -0.0215])\n",
      "pre:left true:left 6356/11700\n",
      "tensor([-0.1608,  0.0494])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1196_0_1196_20200412_112440097.jpg\n",
      "pre:right true:left 6357/11700\n",
      "tensor([ 0.6016, -0.4813])\n",
      "pre:left true:left 6358/11700\n",
      "tensor([ 0.7482, -0.8035])\n",
      "pre:left true:left 6359/11700\n",
      "tensor([ 0.5226, -0.4135])\n",
      "pre:left true:left 6360/11700\n",
      "tensor([ 0.4927, -0.4706])\n",
      "pre:left true:left 6361/11700\n",
      "tensor([ 0.5760, -0.5837])\n",
      "pre:left true:left 6362/11700\n",
      "tensor([ 0.6095, -0.5569])\n",
      "pre:left true:left 6363/11700\n",
      "tensor([ 0.5734, -0.5732])\n",
      "pre:left true:left 6364/11700\n",
      "tensor([-0.1252,  0.2226])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1210_0_1366_20200412_120512529_6.jpg\n",
      "pre:right true:left 6365/11700\n",
      "tensor([ 0.5196, -0.5158])\n",
      "pre:left true:left 6366/11700\n",
      "tensor([ 0.3729, -0.3514])\n",
      "pre:left true:left 6367/11700\n",
      "tensor([ 0.4428, -0.4967])\n",
      "pre:left true:left 6368/11700\n",
      "tensor([ 0.5830, -0.6756])\n",
      "pre:left true:left 6369/11700\n",
      "tensor([0.0840, 0.0250])\n",
      "pre:left true:left 6370/11700\n",
      "tensor([ 0.1895, -0.0785])\n",
      "pre:left true:left 6371/11700\n",
      "tensor([ 0.3286, -0.2763])\n",
      "pre:left true:left 6372/11700\n",
      "tensor([-0.1179,  0.0688])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1597_0_1753_20200412_121336950_4.jpg\n",
      "pre:right true:left 6373/11700\n",
      "tensor([ 1.1056, -1.1061])\n",
      "pre:left true:left 6374/11700\n",
      "tensor([ 0.1580, -0.2151])\n",
      "pre:left true:left 6375/11700\n",
      "tensor([ 0.4233, -0.3405])\n",
      "pre:left true:left 6376/11700\n",
      "tensor([ 0.2039, -0.2535])\n",
      "pre:left true:left 6377/11700\n",
      "tensor([ 1.0949, -1.1136])\n",
      "pre:left true:left 6378/11700\n",
      "tensor([ 0.7719, -0.7880])\n",
      "pre:left true:left 6379/11700\n",
      "tensor([ 0.6247, -0.6203])\n",
      "pre:left true:left 6380/11700\n",
      "tensor([ 0.4180, -0.5027])\n",
      "pre:left true:left 6381/11700\n",
      "tensor([ 1.2226, -1.2884])\n",
      "pre:left true:left 6382/11700\n",
      "tensor([ 0.4295, -0.3866])\n",
      "pre:left true:left 6383/11700\n",
      "tensor([ 0.4713, -0.5542])\n",
      "pre:left true:left 6384/11700\n",
      "tensor([ 2.4291, -2.4813])\n",
      "pre:left true:left 6385/11700\n",
      "tensor([ 0.2873, -0.2277])\n",
      "pre:left true:left 6386/11700\n",
      "tensor([-0.1545,  0.3327])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左356_0_512_20200412_114639579_0.jpg\n",
      "pre:right true:left 6387/11700\n",
      "tensor([ 1.3794, -1.3121])\n",
      "pre:left true:left 6388/11700\n",
      "tensor([ 0.8573, -0.8870])\n",
      "pre:left true:left 6389/11700\n",
      "tensor([0.0934, 0.0069])\n",
      "pre:left true:left 6390/11700\n",
      "tensor([ 0.3082, -0.2817])\n",
      "pre:left true:left 6391/11700\n",
      "tensor([ 0.1103, -0.0676])\n",
      "pre:left true:left 6392/11700\n",
      "tensor([ 1.2781, -1.2548])\n",
      "pre:left true:left 6393/11700\n",
      "tensor([ 0.5861, -0.5218])\n",
      "pre:left true:left 6394/11700\n",
      "tensor([ 1.1828, -1.1515])\n",
      "pre:left true:left 6395/11700\n",
      "tensor([ 0.3505, -0.3935])\n",
      "pre:left true:left 6396/11700\n",
      "tensor([-0.5206,  0.7060])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左601_0_757_20200412_115158849_7.jpg\n",
      "pre:right true:left 6397/11700\n",
      "tensor([ 0.5589, -0.5525])\n",
      "pre:left true:left 6398/11700\n",
      "tensor([ 0.3932, -0.4343])\n",
      "pre:left true:left 6399/11700\n",
      "tensor([ 0.1260, -0.1654])\n",
      "pre:left true:left 6400/11700\n",
      "tensor([ 0.5162, -0.5512])\n",
      "pre:left true:left 6401/11700\n",
      "tensor([-0.1304,  0.0840])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左408_0_564_20200412_114747327_1.jpg\n",
      "pre:right true:left 6402/11700\n",
      "tensor([ 0.6339, -0.7015])\n",
      "pre:left true:left 6403/11700\n",
      "tensor([ 0.7219, -0.7036])\n",
      "pre:left true:left 6404/11700\n",
      "tensor([-0.5276,  0.4701])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左921_0_921_20200412_111841785_3.jpg\n",
      "pre:right true:left 6405/11700\n",
      "tensor([ 0.5761, -0.5845])\n",
      "pre:left true:left 6406/11700\n",
      "tensor([ 1.0345, -0.9181])\n",
      "pre:left true:left 6407/11700\n",
      "tensor([ 0.8964, -0.9404])\n",
      "pre:left true:left 6408/11700\n",
      "tensor([ 0.7128, -0.7945])\n",
      "pre:left true:left 6409/11700\n",
      "tensor([ 0.4222, -0.4092])\n",
      "pre:left true:left 6410/11700\n",
      "tensor([ 0.9826, -1.0360])\n",
      "pre:left true:left 6411/11700\n",
      "tensor([ 0.1131, -0.1624])\n",
      "pre:left true:left 6412/11700\n",
      "tensor([ 0.6543, -0.6151])\n",
      "pre:left true:left 6413/11700\n",
      "tensor([-0.1538,  0.2654])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1320_0_1320_20200412_112731601_9.jpg\n",
      "pre:right true:left 6414/11700\n",
      "tensor([ 0.6008, -0.5690])\n",
      "pre:left true:left 6415/11700\n",
      "tensor([ 0.4042, -0.4142])\n",
      "pre:left true:left 6416/11700\n",
      "tensor([ 0.1729, -0.1748])\n",
      "pre:left true:left 6417/11700\n",
      "tensor([-0.0367,  0.0591])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左417_0_417_20200412_110643540_8.jpg\n",
      "pre:right true:left 6418/11700\n",
      "tensor([ 0.5442, -0.5852])\n",
      "pre:left true:left 6419/11700\n",
      "tensor([ 0.2741, -0.1682])\n",
      "pre:left true:left 6420/11700\n",
      "tensor([ 0.8553, -0.8545])\n",
      "pre:left true:left 6421/11700\n",
      "tensor([ 0.8480, -0.9081])\n",
      "pre:left true:left 6422/11700\n",
      "tensor([-0.4930,  0.4913])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左261_0_261_20200412_110301071_6.jpg\n",
      "pre:right true:left 6423/11700\n",
      "tensor([ 1.1868, -1.2291])\n",
      "pre:left true:left 6424/11700\n",
      "tensor([ 0.1904, -0.2210])\n",
      "pre:left true:left 6425/11700\n",
      "tensor([ 0.6387, -0.5049])\n",
      "pre:left true:left 6426/11700\n",
      "tensor([ 0.3785, -0.4231])\n",
      "pre:left true:left 6427/11700\n",
      "tensor([-0.1298,  0.1743])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左387_0_543_20200412_114719968.jpg\n",
      "pre:right true:left 6428/11700\n",
      "tensor([ 0.0644, -0.0305])\n",
      "pre:left true:left 6429/11700\n",
      "tensor([ 0.4672, -0.4259])\n",
      "pre:left true:left 6430/11700\n",
      "tensor([ 0.8567, -0.8933])\n",
      "pre:left true:left 6431/11700\n",
      "tensor([ 0.5107, -0.5613])\n",
      "pre:left true:left 6432/11700\n",
      "tensor([ 0.1640, -0.1984])\n",
      "pre:left true:left 6433/11700\n",
      "tensor([ 0.9023, -0.9538])\n",
      "pre:left true:left 6434/11700\n",
      "tensor([0.0678, 0.0305])\n",
      "pre:left true:left 6435/11700\n",
      "tensor([ 0.6121, -0.6192])\n",
      "pre:left true:left 6436/11700\n",
      "tensor([ 1.2574, -1.1653])\n",
      "pre:left true:left 6437/11700\n",
      "tensor([ 0.4002, -0.3590])\n",
      "pre:left true:left 6438/11700\n",
      "tensor([ 0.1819, -0.2407])\n",
      "pre:left true:left 6439/11700\n",
      "tensor([ 0.9293, -0.8588])\n",
      "pre:left true:left 6440/11700\n",
      "tensor([ 0.7261, -0.8044])\n",
      "pre:left true:left 6441/11700\n",
      "tensor([ 0.7232, -0.7078])\n",
      "pre:left true:left 6442/11700\n",
      "tensor([ 1.0389, -1.0243])\n",
      "pre:left true:left 6443/11700\n",
      "tensor([ 1.0345, -0.9181])\n",
      "pre:left true:left 6444/11700\n",
      "tensor([0.0443, 0.0245])\n",
      "pre:left true:left 6445/11700\n",
      "tensor([ 1.8333, -1.8845])\n",
      "pre:left true:left 6446/11700\n",
      "tensor([ 0.1355, -0.2483])\n",
      "pre:left true:left 6447/11700\n",
      "tensor([ 0.5864, -0.4996])\n",
      "pre:left true:left 6448/11700\n",
      "tensor([ 0.4892, -0.3450])\n",
      "pre:left true:left 6449/11700\n",
      "tensor([ 0.2511, -0.2577])\n",
      "pre:left true:left 6450/11700\n",
      "tensor([ 0.8436, -0.8079])\n",
      "pre:left true:left 6451/11700\n",
      "tensor([ 0.7444, -0.6750])\n",
      "pre:left true:left 6452/11700\n",
      "tensor([ 0.4757, -0.4982])\n",
      "pre:left true:left 6453/11700\n",
      "tensor([ 0.4102, -0.3775])\n",
      "pre:left true:left 6454/11700\n",
      "tensor([ 0.4830, -0.4225])\n",
      "pre:left true:left 6455/11700\n",
      "tensor([ 0.5648, -0.6051])\n",
      "pre:left true:left 6456/11700\n",
      "tensor([ 0.2855, -0.1637])\n",
      "pre:left true:left 6457/11700\n",
      "tensor([ 0.5321, -0.5631])\n",
      "pre:left true:left 6458/11700\n",
      "tensor([ 0.5006, -0.4900])\n",
      "pre:left true:left 6459/11700\n",
      "tensor([ 0.4092, -0.4754])\n",
      "pre:left true:left 6460/11700\n",
      "tensor([ 0.3932, -0.3737])\n",
      "pre:left true:left 6461/11700\n",
      "tensor([ 0.5397, -0.4928])\n",
      "pre:left true:left 6462/11700\n",
      "tensor([ 1.3251, -1.3634])\n",
      "pre:left true:left 6463/11700\n",
      "tensor([ 0.8223, -0.8647])\n",
      "pre:left true:left 6464/11700\n",
      "tensor([ 0.7190, -0.6388])\n",
      "pre:left true:left 6465/11700\n",
      "tensor([ 1.4631, -1.5545])\n",
      "pre:left true:left 6466/11700\n",
      "tensor([ 0.4195, -0.4640])\n",
      "pre:left true:left 6467/11700\n",
      "tensor([-0.1088, -0.0022])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1362_0_1518_20200412_120830617_4.jpg\n",
      "pre:right true:left 6468/11700\n",
      "tensor([ 0.5783, -0.6335])\n",
      "pre:left true:left 6469/11700\n",
      "tensor([ 0.4675, -0.3892])\n",
      "pre:left true:left 6470/11700\n",
      "tensor([ 0.4674, -0.5218])\n",
      "pre:left true:left 6471/11700\n",
      "tensor([ 0.8550, -0.8094])\n",
      "pre:left true:left 6472/11700\n",
      "tensor([ 0.8853, -0.8496])\n",
      "pre:left true:left 6473/11700\n",
      "tensor([ 0.4421, -0.4188])\n",
      "pre:left true:left 6474/11700\n",
      "tensor([ 0.0719, -0.0666])\n",
      "pre:left true:left 6475/11700\n",
      "tensor([ 1.1124, -1.0611])\n",
      "pre:left true:left 6476/11700\n",
      "tensor([ 1.0704, -1.0316])\n",
      "pre:left true:left 6477/11700\n",
      "tensor([ 0.4634, -0.5406])\n",
      "pre:left true:left 6478/11700\n",
      "tensor([ 1.2539, -1.1568])\n",
      "pre:left true:left 6479/11700\n",
      "tensor([ 0.1364, -0.1471])\n",
      "pre:left true:left 6480/11700\n",
      "tensor([ 0.0228, -0.0891])\n",
      "pre:left true:left 6481/11700\n",
      "tensor([ 1.5043, -1.4996])\n",
      "pre:left true:left 6482/11700\n",
      "tensor([-0.1971,  0.1780])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/右841_0_997_20200412_115711643_2.jpg\n",
      "pre:right true:left 6483/11700\n",
      "tensor([ 0.5571, -0.4387])\n",
      "pre:left true:left 6484/11700\n",
      "tensor([ 1.1371, -1.0772])\n",
      "pre:left true:left 6485/11700\n",
      "tensor([ 0.8652, -0.9116])\n",
      "pre:left true:left 6486/11700\n",
      "tensor([ 0.4939, -0.5608])\n",
      "pre:left true:left 6487/11700\n",
      "tensor([ 0.7097, -0.6264])\n",
      "pre:left true:left 6488/11700\n",
      "tensor([-0.0137, -0.0303])\n",
      "pre:left true:left 6489/11700\n",
      "tensor([ 0.3183, -0.3004])\n",
      "pre:left true:left 6490/11700\n",
      "tensor([0.0446, 0.0248])\n",
      "pre:left true:left 6491/11700\n",
      "tensor([ 0.4087, -0.4694])\n",
      "pre:left true:left 6492/11700\n",
      "tensor([-0.7080,  0.6926])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左371_0_371_20200412_110537948_5.jpg\n",
      "pre:right true:left 6493/11700\n",
      "tensor([ 1.0928, -1.0666])\n",
      "pre:left true:left 6494/11700\n",
      "tensor([ 1.7132, -1.6829])\n",
      "pre:left true:left 6495/11700\n",
      "tensor([ 0.4550, -0.4513])\n",
      "pre:left true:left 6496/11700\n",
      "tensor([0.1059, 0.0609])\n",
      "pre:left true:left 6497/11700\n",
      "tensor([ 0.3985, -0.4192])\n",
      "pre:left true:left 6498/11700\n",
      "tensor([ 0.7454, -0.7838])\n",
      "pre:left true:left 6499/11700\n",
      "tensor([ 0.0031, -0.0176])\n",
      "pre:left true:left 6500/11700\n",
      "tensor([ 0.9006, -0.9687])\n",
      "pre:left true:left 6501/11700\n",
      "tensor([ 1.3111, -1.2729])\n",
      "pre:left true:left 6502/11700\n",
      "tensor([ 0.1746, -0.2216])\n",
      "pre:left true:left 6503/11700\n",
      "tensor([ 0.2909, -0.2230])\n",
      "pre:left true:left 6504/11700\n",
      "tensor([ 0.5536, -0.4741])\n",
      "pre:left true:left 6505/11700\n",
      "tensor([ 0.5206, -0.4727])\n",
      "pre:left true:left 6506/11700\n",
      "tensor([ 0.2972, -0.3036])\n",
      "pre:left true:left 6507/11700\n",
      "tensor([ 0.1241, -0.1065])\n",
      "pre:left true:left 6508/11700\n",
      "tensor([ 0.4668, -0.4347])\n",
      "pre:left true:left 6509/11700\n",
      "tensor([ 0.4156, -0.3970])\n",
      "pre:left true:left 6510/11700\n",
      "tensor([ 0.6140, -0.6241])\n",
      "pre:left true:left 6511/11700\n",
      "tensor([ 0.5033, -0.5607])\n",
      "pre:left true:left 6512/11700\n",
      "tensor([-0.0513,  0.1517])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左677_0_833_20200412_115337892_4.jpg\n",
      "pre:right true:left 6513/11700\n",
      "tensor([ 0.6226, -0.7210])\n",
      "pre:left true:left 6514/11700\n",
      "tensor([ 0.4214, -0.4162])\n",
      "pre:left true:left 6515/11700\n",
      "tensor([ 0.6401, -0.6454])\n",
      "pre:left true:left 6516/11700\n",
      "tensor([ 0.1679, -0.2488])\n",
      "pre:left true:left 6517/11700\n",
      "tensor([-0.6186,  0.6417])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1059_0_1059_20200412_112141573_7.jpg\n",
      "pre:right true:left 6518/11700\n",
      "tensor([ 0.5254, -0.4240])\n",
      "pre:left true:left 6519/11700\n",
      "tensor([ 0.1634, -0.1557])\n",
      "pre:left true:left 6520/11700\n",
      "tensor([ 0.3323, -0.2955])\n",
      "pre:left true:left 6521/11700\n",
      "tensor([ 0.5414, -0.4628])\n",
      "pre:left true:left 6522/11700\n",
      "tensor([ 0.4428, -0.3557])\n",
      "pre:left true:left 6523/11700\n",
      "tensor([ 0.2543, -0.1604])\n",
      "pre:left true:left 6524/11700\n",
      "tensor([ 0.8460, -0.8860])\n",
      "pre:left true:left 6525/11700\n",
      "tensor([ 1.0647, -0.9722])\n",
      "pre:left true:left 6526/11700\n",
      "tensor([ 0.2045, -0.2632])\n",
      "pre:left true:left 6527/11700\n",
      "tensor([ 1.9498, -1.9709])\n",
      "pre:left true:left 6528/11700\n",
      "tensor([ 0.5799, -0.4882])\n",
      "pre:left true:left 6529/11700\n",
      "tensor([ 1.5505, -1.5842])\n",
      "pre:left true:left 6530/11700\n",
      "tensor([ 0.8467, -0.9624])\n",
      "pre:left true:left 6531/11700\n",
      "tensor([ 0.9879, -0.9239])\n",
      "pre:left true:left 6532/11700\n",
      "tensor([ 0.3334, -0.4371])\n",
      "pre:left true:left 6533/11700\n",
      "tensor([ 0.2228, -0.2857])\n",
      "pre:left true:left 6534/11700\n",
      "tensor([ 0.8281, -0.7661])\n",
      "pre:left true:left 6535/11700\n",
      "tensor([ 0.1804, -0.0402])\n",
      "pre:left true:left 6536/11700\n",
      "tensor([ 0.4455, -0.4284])\n",
      "pre:left true:left 6537/11700\n",
      "tensor([0.1502, 0.0137])\n",
      "pre:left true:left 6538/11700\n",
      "tensor([ 0.1858, -0.2424])\n",
      "pre:left true:left 6539/11700\n",
      "tensor([ 0.9958, -0.9022])\n",
      "pre:left true:left 6540/11700\n",
      "tensor([ 0.4228, -0.3733])\n",
      "pre:left true:left 6541/11700\n",
      "tensor([ 1.4615, -1.4019])\n",
      "pre:left true:left 6542/11700\n",
      "tensor([ 0.8366, -0.7582])\n",
      "pre:left true:left 6543/11700\n",
      "tensor([ 0.3972, -0.4104])\n",
      "pre:left true:left 6544/11700\n",
      "tensor([-0.0406,  0.0143])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左769_0_925_20200412_115537807_8.jpg\n",
      "pre:right true:left 6545/11700\n",
      "tensor([ 0.2688, -0.2392])\n",
      "pre:left true:left 6546/11700\n",
      "tensor([ 1.0262, -0.9778])\n",
      "pre:left true:left 6547/11700\n",
      "tensor([ 0.2601, -0.2067])\n",
      "pre:left true:left 6548/11700\n",
      "tensor([-0.6066,  0.7140])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左833_0_989_20200412_115701218_9.jpg\n",
      "pre:right true:left 6549/11700\n",
      "tensor([ 1.3558, -1.2655])\n",
      "pre:left true:left 6550/11700\n",
      "tensor([ 0.4957, -0.4228])\n",
      "pre:left true:left 6551/11700\n",
      "tensor([ 0.3159, -0.3556])\n",
      "pre:left true:left 6552/11700\n",
      "tensor([ 0.7537, -0.8176])\n",
      "pre:left true:left 6553/11700\n",
      "tensor([ 0.3428, -0.3833])\n",
      "pre:left true:left 6554/11700\n",
      "tensor([ 1.4877, -1.4230])\n",
      "pre:left true:left 6555/11700\n",
      "tensor([ 0.5739, -0.5185])\n",
      "pre:left true:left 6556/11700\n",
      "tensor([ 0.2490, -0.2924])\n",
      "pre:left true:left 6557/11700\n",
      "tensor([ 0.2651, -0.3530])\n",
      "pre:left true:left 6558/11700\n",
      "tensor([ 0.2820, -0.2788])\n",
      "pre:left true:left 6559/11700\n",
      "tensor([ 0.8669, -0.8115])\n",
      "pre:left true:left 6560/11700\n",
      "tensor([ 0.2289, -0.1801])\n",
      "pre:left true:left 6561/11700\n",
      "tensor([ 0.9414, -1.0094])\n",
      "pre:left true:left 6562/11700\n",
      "tensor([-0.0144,  0.0697])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左410_0_410_20200412_110633567_10.jpg\n",
      "pre:right true:left 6563/11700\n",
      "tensor([ 0.7226, -0.8109])\n",
      "pre:left true:left 6564/11700\n",
      "tensor([ 0.4733, -0.3979])\n",
      "pre:left true:left 6565/11700\n",
      "tensor([ 0.2006, -0.1627])\n",
      "pre:left true:left 6566/11700\n",
      "tensor([-0.5957,  0.6025])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左162_0_162_20200412_110039865_3.jpg\n",
      "pre:right true:left 6567/11700\n",
      "tensor([ 0.7361, -0.7925])\n",
      "pre:left true:left 6568/11700\n",
      "tensor([ 0.5565, -0.5698])\n",
      "pre:left true:left 6569/11700\n",
      "tensor([ 0.3728, -0.4143])\n",
      "pre:left true:left 6570/11700\n",
      "tensor([ 0.5225, -0.4928])\n",
      "pre:left true:left 6571/11700\n",
      "tensor([ 0.5038, -0.5710])\n",
      "pre:left true:left 6572/11700\n",
      "tensor([ 0.9268, -0.9150])\n",
      "pre:left true:left 6573/11700\n",
      "tensor([-0.1776,  0.1461])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左587_0_743_20200412_115140615_3.jpg\n",
      "pre:right true:left 6574/11700\n",
      "tensor([ 0.8956, -0.9537])\n",
      "pre:left true:left 6575/11700\n",
      "tensor([ 1.1711, -1.0568])\n",
      "pre:left true:left 6576/11700\n",
      "tensor([ 0.5395, -0.4861])\n",
      "pre:left true:left 6577/11700\n",
      "tensor([ 1.6795, -1.7118])\n",
      "pre:left true:left 6578/11700\n",
      "tensor([ 0.3504, -0.3411])\n",
      "pre:left true:left 6579/11700\n",
      "tensor([ 0.2488, -0.2413])\n",
      "pre:left true:left 6580/11700\n",
      "tensor([ 1.0459, -1.0807])\n",
      "pre:left true:left 6581/11700\n",
      "tensor([ 1.4487, -1.5254])\n",
      "pre:left true:left 6582/11700\n",
      "tensor([ 0.1980, -0.2423])\n",
      "pre:left true:left 6583/11700\n",
      "tensor([ 1.0749, -1.1133])\n",
      "pre:left true:left 6584/11700\n",
      "tensor([ 0.4171, -0.4172])\n",
      "pre:left true:left 6585/11700\n",
      "tensor([ 0.6420, -0.6579])\n",
      "pre:left true:left 6586/11700\n",
      "tensor([ 0.6537, -0.7346])\n",
      "pre:left true:left 6587/11700\n",
      "tensor([ 0.8870, -0.8844])\n",
      "pre:left true:left 6588/11700\n",
      "tensor([ 0.7834, -0.7672])\n",
      "pre:left true:left 6589/11700\n",
      "tensor([-0.2901,  0.2685])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左436_0_592_20200412_114823812_7.jpg\n",
      "pre:right true:left 6590/11700\n",
      "tensor([ 0.0962, -0.1316])\n",
      "pre:left true:left 6591/11700\n",
      "tensor([ 0.6924, -0.7306])\n",
      "pre:left true:left 6592/11700\n",
      "tensor([ 0.2842, -0.3189])\n",
      "pre:left true:left 6593/11700\n",
      "tensor([-0.4278,  0.4042])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左432_0_588_20200412_114818615_5.jpg\n",
      "pre:right true:left 6594/11700\n",
      "tensor([ 0.2955, -0.2962])\n",
      "pre:left true:left 6595/11700\n",
      "tensor([ 1.2336, -1.2850])\n",
      "pre:left true:left 6596/11700\n",
      "tensor([ 0.6122, -0.6600])\n",
      "pre:left true:left 6597/11700\n",
      "tensor([ 0.5870, -0.5539])\n",
      "pre:left true:left 6598/11700\n",
      "tensor([ 0.4488, -0.3397])\n",
      "pre:left true:left 6599/11700\n",
      "tensor([ 0.1774, -0.2421])\n",
      "pre:left true:left 6600/11700\n",
      "tensor([ 0.3752, -0.3609])\n",
      "pre:left true:left 6601/11700\n",
      "tensor([ 0.6964, -0.6928])\n",
      "pre:left true:left 6602/11700\n",
      "tensor([ 0.5243, -0.5613])\n",
      "pre:left true:left 6603/11700\n",
      "tensor([ 0.3255, -0.2528])\n",
      "pre:left true:left 6604/11700\n",
      "tensor([ 0.0707, -0.1212])\n",
      "pre:left true:left 6605/11700\n",
      "tensor([ 0.3788, -0.3357])\n",
      "pre:left true:left 6606/11700\n",
      "tensor([ 0.3702, -0.3573])\n",
      "pre:left true:left 6607/11700\n",
      "tensor([ 0.3568, -0.3156])\n",
      "pre:left true:left 6608/11700\n",
      "tensor([-0.2265,  0.2283])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左407_0_407_20200412_110629294_5.jpg\n",
      "pre:right true:left 6609/11700\n",
      "tensor([ 0.4492, -0.4682])\n",
      "pre:left true:left 6610/11700\n",
      "tensor([ 1.0409, -1.1003])\n",
      "pre:left true:left 6611/11700\n",
      "tensor([-0.0923,  0.1484])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左309_0_465_20200412_114538314_2.jpg\n",
      "pre:right true:left 6612/11700\n",
      "tensor([ 0.3387, -0.3461])\n",
      "pre:left true:left 6613/11700\n",
      "tensor([ 0.2320, -0.2700])\n",
      "pre:left true:left 6614/11700\n",
      "tensor([ 0.3583, -0.3762])\n",
      "pre:left true:left 6615/11700\n",
      "tensor([ 0.7146, -0.6700])\n",
      "pre:left true:left 6616/11700\n",
      "tensor([-0.3952,  0.3827])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左888_0_888_20200412_111755369_7.jpg\n",
      "pre:right true:left 6617/11700\n",
      "tensor([ 0.9394, -0.9319])\n",
      "pre:left true:left 6618/11700\n",
      "tensor([ 0.2734, -0.2201])\n",
      "pre:left true:left 6619/11700\n",
      "tensor([ 0.6331, -0.6332])\n",
      "pre:left true:left 6620/11700\n",
      "tensor([ 0.8516, -0.9196])\n",
      "pre:left true:left 6621/11700\n",
      "tensor([ 0.0530, -0.1010])\n",
      "pre:left true:left 6622/11700\n",
      "tensor([ 0.3863, -0.4457])\n",
      "pre:left true:left 6623/11700\n",
      "tensor([ 0.7849, -0.6627])\n",
      "pre:left true:left 6624/11700\n",
      "tensor([ 0.5424, -0.3996])\n",
      "pre:left true:left 6625/11700\n",
      "tensor([ 0.2187, -0.1891])\n",
      "pre:left true:left 6626/11700\n",
      "tensor([ 0.5885, -0.5295])\n",
      "pre:left true:left 6627/11700\n",
      "tensor([ 0.4326, -0.4387])\n",
      "pre:left true:left 6628/11700\n",
      "tensor([ 0.4740, -0.4097])\n",
      "pre:left true:left 6629/11700\n",
      "tensor([-0.6370,  0.6157])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左587_0_743_20200412_115140615_9.jpg\n",
      "pre:right true:left 6630/11700\n",
      "tensor([ 1.3294, -1.3388])\n",
      "pre:left true:left 6631/11700\n",
      "tensor([ 0.4307, -0.4014])\n",
      "pre:left true:left 6632/11700\n",
      "tensor([ 0.2715, -0.2794])\n",
      "pre:left true:left 6633/11700\n",
      "tensor([ 0.2739, -0.2490])\n",
      "pre:left true:left 6634/11700\n",
      "tensor([ 0.0259, -0.0163])\n",
      "pre:left true:left 6635/11700\n",
      "tensor([-0.0081, -0.0028])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左690_0_846_20200412_115354827_1.jpg\n",
      "pre:right true:left 6636/11700\n",
      "tensor([ 0.8449, -0.7157])\n",
      "pre:left true:left 6637/11700\n",
      "tensor([-0.0176,  0.1639])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1059_0_1059_20200412_112141573_5.jpg\n",
      "pre:right true:left 6638/11700\n",
      "tensor([ 0.4706, -0.3809])\n",
      "pre:left true:left 6639/11700\n",
      "tensor([ 0.4702, -0.4032])\n",
      "pre:left true:left 6640/11700\n",
      "tensor([-0.0363,  0.0983])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1413_0_1569_20200412_120937092_4.jpg\n",
      "pre:right true:left 6641/11700\n",
      "tensor([ 0.8526, -0.7952])\n",
      "pre:left true:left 6642/11700\n",
      "tensor([ 0.7667, -0.8285])\n",
      "pre:left true:left 6643/11700\n",
      "tensor([ 1.1626, -1.1870])\n",
      "pre:left true:left 6644/11700\n",
      "tensor([ 0.6155, -0.5743])\n",
      "pre:left true:left 6645/11700\n",
      "tensor([ 0.1894, -0.0977])\n",
      "pre:left true:left 6646/11700\n",
      "tensor([ 0.8676, -0.8417])\n",
      "pre:left true:left 6647/11700\n",
      "tensor([ 0.6189, -0.6667])\n",
      "pre:left true:left 6648/11700\n",
      "tensor([ 0.3007, -0.2145])\n",
      "pre:left true:left 6649/11700\n",
      "tensor([ 0.6508, -0.6178])\n",
      "pre:left true:left 6650/11700\n",
      "tensor([ 0.3421, -0.3011])\n",
      "pre:left true:left 6651/11700\n",
      "tensor([ 0.9807, -1.0118])\n",
      "pre:left true:left 6652/11700\n",
      "tensor([ 0.3374, -0.2619])\n",
      "pre:left true:left 6653/11700\n",
      "tensor([ 0.8721, -0.8555])\n",
      "pre:left true:left 6654/11700\n",
      "tensor([-0.5348,  0.5553])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1238_0_1238_20200412_112534829_7.jpg\n",
      "pre:right true:left 6655/11700\n",
      "tensor([ 0.9761, -0.9144])\n",
      "pre:left true:left 6656/11700\n",
      "tensor([-0.1707,  0.2326])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左799_0_955_20200412_115616893_8.jpg\n",
      "pre:right true:left 6657/11700\n",
      "tensor([ 0.1885, -0.1857])\n",
      "pre:left true:left 6658/11700\n",
      "tensor([ 0.9103, -0.8606])\n",
      "pre:left true:left 6659/11700\n",
      "tensor([ 0.9320, -0.9123])\n",
      "pre:left true:left 6660/11700\n",
      "tensor([ 0.8089, -0.7601])\n",
      "pre:left true:left 6661/11700\n",
      "tensor([ 0.8249, -0.8776])\n",
      "pre:left true:left 6662/11700\n",
      "tensor([ 0.9011, -0.7970])\n",
      "pre:left true:left 6663/11700\n",
      "tensor([ 0.7432, -0.7896])\n",
      "pre:left true:left 6664/11700\n",
      "tensor([-0.7932,  0.8684])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左989_0_989_20200412_112010371_9.jpg\n",
      "pre:right true:left 6665/11700\n",
      "tensor([ 0.4695, -0.3933])\n",
      "pre:left true:left 6666/11700\n",
      "tensor([ 0.4054, -0.3757])\n",
      "pre:left true:left 6667/11700\n",
      "tensor([ 0.5245, -0.6085])\n",
      "pre:left true:left 6668/11700\n",
      "tensor([ 0.2968, -0.2833])\n",
      "pre:left true:left 6669/11700\n",
      "tensor([ 0.6763, -0.6092])\n",
      "pre:left true:left 6670/11700\n",
      "tensor([ 0.4203, -0.3845])\n",
      "pre:left true:left 6671/11700\n",
      "tensor([ 0.6175, -0.5499])\n",
      "pre:left true:left 6672/11700\n",
      "tensor([ 0.4254, -0.5055])\n",
      "pre:left true:left 6673/11700\n",
      "tensor([ 0.9309, -0.9809])\n",
      "pre:left true:left 6674/11700\n",
      "tensor([ 0.9497, -0.9601])\n",
      "pre:left true:left 6675/11700\n",
      "tensor([ 0.3808, -0.3522])\n",
      "pre:left true:left 6676/11700\n",
      "tensor([ 0.4290, -0.3541])\n",
      "pre:left true:left 6677/11700\n",
      "tensor([-0.3062,  0.4860])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左226_0_382_20200412_114350157_10.jpg\n",
      "pre:right true:left 6678/11700\n",
      "tensor([ 0.6562, -0.6333])\n",
      "pre:left true:left 6679/11700\n",
      "tensor([ 0.0700, -0.1348])\n",
      "pre:left true:left 6680/11700\n",
      "tensor([ 0.7335, -0.6425])\n",
      "pre:left true:left 6681/11700\n",
      "tensor([ 0.5341, -0.4172])\n",
      "pre:left true:left 6682/11700\n",
      "tensor([ 1.1770, -1.1808])\n",
      "pre:left true:left 6683/11700\n",
      "tensor([ 0.7612, -0.7923])\n",
      "pre:left true:left 6684/11700\n",
      "tensor([ 0.6342, -0.7512])\n",
      "pre:left true:left 6685/11700\n",
      "tensor([ 0.7692, -0.7165])\n",
      "pre:left true:left 6686/11700\n",
      "tensor([ 0.1302, -0.1506])\n",
      "pre:left true:left 6687/11700\n",
      "tensor([-0.0505,  0.0572])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左967_0_967_20200412_111941711_1.jpg\n",
      "pre:right true:left 6688/11700\n",
      "tensor([-0.3165,  0.2130])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左475_0_475_20200412_110806277_8.jpg\n",
      "pre:right true:left 6689/11700\n",
      "tensor([0.0337, 0.1739])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左607_0_763_20200412_115206661_2.jpg\n",
      "pre:right true:left 6690/11700\n",
      "tensor([ 0.7058, -0.7049])\n",
      "pre:left true:left 6691/11700\n",
      "tensor([-0.3716,  0.4263])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左787_0_787_20200412_111531308_0.jpg\n",
      "pre:right true:left 6692/11700\n",
      "tensor([ 0.0452, -0.0393])\n",
      "pre:left true:left 6693/11700\n",
      "tensor([ 0.1835, -0.1013])\n",
      "pre:left true:left 6694/11700\n",
      "tensor([ 0.5901, -0.5430])\n",
      "pre:left true:left 6695/11700\n",
      "tensor([-0.0746,  0.1693])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左420_0_576_20200412_114802970_1.jpg\n",
      "pre:right true:left 6696/11700\n",
      "tensor([ 1.2048, -1.2293])\n",
      "pre:left true:left 6697/11700\n",
      "tensor([ 0.4570, -0.4415])\n",
      "pre:left true:left 6698/11700\n",
      "tensor([ 0.6709, -0.6649])\n",
      "pre:left true:left 6699/11700\n",
      "tensor([ 0.6222, -0.6268])\n",
      "pre:left true:left 6700/11700\n",
      "tensor([ 0.2299, -0.3138])\n",
      "pre:left true:left 6701/11700\n",
      "tensor([ 0.6718, -0.6869])\n",
      "pre:left true:left 6702/11700\n",
      "tensor([ 0.7602, -0.7209])\n",
      "pre:left true:left 6703/11700\n",
      "tensor([ 0.2380, -0.2073])\n",
      "pre:left true:left 6704/11700\n",
      "tensor([0.0317, 0.0037])\n",
      "pre:left true:left 6705/11700\n",
      "tensor([ 1.0341, -1.0785])\n",
      "pre:left true:left 6706/11700\n",
      "tensor([ 0.9997, -0.8195])\n",
      "pre:left true:left 6707/11700\n",
      "tensor([ 1.0370, -1.0396])\n",
      "pre:left true:left 6708/11700\n",
      "tensor([ 0.7097, -0.7497])\n",
      "pre:left true:left 6709/11700\n",
      "tensor([ 0.2680, -0.2735])\n",
      "pre:left true:left 6710/11700\n",
      "tensor([ 0.0505, -0.0025])\n",
      "pre:left true:left 6711/11700\n",
      "tensor([-1.2012,  1.3130])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左755_0_911_20200412_115519560.jpg\n",
      "pre:right true:left 6712/11700\n",
      "tensor([ 1.1100, -1.1439])\n",
      "pre:left true:left 6713/11700\n",
      "tensor([ 0.6635, -0.6497])\n",
      "pre:left true:left 6714/11700\n",
      "tensor([ 1.1067, -1.0818])\n",
      "pre:left true:left 6715/11700\n",
      "tensor([-0.2560,  0.2487])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1428_0_1584_20200412_120956636_4.jpg\n",
      "pre:right true:left 6716/11700\n",
      "tensor([ 0.6852, -0.5232])\n",
      "pre:left true:left 6717/11700\n",
      "tensor([ 0.6868, -0.6821])\n",
      "pre:left true:left 6718/11700\n",
      "tensor([ 0.7261, -0.7688])\n",
      "pre:left true:left 6719/11700\n",
      "tensor([ 0.8242, -0.9210])\n",
      "pre:left true:left 6720/11700\n",
      "tensor([ 0.2548, -0.2372])\n",
      "pre:left true:left 6721/11700\n",
      "tensor([ 1.4398, -1.4130])\n",
      "pre:left true:left 6722/11700\n",
      "tensor([ 0.5348, -0.5266])\n",
      "pre:left true:left 6723/11700\n",
      "tensor([ 1.2360, -1.2172])\n",
      "pre:left true:left 6724/11700\n",
      "tensor([ 0.6409, -0.6351])\n",
      "pre:left true:left 6725/11700\n",
      "tensor([-0.0527,  0.0050])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左567_0_723_20200412_115114530_4.jpg\n",
      "pre:right true:left 6726/11700\n",
      "tensor([ 0.7585, -0.8634])\n",
      "pre:left true:left 6727/11700\n",
      "tensor([ 0.3274, -0.2644])\n",
      "pre:left true:left 6728/11700\n",
      "tensor([ 0.5029, -0.5086])\n",
      "pre:left true:left 6729/11700\n",
      "tensor([-0.0058, -0.0376])\n",
      "pre:left true:left 6730/11700\n",
      "tensor([ 0.5829, -0.6306])\n",
      "pre:left true:left 6731/11700\n",
      "tensor([ 0.7164, -0.6988])\n",
      "pre:left true:left 6732/11700\n",
      "tensor([ 0.8551, -0.8617])\n",
      "pre:left true:left 6733/11700\n",
      "tensor([ 0.4352, -0.3502])\n",
      "pre:left true:left 6734/11700\n",
      "tensor([ 1.0915, -1.1004])\n",
      "pre:left true:left 6735/11700\n",
      "tensor([0.0422, 0.0522])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左103_0_103_20200412_105915707_2.jpg\n",
      "pre:right true:left 6736/11700\n",
      "tensor([ 0.2030, -0.1157])\n",
      "pre:left true:left 6737/11700\n",
      "tensor([ 1.0755, -1.0205])\n",
      "pre:left true:left 6738/11700\n",
      "tensor([ 0.8704, -0.9450])\n",
      "pre:left true:left 6739/11700\n",
      "tensor([ 0.6577, -0.6065])\n",
      "pre:left true:left 6740/11700\n",
      "tensor([ 0.7501, -0.7212])\n",
      "pre:left true:left 6741/11700\n",
      "tensor([ 0.6183, -0.5840])\n",
      "pre:left true:left 6742/11700\n",
      "tensor([ 0.4038, -0.2947])\n",
      "pre:left true:left 6743/11700\n",
      "tensor([ 0.3616, -0.3214])\n",
      "pre:left true:left 6744/11700\n",
      "tensor([ 0.6104, -0.6417])\n",
      "pre:left true:left 6745/11700\n",
      "tensor([ 0.5918, -0.5977])\n",
      "pre:left true:left 6746/11700\n",
      "tensor([-0.0333,  0.0089])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左580_0_736_20200412_115131473_10.jpg\n",
      "pre:right true:left 6747/11700\n",
      "tensor([ 0.6593, -0.6803])\n",
      "pre:left true:left 6748/11700\n",
      "tensor([ 0.7829, -0.7596])\n",
      "pre:left true:left 6749/11700\n",
      "tensor([ 0.8466, -0.8372])\n",
      "pre:left true:left 6750/11700\n",
      "tensor([ 0.3729, -0.4897])\n",
      "pre:left true:left 6751/11700\n",
      "tensor([ 0.4167, -0.3901])\n",
      "pre:left true:left 6752/11700\n",
      "tensor([ 0.3380, -0.3843])\n",
      "pre:left true:left 6753/11700\n",
      "tensor([ 0.9646, -0.8825])\n",
      "pre:left true:left 6754/11700\n",
      "tensor([ 1.2850, -1.2881])\n",
      "pre:left true:left 6755/11700\n",
      "tensor([ 0.1998, -0.1229])\n",
      "pre:left true:left 6756/11700\n",
      "tensor([ 1.9108, -1.9843])\n",
      "pre:left true:left 6757/11700\n",
      "tensor([ 1.6312, -1.6407])\n",
      "pre:left true:left 6758/11700\n",
      "tensor([ 0.2005, -0.1263])\n",
      "pre:left true:left 6759/11700\n",
      "tensor([ 1.0775, -1.0650])\n",
      "pre:left true:left 6760/11700\n",
      "tensor([ 0.5546, -0.5847])\n",
      "pre:left true:left 6761/11700\n",
      "tensor([-0.3665,  0.4589])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左714_0_870_20200412_115426118_2.jpg\n",
      "pre:right true:left 6762/11700\n",
      "tensor([ 0.7787, -0.6721])\n",
      "pre:left true:left 6763/11700\n",
      "tensor([ 1.5794, -1.5547])\n",
      "pre:left true:left 6764/11700\n",
      "tensor([ 0.2699, -0.2356])\n",
      "pre:left true:left 6765/11700\n",
      "tensor([ 0.1636, -0.1265])\n",
      "pre:left true:left 6766/11700\n",
      "tensor([ 0.7635, -0.8351])\n",
      "pre:left true:left 6767/11700\n",
      "tensor([ 0.9714, -0.9742])\n",
      "pre:left true:left 6768/11700\n",
      "tensor([ 0.0354, -0.1614])\n",
      "pre:left true:left 6769/11700\n",
      "tensor([ 0.4938, -0.5370])\n",
      "pre:left true:left 6770/11700\n",
      "tensor([ 0.3858, -0.3672])\n",
      "pre:left true:left 6771/11700\n",
      "tensor([ 1.3204, -1.3876])\n",
      "pre:left true:left 6772/11700\n",
      "tensor([ 0.5244, -0.5235])\n",
      "pre:left true:left 6773/11700\n",
      "tensor([ 0.0180, -0.0376])\n",
      "pre:left true:left 6774/11700\n",
      "tensor([ 0.2920, -0.2986])\n",
      "pre:left true:left 6775/11700\n",
      "tensor([ 0.6168, -0.6206])\n",
      "pre:left true:left 6776/11700\n",
      "tensor([ 0.9759, -0.9648])\n",
      "pre:left true:left 6777/11700\n",
      "tensor([ 1.0714, -1.0506])\n",
      "pre:left true:left 6778/11700\n",
      "tensor([ 1.4537, -1.4425])\n",
      "pre:left true:left 6779/11700\n",
      "tensor([ 0.1702, -0.1777])\n",
      "pre:left true:left 6780/11700\n",
      "tensor([ 0.1468, -0.0675])\n",
      "pre:left true:left 6781/11700\n",
      "tensor([ 0.3819, -0.4191])\n",
      "pre:left true:left 6782/11700\n",
      "tensor([-0.4142,  0.4257])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左423_0_579_20200412_114806868_10.jpg\n",
      "pre:right true:left 6783/11700\n",
      "tensor([ 0.4325, -0.4599])\n",
      "pre:left true:left 6784/11700\n",
      "tensor([ 0.4142, -0.4555])\n",
      "pre:left true:left 6785/11700\n",
      "tensor([ 0.1504, -0.2727])\n",
      "pre:left true:left 6786/11700\n",
      "tensor([ 1.0519, -1.0494])\n",
      "pre:left true:left 6787/11700\n",
      "tensor([ 1.1140, -1.0994])\n",
      "pre:left true:left 6788/11700\n",
      "tensor([ 0.4669, -0.4252])\n",
      "pre:left true:left 6789/11700\n",
      "tensor([ 0.9721, -0.9351])\n",
      "pre:left true:left 6790/11700\n",
      "tensor([ 0.6888, -0.6816])\n",
      "pre:left true:left 6791/11700\n",
      "tensor([ 0.7775, -0.6372])\n",
      "pre:left true:left 6792/11700\n",
      "tensor([ 0.3380, -0.2884])\n",
      "pre:left true:left 6793/11700\n",
      "tensor([ 0.7355, -0.7343])\n",
      "pre:left true:left 6794/11700\n",
      "tensor([ 0.5844, -0.6082])\n",
      "pre:left true:left 6795/11700\n",
      "tensor([ 0.1436, -0.1003])\n",
      "pre:left true:left 6796/11700\n",
      "tensor([-0.2190,  0.2077])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左607_0_763_20200412_115206661_8.jpg\n",
      "pre:right true:left 6797/11700\n",
      "tensor([ 0.3256, -0.3659])\n",
      "pre:left true:left 6798/11700\n",
      "tensor([ 0.9751, -0.9010])\n",
      "pre:left true:left 6799/11700\n",
      "tensor([-0.0778,  0.0989])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左507_0_507_20200412_110851924_1.jpg\n",
      "pre:right true:left 6800/11700\n",
      "tensor([ 1.4103, -1.3905])\n",
      "pre:left true:left 6801/11700\n",
      "tensor([ 0.8650, -0.8950])\n",
      "pre:left true:left 6802/11700\n",
      "tensor([ 1.0221, -1.0124])\n",
      "pre:left true:left 6803/11700\n",
      "tensor([ 1.3454, -1.3736])\n",
      "pre:left true:left 6804/11700\n",
      "tensor([ 0.2574, -0.2455])\n",
      "pre:left true:left 6805/11700\n",
      "tensor([ 1.8157, -1.9350])\n",
      "pre:left true:left 6806/11700\n",
      "tensor([ 0.3397, -0.3345])\n",
      "pre:left true:left 6807/11700\n",
      "tensor([ 0.0601, -0.0440])\n",
      "pre:left true:left 6808/11700\n",
      "tensor([ 0.2107, -0.2720])\n",
      "pre:left true:left 6809/11700\n",
      "tensor([ 0.6312, -0.7709])\n",
      "pre:left true:left 6810/11700\n",
      "tensor([ 0.1922, -0.2272])\n",
      "pre:left true:left 6811/11700\n",
      "tensor([ 0.0784, -0.0576])\n",
      "pre:left true:left 6812/11700\n",
      "tensor([ 0.6510, -0.5141])\n",
      "pre:left true:left 6813/11700\n",
      "tensor([ 0.3158, -0.3166])\n",
      "pre:left true:left 6814/11700\n",
      "tensor([-0.2033,  0.2726])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左569_0_569_20200412_111020354_1.jpg\n",
      "pre:right true:left 6815/11700\n",
      "tensor([ 0.3381, -0.2708])\n",
      "pre:left true:left 6816/11700\n",
      "tensor([ 0.7051, -0.7664])\n",
      "pre:left true:left 6817/11700\n",
      "tensor([ 1.1102, -1.0175])\n",
      "pre:left true:left 6818/11700\n",
      "tensor([ 0.7226, -0.6762])\n",
      "pre:left true:left 6819/11700\n",
      "tensor([ 0.3273, -0.3842])\n",
      "pre:left true:left 6820/11700\n",
      "tensor([ 0.3672, -0.3667])\n",
      "pre:left true:left 6821/11700\n",
      "tensor([ 0.6074, -0.5314])\n",
      "pre:left true:left 6822/11700\n",
      "tensor([ 0.5684, -0.5095])\n",
      "pre:left true:left 6823/11700\n",
      "tensor([ 0.9016, -0.9282])\n",
      "pre:left true:left 6824/11700\n",
      "tensor([ 0.5702, -0.6373])\n",
      "pre:left true:left 6825/11700\n",
      "tensor([ 0.8689, -0.8820])\n",
      "pre:left true:left 6826/11700\n",
      "tensor([ 0.9301, -0.8955])\n",
      "pre:left true:left 6827/11700\n",
      "tensor([ 0.8592, -0.8734])\n",
      "pre:left true:left 6828/11700\n",
      "tensor([ 0.2023, -0.0777])\n",
      "pre:left true:left 6829/11700\n",
      "tensor([ 0.4697, -0.4904])\n",
      "pre:left true:left 6830/11700\n",
      "tensor([0.1256, 0.0176])\n",
      "pre:left true:left 6831/11700\n",
      "tensor([-0.9634,  1.0470])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左804_0_804_20200412_111555570_10.jpg\n",
      "pre:right true:left 6832/11700\n",
      "tensor([ 1.6054, -1.6016])\n",
      "pre:left true:left 6833/11700\n",
      "tensor([ 0.2006, -0.1317])\n",
      "pre:left true:left 6834/11700\n",
      "tensor([ 0.7377, -0.8332])\n",
      "pre:left true:left 6835/11700\n",
      "tensor([ 0.3958, -0.4228])\n",
      "pre:left true:left 6836/11700\n",
      "tensor([ 1.0263, -1.1502])\n",
      "pre:left true:left 6837/11700\n",
      "tensor([ 1.1483, -1.1545])\n",
      "pre:left true:left 6838/11700\n",
      "tensor([ 0.2275, -0.2105])\n",
      "pre:left true:left 6839/11700\n",
      "tensor([ 1.4803, -1.4350])\n",
      "pre:left true:left 6840/11700\n",
      "tensor([ 0.0894, -0.1096])\n",
      "pre:left true:left 6841/11700\n",
      "tensor([ 1.4230, -1.4476])\n",
      "pre:left true:left 6842/11700\n",
      "tensor([ 0.9380, -0.9173])\n",
      "pre:left true:left 6843/11700\n",
      "tensor([ 0.9024, -0.8129])\n",
      "pre:left true:left 6844/11700\n",
      "tensor([ 0.8844, -0.8477])\n",
      "pre:left true:left 6845/11700\n",
      "tensor([ 0.1439, -0.1210])\n",
      "pre:left true:left 6846/11700\n",
      "tensor([ 0.5023, -0.4925])\n",
      "pre:left true:left 6847/11700\n",
      "tensor([ 0.2502, -0.2384])\n",
      "pre:left true:left 6848/11700\n",
      "tensor([ 0.8367, -0.8842])\n",
      "pre:left true:left 6849/11700\n",
      "tensor([-0.0029,  0.0546])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1201_0_1357_20200412_120500803_7.jpg\n",
      "pre:right true:left 6850/11700\n",
      "tensor([0.0150, 0.0006])\n",
      "pre:left true:left 6851/11700\n",
      "tensor([ 0.8228, -0.8692])\n",
      "pre:left true:left 6852/11700\n",
      "tensor([ 0.8330, -0.7999])\n",
      "pre:left true:left 6853/11700\n",
      "tensor([ 1.1141, -1.0883])\n",
      "pre:left true:left 6854/11700\n",
      "tensor([ 0.8968, -0.8214])\n",
      "pre:left true:left 6855/11700\n",
      "tensor([ 0.5826, -0.5080])\n",
      "pre:left true:left 6856/11700\n",
      "tensor([ 0.5698, -0.5705])\n",
      "pre:left true:left 6857/11700\n",
      "tensor([-0.3690,  0.3638])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左270_0_426_20200412_114447496_10.jpg\n",
      "pre:right true:left 6858/11700\n",
      "tensor([ 0.5021, -0.5166])\n",
      "pre:left true:left 6859/11700\n",
      "tensor([ 0.4067, -0.4404])\n",
      "pre:left true:left 6860/11700\n",
      "tensor([ 0.6150, -0.5942])\n",
      "pre:left true:left 6861/11700\n",
      "tensor([ 0.9990, -1.0346])\n",
      "pre:left true:left 6862/11700\n",
      "tensor([ 0.2772, -0.2780])\n",
      "pre:left true:left 6863/11700\n",
      "tensor([ 0.6712, -0.6937])\n",
      "pre:left true:left 6864/11700\n",
      "tensor([ 0.2878, -0.1853])\n",
      "pre:left true:left 6865/11700\n",
      "tensor([ 0.4414, -0.4831])\n",
      "pre:left true:left 6866/11700\n",
      "tensor([ 0.2329, -0.1426])\n",
      "pre:left true:left 6867/11700\n",
      "tensor([ 0.6386, -0.6356])\n",
      "pre:left true:left 6868/11700\n",
      "tensor([ 1.3794, -1.3255])\n",
      "pre:left true:left 6869/11700\n",
      "tensor([ 0.6221, -0.5057])\n",
      "pre:left true:left 6870/11700\n",
      "tensor([ 0.5061, -0.4016])\n",
      "pre:left true:left 6871/11700\n",
      "tensor([ 0.9133, -0.9949])\n",
      "pre:left true:left 6872/11700\n",
      "tensor([ 0.6124, -0.6667])\n",
      "pre:left true:left 6873/11700\n",
      "tensor([ 1.1255, -1.0398])\n",
      "pre:left true:left 6874/11700\n",
      "tensor([ 1.0027, -0.9908])\n",
      "pre:left true:left 6875/11700\n",
      "tensor([ 0.5029, -0.5642])\n",
      "pre:left true:left 6876/11700\n",
      "tensor([-0.2820,  0.4130])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左659_0_815_20200412_115314448_1.jpg\n",
      "pre:right true:left 6877/11700\n",
      "tensor([ 0.3209, -0.2862])\n",
      "pre:left true:left 6878/11700\n",
      "tensor([ 0.5407, -0.4812])\n",
      "pre:left true:left 6879/11700\n",
      "tensor([ 0.3069, -0.3043])\n",
      "pre:left true:left 6880/11700\n",
      "tensor([ 0.9978, -0.9067])\n",
      "pre:left true:left 6881/11700\n",
      "tensor([ 0.4945, -0.4117])\n",
      "pre:left true:left 6882/11700\n",
      "tensor([ 0.4708, -0.4605])\n",
      "pre:left true:left 6883/11700\n",
      "tensor([ 0.8666, -0.9024])\n",
      "pre:left true:left 6884/11700\n",
      "tensor([ 0.7640, -0.7976])\n",
      "pre:left true:left 6885/11700\n",
      "tensor([ 0.4265, -0.5195])\n",
      "pre:left true:left 6886/11700\n",
      "tensor([ 0.2312, -0.1899])\n",
      "pre:left true:left 6887/11700\n",
      "tensor([ 0.6111, -0.6373])\n",
      "pre:left true:left 6888/11700\n",
      "tensor([ 0.7243, -0.6838])\n",
      "pre:left true:left 6889/11700\n",
      "tensor([-0.1631,  0.0846])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左917_0_917_20200412_111836594_2.jpg\n",
      "pre:right true:left 6890/11700\n",
      "tensor([ 1.1019, -1.0885])\n",
      "pre:left true:left 6891/11700\n",
      "tensor([-0.3338,  0.3064])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左721_0_877_20200412_115435244.jpg\n",
      "pre:right true:left 6892/11700\n",
      "tensor([ 0.7901, -0.6632])\n",
      "pre:left true:left 6893/11700\n",
      "tensor([ 1.1274, -1.1909])\n",
      "pre:left true:left 6894/11700\n",
      "tensor([ 0.9325, -0.8928])\n",
      "pre:left true:left 6895/11700\n",
      "tensor([ 0.7127, -0.6990])\n",
      "pre:left true:left 6896/11700\n",
      "tensor([ 0.4924, -0.4295])\n",
      "pre:left true:left 6897/11700\n",
      "tensor([ 0.1182, -0.0860])\n",
      "pre:left true:left 6898/11700\n",
      "tensor([ 0.2163, -0.1910])\n",
      "pre:left true:left 6899/11700\n",
      "tensor([-0.0817,  0.0335])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左888_0_888_20200412_111755369_3.jpg\n",
      "pre:right true:left 6900/11700\n",
      "tensor([ 0.0492, -0.0841])\n",
      "pre:left true:left 6901/11700\n",
      "tensor([ 0.0678, -0.1210])\n",
      "pre:left true:left 6902/11700\n",
      "tensor([ 0.6497, -0.6334])\n",
      "pre:left true:left 6903/11700\n",
      "tensor([ 0.4041, -0.3441])\n",
      "pre:left true:left 6904/11700\n",
      "tensor([ 0.6418, -0.4838])\n",
      "pre:left true:left 6905/11700\n",
      "tensor([ 0.8933, -0.8051])\n",
      "pre:left true:left 6906/11700\n",
      "tensor([ 0.6061, -0.6579])\n",
      "pre:left true:left 6907/11700\n",
      "tensor([ 0.8836, -0.8623])\n",
      "pre:left true:left 6908/11700\n",
      "tensor([ 0.1969, -0.1682])\n",
      "pre:left true:left 6909/11700\n",
      "tensor([ 0.8438, -0.8806])\n",
      "pre:left true:left 6910/11700\n",
      "tensor([-0.2425,  0.3256])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左107_0_107_20200412_105921416_9.jpg\n",
      "pre:right true:left 6911/11700\n",
      "tensor([ 0.8403, -0.8412])\n",
      "pre:left true:left 6912/11700\n",
      "tensor([ 0.2979, -0.2034])\n",
      "pre:left true:left 6913/11700\n",
      "tensor([-1.3635,  1.3307])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左802_0_958_20200412_115620819_3.jpg\n",
      "pre:right true:left 6914/11700\n",
      "tensor([ 0.1318, -0.0232])\n",
      "pre:left true:left 6915/11700\n",
      "tensor([ 0.2238, -0.2040])\n",
      "pre:left true:left 6916/11700\n",
      "tensor([ 0.5448, -0.5172])\n",
      "pre:left true:left 6917/11700\n",
      "tensor([ 0.4178, -0.4677])\n",
      "pre:left true:left 6918/11700\n",
      "tensor([ 0.5835, -0.5764])\n",
      "pre:left true:left 6919/11700\n",
      "tensor([ 0.2715, -0.3166])\n",
      "pre:left true:left 6920/11700\n",
      "tensor([ 0.3686, -0.4260])\n",
      "pre:left true:left 6921/11700\n",
      "tensor([ 0.9835, -0.9957])\n",
      "pre:left true:left 6922/11700\n",
      "tensor([ 0.3127, -0.3798])\n",
      "pre:left true:left 6923/11700\n",
      "tensor([-0.2196,  0.3031])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左905_0_905_20200412_111819617_1.jpg\n",
      "pre:right true:left 6924/11700\n",
      "tensor([ 0.6602, -0.6125])\n",
      "pre:left true:left 6925/11700\n",
      "tensor([ 0.9429, -0.8537])\n",
      "pre:left true:left 6926/11700\n",
      "tensor([ 1.1671, -1.1537])\n",
      "pre:left true:left 6927/11700\n",
      "tensor([ 0.7066, -0.8020])\n",
      "pre:left true:left 6928/11700\n",
      "tensor([ 0.2227, -0.2106])\n",
      "pre:left true:left 6929/11700\n",
      "tensor([ 0.1362, -0.0616])\n",
      "pre:left true:left 6930/11700\n",
      "tensor([ 0.8053, -0.8113])\n",
      "pre:left true:left 6931/11700\n",
      "tensor([ 0.3874, -0.3376])\n",
      "pre:left true:left 6932/11700\n",
      "tensor([ 0.8322, -0.7150])\n",
      "pre:left true:left 6933/11700\n",
      "tensor([-0.0809,  0.0658])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左165_0_321_20200412_114230687_1.jpg\n",
      "pre:right true:left 6934/11700\n",
      "tensor([ 0.5853, -0.5719])\n",
      "pre:left true:left 6935/11700\n",
      "tensor([ 0.3415, -0.2797])\n",
      "pre:left true:left 6936/11700\n",
      "tensor([ 0.5410, -0.5343])\n",
      "pre:left true:left 6937/11700\n",
      "tensor([ 0.0140, -0.1291])\n",
      "pre:left true:left 6938/11700\n",
      "tensor([ 0.8508, -0.8183])\n",
      "pre:left true:left 6939/11700\n",
      "tensor([ 1.1517, -1.1982])\n",
      "pre:left true:left 6940/11700\n",
      "tensor([ 1.2462, -1.1409])\n",
      "pre:left true:left 6941/11700\n",
      "tensor([ 0.8011, -0.8515])\n",
      "pre:left true:left 6942/11700\n",
      "tensor([ 0.6594, -0.6144])\n",
      "pre:left true:left 6943/11700\n",
      "tensor([ 0.0781, -0.0314])\n",
      "pre:left true:left 6944/11700\n",
      "tensor([ 0.3384, -0.2897])\n",
      "pre:left true:left 6945/11700\n",
      "tensor([ 1.0374, -0.9381])\n",
      "pre:left true:left 6946/11700\n",
      "tensor([ 0.6549, -0.6062])\n",
      "pre:left true:left 6947/11700\n",
      "tensor([ 0.4239, -0.4701])\n",
      "pre:left true:left 6948/11700\n",
      "tensor([-0.5645,  0.6511])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左646_0_802_20200412_115257490_8.jpg\n",
      "pre:right true:left 6949/11700\n",
      "tensor([ 0.1825, -0.1160])\n",
      "pre:left true:left 6950/11700\n",
      "tensor([ 0.3674, -0.3118])\n",
      "pre:left true:left 6951/11700\n",
      "tensor([ 0.1255, -0.2662])\n",
      "pre:left true:left 6952/11700\n",
      "tensor([ 0.0230, -0.0353])\n",
      "pre:left true:left 6953/11700\n",
      "tensor([ 1.1294, -1.0670])\n",
      "pre:left true:left 6954/11700\n",
      "tensor([ 0.5397, -0.5229])\n",
      "pre:left true:left 6955/11700\n",
      "tensor([ 0.7551, -0.6936])\n",
      "pre:left true:left 6956/11700\n",
      "tensor([ 0.2742, -0.2942])\n",
      "pre:left true:left 6957/11700\n",
      "tensor([ 0.4113, -0.4538])\n",
      "pre:left true:left 6958/11700\n",
      "tensor([ 0.7069, -0.6680])\n",
      "pre:left true:left 6959/11700\n",
      "tensor([ 0.8019, -0.7406])\n",
      "pre:left true:left 6960/11700\n",
      "tensor([ 0.6780, -0.5828])\n",
      "pre:left true:left 6961/11700\n",
      "tensor([-0.2054,  0.2679])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左789_0_945_20200412_115603865_5.jpg\n",
      "pre:right true:left 6962/11700\n",
      "tensor([ 0.7289, -0.6939])\n",
      "pre:left true:left 6963/11700\n",
      "tensor([ 0.3919, -0.3867])\n",
      "pre:left true:left 6964/11700\n",
      "tensor([ 0.4885, -0.5017])\n",
      "pre:left true:left 6965/11700\n",
      "tensor([ 0.4566, -0.4806])\n",
      "pre:left true:left 6966/11700\n",
      "tensor([ 0.5033, -0.5607])\n",
      "pre:left true:left 6967/11700\n",
      "tensor([ 0.3051, -0.3286])\n",
      "pre:left true:left 6968/11700\n",
      "tensor([0.0103, 0.1027])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左407_0_407_20200412_110629294_8.jpg\n",
      "pre:right true:left 6969/11700\n",
      "tensor([ 0.4927, -0.5328])\n",
      "pre:left true:left 6970/11700\n",
      "tensor([-0.2247,  0.1573])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左909_0_909_20200412_111825335_4.jpg\n",
      "pre:right true:left 6971/11700\n",
      "tensor([ 1.1002, -1.0946])\n",
      "pre:left true:left 6972/11700\n",
      "tensor([ 0.1065, -0.0308])\n",
      "pre:left true:left 6973/11700\n",
      "tensor([-0.0228,  0.1701])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左621_0_777_20200412_115224917_8.jpg\n",
      "pre:right true:left 6974/11700\n",
      "tensor([ 0.7304, -0.6770])\n",
      "pre:left true:left 6975/11700\n",
      "tensor([ 0.2376, -0.2333])\n",
      "pre:left true:left 6976/11700\n",
      "tensor([ 0.7791, -0.7654])\n",
      "pre:left true:left 6977/11700\n",
      "tensor([ 0.9914, -1.0173])\n",
      "pre:left true:left 6978/11700\n",
      "tensor([ 1.1447, -1.1398])\n",
      "pre:left true:left 6979/11700\n",
      "tensor([ 0.8099, -0.7818])\n",
      "pre:left true:left 6980/11700\n",
      "tensor([ 0.5501, -0.5612])\n",
      "pre:left true:left 6981/11700\n",
      "tensor([ 0.5255, -0.4634])\n",
      "pre:left true:left 6982/11700\n",
      "tensor([ 0.5449, -0.5810])\n",
      "pre:left true:left 6983/11700\n",
      "tensor([ 0.8484, -0.7801])\n",
      "pre:left true:left 6984/11700\n",
      "tensor([ 0.1120, -0.0247])\n",
      "pre:left true:left 6985/11700\n",
      "tensor([ 1.1807, -1.2058])\n",
      "pre:left true:left 6986/11700\n",
      "tensor([ 0.6730, -0.6859])\n",
      "pre:left true:left 6987/11700\n",
      "tensor([ 1.0633, -1.1416])\n",
      "pre:left true:left 6988/11700\n",
      "tensor([-0.2409,  0.1682])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左845_0_1001_20200412_115716845_1.jpg\n",
      "pre:right true:left 6989/11700\n",
      "tensor([ 1.5879, -1.5919])\n",
      "pre:left true:left 6990/11700\n",
      "tensor([ 0.5603, -0.5782])\n",
      "pre:left true:left 6991/11700\n",
      "tensor([ 1.0209, -1.0484])\n",
      "pre:left true:left 6992/11700\n",
      "tensor([ 0.0729, -0.0355])\n",
      "pre:left true:left 6993/11700\n",
      "tensor([-0.0418, -0.0095])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左704_0_860_20200412_115413083_6.jpg\n",
      "pre:right true:left 6994/11700\n",
      "tensor([ 0.1558, -0.2010])\n",
      "pre:left true:left 6995/11700\n",
      "tensor([ 0.4904, -0.4136])\n",
      "pre:left true:left 6996/11700\n",
      "tensor([ 0.4542, -0.5039])\n",
      "pre:left true:left 6997/11700\n",
      "tensor([ 0.6210, -0.6036])\n",
      "pre:left true:left 6998/11700\n",
      "tensor([ 0.5387, -0.4116])\n",
      "pre:left true:left 6999/11700\n",
      "tensor([ 0.5800, -0.5511])\n",
      "pre:left true:left 7000/11700\n",
      "tensor([ 0.4024, -0.4354])\n",
      "pre:left true:left 7001/11700\n",
      "tensor([-0.1502,  0.1848])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左416_0_572_20200412_114757758.jpg\n",
      "pre:right true:left 7002/11700\n",
      "tensor([ 0.4790, -0.5518])\n",
      "pre:left true:left 7003/11700\n",
      "tensor([ 0.3910, -0.4147])\n",
      "pre:left true:left 7004/11700\n",
      "tensor([ 0.4711, -0.5932])\n",
      "pre:left true:left 7005/11700\n",
      "tensor([ 0.7996, -0.7862])\n",
      "pre:left true:left 7006/11700\n",
      "tensor([ 0.0830, -0.0533])\n",
      "pre:left true:left 7007/11700\n",
      "tensor([ 0.2045, -0.2619])\n",
      "pre:left true:left 7008/11700\n",
      "tensor([ 0.0228, -0.0215])\n",
      "pre:left true:left 7009/11700\n",
      "tensor([-0.1628,  0.2058])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左626_0_782_20200412_115231425_9.jpg\n",
      "pre:right true:left 7010/11700\n",
      "tensor([ 0.2807, -0.2465])\n",
      "pre:left true:left 7011/11700\n",
      "tensor([ 0.1231, -0.0924])\n",
      "pre:left true:left 7012/11700\n",
      "tensor([ 0.8237, -0.8419])\n",
      "pre:left true:left 7013/11700\n",
      "tensor([ 0.2369, -0.0998])\n",
      "pre:left true:left 7014/11700\n",
      "tensor([ 1.0907, -1.0395])\n",
      "pre:left true:left 7015/11700\n",
      "tensor([ 0.2474, -0.1533])\n",
      "pre:left true:left 7016/11700\n",
      "tensor([ 0.4572, -0.5244])\n",
      "pre:left true:left 7017/11700\n",
      "tensor([ 0.2971, -0.3093])\n",
      "pre:left true:left 7018/11700\n",
      "tensor([ 0.7101, -0.6224])\n",
      "pre:left true:left 7019/11700\n",
      "tensor([ 1.3670, -1.4641])\n",
      "pre:left true:left 7020/11700\n",
      "tensor([ 0.9679, -1.0033])\n",
      "pre:left true:left 7021/11700\n",
      "tensor([ 1.0127, -0.9761])\n",
      "pre:left true:left 7022/11700\n",
      "tensor([ 1.1486, -1.1490])\n",
      "pre:left true:left 7023/11700\n",
      "tensor([ 0.8504, -0.8652])\n",
      "pre:left true:left 7024/11700\n",
      "tensor([ 1.3729, -1.3436])\n",
      "pre:left true:left 7025/11700\n",
      "tensor([ 0.4626, -0.4676])\n",
      "pre:left true:left 7026/11700\n",
      "tensor([ 0.1073, -0.0512])\n",
      "pre:left true:left 7027/11700\n",
      "tensor([ 0.7466, -0.8263])\n",
      "pre:left true:left 7028/11700\n",
      "tensor([ 1.1973, -1.1362])\n",
      "pre:left true:left 7029/11700\n",
      "tensor([ 0.4531, -0.4997])\n",
      "pre:left true:left 7030/11700\n",
      "tensor([ 1.4343, -1.4544])\n",
      "pre:left true:left 7031/11700\n",
      "tensor([ 0.0857, -0.0811])\n",
      "pre:left true:left 7032/11700\n",
      "tensor([ 0.3671, -0.3295])\n",
      "pre:left true:left 7033/11700\n",
      "tensor([ 1.0868, -1.0765])\n",
      "pre:left true:left 7034/11700\n",
      "tensor([ 0.8706, -0.8270])\n",
      "pre:left true:left 7035/11700\n",
      "tensor([ 0.8819, -0.8635])\n",
      "pre:left true:left 7036/11700\n",
      "tensor([ 0.4563, -0.5519])\n",
      "pre:left true:left 7037/11700\n",
      "tensor([ 0.2428, -0.2468])\n",
      "pre:left true:left 7038/11700\n",
      "tensor([ 0.3500, -0.2913])\n",
      "pre:left true:left 7039/11700\n",
      "tensor([ 0.4444, -0.4164])\n",
      "pre:left true:left 7040/11700\n",
      "tensor([ 0.3841, -0.3358])\n",
      "pre:left true:left 7041/11700\n",
      "tensor([ 0.1294, -0.1920])\n",
      "pre:left true:left 7042/11700\n",
      "tensor([ 0.2736, -0.3719])\n",
      "pre:left true:left 7043/11700\n",
      "tensor([ 0.7864, -0.7733])\n",
      "pre:left true:left 7044/11700\n",
      "tensor([ 0.4419, -0.4735])\n",
      "pre:left true:left 7045/11700\n",
      "tensor([ 0.1432, -0.0752])\n",
      "pre:left true:left 7046/11700\n",
      "tensor([ 0.3941, -0.4248])\n",
      "pre:left true:left 7047/11700\n",
      "tensor([-0.0430,  0.0043])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左446_0_446_20200412_110724905.jpg\n",
      "pre:right true:left 7048/11700\n",
      "tensor([0.0160, 0.0155])\n",
      "pre:left true:left 7049/11700\n",
      "tensor([ 0.7861, -0.6863])\n",
      "pre:left true:left 7050/11700\n",
      "tensor([ 0.2328, -0.1863])\n",
      "pre:left true:left 7051/11700\n",
      "tensor([ 0.7930, -0.7995])\n",
      "pre:left true:left 7052/11700\n",
      "tensor([ 0.2006, -0.1162])\n",
      "pre:left true:left 7053/11700\n",
      "tensor([ 1.0732, -1.0318])\n",
      "pre:left true:left 7054/11700\n",
      "tensor([ 1.2783, -1.2420])\n",
      "pre:left true:left 7055/11700\n",
      "tensor([ 0.6717, -0.6855])\n",
      "pre:left true:left 7056/11700\n",
      "tensor([-0.0026,  0.0952])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左720_0_720_20200412_111355758.jpg\n",
      "pre:right true:left 7057/11700\n",
      "tensor([-0.1262,  0.0903])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左519_0_675_20200412_115011993_4.jpg\n",
      "pre:right true:left 7058/11700\n",
      "tensor([ 0.7719, -0.8137])\n",
      "pre:left true:left 7059/11700\n",
      "tensor([ 0.4286, -0.4696])\n",
      "pre:left true:left 7060/11700\n",
      "tensor([-1.1562,  1.3039])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左566_0_722_20200412_115113231_0.jpg\n",
      "pre:right true:left 7061/11700\n",
      "tensor([ 0.1789, -0.1022])\n",
      "pre:left true:left 7062/11700\n",
      "tensor([ 0.7006, -0.6662])\n",
      "pre:left true:left 7063/11700\n",
      "tensor([ 0.8786, -0.8322])\n",
      "pre:left true:left 7064/11700\n",
      "tensor([-0.3844,  0.4648])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左799_0_955_20200412_115616893_6.jpg\n",
      "pre:right true:left 7065/11700\n",
      "tensor([ 1.2365, -1.2465])\n",
      "pre:left true:left 7066/11700\n",
      "tensor([ 0.1676, -0.0592])\n",
      "pre:left true:left 7067/11700\n",
      "tensor([ 0.3047, -0.3629])\n",
      "pre:left true:left 7068/11700\n",
      "tensor([ 0.8749, -0.8302])\n",
      "pre:left true:left 7069/11700\n",
      "tensor([ 0.9758, -0.9305])\n",
      "pre:left true:left 7070/11700\n",
      "tensor([ 1.1486, -1.1731])\n",
      "pre:left true:left 7071/11700\n",
      "tensor([-0.1549,  0.2592])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左845_0_1001_20200412_115716845_8.jpg\n",
      "pre:right true:left 7072/11700\n",
      "tensor([ 0.8763, -0.9146])\n",
      "pre:left true:left 7073/11700\n",
      "tensor([ 1.1124, -1.0385])\n",
      "pre:left true:left 7074/11700\n",
      "tensor([ 0.4136, -0.4828])\n",
      "pre:left true:left 7075/11700\n",
      "tensor([ 0.4920, -0.4415])\n",
      "pre:left true:left 7076/11700\n",
      "tensor([ 1.3305, -1.2923])\n",
      "pre:left true:left 7077/11700\n",
      "tensor([ 0.3754, -0.4377])\n",
      "pre:left true:left 7078/11700\n",
      "tensor([ 0.8231, -0.7680])\n",
      "pre:left true:left 7079/11700\n",
      "tensor([ 0.1898, -0.1997])\n",
      "pre:left true:left 7080/11700\n",
      "tensor([ 0.9822, -0.9288])\n",
      "pre:left true:left 7081/11700\n",
      "tensor([ 0.9562, -0.9373])\n",
      "pre:left true:left 7082/11700\n",
      "tensor([-0.3791,  0.3386])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左320_0_476_20200412_114552663_5.jpg\n",
      "pre:right true:left 7083/11700\n",
      "tensor([ 0.2578, -0.3022])\n",
      "pre:left true:left 7084/11700\n",
      "tensor([ 0.2855, -0.3387])\n",
      "pre:left true:left 7085/11700\n",
      "tensor([ 0.7992, -0.7474])\n",
      "pre:left true:left 7086/11700\n",
      "tensor([ 0.2073, -0.2376])\n",
      "pre:left true:left 7087/11700\n",
      "tensor([ 0.9132, -0.9351])\n",
      "pre:left true:left 7088/11700\n",
      "tensor([ 0.2214, -0.3813])\n",
      "pre:left true:left 7089/11700\n",
      "tensor([ 0.2821, -0.1821])\n",
      "pre:left true:left 7090/11700\n",
      "tensor([ 0.1356, -0.0516])\n",
      "pre:left true:left 7091/11700\n",
      "tensor([ 0.2940, -0.3984])\n",
      "pre:left true:left 7092/11700\n",
      "tensor([ 0.2448, -0.2524])\n",
      "pre:left true:left 7093/11700\n",
      "tensor([ 0.5516, -0.5025])\n",
      "pre:left true:left 7094/11700\n",
      "tensor([ 0.2987, -0.3101])\n",
      "pre:left true:left 7095/11700\n",
      "tensor([ 0.5530, -0.6228])\n",
      "pre:left true:left 7096/11700\n",
      "tensor([ 0.6572, -0.6608])\n",
      "pre:left true:left 7097/11700\n",
      "tensor([ 0.5770, -0.5669])\n",
      "pre:left true:left 7098/11700\n",
      "tensor([ 0.3838, -0.2364])\n",
      "pre:left true:left 7099/11700\n",
      "tensor([ 0.3894, -0.4682])\n",
      "pre:left true:left 7100/11700\n",
      "tensor([ 0.4421, -0.3242])\n",
      "pre:left true:left 7101/11700\n",
      "tensor([ 0.9508, -1.0336])\n",
      "pre:left true:left 7102/11700\n",
      "tensor([0.0603, 0.0461])\n",
      "pre:left true:left 7103/11700\n",
      "tensor([ 0.5706, -0.5401])\n",
      "pre:left true:left 7104/11700\n",
      "tensor([ 1.2382, -1.3319])\n",
      "pre:left true:left 7105/11700\n",
      "tensor([ 0.6823, -0.6495])\n",
      "pre:left true:left 7106/11700\n",
      "tensor([ 0.5504, -0.5525])\n",
      "pre:left true:left 7107/11700\n",
      "tensor([ 0.9974, -1.0267])\n",
      "pre:left true:left 7108/11700\n",
      "tensor([ 0.0599, -0.1138])\n",
      "pre:left true:left 7109/11700\n",
      "tensor([-0.0361,  0.0325])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1078_0_1078_20200412_112206327.jpg\n",
      "pre:right true:left 7110/11700\n",
      "tensor([ 1.8044, -1.6941])\n",
      "pre:left true:left 7111/11700\n",
      "tensor([ 0.1755, -0.1949])\n",
      "pre:left true:left 7112/11700\n",
      "tensor([ 0.5310, -0.4641])\n",
      "pre:left true:left 7113/11700\n",
      "tensor([-0.0944,  0.1544])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左579_0_735_20200412_115130164_1.jpg\n",
      "pre:right true:left 7114/11700\n",
      "tensor([-0.3387,  0.3491])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左706_0_706_20200412_111335772_5.jpg\n",
      "pre:right true:left 7115/11700\n",
      "tensor([-0.3274,  0.4207])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1088_0_1088_20200412_112219368_3.jpg\n",
      "pre:right true:left 7116/11700\n",
      "tensor([ 0.4882, -0.3623])\n",
      "pre:left true:left 7117/11700\n",
      "tensor([ 0.2393, -0.1842])\n",
      "pre:left true:left 7118/11700\n",
      "tensor([ 0.2925, -0.3125])\n",
      "pre:left true:left 7119/11700\n",
      "tensor([ 0.9758, -0.9224])\n",
      "pre:left true:left 7120/11700\n",
      "tensor([ 0.2122, -0.1330])\n",
      "pre:left true:left 7121/11700\n",
      "tensor([ 0.4579, -0.3322])\n",
      "pre:left true:left 7122/11700\n",
      "tensor([ 0.3937, -0.4018])\n",
      "pre:left true:left 7123/11700\n",
      "tensor([ 0.5080, -0.4891])\n",
      "pre:left true:left 7124/11700\n",
      "tensor([ 0.2681, -0.2856])\n",
      "pre:left true:left 7125/11700\n",
      "tensor([ 0.2868, -0.3174])\n",
      "pre:left true:left 7126/11700\n",
      "tensor([ 0.4832, -0.4862])\n",
      "pre:left true:left 7127/11700\n",
      "tensor([ 1.5474, -1.5597])\n",
      "pre:left true:left 7128/11700\n",
      "tensor([ 0.8363, -0.8205])\n",
      "pre:left true:left 7129/11700\n",
      "tensor([-0.0714,  0.0664])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左657_0_657_20200412_111225902_5.jpg\n",
      "pre:right true:left 7130/11700\n",
      "tensor([ 1.4852, -1.3918])\n",
      "pre:left true:left 7131/11700\n",
      "tensor([ 0.5879, -0.5641])\n",
      "pre:left true:left 7132/11700\n",
      "tensor([0.0585, 0.0032])\n",
      "pre:left true:left 7133/11700\n",
      "tensor([ 0.7028, -0.7220])\n",
      "pre:left true:left 7134/11700\n",
      "tensor([ 0.7165, -0.7529])\n",
      "pre:left true:left 7135/11700\n",
      "tensor([-0.0553,  0.0549])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左482_0_638_20200412_114923761_2.jpg\n",
      "pre:right true:left 7136/11700\n",
      "tensor([ 0.6533, -0.7203])\n",
      "pre:left true:left 7137/11700\n",
      "tensor([ 0.4472, -0.3649])\n",
      "pre:left true:left 7138/11700\n",
      "tensor([ 0.8907, -0.8548])\n",
      "pre:left true:left 7139/11700\n",
      "tensor([ 0.1861, -0.1924])\n",
      "pre:left true:left 7140/11700\n",
      "tensor([ 0.6089, -0.5247])\n",
      "pre:left true:left 7141/11700\n",
      "tensor([ 0.6661, -0.5335])\n",
      "pre:left true:left 7142/11700\n",
      "tensor([-0.1748,  0.1876])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左421_0_577_20200412_114804268_1.jpg\n",
      "pre:right true:left 7143/11700\n",
      "tensor([ 0.7625, -0.6664])\n",
      "pre:left true:left 7144/11700\n",
      "tensor([ 1.3124, -1.2243])\n",
      "pre:left true:left 7145/11700\n",
      "tensor([ 0.2351, -0.2305])\n",
      "pre:left true:left 7146/11700\n",
      "tensor([ 0.6971, -0.7022])\n",
      "pre:left true:left 7147/11700\n",
      "tensor([ 0.9397, -1.0258])\n",
      "pre:left true:left 7148/11700\n",
      "tensor([ 0.2964, -0.3324])\n",
      "pre:left true:left 7149/11700\n",
      "tensor([ 0.0540, -0.0322])\n",
      "pre:left true:left 7150/11700\n",
      "tensor([ 1.0065, -1.0366])\n",
      "pre:left true:left 7151/11700\n",
      "tensor([ 0.8454, -0.9022])\n",
      "pre:left true:left 7152/11700\n",
      "tensor([ 0.7754, -0.7806])\n",
      "pre:left true:left 7153/11700\n",
      "tensor([ 0.5471, -0.5624])\n",
      "pre:left true:left 7154/11700\n",
      "tensor([ 1.2797, -1.1374])\n",
      "pre:left true:left 7155/11700\n",
      "tensor([ 0.3783, -0.3789])\n",
      "pre:left true:left 7156/11700\n",
      "tensor([ 0.9909, -1.0261])\n",
      "pre:left true:left 7157/11700\n",
      "tensor([ 0.4774, -0.4276])\n",
      "pre:left true:left 7158/11700\n",
      "tensor([ 0.6595, -0.7022])\n",
      "pre:left true:left 7159/11700\n",
      "tensor([ 0.8292, -0.9718])\n",
      "pre:left true:left 7160/11700\n",
      "tensor([ 0.2772, -0.2328])\n",
      "pre:left true:left 7161/11700\n",
      "tensor([ 0.8053, -0.8113])\n",
      "pre:left true:left 7162/11700\n",
      "tensor([ 0.5191, -0.4121])\n",
      "pre:left true:left 7163/11700\n",
      "tensor([ 0.1736, -0.1009])\n",
      "pre:left true:left 7164/11700\n",
      "tensor([ 0.1370, -0.1059])\n",
      "pre:left true:left 7165/11700\n",
      "tensor([ 0.7590, -0.6962])\n",
      "pre:left true:left 7166/11700\n",
      "tensor([ 0.5852, -0.5224])\n",
      "pre:left true:left 7167/11700\n",
      "tensor([ 0.5928, -0.6754])\n",
      "pre:left true:left 7168/11700\n",
      "tensor([ 0.8820, -0.8695])\n",
      "pre:left true:left 7169/11700\n",
      "tensor([-0.3116,  0.3185])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左716_0_716_20200412_111350037_7.jpg\n",
      "pre:right true:left 7170/11700\n",
      "tensor([ 0.1219, -0.1213])\n",
      "pre:left true:left 7171/11700\n",
      "tensor([ 0.1869, -0.1953])\n",
      "pre:left true:left 7172/11700\n",
      "tensor([-0.1231,  0.0920])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1448_0_1604_20200412_121022709.jpg\n",
      "pre:right true:left 7173/11700\n",
      "tensor([ 0.5059, -0.5711])\n",
      "pre:left true:left 7174/11700\n",
      "tensor([ 0.4735, -0.4867])\n",
      "pre:left true:left 7175/11700\n",
      "tensor([ 0.1680, -0.1720])\n",
      "pre:left true:left 7176/11700\n",
      "tensor([ 0.1228, -0.1029])\n",
      "pre:left true:left 7177/11700\n",
      "tensor([ 0.9406, -0.9968])\n",
      "pre:left true:left 7178/11700\n",
      "tensor([ 0.9760, -0.9978])\n",
      "pre:left true:left 7179/11700\n",
      "tensor([ 0.3786, -0.4726])\n",
      "pre:left true:left 7180/11700\n",
      "tensor([ 1.0261, -1.0909])\n",
      "pre:left true:left 7181/11700\n",
      "tensor([ 0.1354, -0.0659])\n",
      "pre:left true:left 7182/11700\n",
      "tensor([ 0.2058, -0.2747])\n",
      "pre:left true:left 7183/11700\n",
      "tensor([ 0.7536, -0.7355])\n",
      "pre:left true:left 7184/11700\n",
      "tensor([ 0.5630, -0.4182])\n",
      "pre:left true:left 7185/11700\n",
      "tensor([ 1.4992, -1.4530])\n",
      "pre:left true:left 7186/11700\n",
      "tensor([ 0.5456, -0.3817])\n",
      "pre:left true:left 7187/11700\n",
      "tensor([ 0.1747, -0.0161])\n",
      "pre:left true:left 7188/11700\n",
      "tensor([ 0.3660, -0.4266])\n",
      "pre:left true:left 7189/11700\n",
      "tensor([ 0.8187, -0.8159])\n",
      "pre:left true:left 7190/11700\n",
      "tensor([ 1.0407, -1.0063])\n",
      "pre:left true:left 7191/11700\n",
      "tensor([ 0.4065, -0.3772])\n",
      "pre:left true:left 7192/11700\n",
      "tensor([-0.1409,  0.1964])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左563_0_563_20200412_111011801_0.jpg\n",
      "pre:right true:left 7193/11700\n",
      "tensor([ 0.3938, -0.3032])\n",
      "pre:left true:left 7194/11700\n",
      "tensor([ 0.6570, -0.5841])\n",
      "pre:left true:left 7195/11700\n",
      "tensor([ 1.1814, -1.1103])\n",
      "pre:left true:left 7196/11700\n",
      "tensor([ 0.5096, -0.5068])\n",
      "pre:left true:left 7197/11700\n",
      "tensor([-0.4624,  0.5337])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左505_0_661_20200412_114953740_6.jpg\n",
      "pre:right true:left 7198/11700\n",
      "tensor([-0.2164,  0.2312])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左177_0_177_20200412_110101248_3.jpg\n",
      "pre:right true:left 7199/11700\n",
      "tensor([-0.1665,  0.1718])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左98_0_98_20200412_105908563_2.jpg\n",
      "pre:right true:left 7200/11700\n",
      "tensor([ 0.6968, -0.7457])\n",
      "pre:left true:left 7201/11700\n",
      "tensor([ 0.9147, -1.0315])\n",
      "pre:left true:left 7202/11700\n",
      "tensor([ 0.5242, -0.5249])\n",
      "pre:left true:left 7203/11700\n",
      "tensor([ 0.9891, -0.9978])\n",
      "pre:left true:left 7204/11700\n",
      "tensor([-0.1969,  0.2548])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1155_0_1311_20200412_120400838_6.jpg\n",
      "pre:right true:left 7205/11700\n",
      "tensor([ 1.1407, -1.1396])\n",
      "pre:left true:left 7206/11700\n",
      "tensor([0.0434, 0.0279])\n",
      "pre:left true:left 7207/11700\n",
      "tensor([ 0.2459, -0.2376])\n",
      "pre:left true:left 7208/11700\n",
      "tensor([ 0.7179, -0.6241])\n",
      "pre:left true:left 7209/11700\n",
      "tensor([ 0.1946, -0.2962])\n",
      "pre:left true:left 7210/11700\n",
      "tensor([ 0.7935, -0.8974])\n",
      "pre:left true:left 7211/11700\n",
      "tensor([ 1.0349, -0.9151])\n",
      "pre:left true:left 7212/11700\n",
      "tensor([ 0.5780, -0.5221])\n",
      "pre:left true:left 7213/11700\n",
      "tensor([ 0.6936, -0.6635])\n",
      "pre:left true:left 7214/11700\n",
      "tensor([ 0.9615, -0.8083])\n",
      "pre:left true:left 7215/11700\n",
      "tensor([ 0.1561, -0.1218])\n",
      "pre:left true:left 7216/11700\n",
      "tensor([ 0.7241, -0.7822])\n",
      "pre:left true:left 7217/11700\n",
      "tensor([ 1.4058, -1.4061])\n",
      "pre:left true:left 7218/11700\n",
      "tensor([ 0.1743, -0.2120])\n",
      "pre:left true:left 7219/11700\n",
      "tensor([-0.1662,  0.1763])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左517_0_673_20200412_115009379_7.jpg\n",
      "pre:right true:left 7220/11700\n",
      "tensor([ 0.6720, -0.7736])\n",
      "pre:left true:left 7221/11700\n",
      "tensor([-1.0601,  0.9545])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1526_0_1682_20200412_121204399_6.jpg\n",
      "pre:right true:left 7222/11700\n",
      "tensor([ 0.2763, -0.3007])\n",
      "pre:left true:left 7223/11700\n",
      "tensor([ 0.0628, -0.1158])\n",
      "pre:left true:left 7224/11700\n",
      "tensor([ 0.3474, -0.3612])\n",
      "pre:left true:left 7225/11700\n",
      "tensor([ 1.0699, -0.9848])\n",
      "pre:left true:left 7226/11700\n",
      "tensor([ 0.8650, -0.8950])\n",
      "pre:left true:left 7227/11700\n",
      "tensor([ 0.6813, -0.6865])\n",
      "pre:left true:left 7228/11700\n",
      "tensor([ 0.5247, -0.6064])\n",
      "pre:left true:left 7229/11700\n",
      "tensor([ 1.1021, -1.0520])\n",
      "pre:left true:left 7230/11700\n",
      "tensor([ 0.9263, -0.8489])\n",
      "pre:left true:left 7231/11700\n",
      "tensor([ 1.0303, -1.0511])\n",
      "pre:left true:left 7232/11700\n",
      "tensor([-0.0106, -0.0294])\n",
      "pre:left true:left 7233/11700\n",
      "tensor([ 0.8843, -0.7872])\n",
      "pre:left true:left 7234/11700\n",
      "tensor([ 0.0061, -0.0191])\n",
      "pre:left true:left 7235/11700\n",
      "tensor([ 0.5026, -0.5048])\n",
      "pre:left true:left 7236/11700\n",
      "tensor([-0.3328,  0.2848])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1331_0_1487_20200412_120750217_9.jpg\n",
      "pre:right true:left 7237/11700\n",
      "tensor([ 0.8292, -0.8167])\n",
      "pre:left true:left 7238/11700\n",
      "tensor([ 0.3600, -0.2228])\n",
      "pre:left true:left 7239/11700\n",
      "tensor([ 1.2372, -1.2763])\n",
      "pre:left true:left 7240/11700\n",
      "tensor([ 0.9116, -0.9373])\n",
      "pre:left true:left 7241/11700\n",
      "tensor([ 1.1855, -1.2551])\n",
      "pre:left true:left 7242/11700\n",
      "tensor([ 0.7551, -0.7428])\n",
      "pre:left true:left 7243/11700\n",
      "tensor([0.0905, 0.0129])\n",
      "pre:left true:left 7244/11700\n",
      "tensor([ 0.4218, -0.3893])\n",
      "pre:left true:left 7245/11700\n",
      "tensor([ 0.3564, -0.4493])\n",
      "pre:left true:left 7246/11700\n",
      "tensor([-0.1876,  0.2022])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1504_0_1660_20200412_121135709_5.jpg\n",
      "pre:right true:left 7247/11700\n",
      "tensor([ 0.7676, -0.7406])\n",
      "pre:left true:left 7248/11700\n",
      "tensor([ 0.6716, -0.6432])\n",
      "pre:left true:left 7249/11700\n",
      "tensor([-0.3716,  0.4261])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左109_0_265_20200412_114117712_8.jpg\n",
      "pre:right true:left 7250/11700\n",
      "tensor([ 0.5469, -0.5713])\n",
      "pre:left true:left 7251/11700\n",
      "tensor([ 0.5648, -0.6051])\n",
      "pre:left true:left 7252/11700\n",
      "tensor([-0.1622,  0.1151])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1574_0_1730_20200412_121306937_10.jpg\n",
      "pre:right true:left 7253/11700\n",
      "tensor([ 0.5190, -0.4916])\n",
      "pre:left true:left 7254/11700\n",
      "tensor([ 0.5913, -0.5951])\n",
      "pre:left true:left 7255/11700\n",
      "tensor([ 0.9892, -0.9892])\n",
      "pre:left true:left 7256/11700\n",
      "tensor([ 0.3521, -0.3170])\n",
      "pre:left true:left 7257/11700\n",
      "tensor([ 1.2752, -1.2978])\n",
      "pre:left true:left 7258/11700\n",
      "tensor([ 0.1186, -0.0726])\n",
      "pre:left true:left 7259/11700\n",
      "tensor([ 1.0085, -1.0430])\n",
      "pre:left true:left 7260/11700\n",
      "tensor([-0.1428,  0.0546])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左512_0_512_20200412_110859050_3.jpg\n",
      "pre:right true:left 7261/11700\n",
      "tensor([ 0.3563, -0.3163])\n",
      "pre:left true:left 7262/11700\n",
      "tensor([ 0.5045, -0.4934])\n",
      "pre:left true:left 7263/11700\n",
      "tensor([ 0.3791, -0.3416])\n",
      "pre:left true:left 7264/11700\n",
      "tensor([ 1.0121, -0.9735])\n",
      "pre:left true:left 7265/11700\n",
      "tensor([ 0.3217, -0.3055])\n",
      "pre:left true:left 7266/11700\n",
      "tensor([ 1.0973, -1.0208])\n",
      "pre:left true:left 7267/11700\n",
      "tensor([ 1.5386, -1.3762])\n",
      "pre:left true:left 7268/11700\n",
      "tensor([ 0.5553, -0.5717])\n",
      "pre:left true:left 7269/11700\n",
      "tensor([ 1.3115, -1.3595])\n",
      "pre:left true:left 7270/11700\n",
      "tensor([ 0.6503, -0.6336])\n",
      "pre:left true:left 7271/11700\n",
      "tensor([ 0.7911, -0.8584])\n",
      "pre:left true:left 7272/11700\n",
      "tensor([ 0.2675, -0.3085])\n",
      "pre:left true:left 7273/11700\n",
      "tensor([ 0.6056, -0.6218])\n",
      "pre:left true:left 7274/11700\n",
      "tensor([ 0.8350, -0.7433])\n",
      "pre:left true:left 7275/11700\n",
      "tensor([ 0.7173, -0.7307])\n",
      "pre:left true:left 7276/11700\n",
      "tensor([ 0.7382, -0.7350])\n",
      "pre:left true:left 7277/11700\n",
      "tensor([ 0.5837, -0.5445])\n",
      "pre:left true:left 7278/11700\n",
      "tensor([ 0.7025, -0.5917])\n",
      "pre:left true:left 7279/11700\n",
      "tensor([ 0.4359, -0.4191])\n",
      "pre:left true:left 7280/11700\n",
      "tensor([ 0.6702, -0.6529])\n",
      "pre:left true:left 7281/11700\n",
      "tensor([ 0.4056, -0.3571])\n",
      "pre:left true:left 7282/11700\n",
      "tensor([ 0.4518, -0.3859])\n",
      "pre:left true:left 7283/11700\n",
      "tensor([ 0.4928, -0.5014])\n",
      "pre:left true:left 7284/11700\n",
      "tensor([ 0.4298, -0.3339])\n",
      "pre:left true:left 7285/11700\n",
      "tensor([ 1.5525, -1.4926])\n",
      "pre:left true:left 7286/11700\n",
      "tensor([ 0.6487, -0.5884])\n",
      "pre:left true:left 7287/11700\n",
      "tensor([ 0.5930, -0.5827])\n",
      "pre:left true:left 7288/11700\n",
      "tensor([ 1.2450, -1.3827])\n",
      "pre:left true:left 7289/11700\n",
      "tensor([ 0.7194, -0.6445])\n",
      "pre:left true:left 7290/11700\n",
      "tensor([ 0.3853, -0.3887])\n",
      "pre:left true:left 7291/11700\n",
      "tensor([ 0.2371, -0.1148])\n",
      "pre:left true:left 7292/11700\n",
      "tensor([ 0.2110, -0.2541])\n",
      "pre:left true:left 7293/11700\n",
      "tensor([ 0.2964, -0.2590])\n",
      "pre:left true:left 7294/11700\n",
      "tensor([ 0.0748, -0.0244])\n",
      "pre:left true:left 7295/11700\n",
      "tensor([ 0.6179, -0.5927])\n",
      "pre:left true:left 7296/11700\n",
      "tensor([ 0.1552, -0.1200])\n",
      "pre:left true:left 7297/11700\n",
      "tensor([ 0.1697, -0.1431])\n",
      "pre:left true:left 7298/11700\n",
      "tensor([ 0.7485, -0.7351])\n",
      "pre:left true:left 7299/11700\n",
      "tensor([ 0.5991, -0.6199])\n",
      "pre:left true:left 7300/11700\n",
      "tensor([ 0.3008, -0.2338])\n",
      "pre:left true:left 7301/11700\n",
      "tensor([ 1.2644, -1.2919])\n",
      "pre:left true:left 7302/11700\n",
      "tensor([ 0.2743, -0.1993])\n",
      "pre:left true:left 7303/11700\n",
      "tensor([ 0.2071, -0.2862])\n",
      "pre:left true:left 7304/11700\n",
      "tensor([ 0.3873, -0.5020])\n",
      "pre:left true:left 7305/11700\n",
      "tensor([ 0.8760, -0.7891])\n",
      "pre:left true:left 7306/11700\n",
      "tensor([ 0.7467, -0.7439])\n",
      "pre:left true:left 7307/11700\n",
      "tensor([ 0.8174, -0.8643])\n",
      "pre:left true:left 7308/11700\n",
      "tensor([ 0.3153, -0.2518])\n",
      "pre:left true:left 7309/11700\n",
      "tensor([ 0.3174, -0.3271])\n",
      "pre:left true:left 7310/11700\n",
      "tensor([ 0.4130, -0.3801])\n",
      "pre:left true:left 7311/11700\n",
      "tensor([ 0.3494, -0.4089])\n",
      "pre:left true:left 7312/11700\n",
      "tensor([-0.0333,  0.0089])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左580_0_736_20200412_115131473.jpg\n",
      "pre:right true:left 7313/11700\n",
      "tensor([ 0.4125, -0.4127])\n",
      "pre:left true:left 7314/11700\n",
      "tensor([ 0.2230, -0.2317])\n",
      "pre:left true:left 7315/11700\n",
      "tensor([ 0.9583, -0.9099])\n",
      "pre:left true:left 7316/11700\n",
      "tensor([-0.9789,  0.9736])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左344_0_500_20200412_114623927_0.jpg\n",
      "pre:right true:left 7317/11700\n",
      "tensor([ 0.7855, -0.7834])\n",
      "pre:left true:left 7318/11700\n",
      "tensor([ 0.1979, -0.2205])\n",
      "pre:left true:left 7319/11700\n",
      "tensor([ 0.0548, -0.1987])\n",
      "pre:left true:left 7320/11700\n",
      "tensor([ 0.1975, -0.1987])\n",
      "pre:left true:left 7321/11700\n",
      "tensor([ 0.2755, -0.1920])\n",
      "pre:left true:left 7322/11700\n",
      "tensor([ 0.9376, -0.8391])\n",
      "pre:left true:left 7323/11700\n",
      "tensor([ 0.4668, -0.4185])\n",
      "pre:left true:left 7324/11700\n",
      "tensor([ 0.5287, -0.5587])\n",
      "pre:left true:left 7325/11700\n",
      "tensor([ 0.9105, -0.9014])\n",
      "pre:left true:left 7326/11700\n",
      "tensor([ 1.7182, -1.7205])\n",
      "pre:left true:left 7327/11700\n",
      "tensor([-0.1499,  0.1931])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左381_0_381_20200412_110552198_9.jpg\n",
      "pre:right true:left 7328/11700\n",
      "tensor([ 0.3597, -0.4410])\n",
      "pre:left true:left 7329/11700\n",
      "tensor([ 1.5201, -1.5688])\n",
      "pre:left true:left 7330/11700\n",
      "tensor([ 0.7229, -0.7546])\n",
      "pre:left true:left 7331/11700\n",
      "tensor([ 0.7066, -0.7201])\n",
      "pre:left true:left 7332/11700\n",
      "tensor([ 0.7642, -0.7675])\n",
      "pre:left true:left 7333/11700\n",
      "tensor([ 1.5330, -1.5804])\n",
      "pre:left true:left 7334/11700\n",
      "tensor([ 0.8199, -0.5962])\n",
      "pre:left true:left 7335/11700\n",
      "tensor([ 0.2699, -0.1924])\n",
      "pre:left true:left 7336/11700\n",
      "tensor([ 0.8692, -0.8736])\n",
      "pre:left true:left 7337/11700\n",
      "tensor([ 0.5264, -0.6129])\n",
      "pre:left true:left 7338/11700\n",
      "tensor([ 0.8801, -0.8040])\n",
      "pre:left true:left 7339/11700\n",
      "tensor([ 1.0502, -0.9936])\n",
      "pre:left true:left 7340/11700\n",
      "tensor([ 1.2570, -1.2385])\n",
      "pre:left true:left 7341/11700\n",
      "tensor([ 0.2241, -0.2444])\n",
      "pre:left true:left 7342/11700\n",
      "tensor([-0.4177,  0.3833])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1297_0_1453_20200412_120705914_10.jpg\n",
      "pre:right true:left 7343/11700\n",
      "tensor([ 0.7128, -0.6531])\n",
      "pre:left true:left 7344/11700\n",
      "tensor([0.0177, 0.0043])\n",
      "pre:left true:left 7345/11700\n",
      "tensor([-0.2989,  0.3228])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1340_0_1340_20200412_112757673_1.jpg\n",
      "pre:right true:left 7346/11700\n",
      "tensor([ 0.0246, -0.0717])\n",
      "pre:left true:left 7347/11700\n",
      "tensor([0.0462, 0.0110])\n",
      "pre:left true:left 7348/11700\n",
      "tensor([ 1.5936, -1.5708])\n",
      "pre:left true:left 7349/11700\n",
      "tensor([-0.0853,  0.1369])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左924_0_924_20200412_111845702_1.jpg\n",
      "pre:right true:left 7350/11700\n",
      "tensor([ 1.4976, -1.6422])\n",
      "pre:left true:left 7351/11700\n",
      "tensor([ 0.6122, -0.6600])\n",
      "pre:left true:left 7352/11700\n",
      "tensor([ 0.2501, -0.2625])\n",
      "pre:left true:left 7353/11700\n",
      "tensor([-0.4643,  0.5013])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1286_0_1286_20200412_112637374_1.jpg\n",
      "pre:right true:left 7354/11700\n",
      "tensor([ 0.4034, -0.3236])\n",
      "pre:left true:left 7355/11700\n",
      "tensor([ 0.7787, -0.7899])\n",
      "pre:left true:left 7356/11700\n",
      "tensor([ 0.7631, -0.7231])\n",
      "pre:left true:left 7357/11700\n",
      "tensor([ 1.0333, -0.9815])\n",
      "pre:left true:left 7358/11700\n",
      "tensor([ 0.3015, -0.2670])\n",
      "pre:left true:left 7359/11700\n",
      "tensor([ 0.3907, -0.2679])\n",
      "pre:left true:left 7360/11700\n",
      "tensor([ 0.6909, -0.6756])\n",
      "pre:left true:left 7361/11700\n",
      "tensor([ 0.1669, -0.2203])\n",
      "pre:left true:left 7362/11700\n",
      "tensor([ 0.6524, -0.6638])\n",
      "pre:left true:left 7363/11700\n",
      "tensor([ 0.0790, -0.0056])\n",
      "pre:left true:left 7364/11700\n",
      "tensor([ 0.0830, -0.1137])\n",
      "pre:left true:left 7365/11700\n",
      "tensor([ 0.7424, -0.7829])\n",
      "pre:left true:left 7366/11700\n",
      "tensor([0.0043, 0.0538])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左270_0_426_20200412_114447496_1.jpg\n",
      "pre:right true:left 7367/11700\n",
      "tensor([ 1.2619, -1.2603])\n",
      "pre:left true:left 7368/11700\n",
      "tensor([ 0.3141, -0.3182])\n",
      "pre:left true:left 7369/11700\n",
      "tensor([ 0.2472, -0.2709])\n",
      "pre:left true:left 7370/11700\n",
      "tensor([ 0.3197, -0.3578])\n",
      "pre:left true:left 7371/11700\n",
      "tensor([ 0.5242, -0.4184])\n",
      "pre:left true:left 7372/11700\n",
      "tensor([ 0.5246, -0.5141])\n",
      "pre:left true:left 7373/11700\n",
      "tensor([ 0.2890, -0.2461])\n",
      "pre:left true:left 7374/11700\n",
      "tensor([ 0.9494, -0.9212])\n",
      "pre:left true:left 7375/11700\n",
      "tensor([-0.1009,  0.0705])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左628_0_784_20200412_115234036_4.jpg\n",
      "pre:right true:left 7376/11700\n",
      "tensor([ 0.5165, -0.5404])\n",
      "pre:left true:left 7377/11700\n",
      "tensor([ 0.9334, -0.9693])\n",
      "pre:left true:left 7378/11700\n",
      "tensor([ 0.7931, -0.8634])\n",
      "pre:left true:left 7379/11700\n",
      "tensor([ 0.3251, -0.2291])\n",
      "pre:left true:left 7380/11700\n",
      "tensor([ 0.1088, -0.1034])\n",
      "pre:left true:left 7381/11700\n",
      "tensor([ 1.4725, -1.4318])\n",
      "pre:left true:left 7382/11700\n",
      "tensor([ 0.6437, -0.6882])\n",
      "pre:left true:left 7383/11700\n",
      "tensor([ 0.5857, -0.4668])\n",
      "pre:left true:left 7384/11700\n",
      "tensor([ 0.6903, -0.6045])\n",
      "pre:left true:left 7385/11700\n",
      "tensor([ 0.8030, -0.7950])\n",
      "pre:left true:left 7386/11700\n",
      "tensor([ 0.2925, -0.3313])\n",
      "pre:left true:left 7387/11700\n",
      "tensor([ 0.6615, -0.6600])\n",
      "pre:left true:left 7388/11700\n",
      "tensor([ 0.5016, -0.4422])\n",
      "pre:left true:left 7389/11700\n",
      "tensor([ 0.9822, -0.9288])\n",
      "pre:left true:left 7390/11700\n",
      "tensor([ 0.6148, -0.6788])\n",
      "pre:left true:left 7391/11700\n",
      "tensor([-0.3324,  0.3996])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1589_0_1745_20200412_121326516.jpg\n",
      "pre:right true:left 7392/11700\n",
      "tensor([ 0.2924, -0.2361])\n",
      "pre:left true:left 7393/11700\n",
      "tensor([ 0.6479, -0.6593])\n",
      "pre:left true:left 7394/11700\n",
      "tensor([0.0420, 0.0858])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左658_0_814_20200412_115313134.jpg\n",
      "pre:right true:left 7395/11700\n",
      "tensor([ 0.5857, -0.5281])\n",
      "pre:left true:left 7396/11700\n",
      "tensor([ 0.2249, -0.2334])\n",
      "pre:left true:left 7397/11700\n",
      "tensor([ 0.3582, -0.3451])\n",
      "pre:left true:left 7398/11700\n",
      "tensor([ 0.6598, -0.6653])\n",
      "pre:left true:left 7399/11700\n",
      "tensor([ 0.4733, -0.5172])\n",
      "pre:left true:left 7400/11700\n",
      "tensor([ 0.3140, -0.2940])\n",
      "pre:left true:left 7401/11700\n",
      "tensor([ 0.1560, -0.2593])\n",
      "pre:left true:left 7402/11700\n",
      "tensor([ 0.7513, -0.7318])\n",
      "pre:left true:left 7403/11700\n",
      "tensor([ 0.6719, -0.5942])\n",
      "pre:left true:left 7404/11700\n",
      "tensor([ 0.4294, -0.3584])\n",
      "pre:left true:left 7405/11700\n",
      "tensor([ 0.4869, -0.4829])\n",
      "pre:left true:left 7406/11700\n",
      "tensor([ 0.9807, -0.8135])\n",
      "pre:left true:left 7407/11700\n",
      "tensor([ 0.6243, -0.6104])\n",
      "pre:left true:left 7408/11700\n",
      "tensor([ 0.5380, -0.5383])\n",
      "pre:left true:left 7409/11700\n",
      "tensor([ 0.5326, -0.5839])\n",
      "pre:left true:left 7410/11700\n",
      "tensor([ 1.2123, -1.2546])\n",
      "pre:left true:left 7411/11700\n",
      "tensor([ 0.9218, -0.8654])\n",
      "pre:left true:left 7412/11700\n",
      "tensor([ 1.4104, -1.4068])\n",
      "pre:left true:left 7413/11700\n",
      "tensor([ 0.4120, -0.4515])\n",
      "pre:left true:left 7414/11700\n",
      "tensor([ 1.5044, -1.5958])\n",
      "pre:left true:left 7415/11700\n",
      "tensor([ 1.4765, -1.3976])\n",
      "pre:left true:left 7416/11700\n",
      "tensor([ 0.2707, -0.1869])\n",
      "pre:left true:left 7417/11700\n",
      "tensor([ 0.1441, -0.0044])\n",
      "pre:left true:left 7418/11700\n",
      "tensor([ 0.1413, -0.1214])\n",
      "pre:left true:left 7419/11700\n",
      "tensor([ 0.5712, -0.5729])\n",
      "pre:left true:left 7420/11700\n",
      "tensor([ 0.2990, -0.3691])\n",
      "pre:left true:left 7421/11700\n",
      "tensor([ 0.2943, -0.1683])\n",
      "pre:left true:left 7422/11700\n",
      "tensor([-0.6223,  0.7193])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左981_0_981_20200412_111959966_7.jpg\n",
      "pre:right true:left 7423/11700\n",
      "tensor([ 0.8154, -0.6838])\n",
      "pre:left true:left 7424/11700\n",
      "tensor([ 0.6228, -0.5848])\n",
      "pre:left true:left 7425/11700\n",
      "tensor([ 0.7169, -0.7771])\n",
      "pre:left true:left 7426/11700\n",
      "tensor([-0.5321,  0.5396])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左519_0_675_20200412_115011993_8.jpg\n",
      "pre:right true:left 7427/11700\n",
      "tensor([-0.2862,  0.3745])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左321_0_321_20200412_105600268.jpg\n",
      "pre:right true:left 7428/11700\n",
      "tensor([ 0.2423, -0.2544])\n",
      "pre:left true:left 7429/11700\n",
      "tensor([ 0.6323, -0.6266])\n",
      "pre:left true:left 7430/11700\n",
      "tensor([ 0.3589, -0.4062])\n",
      "pre:left true:left 7431/11700\n",
      "tensor([ 0.9447, -0.9640])\n",
      "pre:left true:left 7432/11700\n",
      "tensor([-0.1684,  0.2128])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左625_0_781_20200412_115230120_10.jpg\n",
      "pre:right true:left 7433/11700\n",
      "tensor([ 0.1124, -0.0254])\n",
      "pre:left true:left 7434/11700\n",
      "tensor([0.0899, 0.1384])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左552_0_708_20200412_115054990_4.jpg\n",
      "pre:right true:left 7435/11700\n",
      "tensor([ 0.6366, -0.6286])\n",
      "pre:left true:left 7436/11700\n",
      "tensor([ 0.5551, -0.6172])\n",
      "pre:left true:left 7437/11700\n",
      "tensor([ 0.5094, -0.5684])\n",
      "pre:left true:left 7438/11700\n",
      "tensor([ 0.6966, -0.6491])\n",
      "pre:left true:left 7439/11700\n",
      "tensor([-0.2466,  0.3800])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左166_0_166_20200412_110045563_6.jpg\n",
      "pre:right true:left 7440/11700\n",
      "tensor([ 0.6061, -0.6579])\n",
      "pre:left true:left 7441/11700\n",
      "tensor([ 0.6274, -0.6097])\n",
      "pre:left true:left 7442/11700\n",
      "tensor([-0.1944,  0.2431])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1407_0_1563_20200412_120929273_7.jpg\n",
      "pre:right true:left 7443/11700\n",
      "tensor([ 0.7897, -0.8050])\n",
      "pre:left true:left 7444/11700\n",
      "tensor([ 0.3396, -0.2917])\n",
      "pre:left true:left 7445/11700\n",
      "tensor([0.0004, 0.0691])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左741_0_741_20200412_111425707_9.jpg\n",
      "pre:right true:left 7446/11700\n",
      "tensor([-0.3730,  0.3756])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左522_0_678_20200412_115015870.jpg\n",
      "pre:right true:left 7447/11700\n",
      "tensor([ 0.1994, -0.2239])\n",
      "pre:left true:left 7448/11700\n",
      "tensor([ 0.8155, -0.6064])\n",
      "pre:left true:left 7449/11700\n",
      "tensor([-0.4071,  0.4364])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左551_0_707_20200412_115053685.jpg\n",
      "pre:right true:left 7450/11700\n",
      "tensor([ 0.4490, -0.4435])\n",
      "pre:left true:left 7451/11700\n",
      "tensor([-0.0991,  0.0582])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左704_0_704_20200412_111332923_4.jpg\n",
      "pre:right true:left 7452/11700\n",
      "tensor([-0.3068,  0.2825])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1081_0_1081_20200412_112210244_5.jpg\n",
      "pre:right true:left 7453/11700\n",
      "tensor([ 0.4509, -0.3546])\n",
      "pre:left true:left 7454/11700\n",
      "tensor([ 0.9001, -0.8555])\n",
      "pre:left true:left 7455/11700\n",
      "tensor([ 0.0603, -0.1807])\n",
      "pre:left true:left 7456/11700\n",
      "tensor([ 0.6335, -0.5141])\n",
      "pre:left true:left 7457/11700\n",
      "tensor([ 0.1745, -0.1500])\n",
      "pre:left true:left 7458/11700\n",
      "tensor([ 0.5713, -0.4950])\n",
      "pre:left true:left 7459/11700\n",
      "tensor([ 0.7751, -0.9654])\n",
      "pre:left true:left 7460/11700\n",
      "tensor([-0.8853,  0.8227])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左596_0_752_20200412_115152325_2.jpg\n",
      "pre:right true:left 7461/11700\n",
      "tensor([ 0.6604, -0.6336])\n",
      "pre:left true:left 7462/11700\n",
      "tensor([ 0.5999, -0.5979])\n",
      "pre:left true:left 7463/11700\n",
      "tensor([ 0.9928, -0.9229])\n",
      "pre:left true:left 7464/11700\n",
      "tensor([ 0.8045, -0.7217])\n",
      "pre:left true:left 7465/11700\n",
      "tensor([-0.1495,  0.1806])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左606_0_606_20200412_111113150_10.jpg\n",
      "pre:right true:left 7466/11700\n",
      "tensor([ 0.9164, -0.8867])\n",
      "pre:left true:left 7467/11700\n",
      "tensor([ 0.6878, -0.6848])\n",
      "pre:left true:left 7468/11700\n",
      "tensor([ 0.5542, -0.5708])\n",
      "pre:left true:left 7469/11700\n",
      "tensor([ 0.5962, -0.6704])\n",
      "pre:left true:left 7470/11700\n",
      "tensor([ 0.4886, -0.3200])\n",
      "pre:left true:left 7471/11700\n",
      "tensor([ 1.4938, -1.5186])\n",
      "pre:left true:left 7472/11700\n",
      "tensor([ 0.5202, -0.5500])\n",
      "pre:left true:left 7473/11700\n",
      "tensor([ 0.6031, -0.6181])\n",
      "pre:left true:left 7474/11700\n",
      "tensor([ 0.8332, -0.7830])\n",
      "pre:left true:left 7475/11700\n",
      "tensor([ 0.7064, -0.8287])\n",
      "pre:left true:left 7476/11700\n",
      "tensor([ 0.8842, -0.9002])\n",
      "pre:left true:left 7477/11700\n",
      "tensor([ 0.6277, -0.6049])\n",
      "pre:left true:left 7478/11700\n",
      "tensor([-0.3307,  0.4120])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左456_0_456_20200412_110739162_9.jpg\n",
      "pre:right true:left 7479/11700\n",
      "tensor([ 0.2528, -0.1604])\n",
      "pre:left true:left 7480/11700\n",
      "tensor([ 0.9691, -1.0046])\n",
      "pre:left true:left 7481/11700\n",
      "tensor([ 0.3589, -0.4475])\n",
      "pre:left true:left 7482/11700\n",
      "tensor([ 0.9721, -0.9351])\n",
      "pre:left true:left 7483/11700\n",
      "tensor([ 0.2250, -0.1746])\n",
      "pre:left true:left 7484/11700\n",
      "tensor([ 0.7673, -0.8010])\n",
      "pre:left true:left 7485/11700\n",
      "tensor([ 1.2419, -1.2321])\n",
      "pre:left true:left 7486/11700\n",
      "tensor([ 0.1917, -0.1150])\n",
      "pre:left true:left 7487/11700\n",
      "tensor([-0.0157,  0.1508])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左595_0_751_20200412_115151022_3.jpg\n",
      "pre:right true:left 7488/11700\n",
      "tensor([ 0.0289, -0.0094])\n",
      "pre:left true:left 7489/11700\n",
      "tensor([ 0.3477, -0.3288])\n",
      "pre:left true:left 7490/11700\n",
      "tensor([-0.0601,  0.0959])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1497_0_1653_20200412_121126589_4.jpg\n",
      "pre:right true:left 7491/11700\n",
      "tensor([ 0.7914, -0.7367])\n",
      "pre:left true:left 7492/11700\n",
      "tensor([ 1.0155, -0.9884])\n",
      "pre:left true:left 7493/11700\n",
      "tensor([-0.4788,  0.4468])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左606_0_762_20200412_115205352_7.jpg\n",
      "pre:right true:left 7494/11700\n",
      "tensor([ 0.7768, -0.8551])\n",
      "pre:left true:left 7495/11700\n",
      "tensor([ 0.7248, -0.7169])\n",
      "pre:left true:left 7496/11700\n",
      "tensor([ 0.2032, -0.2160])\n",
      "pre:left true:left 7497/11700\n",
      "tensor([ 1.1071, -1.1378])\n",
      "pre:left true:left 7498/11700\n",
      "tensor([ 0.5724, -0.5895])\n",
      "pre:left true:left 7499/11700\n",
      "tensor([ 0.6299, -0.5504])\n",
      "pre:left true:left 7500/11700\n",
      "tensor([ 0.1532, -0.2429])\n",
      "pre:left true:left 7501/11700\n",
      "tensor([ 0.4960, -0.4374])\n",
      "pre:left true:left 7502/11700\n",
      "tensor([ 0.5271, -0.5340])\n",
      "pre:left true:left 7503/11700\n",
      "tensor([ 0.7226, -0.7135])\n",
      "pre:left true:left 7504/11700\n",
      "tensor([ 0.3225, -0.3172])\n",
      "pre:left true:left 7505/11700\n",
      "tensor([ 0.1522, -0.1529])\n",
      "pre:left true:left 7506/11700\n",
      "tensor([ 0.5970, -0.6176])\n",
      "pre:left true:left 7507/11700\n",
      "tensor([ 0.1194, -0.0687])\n",
      "pre:left true:left 7508/11700\n",
      "tensor([ 0.4151, -0.4214])\n",
      "pre:left true:left 7509/11700\n",
      "tensor([ 0.7452, -0.7614])\n",
      "pre:left true:left 7510/11700\n",
      "tensor([ 0.5994, -0.5491])\n",
      "pre:left true:left 7511/11700\n",
      "tensor([ 0.6278, -0.6372])\n",
      "pre:left true:left 7512/11700\n",
      "tensor([-0.5061,  0.5055])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1552_0_1708_20200412_121238312_6.jpg\n",
      "pre:right true:left 7513/11700\n",
      "tensor([ 0.9001, -0.9125])\n",
      "pre:left true:left 7514/11700\n",
      "tensor([ 0.7567, -0.7992])\n",
      "pre:left true:left 7515/11700\n",
      "tensor([-0.1466,  0.1399])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左917_0_917_20200412_111836594.jpg\n",
      "pre:right true:left 7516/11700\n",
      "tensor([ 1.1378, -1.1514])\n",
      "pre:left true:left 7517/11700\n",
      "tensor([ 0.7691, -0.8147])\n",
      "pre:left true:left 7518/11700\n",
      "tensor([-0.5713,  0.6174])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1291_0_1291_20200412_112643889.jpg\n",
      "pre:right true:left 7519/11700\n",
      "tensor([ 0.8755, -0.9236])\n",
      "pre:left true:left 7520/11700\n",
      "tensor([ 0.6423, -0.6656])\n",
      "pre:left true:left 7521/11700\n",
      "tensor([ 0.7846, -0.7018])\n",
      "pre:left true:left 7522/11700\n",
      "tensor([ 0.6497, -0.6711])\n",
      "pre:left true:left 7523/11700\n",
      "tensor([-0.1162,  0.1463])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左407_0_407_20200412_110629294_2.jpg\n",
      "pre:right true:left 7524/11700\n",
      "tensor([ 1.0823, -0.9807])\n",
      "pre:left true:left 7525/11700\n",
      "tensor([ 1.0908, -1.0821])\n",
      "pre:left true:left 7526/11700\n",
      "tensor([ 0.3947, -0.3715])\n",
      "pre:left true:left 7527/11700\n",
      "tensor([ 0.6433, -0.5184])\n",
      "pre:left true:left 7528/11700\n",
      "tensor([ 0.5466, -0.5348])\n",
      "pre:left true:left 7529/11700\n",
      "tensor([ 1.0692, -1.0570])\n",
      "pre:left true:left 7530/11700\n",
      "tensor([ 0.7580, -0.8157])\n",
      "pre:left true:left 7531/11700\n",
      "tensor([-0.2340,  0.1898])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1177_0_1177_20200412_112415330_3.jpg\n",
      "pre:right true:left 7532/11700\n",
      "tensor([ 0.7508, -0.7791])\n",
      "pre:left true:left 7533/11700\n",
      "tensor([ 0.3501, -0.2285])\n",
      "pre:left true:left 7534/11700\n",
      "tensor([ 0.4189, -0.3227])\n",
      "pre:left true:left 7535/11700\n",
      "tensor([ 1.3976, -1.3399])\n",
      "pre:left true:left 7536/11700\n",
      "tensor([ 0.7940, -0.7412])\n",
      "pre:left true:left 7537/11700\n",
      "tensor([ 0.6581, -0.6306])\n",
      "pre:left true:left 7538/11700\n",
      "tensor([ 1.2431, -1.2519])\n",
      "pre:left true:left 7539/11700\n",
      "tensor([-0.1973,  0.2282])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左643_0_799_20200412_115253573_5.jpg\n",
      "pre:right true:left 7540/11700\n",
      "tensor([ 0.8009, -0.7254])\n",
      "pre:left true:left 7541/11700\n",
      "tensor([ 0.9194, -0.9914])\n",
      "pre:left true:left 7542/11700\n",
      "tensor([ 0.1411, -0.1085])\n",
      "pre:left true:left 7543/11700\n",
      "tensor([-0.5282,  0.4926])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左725_0_881_20200412_115440452_8.jpg\n",
      "pre:right true:left 7544/11700\n",
      "tensor([ 0.2250, -0.1484])\n",
      "pre:left true:left 7545/11700\n",
      "tensor([-0.0914,  0.0605])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左280_0_280_20200412_110328165.jpg\n",
      "pre:right true:left 7546/11700\n",
      "tensor([-0.4083,  0.3341])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1207_0_1207_20200412_112454432_0.jpg\n",
      "pre:right true:left 7547/11700\n",
      "tensor([ 0.4134, -0.3507])\n",
      "pre:left true:left 7548/11700\n",
      "tensor([ 0.0595, -0.0870])\n",
      "pre:left true:left 7549/11700\n",
      "tensor([ 1.0738, -1.0695])\n",
      "pre:left true:left 7550/11700\n",
      "tensor([ 0.1624, -0.0681])\n",
      "pre:left true:left 7551/11700\n",
      "tensor([ 0.6882, -0.7129])\n",
      "pre:left true:left 7552/11700\n",
      "tensor([0.0093, 0.0660])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左661_0_661_20200412_111231607.jpg\n",
      "pre:right true:left 7553/11700\n",
      "tensor([ 0.4021, -0.2533])\n",
      "pre:left true:left 7554/11700\n",
      "tensor([ 0.9097, -0.9238])\n",
      "pre:left true:left 7555/11700\n",
      "tensor([ 0.9296, -0.8617])\n",
      "pre:left true:left 7556/11700\n",
      "tensor([-0.0196,  0.0165])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左844_0_1000_20200412_115715544_10.jpg\n",
      "pre:right true:left 7557/11700\n",
      "tensor([0.0390, 0.0795])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1303_0_1303_20200412_112659539_9.jpg\n",
      "pre:right true:left 7558/11700\n",
      "tensor([ 0.5333, -0.3834])\n",
      "pre:left true:left 7559/11700\n",
      "tensor([ 0.3149, -0.2081])\n",
      "pre:left true:left 7560/11700\n",
      "tensor([ 1.0098, -0.9780])\n",
      "pre:left true:left 7561/11700\n",
      "tensor([ 0.8656, -0.8739])\n",
      "pre:left true:left 7562/11700\n",
      "tensor([ 0.3606, -0.4080])\n",
      "pre:left true:left 7563/11700\n",
      "tensor([ 1.4365, -1.5348])\n",
      "pre:left true:left 7564/11700\n",
      "tensor([ 1.1413, -1.1274])\n",
      "pre:left true:left 7565/11700\n",
      "tensor([ 0.6943, -0.6778])\n",
      "pre:left true:left 7566/11700\n",
      "tensor([ 0.1823, -0.1142])\n",
      "pre:left true:left 7567/11700\n",
      "tensor([ 1.1228, -1.0145])\n",
      "pre:left true:left 7568/11700\n",
      "tensor([ 0.5486, -0.4675])\n",
      "pre:left true:left 7569/11700\n",
      "tensor([ 0.6243, -0.5949])\n",
      "pre:left true:left 7570/11700\n",
      "tensor([ 0.7652, -0.7568])\n",
      "pre:left true:left 7571/11700\n",
      "tensor([ 1.1352, -1.1115])\n",
      "pre:left true:left 7572/11700\n",
      "tensor([ 0.3968, -0.3251])\n",
      "pre:left true:left 7573/11700\n",
      "tensor([ 0.7481, -0.5447])\n",
      "pre:left true:left 7574/11700\n",
      "tensor([-0.0118,  0.0050])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左273_0_273_20200412_105502724_8.jpg\n",
      "pre:right true:left 7575/11700\n",
      "tensor([ 0.8884, -0.8634])\n",
      "pre:left true:left 7576/11700\n",
      "tensor([ 1.0380, -0.9869])\n",
      "pre:left true:left 7577/11700\n",
      "tensor([ 0.6367, -0.6365])\n",
      "pre:left true:left 7578/11700\n",
      "tensor([ 0.2196, -0.2295])\n",
      "pre:left true:left 7579/11700\n",
      "tensor([-0.3774,  0.4481])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左526_0_682_20200412_115021100.jpg\n",
      "pre:right true:left 7580/11700\n",
      "tensor([ 0.4779, -0.3978])\n",
      "pre:left true:left 7581/11700\n",
      "tensor([ 0.6919, -0.5534])\n",
      "pre:left true:left 7582/11700\n",
      "tensor([ 0.5222, -0.5417])\n",
      "pre:left true:left 7583/11700\n",
      "tensor([ 0.7664, -0.7186])\n",
      "pre:left true:left 7584/11700\n",
      "tensor([ 0.2722, -0.3523])\n",
      "pre:left true:left 7585/11700\n",
      "tensor([ 0.4449, -0.5152])\n",
      "pre:left true:left 7586/11700\n",
      "tensor([ 0.1856, -0.1311])\n",
      "pre:left true:left 7587/11700\n",
      "tensor([ 1.4118, -1.4916])\n",
      "pre:left true:left 7588/11700\n",
      "tensor([ 1.0782, -1.1309])\n",
      "pre:left true:left 7589/11700\n",
      "tensor([ 0.4427, -0.4971])\n",
      "pre:left true:left 7590/11700\n",
      "tensor([ 0.2279, -0.2790])\n",
      "pre:left true:left 7591/11700\n",
      "tensor([ 0.6661, -0.6263])\n",
      "pre:left true:left 7592/11700\n",
      "tensor([ 0.6878, -0.6823])\n",
      "pre:left true:left 7593/11700\n",
      "tensor([ 0.7984, -0.8714])\n",
      "pre:left true:left 7594/11700\n",
      "tensor([ 0.2384, -0.2413])\n",
      "pre:left true:left 7595/11700\n",
      "tensor([ 0.5354, -0.5219])\n",
      "pre:left true:left 7596/11700\n",
      "tensor([ 1.2440, -1.1834])\n",
      "pre:left true:left 7597/11700\n",
      "tensor([ 0.4521, -0.4666])\n",
      "pre:left true:left 7598/11700\n",
      "tensor([ 0.5184, -0.5922])\n",
      "pre:left true:left 7599/11700\n",
      "tensor([ 0.1341, -0.1309])\n",
      "pre:left true:left 7600/11700\n",
      "tensor([ 0.3906, -0.3371])\n",
      "pre:left true:left 7601/11700\n",
      "tensor([ 1.0971, -1.0669])\n",
      "pre:left true:left 7602/11700\n",
      "tensor([ 0.3949, -0.4429])\n",
      "pre:left true:left 7603/11700\n",
      "tensor([ 0.4633, -0.2714])\n",
      "pre:left true:left 7604/11700\n",
      "tensor([ 0.4367, -0.5034])\n",
      "pre:left true:left 7605/11700\n",
      "tensor([ 0.6480, -0.5730])\n",
      "pre:left true:left 7606/11700\n",
      "tensor([ 0.8182, -0.6917])\n",
      "pre:left true:left 7607/11700\n",
      "tensor([ 0.3699, -0.3675])\n",
      "pre:left true:left 7608/11700\n",
      "tensor([-0.1296,  0.2572])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左277_0_277_20200412_110323869_10.jpg\n",
      "pre:right true:left 7609/11700\n",
      "tensor([ 0.8749, -0.9686])\n",
      "pre:left true:left 7610/11700\n",
      "tensor([ 0.6911, -0.6081])\n",
      "pre:left true:left 7611/11700\n",
      "tensor([ 1.7594, -1.6484])\n",
      "pre:left true:left 7612/11700\n",
      "tensor([-0.1249,  0.1872])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1201_0_1357_20200412_120500803_3.jpg\n",
      "pre:right true:left 7613/11700\n",
      "tensor([ 0.3148, -0.2763])\n",
      "pre:left true:left 7614/11700\n",
      "tensor([ 0.3084, -0.3480])\n",
      "pre:left true:left 7615/11700\n",
      "tensor([ 0.2913, -0.2493])\n",
      "pre:left true:left 7616/11700\n",
      "tensor([-0.3436,  0.2790])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左643_0_799_20200412_115253573_3.jpg\n",
      "pre:right true:left 7617/11700\n",
      "tensor([ 0.1439, -0.0634])\n",
      "pre:left true:left 7618/11700\n",
      "tensor([ 1.3124, -1.2243])\n",
      "pre:left true:left 7619/11700\n",
      "tensor([ 0.3664, -0.3512])\n",
      "pre:left true:left 7620/11700\n",
      "tensor([ 0.5076, -0.4056])\n",
      "pre:left true:left 7621/11700\n",
      "tensor([ 0.2473, -0.2710])\n",
      "pre:left true:left 7622/11700\n",
      "tensor([-0.2720,  0.2425])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左831_0_987_20200412_115658606_7.jpg\n",
      "pre:right true:left 7623/11700\n",
      "tensor([ 0.5625, -0.6801])\n",
      "pre:left true:left 7624/11700\n",
      "tensor([ 0.9752, -0.9460])\n",
      "pre:left true:left 7625/11700\n",
      "tensor([ 0.3235, -0.3957])\n",
      "pre:left true:left 7626/11700\n",
      "tensor([-0.3563,  0.3988])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1562_0_1718_20200412_121251317_1.jpg\n",
      "pre:right true:left 7627/11700\n",
      "tensor([ 0.5869, -0.5801])\n",
      "pre:left true:left 7628/11700\n",
      "tensor([ 1.1640, -1.1858])\n",
      "pre:left true:left 7629/11700\n",
      "tensor([ 0.3193, -0.2894])\n",
      "pre:left true:left 7630/11700\n",
      "tensor([-0.3692,  0.4031])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左412_0_412_20200412_110636409_2.jpg\n",
      "pre:right true:left 7631/11700\n",
      "tensor([ 0.3196, -0.3183])\n",
      "pre:left true:left 7632/11700\n",
      "tensor([ 0.8124, -0.7921])\n",
      "pre:left true:left 7633/11700\n",
      "tensor([-2.0163,  1.9804])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左747_0_903_20200412_115509118_6.jpg\n",
      "pre:right true:left 7634/11700\n",
      "tensor([-0.3690,  0.3638])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左270_0_426_20200412_114447496.jpg\n",
      "pre:right true:left 7635/11700\n",
      "tensor([ 0.4755, -0.4914])\n",
      "pre:left true:left 7636/11700\n",
      "tensor([ 0.1834, -0.1436])\n",
      "pre:left true:left 7637/11700\n",
      "tensor([ 0.5447, -0.6032])\n",
      "pre:left true:left 7638/11700\n",
      "tensor([ 0.5355, -0.5599])\n",
      "pre:left true:left 7639/11700\n",
      "tensor([ 0.8008, -0.8059])\n",
      "pre:left true:left 7640/11700\n",
      "tensor([ 0.5965, -0.6270])\n",
      "pre:left true:left 7641/11700\n",
      "tensor([ 0.5525, -0.5863])\n",
      "pre:left true:left 7642/11700\n",
      "tensor([ 0.0856, -0.0582])\n",
      "pre:left true:left 7643/11700\n",
      "tensor([ 1.5968, -1.6418])\n",
      "pre:left true:left 7644/11700\n",
      "tensor([ 0.1261, -0.1973])\n",
      "pre:left true:left 7645/11700\n",
      "tensor([ 0.4039, -0.3826])\n",
      "pre:left true:left 7646/11700\n",
      "tensor([ 0.8634, -0.9108])\n",
      "pre:left true:left 7647/11700\n",
      "tensor([ 0.8497, -0.7797])\n",
      "pre:left true:left 7648/11700\n",
      "tensor([ 0.9102, -0.8546])\n",
      "pre:left true:left 7649/11700\n",
      "tensor([ 0.9678, -0.9194])\n",
      "pre:left true:left 7650/11700\n",
      "tensor([ 0.2594, -0.2734])\n",
      "pre:left true:left 7651/11700\n",
      "tensor([ 1.1848, -1.2367])\n",
      "pre:left true:left 7652/11700\n",
      "tensor([ 0.5745, -0.5220])\n",
      "pre:left true:left 7653/11700\n",
      "tensor([ 1.4929, -1.4545])\n",
      "pre:left true:left 7654/11700\n",
      "tensor([ 0.7050, -0.6729])\n",
      "pre:left true:left 7655/11700\n",
      "tensor([ 0.7816, -0.7558])\n",
      "pre:left true:left 7656/11700\n",
      "tensor([ 0.4899, -0.4623])\n",
      "pre:left true:left 7657/11700\n",
      "tensor([ 0.7567, -0.4959])\n",
      "pre:left true:left 7658/11700\n",
      "tensor([ 0.4209, -0.4150])\n",
      "pre:left true:left 7659/11700\n",
      "tensor([ 1.4361, -1.4088])\n",
      "pre:left true:left 7660/11700\n",
      "tensor([-0.7110,  0.8118])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左773_0_773_20200412_111511346_2.jpg\n",
      "pre:right true:left 7661/11700\n",
      "tensor([ 0.9594, -1.0727])\n",
      "pre:left true:left 7662/11700\n",
      "tensor([ 0.7810, -0.7917])\n",
      "pre:left true:left 7663/11700\n",
      "tensor([0.0045, 0.0250])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左346_0_502_20200412_114626545_3.jpg\n",
      "pre:right true:left 7664/11700\n",
      "tensor([ 0.5319, -0.5654])\n",
      "pre:left true:left 7665/11700\n",
      "tensor([ 0.6403, -0.7163])\n",
      "pre:left true:left 7666/11700\n",
      "tensor([ 0.7217, -0.7748])\n",
      "pre:left true:left 7667/11700\n",
      "tensor([ 0.8655, -0.8810])\n",
      "pre:left true:left 7668/11700\n",
      "tensor([ 0.6017, -0.5082])\n",
      "pre:left true:left 7669/11700\n",
      "tensor([-0.8777,  0.8399])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左608_0_764_20200412_115207969_5.jpg\n",
      "pre:right true:left 7670/11700\n",
      "tensor([ 0.8928, -1.0086])\n",
      "pre:left true:left 7671/11700\n",
      "tensor([ 0.5056, -0.4884])\n",
      "pre:left true:left 7672/11700\n",
      "tensor([ 0.4321, -0.4426])\n",
      "pre:left true:left 7673/11700\n",
      "tensor([-0.6147,  0.6291])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左659_0_815_20200412_115314448_2.jpg\n",
      "pre:right true:left 7674/11700\n",
      "tensor([-0.2172,  0.2649])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左415_0_571_20200412_114756452_9.jpg\n",
      "pre:right true:left 7675/11700\n",
      "tensor([ 0.4577, -0.5073])\n",
      "pre:left true:left 7676/11700\n",
      "tensor([ 0.3162, -0.2879])\n",
      "pre:left true:left 7677/11700\n",
      "tensor([ 1.1377, -1.0780])\n",
      "pre:left true:left 7678/11700\n",
      "tensor([ 0.2219, -0.2841])\n",
      "pre:left true:left 7679/11700\n",
      "tensor([ 0.7411, -0.7356])\n",
      "pre:left true:left 7680/11700\n",
      "tensor([ 1.4808, -1.4243])\n",
      "pre:left true:left 7681/11700\n",
      "tensor([ 0.1347, -0.0396])\n",
      "pre:left true:left 7682/11700\n",
      "tensor([ 0.5985, -0.5360])\n",
      "pre:left true:left 7683/11700\n",
      "tensor([ 0.6504, -0.6017])\n",
      "pre:left true:left 7684/11700\n",
      "tensor([ 0.4310, -0.4045])\n",
      "pre:left true:left 7685/11700\n",
      "tensor([-0.2086,  0.2516])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左633_0_789_20200412_115240544_3.jpg\n",
      "pre:right true:left 7686/11700\n",
      "tensor([ 0.9167, -0.8174])\n",
      "pre:left true:left 7687/11700\n",
      "tensor([ 0.7573, -0.8009])\n",
      "pre:left true:left 7688/11700\n",
      "tensor([ 0.8481, -0.7420])\n",
      "pre:left true:left 7689/11700\n",
      "tensor([ 0.3572, -0.3360])\n",
      "pre:left true:left 7690/11700\n",
      "tensor([-0.1992,  0.1654])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左862_0_1018_20200412_115739004.jpg\n",
      "pre:right true:left 7691/11700\n",
      "tensor([ 0.6401, -0.6950])\n",
      "pre:left true:left 7692/11700\n",
      "tensor([ 0.8315, -0.7742])\n",
      "pre:left true:left 7693/11700\n",
      "tensor([ 0.5822, -0.5605])\n",
      "pre:left true:left 7694/11700\n",
      "tensor([ 1.3208, -1.2750])\n",
      "pre:left true:left 7695/11700\n",
      "tensor([-0.1727,  0.0959])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左637_0_793_20200412_115245771_3.jpg\n",
      "pre:right true:left 7696/11700\n",
      "tensor([ 0.1851, -0.0660])\n",
      "pre:left true:left 7697/11700\n",
      "tensor([ 0.4701, -0.3956])\n",
      "pre:left true:left 7698/11700\n",
      "tensor([ 0.6459, -0.5493])\n",
      "pre:left true:left 7699/11700\n",
      "tensor([ 1.2013, -1.1675])\n",
      "pre:left true:left 7700/11700\n",
      "tensor([0.0360, 0.0133])\n",
      "pre:left true:left 7701/11700\n",
      "tensor([ 0.4284, -0.4906])\n",
      "pre:left true:left 7702/11700\n",
      "tensor([-0.2351,  0.3773])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左346_0_502_20200412_114626545_9.jpg\n",
      "pre:right true:left 7703/11700\n",
      "tensor([ 0.6457, -0.5796])\n",
      "pre:left true:left 7704/11700\n",
      "tensor([ 0.1488, -0.1689])\n",
      "pre:left true:left 7705/11700\n",
      "tensor([ 0.5016, -0.4422])\n",
      "pre:left true:left 7706/11700\n",
      "tensor([ 1.7668, -1.8868])\n",
      "pre:left true:left 7707/11700\n",
      "tensor([-0.0454,  0.1462])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1450_0_1606_20200412_121025327_4.jpg\n",
      "pre:right true:left 7708/11700\n",
      "tensor([ 1.0476, -1.0844])\n",
      "pre:left true:left 7709/11700\n",
      "tensor([ 0.8475, -0.8372])\n",
      "pre:left true:left 7710/11700\n",
      "tensor([ 0.2317, -0.2185])\n",
      "pre:left true:left 7711/11700\n",
      "tensor([-0.1766,  0.1392])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左429_0_585_20200412_114814696_9.jpg\n",
      "pre:right true:left 7712/11700\n",
      "tensor([ 1.0331, -1.0058])\n",
      "pre:left true:left 7713/11700\n",
      "tensor([ 0.4723, -0.4304])\n",
      "pre:left true:left 7714/11700\n",
      "tensor([ 0.7757, -0.6965])\n",
      "pre:left true:left 7715/11700\n",
      "tensor([ 0.8852, -0.9689])\n",
      "pre:left true:left 7716/11700\n",
      "tensor([ 0.0453, -0.1158])\n",
      "pre:left true:left 7717/11700\n",
      "tensor([ 1.1011, -1.1774])\n",
      "pre:left true:left 7718/11700\n",
      "tensor([ 1.0607, -1.1238])\n",
      "pre:left true:left 7719/11700\n",
      "tensor([ 0.7726, -0.8303])\n",
      "pre:left true:left 7720/11700\n",
      "tensor([ 0.7966, -0.7827])\n",
      "pre:left true:left 7721/11700\n",
      "tensor([ 0.4699, -0.5870])\n",
      "pre:left true:left 7722/11700\n",
      "tensor([ 0.6590, -0.7069])\n",
      "pre:left true:left 7723/11700\n",
      "tensor([ 0.3037, -0.3751])\n",
      "pre:left true:left 7724/11700\n",
      "tensor([ 0.4705, -0.5205])\n",
      "pre:left true:left 7725/11700\n",
      "tensor([ 0.3202, -0.3416])\n",
      "pre:left true:left 7726/11700\n",
      "tensor([ 0.8302, -0.7902])\n",
      "pre:left true:left 7727/11700\n",
      "tensor([ 0.4804, -0.4431])\n",
      "pre:left true:left 7728/11700\n",
      "tensor([ 0.7831, -0.7670])\n",
      "pre:left true:left 7729/11700\n",
      "tensor([ 0.0571, -0.0814])\n",
      "pre:left true:left 7730/11700\n",
      "tensor([ 0.5792, -0.5459])\n",
      "pre:left true:left 7731/11700\n",
      "tensor([ 0.4096, -0.5207])\n",
      "pre:left true:left 7732/11700\n",
      "tensor([ 0.4299, -0.5188])\n",
      "pre:left true:left 7733/11700\n",
      "tensor([ 1.4619, -1.3843])\n",
      "pre:left true:left 7734/11700\n",
      "tensor([-0.4403,  0.4183])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1617_0_1773_20200412_121402989_4.jpg\n",
      "pre:right true:left 7735/11700\n",
      "tensor([ 0.4420, -0.4455])\n",
      "pre:left true:left 7736/11700\n",
      "tensor([ 0.6973, -0.7526])\n",
      "pre:left true:left 7737/11700\n",
      "tensor([-0.3263,  0.3265])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左990_0_990_20200412_112011687_6.jpg\n",
      "pre:right true:left 7738/11700\n",
      "tensor([ 1.3547, -1.2629])\n",
      "pre:left true:left 7739/11700\n",
      "tensor([ 0.3743, -0.3568])\n",
      "pre:left true:left 7740/11700\n",
      "tensor([ 0.2013, -0.1621])\n",
      "pre:left true:left 7741/11700\n",
      "tensor([-0.0450,  0.1845])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1155_0_1311_20200412_120400838_5.jpg\n",
      "pre:right true:left 7742/11700\n",
      "tensor([ 0.8910, -0.7947])\n",
      "pre:left true:left 7743/11700\n",
      "tensor([ 1.6988, -1.7960])\n",
      "pre:left true:left 7744/11700\n",
      "tensor([-0.9933,  1.1026])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左309_0_465_20200412_114538314_4.jpg\n",
      "pre:right true:left 7745/11700\n",
      "tensor([ 0.4837, -0.4357])\n",
      "pre:left true:left 7746/11700\n",
      "tensor([ 0.4588, -0.4098])\n",
      "pre:left true:left 7747/11700\n",
      "tensor([ 0.2452, -0.2380])\n",
      "pre:left true:left 7748/11700\n",
      "tensor([ 1.0267, -1.0342])\n",
      "pre:left true:left 7749/11700\n",
      "tensor([ 0.2991, -0.3114])\n",
      "pre:left true:left 7750/11700\n",
      "tensor([ 0.7024, -0.7124])\n",
      "pre:left true:left 7751/11700\n",
      "tensor([ 0.7780, -0.7949])\n",
      "pre:left true:left 7752/11700\n",
      "tensor([ 0.5942, -0.5066])\n",
      "pre:left true:left 7753/11700\n",
      "tensor([-0.1508,  0.2606])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1113_0_1113_20200412_112251946_4.jpg\n",
      "pre:right true:left 7754/11700\n",
      "tensor([-0.3215,  0.3940])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左264_0_420_20200412_114439693_5.jpg\n",
      "pre:right true:left 7755/11700\n",
      "tensor([ 0.2504, -0.2871])\n",
      "pre:left true:left 7756/11700\n",
      "tensor([ 0.9040, -0.8432])\n",
      "pre:left true:left 7757/11700\n",
      "tensor([ 0.9401, -0.8911])\n",
      "pre:left true:left 7758/11700\n",
      "tensor([ 0.2615, -0.1527])\n",
      "pre:left true:left 7759/11700\n",
      "tensor([-0.1615,  0.0995])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1273_0_1273_20200412_112620448_1.jpg\n",
      "pre:right true:left 7760/11700\n",
      "tensor([ 0.2877, -0.3360])\n",
      "pre:left true:left 7761/11700\n",
      "tensor([ 1.1448, -1.0905])\n",
      "pre:left true:left 7762/11700\n",
      "tensor([-0.1536,  0.2599])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左774_0_930_20200412_115544313_5.jpg\n",
      "pre:right true:left 7763/11700\n",
      "tensor([ 0.3723, -0.3110])\n",
      "pre:left true:left 7764/11700\n",
      "tensor([ 0.7530, -0.8157])\n",
      "pre:left true:left 7765/11700\n",
      "tensor([ 1.2303, -1.2366])\n",
      "pre:left true:left 7766/11700\n",
      "tensor([ 0.5045, -0.4813])\n",
      "pre:left true:left 7767/11700\n",
      "tensor([ 0.8588, -0.7813])\n",
      "pre:left true:left 7768/11700\n",
      "tensor([ 0.5689, -0.5247])\n",
      "pre:left true:left 7769/11700\n",
      "tensor([-0.7639,  0.7560])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左375_0_531_20200412_114704342_10.jpg\n",
      "pre:right true:left 7770/11700\n",
      "tensor([ 0.0246, -0.0694])\n",
      "pre:left true:left 7771/11700\n",
      "tensor([ 0.4442, -0.3619])\n",
      "pre:left true:left 7772/11700\n",
      "tensor([ 0.0527, -0.0434])\n",
      "pre:left true:left 7773/11700\n",
      "tensor([ 0.5442, -0.6272])\n",
      "pre:left true:left 7774/11700\n",
      "tensor([ 0.2220, -0.1619])\n",
      "pre:left true:left 7775/11700\n",
      "tensor([ 0.1820, -0.1699])\n",
      "pre:left true:left 7776/11700\n",
      "tensor([ 1.1011, -1.1774])\n",
      "pre:left true:left 7777/11700\n",
      "tensor([ 0.9794, -0.9289])\n",
      "pre:left true:left 7778/11700\n",
      "tensor([ 1.1454, -1.1706])\n",
      "pre:left true:left 7779/11700\n",
      "tensor([ 0.5557, -0.5182])\n",
      "pre:left true:left 7780/11700\n",
      "tensor([ 0.5102, -0.5065])\n",
      "pre:left true:left 7781/11700\n",
      "tensor([ 1.3614, -1.2700])\n",
      "pre:left true:left 7782/11700\n",
      "tensor([-0.0596,  0.1015])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左820_0_976_20200412_115644262_4.jpg\n",
      "pre:right true:left 7783/11700\n",
      "tensor([ 0.3846, -0.3011])\n",
      "pre:left true:left 7784/11700\n",
      "tensor([ 0.2195, -0.2393])\n",
      "pre:left true:left 7785/11700\n",
      "tensor([ 0.2007, -0.2048])\n",
      "pre:left true:left 7786/11700\n",
      "tensor([ 0.0408, -0.0202])\n",
      "pre:left true:left 7787/11700\n",
      "tensor([ 0.7116, -0.5680])\n",
      "pre:left true:left 7788/11700\n",
      "tensor([-0.0479,  0.0606])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左592_0_748_20200412_115147113_8.jpg\n",
      "pre:right true:left 7789/11700\n",
      "tensor([ 1.1590, -1.2299])\n",
      "pre:left true:left 7790/11700\n",
      "tensor([ 1.3313, -1.3169])\n",
      "pre:left true:left 7791/11700\n",
      "tensor([ 0.2151, -0.0366])\n",
      "pre:left true:left 7792/11700\n",
      "tensor([ 0.3299, -0.2880])\n",
      "pre:left true:left 7793/11700\n",
      "tensor([ 0.6021, -0.5926])\n",
      "pre:left true:left 7794/11700\n",
      "tensor([-0.0274, -0.0263])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左786_0_942_20200412_115559966_4.jpg\n",
      "pre:right true:left 7795/11700\n",
      "tensor([ 0.5716, -0.5696])\n",
      "pre:left true:left 7796/11700\n",
      "tensor([ 0.7789, -0.8804])\n",
      "pre:left true:left 7797/11700\n",
      "tensor([ 0.3394, -0.4404])\n",
      "pre:left true:left 7798/11700\n",
      "tensor([ 0.5179, -0.4924])\n",
      "pre:left true:left 7799/11700\n",
      "tensor([ 1.9198, -1.7862])\n",
      "pre:left true:left 7800/11700\n",
      "tensor([ 0.4501, -0.4577])\n",
      "pre:left true:left 7801/11700\n",
      "tensor([-0.1617,  0.2355])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左787_0_943_20200412_115601257_9.jpg\n",
      "pre:right true:left 7802/11700\n",
      "tensor([0.0142, 0.0092])\n",
      "pre:left true:left 7803/11700\n",
      "tensor([ 0.0577, -0.1188])\n",
      "pre:left true:left 7804/11700\n",
      "tensor([ 0.7319, -0.7665])\n",
      "pre:left true:left 7805/11700\n",
      "tensor([-0.1451,  0.0924])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左447_0_603_20200412_114838168_10.jpg\n",
      "pre:right true:left 7806/11700\n",
      "tensor([ 0.2406, -0.1720])\n",
      "pre:left true:left 7807/11700\n",
      "tensor([ 0.7142, -0.7056])\n",
      "pre:left true:left 7808/11700\n",
      "tensor([ 0.4161, -0.3674])\n",
      "pre:left true:left 7809/11700\n",
      "tensor([-0.1347,  0.1227])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左704_0_860_20200412_115413083_8.jpg\n",
      "pre:right true:left 7810/11700\n",
      "tensor([ 1.9308, -1.9403])\n",
      "pre:left true:left 7811/11700\n",
      "tensor([ 1.3837, -1.4135])\n",
      "pre:left true:left 7812/11700\n",
      "tensor([-0.6629,  0.7769])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左808_0_964_20200412_115628626_10.jpg\n",
      "pre:right true:left 7813/11700\n",
      "tensor([ 0.6546, -0.4685])\n",
      "pre:left true:left 7814/11700\n",
      "tensor([ 0.0745, -0.0517])\n",
      "pre:left true:left 7815/11700\n",
      "tensor([ 0.8335, -0.8013])\n",
      "pre:left true:left 7816/11700\n",
      "tensor([ 0.8960, -0.9108])\n",
      "pre:left true:left 7817/11700\n",
      "tensor([ 0.5735, -0.4926])\n",
      "pre:left true:left 7818/11700\n",
      "tensor([ 0.6034, -0.6532])\n",
      "pre:left true:left 7819/11700\n",
      "tensor([ 0.2741, -0.2922])\n",
      "pre:left true:left 7820/11700\n",
      "tensor([-0.5398,  0.6345])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1302_0_1302_20200412_112658222_3.jpg\n",
      "pre:right true:left 7821/11700\n",
      "tensor([ 0.7724, -0.7086])\n",
      "pre:left true:left 7822/11700\n",
      "tensor([ 0.5732, -0.4759])\n",
      "pre:left true:left 7823/11700\n",
      "tensor([ 0.4036, -0.2847])\n",
      "pre:left true:left 7824/11700\n",
      "tensor([ 0.8839, -0.8487])\n",
      "pre:left true:left 7825/11700\n",
      "tensor([ 1.2929, -1.3179])\n",
      "pre:left true:left 7826/11700\n",
      "tensor([ 0.4785, -0.5257])\n",
      "pre:left true:left 7827/11700\n",
      "tensor([ 0.7636, -0.7997])\n",
      "pre:left true:left 7828/11700\n",
      "tensor([ 0.5328, -0.5406])\n",
      "pre:left true:left 7829/11700\n",
      "tensor([ 1.5348, -1.4835])\n",
      "pre:left true:left 7830/11700\n",
      "tensor([ 0.6171, -0.5650])\n",
      "pre:left true:left 7831/11700\n",
      "tensor([ 1.0313, -1.0078])\n",
      "pre:left true:left 7832/11700\n",
      "tensor([ 0.4816, -0.4951])\n",
      "pre:left true:left 7833/11700\n",
      "tensor([ 0.8190, -0.8076])\n",
      "pre:left true:left 7834/11700\n",
      "tensor([ 1.2533, -1.2529])\n",
      "pre:left true:left 7835/11700\n",
      "tensor([ 0.6806, -0.8067])\n",
      "pre:left true:left 7836/11700\n",
      "tensor([ 0.5147, -0.4181])\n",
      "pre:left true:left 7837/11700\n",
      "tensor([ 0.6942, -0.7217])\n",
      "pre:left true:left 7838/11700\n",
      "tensor([ 0.3709, -0.3547])\n",
      "pre:left true:left 7839/11700\n",
      "tensor([ 0.5295, -0.5076])\n",
      "pre:left true:left 7840/11700\n",
      "tensor([ 0.1809, -0.2080])\n",
      "pre:left true:left 7841/11700\n",
      "tensor([ 0.6197, -0.5303])\n",
      "pre:left true:left 7842/11700\n",
      "tensor([ 0.4124, -0.3296])\n",
      "pre:left true:left 7843/11700\n",
      "tensor([-0.6280,  0.6468])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左654_0_810_20200412_115307919_7.jpg\n",
      "pre:right true:left 7844/11700\n",
      "tensor([ 0.5342, -0.4631])\n",
      "pre:left true:left 7845/11700\n",
      "tensor([ 0.2696, -0.3348])\n",
      "pre:left true:left 7846/11700\n",
      "tensor([ 0.9779, -1.0314])\n",
      "pre:left true:left 7847/11700\n",
      "tensor([ 1.0315, -0.9893])\n",
      "pre:left true:left 7848/11700\n",
      "tensor([ 0.4510, -0.3546])\n",
      "pre:left true:left 7849/11700\n",
      "tensor([ 0.5346, -0.5437])\n",
      "pre:left true:left 7850/11700\n",
      "tensor([0.0016, 0.0921])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左351_0_507_20200412_114633054_9.jpg\n",
      "pre:right true:left 7851/11700\n",
      "tensor([ 0.3644, -0.3541])\n",
      "pre:left true:left 7852/11700\n",
      "tensor([-0.0710,  0.0303])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左387_0_543_20200412_114719968_7.jpg\n",
      "pre:right true:left 7853/11700\n",
      "tensor([ 1.1269, -1.1267])\n",
      "pre:left true:left 7854/11700\n",
      "tensor([0.0434, 0.0195])\n",
      "pre:left true:left 7855/11700\n",
      "tensor([-0.2073,  0.2765])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左524_0_680_20200412_115018501_6.jpg\n",
      "pre:right true:left 7856/11700\n",
      "tensor([ 0.1711, -0.2080])\n",
      "pre:left true:left 7857/11700\n",
      "tensor([ 0.0281, -0.0177])\n",
      "pre:left true:left 7858/11700\n",
      "tensor([ 0.4671, -0.5222])\n",
      "pre:left true:left 7859/11700\n",
      "tensor([-0.1184,  0.0738])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左543_0_699_20200412_115043250_4.jpg\n",
      "pre:right true:left 7860/11700\n",
      "tensor([ 1.3828, -1.4305])\n",
      "pre:left true:left 7861/11700\n",
      "tensor([ 0.5547, -0.5865])\n",
      "pre:left true:left 7862/11700\n",
      "tensor([-0.0960,  0.1518])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1306_0_1306_20200412_112703459_0.jpg\n",
      "pre:right true:left 7863/11700\n",
      "tensor([ 0.7944, -0.8595])\n",
      "pre:left true:left 7864/11700\n",
      "tensor([ 0.3704, -0.4003])\n",
      "pre:left true:left 7865/11700\n",
      "tensor([ 0.4802, -0.3879])\n",
      "pre:left true:left 7866/11700\n",
      "tensor([ 1.2192, -1.1918])\n",
      "pre:left true:left 7867/11700\n",
      "tensor([ 0.9937, -0.9432])\n",
      "pre:left true:left 7868/11700\n",
      "tensor([ 1.2270, -1.2416])\n",
      "pre:left true:left 7869/11700\n",
      "tensor([ 0.8451, -0.8639])\n",
      "pre:left true:left 7870/11700\n",
      "tensor([ 0.7826, -0.7763])\n",
      "pre:left true:left 7871/11700\n",
      "tensor([ 1.0441, -0.9806])\n",
      "pre:left true:left 7872/11700\n",
      "tensor([ 0.1093, -0.1438])\n",
      "pre:left true:left 7873/11700\n",
      "tensor([ 0.8620, -0.8512])\n",
      "pre:left true:left 7874/11700\n",
      "tensor([ 0.8822, -0.8107])\n",
      "pre:left true:left 7875/11700\n",
      "tensor([-0.0757,  0.0423])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左431_0_587_20200412_114817293_1.jpg\n",
      "pre:right true:left 7876/11700\n",
      "tensor([ 0.5679, -0.5488])\n",
      "pre:left true:left 7877/11700\n",
      "tensor([-0.0164,  0.0510])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1286_0_1286_20200412_112637374_2.jpg\n",
      "pre:right true:left 7878/11700\n",
      "tensor([ 0.3230, -0.2287])\n",
      "pre:left true:left 7879/11700\n",
      "tensor([ 1.2265, -1.2072])\n",
      "pre:left true:left 7880/11700\n",
      "tensor([ 0.5672, -0.5544])\n",
      "pre:left true:left 7881/11700\n",
      "tensor([ 0.3600, -0.3169])\n",
      "pre:left true:left 7882/11700\n",
      "tensor([ 1.4147, -1.4349])\n",
      "pre:left true:left 7883/11700\n",
      "tensor([ 0.6181, -0.5919])\n",
      "pre:left true:left 7884/11700\n",
      "tensor([ 0.5524, -0.5217])\n",
      "pre:left true:left 7885/11700\n",
      "tensor([0.0015, 0.0121])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1302_0_1458_20200412_120712431_10.jpg\n",
      "pre:right true:left 7886/11700\n",
      "tensor([ 1.0572, -1.0216])\n",
      "pre:left true:left 7887/11700\n",
      "tensor([ 0.6623, -0.5826])\n",
      "pre:left true:left 7888/11700\n",
      "tensor([ 0.5917, -0.5377])\n",
      "pre:left true:left 7889/11700\n",
      "tensor([ 0.6794, -0.6063])\n",
      "pre:left true:left 7890/11700\n",
      "tensor([0.0533, 0.0253])\n",
      "pre:left true:left 7891/11700\n",
      "tensor([ 0.3795, -0.2919])\n",
      "pre:left true:left 7892/11700\n",
      "tensor([ 1.3250, -1.2534])\n",
      "pre:left true:left 7893/11700\n",
      "tensor([ 0.5164, -0.4416])\n",
      "pre:left true:left 7894/11700\n",
      "tensor([ 0.3677, -0.3367])\n",
      "pre:left true:left 7895/11700\n",
      "tensor([-0.4332,  0.3644])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左375_0_531_20200412_114704342_0.jpg\n",
      "pre:right true:left 7896/11700\n",
      "tensor([ 0.9919, -0.9283])\n",
      "pre:left true:left 7897/11700\n",
      "tensor([ 0.2915, -0.2058])\n",
      "pre:left true:left 7898/11700\n",
      "tensor([ 0.6425, -0.6599])\n",
      "pre:left true:left 7899/11700\n",
      "tensor([-0.0019, -0.0150])\n",
      "pre:left true:left 7900/11700\n",
      "tensor([ 1.2122, -1.0879])\n",
      "pre:left true:left 7901/11700\n",
      "tensor([ 0.3686, -0.4442])\n",
      "pre:left true:left 7902/11700\n",
      "tensor([ 0.8166, -0.8717])\n",
      "pre:left true:left 7903/11700\n",
      "tensor([ 0.2474, -0.1973])\n",
      "pre:left true:left 7904/11700\n",
      "tensor([ 1.1237, -1.2946])\n",
      "pre:left true:left 7905/11700\n",
      "tensor([ 1.5055, -1.4587])\n",
      "pre:left true:left 7906/11700\n",
      "tensor([ 0.5890, -0.5800])\n",
      "pre:left true:left 7907/11700\n",
      "tensor([ 0.5895, -0.5874])\n",
      "pre:left true:left 7908/11700\n",
      "tensor([ 0.7877, -0.7460])\n",
      "pre:left true:left 7909/11700\n",
      "tensor([ 0.3748, -0.3825])\n",
      "pre:left true:left 7910/11700\n",
      "tensor([ 0.6944, -0.7229])\n",
      "pre:left true:left 7911/11700\n",
      "tensor([ 0.6982, -0.7806])\n",
      "pre:left true:left 7912/11700\n",
      "tensor([ 0.0799, -0.0017])\n",
      "pre:left true:left 7913/11700\n",
      "tensor([ 1.4512, -1.4801])\n",
      "pre:left true:left 7914/11700\n",
      "tensor([ 0.6113, -0.6317])\n",
      "pre:left true:left 7915/11700\n",
      "tensor([-2.1026,  2.3299])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左422_0_578_20200412_114805569_4.jpg\n",
      "pre:right true:left 7916/11700\n",
      "tensor([ 0.7286, -0.6967])\n",
      "pre:left true:left 7917/11700\n",
      "tensor([ 0.5665, -0.5698])\n",
      "pre:left true:left 7918/11700\n",
      "tensor([ 0.9076, -0.9931])\n",
      "pre:left true:left 7919/11700\n",
      "tensor([ 0.2690, -0.1997])\n",
      "pre:left true:left 7920/11700\n",
      "tensor([ 0.9585, -0.9110])\n",
      "pre:left true:left 7921/11700\n",
      "tensor([ 0.9332, -0.9366])\n",
      "pre:left true:left 7922/11700\n",
      "tensor([ 0.7330, -0.7427])\n",
      "pre:left true:left 7923/11700\n",
      "tensor([ 0.3351, -0.3491])\n",
      "pre:left true:left 7924/11700\n",
      "tensor([ 0.1220, -0.0204])\n",
      "pre:left true:left 7925/11700\n",
      "tensor([ 0.4531, -0.4806])\n",
      "pre:left true:left 7926/11700\n",
      "tensor([ 0.2969, -0.2666])\n",
      "pre:left true:left 7927/11700\n",
      "tensor([ 1.1938, -1.1905])\n",
      "pre:left true:left 7928/11700\n",
      "tensor([ 0.6312, -0.6490])\n",
      "pre:left true:left 7929/11700\n",
      "tensor([ 0.7183, -0.6213])\n",
      "pre:left true:left 7930/11700\n",
      "tensor([ 0.6081, -0.6211])\n",
      "pre:left true:left 7931/11700\n",
      "tensor([ 0.1150, -0.1113])\n",
      "pre:left true:left 7932/11700\n",
      "tensor([ 0.3068, -0.4035])\n",
      "pre:left true:left 7933/11700\n",
      "tensor([ 0.7889, -0.7655])\n",
      "pre:left true:left 7934/11700\n",
      "tensor([ 0.2052, -0.2636])\n",
      "pre:left true:left 7935/11700\n",
      "tensor([ 1.9696, -2.0647])\n",
      "pre:left true:left 7936/11700\n",
      "tensor([ 0.8693, -0.8888])\n",
      "pre:left true:left 7937/11700\n",
      "tensor([ 1.2982, -1.2112])\n",
      "pre:left true:left 7938/11700\n",
      "tensor([ 0.3911, -0.4285])\n",
      "pre:left true:left 7939/11700\n",
      "tensor([ 0.9724, -0.9454])\n",
      "pre:left true:left 7940/11700\n",
      "tensor([-0.4575,  0.5437])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左398_0_554_20200412_114734290_2.jpg\n",
      "pre:right true:left 7941/11700\n",
      "tensor([ 1.4823, -1.4385])\n",
      "pre:left true:left 7942/11700\n",
      "tensor([ 0.5769, -0.4948])\n",
      "pre:left true:left 7943/11700\n",
      "tensor([ 0.4868, -0.4217])\n",
      "pre:left true:left 7944/11700\n",
      "tensor([ 0.2188, -0.2258])\n",
      "pre:left true:left 7945/11700\n",
      "tensor([ 0.2747, -0.1950])\n",
      "pre:left true:left 7946/11700\n",
      "tensor([-0.4142,  0.3406])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左265_0_265_20200412_110306768_9.jpg\n",
      "pre:right true:left 7947/11700\n",
      "tensor([ 1.0262, -1.0860])\n",
      "pre:left true:left 7948/11700\n",
      "tensor([-0.5848,  0.6382])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左653_0_809_20200412_115306601_3.jpg\n",
      "pre:right true:left 7949/11700\n",
      "tensor([ 0.8307, -0.8952])\n",
      "pre:left true:left 7950/11700\n",
      "tensor([ 1.5373, -1.6392])\n",
      "pre:left true:left 7951/11700\n",
      "tensor([ 0.4816, -0.4251])\n",
      "pre:left true:left 7952/11700\n",
      "tensor([ 0.5627, -0.5284])\n",
      "pre:left true:left 7953/11700\n",
      "tensor([ 0.8264, -0.8324])\n",
      "pre:left true:left 7954/11700\n",
      "tensor([ 0.3098, -0.2369])\n",
      "pre:left true:left 7955/11700\n",
      "tensor([ 0.3184, -0.2441])\n",
      "pre:left true:left 7956/11700\n",
      "tensor([ 0.8543, -0.8144])\n",
      "pre:left true:left 7957/11700\n",
      "tensor([ 0.2858, -0.2972])\n",
      "pre:left true:left 7958/11700\n",
      "tensor([ 0.2730, -0.2538])\n",
      "pre:left true:left 7959/11700\n",
      "tensor([ 1.0410, -1.0409])\n",
      "pre:left true:left 7960/11700\n",
      "tensor([ 0.6372, -0.5812])\n",
      "pre:left true:left 7961/11700\n",
      "tensor([ 0.6931, -0.6997])\n",
      "pre:left true:left 7962/11700\n",
      "tensor([ 0.2699, -0.1809])\n",
      "pre:left true:left 7963/11700\n",
      "tensor([-0.0986,  0.2369])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左539_0_695_20200412_115038042_10.jpg\n",
      "pre:right true:left 7964/11700\n",
      "tensor([ 0.3434, -0.3413])\n",
      "pre:left true:left 7965/11700\n",
      "tensor([ 1.0360, -1.1131])\n",
      "pre:left true:left 7966/11700\n",
      "tensor([ 0.5630, -0.4864])\n",
      "pre:left true:left 7967/11700\n",
      "tensor([-0.1110,  0.1678])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左585_0_741_20200412_115137994_7.jpg\n",
      "pre:right true:left 7968/11700\n",
      "tensor([-0.2243,  0.2557])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左426_0_582_20200412_114810786_1.jpg\n",
      "pre:right true:left 7969/11700\n",
      "tensor([ 0.5103, -0.6114])\n",
      "pre:left true:left 7970/11700\n",
      "tensor([ 0.3255, -0.4012])\n",
      "pre:left true:left 7971/11700\n",
      "tensor([ 2.5625, -2.5297])\n",
      "pre:left true:left 7972/11700\n",
      "tensor([ 0.7446, -0.7565])\n",
      "pre:left true:left 7973/11700\n",
      "tensor([ 0.1145, -0.1606])\n",
      "pre:left true:left 7974/11700\n",
      "tensor([-0.2915,  0.4028])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左521_0_677_20200412_115014578_1.jpg\n",
      "pre:right true:left 7975/11700\n",
      "tensor([ 0.8007, -0.7794])\n",
      "pre:left true:left 7976/11700\n",
      "tensor([ 0.1344, -0.1650])\n",
      "pre:left true:left 7977/11700\n",
      "tensor([-0.2303,  0.1525])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左828_0_984_20200412_115654687_1.jpg\n",
      "pre:right true:left 7978/11700\n",
      "tensor([-0.1698,  0.1305])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1616_0_1772_20200412_121401710_7.jpg\n",
      "pre:right true:left 7979/11700\n",
      "tensor([ 0.1234, -0.2323])\n",
      "pre:left true:left 7980/11700\n",
      "tensor([-0.8140,  0.7834])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左888_0_888_20200412_111755369_4.jpg\n",
      "pre:right true:left 7981/11700\n",
      "tensor([ 0.6567, -0.6184])\n",
      "pre:left true:left 7982/11700\n",
      "tensor([ 0.0555, -0.0438])\n",
      "pre:left true:left 7983/11700\n",
      "tensor([-0.0946,  0.1368])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左881_0_881_20200412_111745390_6.jpg\n",
      "pre:right true:left 7984/11700\n",
      "tensor([ 0.5582, -0.5434])\n",
      "pre:left true:left 7985/11700\n",
      "tensor([ 0.6030, -0.5396])\n",
      "pre:left true:left 7986/11700\n",
      "tensor([-0.1766,  0.2526])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左599_0_755_20200412_115156230_6.jpg\n",
      "pre:right true:left 7987/11700\n",
      "tensor([ 0.8142, -0.7823])\n",
      "pre:left true:left 7988/11700\n",
      "tensor([ 1.2746, -1.1614])\n",
      "pre:left true:left 7989/11700\n",
      "tensor([ 0.5725, -0.5421])\n",
      "pre:left true:left 7990/11700\n",
      "tensor([ 1.1465, -1.1050])\n",
      "pre:left true:left 7991/11700\n",
      "tensor([ 0.5707, -0.5555])\n",
      "pre:left true:left 7992/11700\n",
      "tensor([ 0.6643, -0.6412])\n",
      "pre:left true:left 7993/11700\n",
      "tensor([ 0.2280, -0.2413])\n",
      "pre:left true:left 7994/11700\n",
      "tensor([ 0.6923, -0.6811])\n",
      "pre:left true:left 7995/11700\n",
      "tensor([-0.1827,  0.0931])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左570_0_570_20200412_111021790_10.jpg\n",
      "pre:right true:left 7996/11700\n",
      "tensor([ 1.2401, -1.1850])\n",
      "pre:left true:left 7997/11700\n",
      "tensor([ 0.2472, -0.2584])\n",
      "pre:left true:left 7998/11700\n",
      "tensor([ 0.7763, -0.7392])\n",
      "pre:left true:left 7999/11700\n",
      "tensor([ 0.1200, -0.0839])\n",
      "pre:left true:left 8000/11700\n",
      "tensor([ 0.8947, -0.7842])\n",
      "pre:left true:left 8001/11700\n",
      "tensor([ 0.6439, -0.6146])\n",
      "pre:left true:left 8002/11700\n",
      "tensor([ 0.7192, -0.6986])\n",
      "pre:left true:left 8003/11700\n",
      "tensor([ 1.4047, -1.2863])\n",
      "pre:left true:left 8004/11700\n",
      "tensor([ 0.6992, -0.5828])\n",
      "pre:left true:left 8005/11700\n",
      "tensor([ 0.2435, -0.3188])\n",
      "pre:left true:left 8006/11700\n",
      "tensor([-0.2312,  0.2509])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左673_0_673_20200412_111248699.jpg\n",
      "pre:right true:left 8007/11700\n",
      "tensor([ 0.3576, -0.4505])\n",
      "pre:left true:left 8008/11700\n",
      "tensor([ 0.9089, -0.8616])\n",
      "pre:left true:left 8009/11700\n",
      "tensor([ 0.0912, -0.0320])\n",
      "pre:left true:left 8010/11700\n",
      "tensor([ 0.3716, -0.4268])\n",
      "pre:left true:left 8011/11700\n",
      "tensor([ 1.3239, -1.2690])\n",
      "pre:left true:left 8012/11700\n",
      "tensor([ 1.0788, -1.0670])\n",
      "pre:left true:left 8013/11700\n",
      "tensor([ 0.2578, -0.2505])\n",
      "pre:left true:left 8014/11700\n",
      "tensor([-0.0963,  0.0198])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左600_0_600_20200412_111104575_10.jpg\n",
      "pre:right true:left 8015/11700\n",
      "tensor([ 0.7088, -0.7537])\n",
      "pre:left true:left 8016/11700\n",
      "tensor([ 0.3121, -0.2888])\n",
      "pre:left true:left 8017/11700\n",
      "tensor([ 0.9437, -0.8917])\n",
      "pre:left true:left 8018/11700\n",
      "tensor([ 0.2251, -0.1620])\n",
      "pre:left true:left 8019/11700\n",
      "tensor([ 0.9613, -0.9599])\n",
      "pre:left true:left 8020/11700\n",
      "tensor([ 0.3380, -0.4538])\n",
      "pre:left true:left 8021/11700\n",
      "tensor([ 0.1362, -0.0212])\n",
      "pre:left true:left 8022/11700\n",
      "tensor([ 0.4554, -0.4756])\n",
      "pre:left true:left 8023/11700\n",
      "tensor([ 0.0363, -0.0310])\n",
      "pre:left true:left 8024/11700\n",
      "tensor([0.1032, 0.0102])\n",
      "pre:left true:left 8025/11700\n",
      "tensor([ 0.9670, -0.9973])\n",
      "pre:left true:left 8026/11700\n",
      "tensor([ 0.1161, -0.0548])\n",
      "pre:left true:left 8027/11700\n",
      "tensor([ 1.7081, -1.7415])\n",
      "pre:left true:left 8028/11700\n",
      "tensor([ 0.6066, -0.6544])\n",
      "pre:left true:left 8029/11700\n",
      "tensor([ 0.1999, -0.1644])\n",
      "pre:left true:left 8030/11700\n",
      "tensor([ 0.6733, -0.6752])\n",
      "pre:left true:left 8031/11700\n",
      "tensor([-0.3140,  0.2843])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左456_0_612_20200412_114849884_5.jpg\n",
      "pre:right true:left 8032/11700\n",
      "tensor([ 0.6867, -0.7135])\n",
      "pre:left true:left 8033/11700\n",
      "tensor([ 0.6610, -0.5973])\n",
      "pre:left true:left 8034/11700\n",
      "tensor([ 1.3554, -1.3788])\n",
      "pre:left true:left 8035/11700\n",
      "tensor([ 0.2986, -0.3214])\n",
      "pre:left true:left 8036/11700\n",
      "tensor([ 0.6312, -0.5739])\n",
      "pre:left true:left 8037/11700\n",
      "tensor([ 1.5601, -1.5077])\n",
      "pre:left true:left 8038/11700\n",
      "tensor([ 0.2100, -0.2026])\n",
      "pre:left true:left 8039/11700\n",
      "tensor([ 0.0685, -0.0899])\n",
      "pre:left true:left 8040/11700\n",
      "tensor([ 0.3842, -0.2615])\n",
      "pre:left true:left 8041/11700\n",
      "tensor([ 0.8941, -0.8822])\n",
      "pre:left true:left 8042/11700\n",
      "tensor([-0.4260,  0.5094])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左226_0_382_20200412_114350157_3.jpg\n",
      "pre:right true:left 8043/11700\n",
      "tensor([ 0.5859, -0.5364])\n",
      "pre:left true:left 8044/11700\n",
      "tensor([-0.0263,  0.0640])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左735_0_891_20200412_115453481_2.jpg\n",
      "pre:right true:left 8045/11700\n",
      "tensor([ 0.6439, -0.6517])\n",
      "pre:left true:left 8046/11700\n",
      "tensor([-0.0631,  0.0353])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左847_0_1003_20200412_115719460_6.jpg\n",
      "pre:right true:left 8047/11700\n",
      "tensor([ 0.5793, -0.5900])\n",
      "pre:left true:left 8048/11700\n",
      "tensor([ 1.1993, -1.2375])\n",
      "pre:left true:left 8049/11700\n",
      "tensor([-0.1161,  0.1643])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1172_0_1172_20200412_112408825_2.jpg\n",
      "pre:right true:left 8050/11700\n",
      "tensor([ 0.5752, -0.5473])\n",
      "pre:left true:left 8051/11700\n",
      "tensor([ 0.4776, -0.3884])\n",
      "pre:left true:left 8052/11700\n",
      "tensor([ 0.0216, -0.1523])\n",
      "pre:left true:left 8053/11700\n",
      "tensor([-0.0481,  0.1213])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左710_0_866_20200412_115420900_4.jpg\n",
      "pre:right true:left 8054/11700\n",
      "tensor([ 0.4324, -0.4172])\n",
      "pre:left true:left 8055/11700\n",
      "tensor([-0.1534,  0.1765])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左856_0_856_20200412_111709718_6.jpg\n",
      "pre:right true:left 8056/11700\n",
      "tensor([-0.1183, -0.0289])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左955_0_955_20200412_111926089_2.jpg\n",
      "pre:right true:left 8057/11700\n",
      "tensor([ 0.3760, -0.2972])\n",
      "pre:left true:left 8058/11700\n",
      "tensor([ 0.2712, -0.3144])\n",
      "pre:left true:left 8059/11700\n",
      "tensor([ 0.1128, -0.0504])\n",
      "pre:left true:left 8060/11700\n",
      "tensor([ 0.7654, -0.7992])\n",
      "pre:left true:left 8061/11700\n",
      "tensor([ 0.1804, -0.2145])\n",
      "pre:left true:left 8062/11700\n",
      "tensor([ 0.9632, -0.9380])\n",
      "pre:left true:left 8063/11700\n",
      "tensor([ 0.5693, -0.6787])\n",
      "pre:left true:left 8064/11700\n",
      "tensor([ 0.4444, -0.3947])\n",
      "pre:left true:left 8065/11700\n",
      "tensor([ 0.7200, -0.6899])\n",
      "pre:left true:left 8066/11700\n",
      "tensor([ 0.3867, -0.3448])\n",
      "pre:left true:left 8067/11700\n",
      "tensor([ 0.4091, -0.4873])\n",
      "pre:left true:left 8068/11700\n",
      "tensor([ 0.2740, -0.1367])\n",
      "pre:left true:left 8069/11700\n",
      "tensor([ 0.9312, -0.9675])\n",
      "pre:left true:left 8070/11700\n",
      "tensor([ 0.6157, -0.5577])\n",
      "pre:left true:left 8071/11700\n",
      "tensor([ 0.5404, -0.4284])\n",
      "pre:left true:left 8072/11700\n",
      "tensor([-0.5085,  0.5048])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1320_0_1320_20200412_112731601.jpg\n",
      "pre:right true:left 8073/11700\n",
      "tensor([ 1.0390, -0.9391])\n",
      "pre:left true:left 8074/11700\n",
      "tensor([ 0.2118, -0.1501])\n",
      "pre:left true:left 8075/11700\n",
      "tensor([ 0.1355, -0.1065])\n",
      "pre:left true:left 8076/11700\n",
      "tensor([ 0.5877, -0.6987])\n",
      "pre:left true:left 8077/11700\n",
      "tensor([ 1.3884, -1.3605])\n",
      "pre:left true:left 8078/11700\n",
      "tensor([ 0.3443, -0.3620])\n",
      "pre:left true:left 8079/11700\n",
      "tensor([ 0.0762, -0.1174])\n",
      "pre:left true:left 8080/11700\n",
      "tensor([ 1.1735, -1.1473])\n",
      "pre:left true:left 8081/11700\n",
      "tensor([ 0.6656, -0.6064])\n",
      "pre:left true:left 8082/11700\n",
      "tensor([ 0.2927, -0.3519])\n",
      "pre:left true:left 8083/11700\n",
      "tensor([ 0.6658, -0.6505])\n",
      "pre:left true:left 8084/11700\n",
      "tensor([ 0.1885, -0.2216])\n",
      "pre:left true:left 8085/11700\n",
      "tensor([ 0.8874, -0.7736])\n",
      "pre:left true:left 8086/11700\n",
      "tensor([ 0.5973, -0.5808])\n",
      "pre:left true:left 8087/11700\n",
      "tensor([ 0.0229, -0.0433])\n",
      "pre:left true:left 8088/11700\n",
      "tensor([-0.0903,  0.0518])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左767_0_767_20200412_111502802_6.jpg\n",
      "pre:right true:left 8089/11700\n",
      "tensor([ 0.6311, -0.6372])\n",
      "pre:left true:left 8090/11700\n",
      "tensor([ 0.4836, -0.5197])\n",
      "pre:left true:left 8091/11700\n",
      "tensor([ 0.7018, -0.7497])\n",
      "pre:left true:left 8092/11700\n",
      "tensor([ 0.4951, -0.4089])\n",
      "pre:left true:left 8093/11700\n",
      "tensor([ 0.9009, -0.8612])\n",
      "pre:left true:left 8094/11700\n",
      "tensor([ 0.4786, -0.4997])\n",
      "pre:left true:left 8095/11700\n",
      "tensor([ 0.1704, -0.1768])\n",
      "pre:left true:left 8096/11700\n",
      "tensor([ 0.9666, -0.8817])\n",
      "pre:left true:left 8097/11700\n",
      "tensor([ 0.7084, -0.7122])\n",
      "pre:left true:left 8098/11700\n",
      "tensor([ 0.9197, -0.9455])\n",
      "pre:left true:left 8099/11700\n",
      "tensor([ 0.2748, -0.3073])\n",
      "pre:left true:left 8100/11700\n",
      "tensor([ 1.2015, -1.2287])\n",
      "pre:left true:left 8101/11700\n",
      "tensor([ 0.6390, -0.7463])\n",
      "pre:left true:left 8102/11700\n",
      "tensor([ 0.1813, -0.2036])\n",
      "pre:left true:left 8103/11700\n",
      "tensor([ 0.7665, -0.7639])\n",
      "pre:left true:left 8104/11700\n",
      "tensor([ 0.2804, -0.3011])\n",
      "pre:left true:left 8105/11700\n",
      "tensor([-0.0975,  0.2214])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1433_0_1589_20200412_121003157_9.jpg\n",
      "pre:right true:left 8106/11700\n",
      "tensor([ 0.6059, -0.6193])\n",
      "pre:left true:left 8107/11700\n",
      "tensor([ 0.3471, -0.3656])\n",
      "pre:left true:left 8108/11700\n",
      "tensor([ 0.4230, -0.3539])\n",
      "pre:left true:left 8109/11700\n",
      "tensor([ 1.0437, -0.9903])\n",
      "pre:left true:left 8110/11700\n",
      "tensor([ 0.8593, -0.8854])\n",
      "pre:left true:left 8111/11700\n",
      "tensor([ 1.5571, -1.5739])\n",
      "pre:left true:left 8112/11700\n",
      "tensor([ 0.1220, -0.0819])\n",
      "pre:left true:left 8113/11700\n",
      "tensor([ 0.4706, -0.5077])\n",
      "pre:left true:left 8114/11700\n",
      "tensor([ 0.6714, -0.7064])\n",
      "pre:left true:left 8115/11700\n",
      "tensor([ 0.2055, -0.2364])\n",
      "pre:left true:left 8116/11700\n",
      "tensor([ 0.1433, -0.0518])\n",
      "pre:left true:left 8117/11700\n",
      "tensor([ 0.5310, -0.4020])\n",
      "pre:left true:left 8118/11700\n",
      "tensor([ 1.5635, -1.5866])\n",
      "pre:left true:left 8119/11700\n",
      "tensor([ 0.3799, -0.4192])\n",
      "pre:left true:left 8120/11700\n",
      "tensor([ 0.8786, -0.8966])\n",
      "pre:left true:left 8121/11700\n",
      "tensor([ 0.3951, -0.3928])\n",
      "pre:left true:left 8122/11700\n",
      "tensor([ 1.0105, -1.0332])\n",
      "pre:left true:left 8123/11700\n",
      "tensor([ 0.6662, -0.7316])\n",
      "pre:left true:left 8124/11700\n",
      "tensor([ 0.0685, -0.0899])\n",
      "pre:left true:left 8125/11700\n",
      "tensor([ 0.2873, -0.2277])\n",
      "pre:left true:left 8126/11700\n",
      "tensor([ 1.3835, -1.4385])\n",
      "pre:left true:left 8127/11700\n",
      "tensor([ 0.5682, -0.6082])\n",
      "pre:left true:left 8128/11700\n",
      "tensor([ 0.6203, -0.5764])\n",
      "pre:left true:left 8129/11700\n",
      "tensor([ 1.1102, -1.1061])\n",
      "pre:left true:left 8130/11700\n",
      "tensor([ 1.0064, -1.0088])\n",
      "pre:left true:left 8131/11700\n",
      "tensor([0.0323, 0.1397])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左776_0_776_20200412_111515622_9.jpg\n",
      "pre:right true:left 8132/11700\n",
      "tensor([ 0.6936, -0.5885])\n",
      "pre:left true:left 8133/11700\n",
      "tensor([ 0.8572, -0.8567])\n",
      "pre:left true:left 8134/11700\n",
      "tensor([ 0.9204, -0.8215])\n",
      "pre:left true:left 8135/11700\n",
      "tensor([ 0.6265, -0.6156])\n",
      "pre:left true:left 8136/11700\n",
      "tensor([ 0.8433, -0.8365])\n",
      "pre:left true:left 8137/11700\n",
      "tensor([ 1.1178, -1.1819])\n",
      "pre:left true:left 8138/11700\n",
      "tensor([-0.1686,  0.0753])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左752_0_752_20200412_111441398_0.jpg\n",
      "pre:right true:left 8139/11700\n",
      "tensor([ 0.4757, -0.5734])\n",
      "pre:left true:left 8140/11700\n",
      "tensor([ 0.0550, -0.0245])\n",
      "pre:left true:left 8141/11700\n",
      "tensor([ 1.1222, -1.1143])\n",
      "pre:left true:left 8142/11700\n",
      "tensor([ 0.3927, -0.2832])\n",
      "pre:left true:left 8143/11700\n",
      "tensor([-0.0386,  0.0974])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左659_0_815_20200412_115314448_8.jpg\n",
      "pre:right true:left 8144/11700\n",
      "tensor([ 0.4916, -0.4796])\n",
      "pre:left true:left 8145/11700\n",
      "tensor([ 1.3812, -1.4081])\n",
      "pre:left true:left 8146/11700\n",
      "tensor([ 0.7474, -0.6826])\n",
      "pre:left true:left 8147/11700\n",
      "tensor([-0.4247,  0.4990])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左179_0_179_20200412_110104093_8.jpg\n",
      "pre:right true:left 8148/11700\n",
      "tensor([-0.2980,  0.2788])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左510_0_666_20200412_115000244_6.jpg\n",
      "pre:right true:left 8149/11700\n",
      "tensor([ 0.2797, -0.1876])\n",
      "pre:left true:left 8150/11700\n",
      "tensor([ 0.0732, -0.0941])\n",
      "pre:left true:left 8151/11700\n",
      "tensor([ 0.2728, -0.2408])\n",
      "pre:left true:left 8152/11700\n",
      "tensor([ 0.6223, -0.6261])\n",
      "pre:left true:left 8153/11700\n",
      "tensor([-0.4492,  0.4326])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左68_0_68_20200412_105825772_10.jpg\n",
      "pre:right true:left 8154/11700\n",
      "tensor([ 0.4532, -0.4970])\n",
      "pre:left true:left 8155/11700\n",
      "tensor([ 0.5389, -0.5073])\n",
      "pre:left true:left 8156/11700\n",
      "tensor([ 0.5447, -0.6328])\n",
      "pre:left true:left 8157/11700\n",
      "tensor([ 0.4023, -0.3793])\n",
      "pre:left true:left 8158/11700\n",
      "tensor([ 0.6280, -0.6103])\n",
      "pre:left true:left 8159/11700\n",
      "tensor([ 0.3139, -0.2445])\n",
      "pre:left true:left 8160/11700\n",
      "tensor([ 0.6693, -0.5308])\n",
      "pre:left true:left 8161/11700\n",
      "tensor([ 0.4741, -0.4589])\n",
      "pre:left true:left 8162/11700\n",
      "tensor([ 0.8895, -0.9419])\n",
      "pre:left true:left 8163/11700\n",
      "tensor([ 0.5244, -0.5196])\n",
      "pre:left true:left 8164/11700\n",
      "tensor([ 0.3557, -0.2560])\n",
      "pre:left true:left 8165/11700\n",
      "tensor([ 0.1980, -0.2191])\n",
      "pre:left true:left 8166/11700\n",
      "tensor([ 0.7711, -0.7682])\n",
      "pre:left true:left 8167/11700\n",
      "tensor([-0.1541,  0.0281])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左451_0_607_20200412_114843369_0.jpg\n",
      "pre:right true:left 8168/11700\n",
      "tensor([-0.0550,  0.1167])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左757_0_757_20200412_111448527_0.jpg\n",
      "pre:right true:left 8169/11700\n",
      "tensor([-0.1234,  0.1398])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左473_0_629_20200412_114912034_9.jpg\n",
      "pre:right true:left 8170/11700\n",
      "tensor([ 0.6066, -0.6421])\n",
      "pre:left true:left 8171/11700\n",
      "tensor([ 0.6770, -0.6770])\n",
      "pre:left true:left 8172/11700\n",
      "tensor([ 1.0565, -1.0821])\n",
      "pre:left true:left 8173/11700\n",
      "tensor([-0.1518,  0.1591])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左844_0_1000_20200412_115715544_7.jpg\n",
      "pre:right true:left 8174/11700\n",
      "tensor([ 0.5400, -0.3087])\n",
      "pre:left true:left 8175/11700\n",
      "tensor([ 0.7953, -0.6669])\n",
      "pre:left true:left 8176/11700\n",
      "tensor([ 0.5306, -0.5014])\n",
      "pre:left true:left 8177/11700\n",
      "tensor([ 0.4970, -0.5020])\n",
      "pre:left true:left 8178/11700\n",
      "tensor([-0.4079,  0.3120])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左495_0_651_20200412_114940709.jpg\n",
      "pre:right true:left 8179/11700\n",
      "tensor([-0.2428,  0.2555])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左494_0_650_20200412_114939397.jpg\n",
      "pre:right true:left 8180/11700\n",
      "tensor([ 0.7375, -0.6509])\n",
      "pre:left true:left 8181/11700\n",
      "tensor([-0.8313,  0.8049])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左615_0_615_20200412_111125989_6.jpg\n",
      "pre:right true:left 8182/11700\n",
      "tensor([ 0.8628, -0.8598])\n",
      "pre:left true:left 8183/11700\n",
      "tensor([ 0.7494, -0.6847])\n",
      "pre:left true:left 8184/11700\n",
      "tensor([ 0.8056, -0.7797])\n",
      "pre:left true:left 8185/11700\n",
      "tensor([ 0.3043, -0.3057])\n",
      "pre:left true:left 8186/11700\n",
      "tensor([ 0.7768, -0.7519])\n",
      "pre:left true:left 8187/11700\n",
      "tensor([ 1.1486, -1.1731])\n",
      "pre:left true:left 8188/11700\n",
      "tensor([ 0.5064, -0.5103])\n",
      "pre:left true:left 8189/11700\n",
      "tensor([ 0.6908, -0.6924])\n",
      "pre:left true:left 8190/11700\n",
      "tensor([ 0.3196, -0.3374])\n",
      "pre:left true:left 8191/11700\n",
      "tensor([ 0.0546, -0.1583])\n",
      "pre:left true:left 8192/11700\n",
      "tensor([ 0.7237, -0.6673])\n",
      "pre:left true:left 8193/11700\n",
      "tensor([ 0.5269, -0.4507])\n",
      "pre:left true:left 8194/11700\n",
      "tensor([-0.2754,  0.3749])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1094_0_1094_20200412_112227186_2.jpg\n",
      "pre:right true:left 8195/11700\n",
      "tensor([ 0.3217, -0.3560])\n",
      "pre:left true:left 8196/11700\n",
      "tensor([ 0.3628, -0.4336])\n",
      "pre:left true:left 8197/11700\n",
      "tensor([ 0.2440, -0.2464])\n",
      "pre:left true:left 8198/11700\n",
      "tensor([ 0.4638, -0.4723])\n",
      "pre:left true:left 8199/11700\n",
      "tensor([-0.2677,  0.3021])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左450_0_450_20200412_110730627_2.jpg\n",
      "pre:right true:left 8200/11700\n",
      "tensor([ 0.6081, -0.6676])\n",
      "pre:left true:left 8201/11700\n",
      "tensor([ 1.4278, -1.5225])\n",
      "pre:left true:left 8202/11700\n",
      "tensor([ 0.6986, -0.6348])\n",
      "pre:left true:left 8203/11700\n",
      "tensor([-0.6065,  0.6130])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左817_0_817_20200412_111614098_3.jpg\n",
      "pre:right true:left 8204/11700\n",
      "tensor([ 0.1047, -0.0904])\n",
      "pre:left true:left 8205/11700\n",
      "tensor([ 0.1822, -0.1137])\n",
      "pre:left true:left 8206/11700\n",
      "tensor([ 1.0535, -1.0232])\n",
      "pre:left true:left 8207/11700\n",
      "tensor([-0.5251,  0.5752])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左615_0_615_20200412_111125989_8.jpg\n",
      "pre:right true:left 8208/11700\n",
      "tensor([-0.0795,  0.0546])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左415_0_415_20200412_110640700_3.jpg\n",
      "pre:right true:left 8209/11700\n",
      "tensor([ 0.0955, -0.0340])\n",
      "pre:left true:left 8210/11700\n",
      "tensor([ 0.1115, -0.0434])\n",
      "pre:left true:left 8211/11700\n",
      "tensor([ 0.0978, -0.0347])\n",
      "pre:left true:left 8212/11700\n",
      "tensor([ 0.9078, -0.9010])\n",
      "pre:left true:left 8213/11700\n",
      "tensor([ 0.3255, -0.2904])\n",
      "pre:left true:left 8214/11700\n",
      "tensor([ 0.3868, -0.4029])\n",
      "pre:left true:left 8215/11700\n",
      "tensor([ 0.5992, -0.5373])\n",
      "pre:left true:left 8216/11700\n",
      "tensor([ 0.3321, -0.2911])\n",
      "pre:left true:left 8217/11700\n",
      "tensor([ 1.0826, -1.0443])\n",
      "pre:left true:left 8218/11700\n",
      "tensor([ 0.5466, -0.5264])\n",
      "pre:left true:left 8219/11700\n",
      "tensor([ 0.7667, -0.7789])\n",
      "pre:left true:left 8220/11700\n",
      "tensor([ 0.6115, -0.4831])\n",
      "pre:left true:left 8221/11700\n",
      "tensor([-0.0264, -0.0019])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左776_0_932_20200412_115546918_4.jpg\n",
      "pre:right true:left 8222/11700\n",
      "tensor([ 0.7834, -0.8517])\n",
      "pre:left true:left 8223/11700\n",
      "tensor([ 0.2559, -0.1985])\n",
      "pre:left true:left 8224/11700\n",
      "tensor([ 0.6066, -0.6241])\n",
      "pre:left true:left 8225/11700\n",
      "tensor([ 0.4991, -0.4836])\n",
      "pre:left true:left 8226/11700\n",
      "tensor([ 0.6850, -0.6098])\n",
      "pre:left true:left 8227/11700\n",
      "tensor([ 0.6272, -0.6060])\n",
      "pre:left true:left 8228/11700\n",
      "tensor([ 0.8341, -0.8127])\n",
      "pre:left true:left 8229/11700\n",
      "tensor([-0.5789,  0.6006])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左552_0_708_20200412_115054990_5.jpg\n",
      "pre:right true:left 8230/11700\n",
      "tensor([ 0.5463, -0.5386])\n",
      "pre:left true:left 8231/11700\n",
      "tensor([ 0.4366, -0.4563])\n",
      "pre:left true:left 8232/11700\n",
      "tensor([ 0.7477, -0.7663])\n",
      "pre:left true:left 8233/11700\n",
      "tensor([ 0.4027, -0.4220])\n",
      "pre:left true:left 8234/11700\n",
      "tensor([ 0.0860, -0.0652])\n",
      "pre:left true:left 8235/11700\n",
      "tensor([ 0.5713, -0.5958])\n",
      "pre:left true:left 8236/11700\n",
      "tensor([ 0.8059, -0.8123])\n",
      "pre:left true:left 8237/11700\n",
      "tensor([ 0.4643, -0.4523])\n",
      "pre:left true:left 8238/11700\n",
      "tensor([ 0.0979, -0.0145])\n",
      "pre:left true:left 8239/11700\n",
      "tensor([ 0.1045, -0.1101])\n",
      "pre:left true:left 8240/11700\n",
      "tensor([-0.0323,  0.0452])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1229_0_1229_20200412_112523087_1.jpg\n",
      "pre:right true:left 8241/11700\n",
      "tensor([ 0.9632, -0.9533])\n",
      "pre:left true:left 8242/11700\n",
      "tensor([ 0.6358, -0.7152])\n",
      "pre:left true:left 8243/11700\n",
      "tensor([-0.6499,  0.6349])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左737_0_893_20200412_115456089_3.jpg\n",
      "pre:right true:left 8244/11700\n",
      "tensor([ 0.2394, -0.1649])\n",
      "pre:left true:left 8245/11700\n",
      "tensor([ 0.5917, -0.6759])\n",
      "pre:left true:left 8246/11700\n",
      "tensor([ 0.4451, -0.5013])\n",
      "pre:left true:left 8247/11700\n",
      "tensor([ 0.1514, -0.1055])\n",
      "pre:left true:left 8248/11700\n",
      "tensor([ 0.7399, -0.7665])\n",
      "pre:left true:left 8249/11700\n",
      "tensor([ 0.8847, -0.8252])\n",
      "pre:left true:left 8250/11700\n",
      "tensor([0.0421, 0.0326])\n",
      "pre:left true:left 8251/11700\n",
      "tensor([ 0.6755, -0.6199])\n",
      "pre:left true:left 8252/11700\n",
      "tensor([-0.2081,  0.1896])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1387_0_1543_20200412_120903209_6.jpg\n",
      "pre:right true:left 8253/11700\n",
      "tensor([ 0.5286, -0.5845])\n",
      "pre:left true:left 8254/11700\n",
      "tensor([ 1.0598, -1.0429])\n",
      "pre:left true:left 8255/11700\n",
      "tensor([ 0.2626, -0.2212])\n",
      "pre:left true:left 8256/11700\n",
      "tensor([ 0.3841, -0.3358])\n",
      "pre:left true:left 8257/11700\n",
      "tensor([ 0.2460, -0.3171])\n",
      "pre:left true:left 8258/11700\n",
      "tensor([ 0.3513, -0.3800])\n",
      "pre:left true:left 8259/11700\n",
      "tensor([ 0.7101, -0.7933])\n",
      "pre:left true:left 8260/11700\n",
      "tensor([ 0.9152, -1.0381])\n",
      "pre:left true:left 8261/11700\n",
      "tensor([ 0.7960, -0.6829])\n",
      "pre:left true:left 8262/11700\n",
      "tensor([ 0.5078, -0.4339])\n",
      "pre:left true:left 8263/11700\n",
      "tensor([ 0.5904, -0.4626])\n",
      "pre:left true:left 8264/11700\n",
      "tensor([ 1.2514, -1.1513])\n",
      "pre:left true:left 8265/11700\n",
      "tensor([ 0.8430, -0.8194])\n",
      "pre:left true:left 8266/11700\n",
      "tensor([ 0.8714, -0.8865])\n",
      "pre:left true:left 8267/11700\n",
      "tensor([ 0.1815, -0.1879])\n",
      "pre:left true:left 8268/11700\n",
      "tensor([ 0.9362, -0.8957])\n",
      "pre:left true:left 8269/11700\n",
      "tensor([ 0.7461, -0.7671])\n",
      "pre:left true:left 8270/11700\n",
      "tensor([ 1.2242, -1.3093])\n",
      "pre:left true:left 8271/11700\n",
      "tensor([ 0.8723, -0.7456])\n",
      "pre:left true:left 8272/11700\n",
      "tensor([ 0.9268, -0.9486])\n",
      "pre:left true:left 8273/11700\n",
      "tensor([ 0.6951, -0.6807])\n",
      "pre:left true:left 8274/11700\n",
      "tensor([ 0.5769, -0.5339])\n",
      "pre:left true:left 8275/11700\n",
      "tensor([0.0290, 0.0148])\n",
      "pre:left true:left 8276/11700\n",
      "tensor([ 0.9126, -0.9407])\n",
      "pre:left true:left 8277/11700\n",
      "tensor([ 0.9868, -0.9342])\n",
      "pre:left true:left 8278/11700\n",
      "tensor([ 0.8871, -0.9198])\n",
      "pre:left true:left 8279/11700\n",
      "tensor([ 0.5085, -0.5520])\n",
      "pre:left true:left 8280/11700\n",
      "tensor([ 0.4300, -0.3954])\n",
      "pre:left true:left 8281/11700\n",
      "tensor([ 0.3991, -0.3108])\n",
      "pre:left true:left 8282/11700\n",
      "tensor([ 0.4316, -0.3900])\n",
      "pre:left true:left 8283/11700\n",
      "tensor([-0.6075,  0.5841])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左96_0_252_20200412_114100770_3.jpg\n",
      "pre:right true:left 8284/11700\n",
      "tensor([ 0.0685, -0.0183])\n",
      "pre:left true:left 8285/11700\n",
      "tensor([ 0.4539, -0.4054])\n",
      "pre:left true:left 8286/11700\n",
      "tensor([ 0.3007, -0.2405])\n",
      "pre:left true:left 8287/11700\n",
      "tensor([ 0.5112, -0.4508])\n",
      "pre:left true:left 8288/11700\n",
      "tensor([ 0.9022, -0.7762])\n",
      "pre:left true:left 8289/11700\n",
      "tensor([-0.3042,  0.3017])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左341_0_341_20200412_110455144.jpg\n",
      "pre:right true:left 8290/11700\n",
      "tensor([ 0.7431, -0.8184])\n",
      "pre:left true:left 8291/11700\n",
      "tensor([ 0.6493, -0.6778])\n",
      "pre:left true:left 8292/11700\n",
      "tensor([ 0.2157, -0.1555])\n",
      "pre:left true:left 8293/11700\n",
      "tensor([ 0.2894, -0.2743])\n",
      "pre:left true:left 8294/11700\n",
      "tensor([ 0.2305, -0.2446])\n",
      "pre:left true:left 8295/11700\n",
      "tensor([ 0.7395, -0.7370])\n",
      "pre:left true:left 8296/11700\n",
      "tensor([ 0.8547, -0.9057])\n",
      "pre:left true:left 8297/11700\n",
      "tensor([ 0.4551, -0.4780])\n",
      "pre:left true:left 8298/11700\n",
      "tensor([-0.3614,  0.3076])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左589_0_745_20200412_115143203.jpg\n",
      "pre:right true:left 8299/11700\n",
      "tensor([ 0.4105, -0.3622])\n",
      "pre:left true:left 8300/11700\n",
      "tensor([ 1.0568, -0.9452])\n",
      "pre:left true:left 8301/11700\n",
      "tensor([ 0.6551, -0.5562])\n",
      "pre:left true:left 8302/11700\n",
      "tensor([ 0.7030, -0.5996])\n",
      "pre:left true:left 8303/11700\n",
      "tensor([ 0.6082, -0.6425])\n",
      "pre:left true:left 8304/11700\n",
      "tensor([ 0.8942, -0.8618])\n",
      "pre:left true:left 8305/11700\n",
      "tensor([ 0.9808, -1.0206])\n",
      "pre:left true:left 8306/11700\n",
      "tensor([ 0.3242, -0.1996])\n",
      "pre:left true:left 8307/11700\n",
      "tensor([ 0.7672, -0.7766])\n",
      "pre:left true:left 8308/11700\n",
      "tensor([ 0.1435, -0.1628])\n",
      "pre:left true:left 8309/11700\n",
      "tensor([ 0.9399, -0.9341])\n",
      "pre:left true:left 8310/11700\n",
      "tensor([ 0.7173, -0.7437])\n",
      "pre:left true:left 8311/11700\n",
      "tensor([ 0.5436, -0.4872])\n",
      "pre:left true:left 8312/11700\n",
      "tensor([ 0.8763, -0.8759])\n",
      "pre:left true:left 8313/11700\n",
      "tensor([ 0.0053, -0.0561])\n",
      "pre:left true:left 8314/11700\n",
      "tensor([ 0.5878, -0.5434])\n",
      "pre:left true:left 8315/11700\n",
      "tensor([ 0.3436, -0.3052])\n",
      "pre:left true:left 8316/11700\n",
      "tensor([ 0.9547, -0.8885])\n",
      "pre:left true:left 8317/11700\n",
      "tensor([ 0.6263, -0.5970])\n",
      "pre:left true:left 8318/11700\n",
      "tensor([ 0.3383, -0.3788])\n",
      "pre:left true:left 8319/11700\n",
      "tensor([ 1.1013, -1.0490])\n",
      "pre:left true:left 8320/11700\n",
      "tensor([ 1.0886, -1.1521])\n",
      "pre:left true:left 8321/11700\n",
      "tensor([ 0.2062, -0.0556])\n",
      "pre:left true:left 8322/11700\n",
      "tensor([ 0.6040, -0.5630])\n",
      "pre:left true:left 8323/11700\n",
      "tensor([ 0.6176, -0.5704])\n",
      "pre:left true:left 8324/11700\n",
      "tensor([ 1.6182, -1.6846])\n",
      "pre:left true:left 8325/11700\n",
      "tensor([ 0.7068, -0.7048])\n",
      "pre:left true:left 8326/11700\n",
      "tensor([ 0.4447, -0.3006])\n",
      "pre:left true:left 8327/11700\n",
      "tensor([ 0.9925, -0.9900])\n",
      "pre:left true:left 8328/11700\n",
      "tensor([ 0.8608, -0.8518])\n",
      "pre:left true:left 8329/11700\n",
      "tensor([ 0.3024, -0.2268])\n",
      "pre:left true:left 8330/11700\n",
      "tensor([ 0.7765, -0.7351])\n",
      "pre:left true:left 8331/11700\n",
      "tensor([ 0.8194, -0.9094])\n",
      "pre:left true:left 8332/11700\n",
      "tensor([ 1.1070, -1.1691])\n",
      "pre:left true:left 8333/11700\n",
      "tensor([ 1.2956, -1.3589])\n",
      "pre:left true:left 8334/11700\n",
      "tensor([ 1.0098, -1.0099])\n",
      "pre:left true:left 8335/11700\n",
      "tensor([ 1.1989, -1.1106])\n",
      "pre:left true:left 8336/11700\n",
      "tensor([ 0.2984, -0.2156])\n",
      "pre:left true:left 8337/11700\n",
      "tensor([ 0.5795, -0.5556])\n",
      "pre:left true:left 8338/11700\n",
      "tensor([ 1.6132, -1.6086])\n",
      "pre:left true:left 8339/11700\n",
      "tensor([ 0.4533, -0.4752])\n",
      "pre:left true:left 8340/11700\n",
      "tensor([ 0.4431, -0.4015])\n",
      "pre:left true:left 8341/11700\n",
      "tensor([ 0.0484, -0.0101])\n",
      "pre:left true:left 8342/11700\n",
      "tensor([-0.5443,  0.6268])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左326_0_482_20200412_114600486_2.jpg\n",
      "pre:right true:left 8343/11700\n",
      "tensor([ 0.3615, -0.3643])\n",
      "pre:left true:left 8344/11700\n",
      "tensor([ 0.3043, -0.2829])\n",
      "pre:left true:left 8345/11700\n",
      "tensor([ 0.4889, -0.5330])\n",
      "pre:left true:left 8346/11700\n",
      "tensor([ 0.4406, -0.3949])\n",
      "pre:left true:left 8347/11700\n",
      "tensor([ 0.6205, -0.6019])\n",
      "pre:left true:left 8348/11700\n",
      "tensor([-0.3626,  0.4291])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左607_0_763_20200412_115206661.jpg\n",
      "pre:right true:left 8349/11700\n",
      "tensor([ 0.5447, -0.6032])\n",
      "pre:left true:left 8350/11700\n",
      "tensor([ 0.8117, -0.8359])\n",
      "pre:left true:left 8351/11700\n",
      "tensor([ 0.1530, -0.1427])\n",
      "pre:left true:left 8352/11700\n",
      "tensor([-0.2137,  0.2645])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左700_0_856_20200412_115407862_4.jpg\n",
      "pre:right true:left 8353/11700\n",
      "tensor([ 0.7092, -0.6954])\n",
      "pre:left true:left 8354/11700\n",
      "tensor([ 0.9593, -0.9433])\n",
      "pre:left true:left 8355/11700\n",
      "tensor([ 1.5266, -1.5396])\n",
      "pre:left true:left 8356/11700\n",
      "tensor([ 0.1093, -0.1790])\n",
      "pre:left true:left 8357/11700\n",
      "tensor([ 0.3849, -0.2938])\n",
      "pre:left true:left 8358/11700\n",
      "tensor([ 1.0894, -1.1563])\n",
      "pre:left true:left 8359/11700\n",
      "tensor([ 0.6838, -0.5875])\n",
      "pre:left true:left 8360/11700\n",
      "tensor([ 0.4916, -0.5270])\n",
      "pre:left true:left 8361/11700\n",
      "tensor([ 0.6076, -0.6759])\n",
      "pre:left true:left 8362/11700\n",
      "tensor([ 0.7680, -0.7777])\n",
      "pre:left true:left 8363/11700\n",
      "tensor([ 0.8212, -0.7750])\n",
      "pre:left true:left 8364/11700\n",
      "tensor([ 0.6934, -0.6223])\n",
      "pre:left true:left 8365/11700\n",
      "tensor([ 0.5920, -0.5594])\n",
      "pre:left true:left 8366/11700\n",
      "tensor([ 0.4827, -0.4460])\n",
      "pre:left true:left 8367/11700\n",
      "tensor([ 0.7498, -0.7330])\n",
      "pre:left true:left 8368/11700\n",
      "tensor([ 0.3561, -0.3127])\n",
      "pre:left true:left 8369/11700\n",
      "tensor([ 0.4926, -0.5430])\n",
      "pre:left true:left 8370/11700\n",
      "tensor([ 1.1797, -1.1439])\n",
      "pre:left true:left 8371/11700\n",
      "tensor([ 0.3819, -0.4191])\n",
      "pre:left true:left 8372/11700\n",
      "tensor([ 0.6847, -0.6181])\n",
      "pre:left true:left 8373/11700\n",
      "tensor([-0.2741,  0.2300])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左600_0_756_20200412_115157535_9.jpg\n",
      "pre:right true:left 8374/11700\n",
      "tensor([ 0.6950, -0.6923])\n",
      "pre:left true:left 8375/11700\n",
      "tensor([ 0.8143, -0.8158])\n",
      "pre:left true:left 8376/11700\n",
      "tensor([ 0.1994, -0.1599])\n",
      "pre:left true:left 8377/11700\n",
      "tensor([ 0.0702, -0.1548])\n",
      "pre:left true:left 8378/11700\n",
      "tensor([ 0.4993, -0.5278])\n",
      "pre:left true:left 8379/11700\n",
      "tensor([ 0.6400, -0.6617])\n",
      "pre:left true:left 8380/11700\n",
      "tensor([ 0.5446, -0.5048])\n",
      "pre:left true:left 8381/11700\n",
      "tensor([ 0.5858, -0.6037])\n",
      "pre:left true:left 8382/11700\n",
      "tensor([ 0.6488, -0.6273])\n",
      "pre:left true:left 8383/11700\n",
      "tensor([ 0.7913, -0.8169])\n",
      "pre:left true:left 8384/11700\n",
      "tensor([ 0.4947, -0.2542])\n",
      "pre:left true:left 8385/11700\n",
      "tensor([ 0.8189, -0.8234])\n",
      "pre:left true:left 8386/11700\n",
      "tensor([ 0.8987, -0.9609])\n",
      "pre:left true:left 8387/11700\n",
      "tensor([ 0.1692, -0.1542])\n",
      "pre:left true:left 8388/11700\n",
      "tensor([ 0.4860, -0.4753])\n",
      "pre:left true:left 8389/11700\n",
      "tensor([ 0.1257, -0.1463])\n",
      "pre:left true:left 8390/11700\n",
      "tensor([ 0.2955, -0.3652])\n",
      "pre:left true:left 8391/11700\n",
      "tensor([-0.0581,  0.0394])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左629_0_785_20200412_115235324_5.jpg\n",
      "pre:right true:left 8392/11700\n",
      "tensor([ 0.8369, -0.8432])\n",
      "pre:left true:left 8393/11700\n",
      "tensor([ 0.0436, -0.0074])\n",
      "pre:left true:left 8394/11700\n",
      "tensor([ 0.4878, -0.5163])\n",
      "pre:left true:left 8395/11700\n",
      "tensor([ 0.8300, -0.7095])\n",
      "pre:left true:left 8396/11700\n",
      "tensor([ 0.0531, -0.1107])\n",
      "pre:left true:left 8397/11700\n",
      "tensor([ 0.3706, -0.3787])\n",
      "pre:left true:left 8398/11700\n",
      "tensor([ 0.8194, -0.7351])\n",
      "pre:left true:left 8399/11700\n",
      "tensor([ 0.5772, -0.6213])\n",
      "pre:left true:left 8400/11700\n",
      "tensor([ 0.5029, -0.4164])\n",
      "pre:left true:left 8401/11700\n",
      "tensor([ 0.5567, -0.5324])\n",
      "pre:left true:left 8402/11700\n",
      "tensor([-0.8492,  0.8291])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左193_0_193_20200412_110124081_6.jpg\n",
      "pre:right true:left 8403/11700\n",
      "tensor([ 0.5195, -0.4802])\n",
      "pre:left true:left 8404/11700\n",
      "tensor([0.0626, 0.0066])\n",
      "pre:left true:left 8405/11700\n",
      "tensor([ 2.0157, -1.9361])\n",
      "pre:left true:left 8406/11700\n",
      "tensor([ 1.1971, -1.2315])\n",
      "pre:left true:left 8407/11700\n",
      "tensor([ 0.9305, -0.9632])\n",
      "pre:left true:left 8408/11700\n",
      "tensor([ 0.3806, -0.3377])\n",
      "pre:left true:left 8409/11700\n",
      "tensor([ 0.6999, -0.7111])\n",
      "pre:left true:left 8410/11700\n",
      "tensor([ 0.0921, -0.1084])\n",
      "pre:left true:left 8411/11700\n",
      "tensor([ 0.8903, -0.9262])\n",
      "pre:left true:left 8412/11700\n",
      "tensor([-0.2025,  0.2619])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左881_0_881_20200412_111745390_10.jpg\n",
      "pre:right true:left 8413/11700\n",
      "tensor([ 0.4443, -0.4070])\n",
      "pre:left true:left 8414/11700\n",
      "tensor([ 0.7295, -0.7144])\n",
      "pre:left true:left 8415/11700\n",
      "tensor([-0.0306, -0.0682])\n",
      "pre:left true:left 8416/11700\n",
      "tensor([ 1.9284, -1.9425])\n",
      "pre:left true:left 8417/11700\n",
      "tensor([-0.2125,  0.3123])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1083_0_1083_20200412_112212846_6.jpg\n",
      "pre:right true:left 8418/11700\n",
      "tensor([-0.2448,  0.2951])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左689_0_845_20200412_115353526_9.jpg\n",
      "pre:right true:left 8419/11700\n",
      "tensor([ 0.3375, -0.2984])\n",
      "pre:left true:left 8420/11700\n",
      "tensor([ 1.1797, -1.2076])\n",
      "pre:left true:left 8421/11700\n",
      "tensor([ 0.6622, -0.7334])\n",
      "pre:left true:left 8422/11700\n",
      "tensor([ 0.5500, -0.6126])\n",
      "pre:left true:left 8423/11700\n",
      "tensor([ 1.0607, -1.1238])\n",
      "pre:left true:left 8424/11700\n",
      "tensor([ 0.7773, -0.7597])\n",
      "pre:left true:left 8425/11700\n",
      "tensor([ 0.1971, -0.1519])\n",
      "pre:left true:left 8426/11700\n",
      "tensor([-0.2312,  0.2509])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左673_0_673_20200412_111248699_10.jpg\n",
      "pre:right true:left 8427/11700\n",
      "tensor([ 0.7698, -0.8039])\n",
      "pre:left true:left 8428/11700\n",
      "tensor([-0.7781,  0.7498])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左993_0_1149_20200412_120029734_6.jpg\n",
      "pre:right true:left 8429/11700\n",
      "tensor([ 0.9317, -0.9203])\n",
      "pre:left true:left 8430/11700\n",
      "tensor([ 0.2899, -0.4329])\n",
      "pre:left true:left 8431/11700\n",
      "tensor([ 0.5777, -0.5784])\n",
      "pre:left true:left 8432/11700\n",
      "tensor([ 0.9242, -0.9650])\n",
      "pre:left true:left 8433/11700\n",
      "tensor([ 0.8437, -0.7242])\n",
      "pre:left true:left 8434/11700\n",
      "tensor([ 0.7225, -0.5848])\n",
      "pre:left true:left 8435/11700\n",
      "tensor([ 0.5385, -0.5745])\n",
      "pre:left true:left 8436/11700\n",
      "tensor([ 0.2409, -0.2164])\n",
      "pre:left true:left 8437/11700\n",
      "tensor([ 0.2859, -0.3012])\n",
      "pre:left true:left 8438/11700\n",
      "tensor([ 0.4788, -0.4387])\n",
      "pre:left true:left 8439/11700\n",
      "tensor([ 1.0462, -1.0019])\n",
      "pre:left true:left 8440/11700\n",
      "tensor([ 0.5088, -0.4731])\n",
      "pre:left true:left 8441/11700\n",
      "tensor([-0.3566,  0.3456])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1092_0_1092_20200412_112224571_9.jpg\n",
      "pre:right true:left 8442/11700\n",
      "tensor([ 0.0418, -0.0681])\n",
      "pre:left true:left 8443/11700\n",
      "tensor([ 0.3598, -0.3279])\n",
      "pre:left true:left 8444/11700\n",
      "tensor([ 0.5081, -0.5303])\n",
      "pre:left true:left 8445/11700\n",
      "tensor([ 0.9316, -0.9510])\n",
      "pre:left true:left 8446/11700\n",
      "tensor([ 0.7699, -0.8642])\n",
      "pre:left true:left 8447/11700\n",
      "tensor([ 0.7970, -0.7648])\n",
      "pre:left true:left 8448/11700\n",
      "tensor([ 0.4245, -0.3669])\n",
      "pre:left true:left 8449/11700\n",
      "tensor([ 0.8344, -0.6735])\n",
      "pre:left true:left 8450/11700\n",
      "tensor([ 0.6592, -0.7262])\n",
      "pre:left true:left 8451/11700\n",
      "tensor([ 0.9958, -1.0557])\n",
      "pre:left true:left 8452/11700\n",
      "tensor([ 1.5763, -1.5509])\n",
      "pre:left true:left 8453/11700\n",
      "tensor([ 0.9468, -0.8214])\n",
      "pre:left true:left 8454/11700\n",
      "tensor([ 1.3955, -1.4560])\n",
      "pre:left true:left 8455/11700\n",
      "tensor([ 0.8057, -0.8058])\n",
      "pre:left true:left 8456/11700\n",
      "tensor([ 0.5770, -0.5875])\n",
      "pre:left true:left 8457/11700\n",
      "tensor([ 0.5480, -0.5427])\n",
      "pre:left true:left 8458/11700\n",
      "tensor([ 1.1070, -1.1495])\n",
      "pre:left true:left 8459/11700\n",
      "tensor([ 0.3478, -0.2910])\n",
      "pre:left true:left 8460/11700\n",
      "tensor([ 1.1384, -1.1335])\n",
      "pre:left true:left 8461/11700\n",
      "tensor([ 0.5864, -0.5966])\n",
      "pre:left true:left 8462/11700\n",
      "tensor([ 0.1804, -0.1307])\n",
      "pre:left true:left 8463/11700\n",
      "tensor([ 1.1216, -1.0912])\n",
      "pre:left true:left 8464/11700\n",
      "tensor([-0.5456,  0.5982])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左676_0_832_20200412_115336593_3.jpg\n",
      "pre:right true:left 8465/11700\n",
      "tensor([ 0.4334, -0.3523])\n",
      "pre:left true:left 8466/11700\n",
      "tensor([ 1.1852, -1.1582])\n",
      "pre:left true:left 8467/11700\n",
      "tensor([ 0.9400, -0.8938])\n",
      "pre:left true:left 8468/11700\n",
      "tensor([ 0.1598, -0.0615])\n",
      "pre:left true:left 8469/11700\n",
      "tensor([ 0.6855, -0.6455])\n",
      "pre:left true:left 8470/11700\n",
      "tensor([ 0.1879, -0.2371])\n",
      "pre:left true:left 8471/11700\n",
      "tensor([ 0.7628, -0.8314])\n",
      "pre:left true:left 8472/11700\n",
      "tensor([ 0.2903, -0.2751])\n",
      "pre:left true:left 8473/11700\n",
      "tensor([ 0.5009, -0.5264])\n",
      "pre:left true:left 8474/11700\n",
      "tensor([ 0.1393, -0.1854])\n",
      "pre:left true:left 8475/11700\n",
      "tensor([ 0.7267, -0.6953])\n",
      "pre:left true:left 8476/11700\n",
      "tensor([ 0.6694, -0.6342])\n",
      "pre:left true:left 8477/11700\n",
      "tensor([ 0.9665, -0.9551])\n",
      "pre:left true:left 8478/11700\n",
      "tensor([ 0.7046, -0.7423])\n",
      "pre:left true:left 8479/11700\n",
      "tensor([ 1.3452, -1.3338])\n",
      "pre:left true:left 8480/11700\n",
      "tensor([ 0.7113, -0.7138])\n",
      "pre:left true:left 8481/11700\n",
      "tensor([ 0.4560, -0.5097])\n",
      "pre:left true:left 8482/11700\n",
      "tensor([ 0.2116, -0.3176])\n",
      "pre:left true:left 8483/11700\n",
      "tensor([ 0.9953, -0.9333])\n",
      "pre:left true:left 8484/11700\n",
      "tensor([-0.5005,  0.5741])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1597_0_1753_20200412_121336950_0.jpg\n",
      "pre:right true:left 8485/11700\n",
      "tensor([ 0.7671, -0.8179])\n",
      "pre:left true:left 8486/11700\n",
      "tensor([ 0.4503, -0.4812])\n",
      "pre:left true:left 8487/11700\n",
      "tensor([ 0.8245, -0.8111])\n",
      "pre:left true:left 8488/11700\n",
      "tensor([ 0.5948, -0.4851])\n",
      "pre:left true:left 8489/11700\n",
      "tensor([ 0.1106, -0.0660])\n",
      "pre:left true:left 8490/11700\n",
      "tensor([ 0.1453, -0.1559])\n",
      "pre:left true:left 8491/11700\n",
      "tensor([ 0.1523, -0.0249])\n",
      "pre:left true:left 8492/11700\n",
      "tensor([ 0.5232, -0.4738])\n",
      "pre:left true:left 8493/11700\n",
      "tensor([-0.0092, -0.1356])\n",
      "pre:left true:left 8494/11700\n",
      "tensor([ 0.2115, -0.2650])\n",
      "pre:left true:left 8495/11700\n",
      "tensor([ 0.8874, -0.8262])\n",
      "pre:left true:left 8496/11700\n",
      "tensor([-0.3552,  0.3656])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1168_0_1168_20200412_112403610_7.jpg\n",
      "pre:right true:left 8497/11700\n",
      "tensor([ 0.4020, -0.3148])\n",
      "pre:left true:left 8498/11700\n",
      "tensor([ 0.0793, -0.0910])\n",
      "pre:left true:left 8499/11700\n",
      "tensor([-0.0081,  0.1008])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左636_0_792_20200412_115244458_0.jpg\n",
      "pre:right true:left 8500/11700\n",
      "tensor([ 0.9268, -0.9947])\n",
      "pre:left true:left 8501/11700\n",
      "tensor([-0.0683,  0.1296])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左131_0_131_20200412_105955655_6.jpg\n",
      "pre:right true:left 8502/11700\n",
      "tensor([ 0.8105, -0.9359])\n",
      "pre:left true:left 8503/11700\n",
      "tensor([ 0.6732, -0.6451])\n",
      "pre:left true:left 8504/11700\n",
      "tensor([ 1.1187, -1.1766])\n",
      "pre:left true:left 8505/11700\n",
      "tensor([ 0.7765, -0.7004])\n",
      "pre:left true:left 8506/11700\n",
      "tensor([ 0.6558, -0.5806])\n",
      "pre:left true:left 8507/11700\n",
      "tensor([-0.2018,  0.1577])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左938_0_938_20200412_111903938_4.jpg\n",
      "pre:right true:left 8508/11700\n",
      "tensor([ 1.2182, -1.3074])\n",
      "pre:left true:left 8509/11700\n",
      "tensor([ 0.3962, -0.3664])\n",
      "pre:left true:left 8510/11700\n",
      "tensor([ 0.3733, -0.3402])\n",
      "pre:left true:left 8511/11700\n",
      "tensor([ 0.1125, -0.0493])\n",
      "pre:left true:left 8512/11700\n",
      "tensor([ 0.9229, -1.0320])\n",
      "pre:left true:left 8513/11700\n",
      "tensor([-0.3591,  0.3327])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左828_0_984_20200412_115654687_5.jpg\n",
      "pre:right true:left 8514/11700\n",
      "tensor([ 0.9878, -0.9818])\n",
      "pre:left true:left 8515/11700\n",
      "tensor([ 0.4647, -0.4421])\n",
      "pre:left true:left 8516/11700\n",
      "tensor([ 0.6270, -0.4903])\n",
      "pre:left true:left 8517/11700\n",
      "tensor([ 1.1720, -1.1690])\n",
      "pre:left true:left 8518/11700\n",
      "tensor([ 1.0954, -1.0212])\n",
      "pre:left true:left 8519/11700\n",
      "tensor([ 0.8058, -0.8206])\n",
      "pre:left true:left 8520/11700\n",
      "tensor([ 0.5265, -0.5319])\n",
      "pre:left true:left 8521/11700\n",
      "tensor([ 0.3424, -0.2188])\n",
      "pre:left true:left 8522/11700\n",
      "tensor([ 0.5807, -0.6279])\n",
      "pre:left true:left 8523/11700\n",
      "tensor([ 0.6600, -0.7109])\n",
      "pre:left true:left 8524/11700\n",
      "tensor([ 0.2936, -0.2564])\n",
      "pre:left true:left 8525/11700\n",
      "tensor([ 0.5341, -0.4172])\n",
      "pre:left true:left 8526/11700\n",
      "tensor([ 0.8065, -0.7427])\n",
      "pre:left true:left 8527/11700\n",
      "tensor([ 0.9785, -1.0582])\n",
      "pre:left true:left 8528/11700\n",
      "tensor([ 0.3619, -0.3151])\n",
      "pre:left true:left 8529/11700\n",
      "tensor([ 0.8158, -0.8918])\n",
      "pre:left true:left 8530/11700\n",
      "tensor([ 0.2129, -0.2707])\n",
      "pre:left true:left 8531/11700\n",
      "tensor([ 0.8192, -0.8417])\n",
      "pre:left true:left 8532/11700\n",
      "tensor([ 0.7940, -0.8740])\n",
      "pre:left true:left 8533/11700\n",
      "tensor([ 0.9406, -0.9395])\n",
      "pre:left true:left 8534/11700\n",
      "tensor([ 0.3987, -0.3772])\n",
      "pre:left true:left 8535/11700\n",
      "tensor([ 1.4455, -1.4786])\n",
      "pre:left true:left 8536/11700\n",
      "tensor([ 0.4214, -0.3720])\n",
      "pre:left true:left 8537/11700\n",
      "tensor([ 0.5926, -0.6753])\n",
      "pre:left true:left 8538/11700\n",
      "tensor([ 0.8502, -0.8548])\n",
      "pre:left true:left 8539/11700\n",
      "tensor([ 1.0290, -1.0604])\n",
      "pre:left true:left 8540/11700\n",
      "tensor([ 1.3132, -1.2825])\n",
      "pre:left true:left 8541/11700\n",
      "tensor([-0.1636,  0.1864])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1113_0_1113_20200412_112251946_7.jpg\n",
      "pre:right true:left 8542/11700\n",
      "tensor([ 0.2691, -0.2816])\n",
      "pre:left true:left 8543/11700\n",
      "tensor([ 0.7836, -0.7959])\n",
      "pre:left true:left 8544/11700\n",
      "tensor([ 0.1892, -0.1955])\n",
      "pre:left true:left 8545/11700\n",
      "tensor([ 0.0106, -0.0115])\n",
      "pre:left true:left 8546/11700\n",
      "tensor([ 2.2564, -2.2405])\n",
      "pre:left true:left 8547/11700\n",
      "tensor([ 0.1902, -0.2568])\n",
      "pre:left true:left 8548/11700\n",
      "tensor([ 0.4790, -0.3988])\n",
      "pre:left true:left 8549/11700\n",
      "tensor([0.0159, 0.0544])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1448_0_1604_20200412_121022709_1.jpg\n",
      "pre:right true:left 8550/11700\n",
      "tensor([0.0432, 0.1019])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1577_0_1733_20200412_121310863_5.jpg\n",
      "pre:right true:left 8551/11700\n",
      "tensor([0.0305, 0.0283])\n",
      "pre:left true:left 8552/11700\n",
      "tensor([ 0.4132, -0.5519])\n",
      "pre:left true:left 8553/11700\n",
      "tensor([ 0.5758, -0.6139])\n",
      "pre:left true:left 8554/11700\n",
      "tensor([ 0.2673, -0.1970])\n",
      "pre:left true:left 8555/11700\n",
      "tensor([ 0.1255, -0.2662])\n",
      "pre:left true:left 8556/11700\n",
      "tensor([ 0.2554, -0.1475])\n",
      "pre:left true:left 8557/11700\n",
      "tensor([ 0.9583, -0.9099])\n",
      "pre:left true:left 8558/11700\n",
      "tensor([ 0.0280, -0.0003])\n",
      "pre:left true:left 8559/11700\n",
      "tensor([ 0.4834, -0.5738])\n",
      "pre:left true:left 8560/11700\n",
      "tensor([ 0.5735, -0.5051])\n",
      "pre:left true:left 8561/11700\n",
      "tensor([ 0.4018, -0.4224])\n",
      "pre:left true:left 8562/11700\n",
      "tensor([ 1.3554, -1.3521])\n",
      "pre:left true:left 8563/11700\n",
      "tensor([ 1.2575, -1.2087])\n",
      "pre:left true:left 8564/11700\n",
      "tensor([ 0.3813, -0.4739])\n",
      "pre:left true:left 8565/11700\n",
      "tensor([ 0.8274, -0.6931])\n",
      "pre:left true:left 8566/11700\n",
      "tensor([ 0.0231, -0.0213])\n",
      "pre:left true:left 8567/11700\n",
      "tensor([ 0.4817, -0.3310])\n",
      "pre:left true:left 8568/11700\n",
      "tensor([ 0.7628, -0.7055])\n",
      "pre:left true:left 8569/11700\n",
      "tensor([ 0.9221, -0.9040])\n",
      "pre:left true:left 8570/11700\n",
      "tensor([-0.1279,  0.1889])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左772_0_928_20200412_115541714_9.jpg\n",
      "pre:right true:left 8571/11700\n",
      "tensor([ 1.0314, -1.0162])\n",
      "pre:left true:left 8572/11700\n",
      "tensor([ 0.0245, -0.0729])\n",
      "pre:left true:left 8573/11700\n",
      "tensor([ 0.6595, -0.6181])\n",
      "pre:left true:left 8574/11700\n",
      "tensor([ 0.4445, -0.3802])\n",
      "pre:left true:left 8575/11700\n",
      "tensor([-0.0835,  0.1718])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左699_0_855_20200412_115406565_1.jpg\n",
      "pre:right true:left 8576/11700\n",
      "tensor([ 0.8647, -0.9710])\n",
      "pre:left true:left 8577/11700\n",
      "tensor([ 0.3534, -0.3318])\n",
      "pre:left true:left 8578/11700\n",
      "tensor([ 0.7316, -0.7321])\n",
      "pre:left true:left 8579/11700\n",
      "tensor([ 0.0102, -0.0348])\n",
      "pre:left true:left 8580/11700\n",
      "tensor([ 0.6538, -0.7197])\n",
      "pre:left true:left 8581/11700\n",
      "tensor([-1.1400,  1.1612])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左744_0_900_20200412_115505217_10.jpg\n",
      "pre:right true:left 8582/11700\n",
      "tensor([ 1.2042, -1.2370])\n",
      "pre:left true:left 8583/11700\n",
      "tensor([-0.3012,  0.3032])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左802_0_958_20200412_115620819.jpg\n",
      "pre:right true:left 8584/11700\n",
      "tensor([ 0.4199, -0.4629])\n",
      "pre:left true:left 8585/11700\n",
      "tensor([ 1.1788, -1.2555])\n",
      "pre:left true:left 8586/11700\n",
      "tensor([ 0.6757, -0.7435])\n",
      "pre:left true:left 8587/11700\n",
      "tensor([ 0.3683, -0.3590])\n",
      "pre:left true:left 8588/11700\n",
      "tensor([ 0.1953, -0.1171])\n",
      "pre:left true:left 8589/11700\n",
      "tensor([ 1.0900, -1.0811])\n",
      "pre:left true:left 8590/11700\n",
      "tensor([ 0.6929, -0.6675])\n",
      "pre:left true:left 8591/11700\n",
      "tensor([ 0.3212, -0.2970])\n",
      "pre:left true:left 8592/11700\n",
      "tensor([ 0.7895, -0.7912])\n",
      "pre:left true:left 8593/11700\n",
      "tensor([ 1.0642, -1.0803])\n",
      "pre:left true:left 8594/11700\n",
      "tensor([ 0.0964, -0.0973])\n",
      "pre:left true:left 8595/11700\n",
      "tensor([ 0.9488, -0.9102])\n",
      "pre:left true:left 8596/11700\n",
      "tensor([ 0.5795, -0.5566])\n",
      "pre:left true:left 8597/11700\n",
      "tensor([ 0.8328, -0.8617])\n",
      "pre:left true:left 8598/11700\n",
      "tensor([ 1.2088, -1.1882])\n",
      "pre:left true:left 8599/11700\n",
      "tensor([-0.0302, -0.0247])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左672_0_672_20200412_111247280_7.jpg\n",
      "pre:right true:left 8600/11700\n",
      "tensor([-0.1622,  0.1151])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1574_0_1730_20200412_121306937.jpg\n",
      "pre:right true:left 8601/11700\n",
      "tensor([ 0.3146, -0.2680])\n",
      "pre:left true:left 8602/11700\n",
      "tensor([ 0.7583, -0.8257])\n",
      "pre:left true:left 8603/11700\n",
      "tensor([ 0.3208, -0.0994])\n",
      "pre:left true:left 8604/11700\n",
      "tensor([ 0.1285, -0.0459])\n",
      "pre:left true:left 8605/11700\n",
      "tensor([ 0.6037, -0.5895])\n",
      "pre:left true:left 8606/11700\n",
      "tensor([ 0.4027, -0.3257])\n",
      "pre:left true:left 8607/11700\n",
      "tensor([-0.2133,  0.2636])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1367_0_1523_20200412_120837154_6.jpg\n",
      "pre:right true:left 8608/11700\n",
      "tensor([ 0.6779, -0.6520])\n",
      "pre:left true:left 8609/11700\n",
      "tensor([ 0.7502, -0.6296])\n",
      "pre:left true:left 8610/11700\n",
      "tensor([ 0.1070, -0.1195])\n",
      "pre:left true:left 8611/11700\n",
      "tensor([ 0.0944, -0.0709])\n",
      "pre:left true:left 8612/11700\n",
      "tensor([ 0.9124, -0.8504])\n",
      "pre:left true:left 8613/11700\n",
      "tensor([ 0.4563, -0.4581])\n",
      "pre:left true:left 8614/11700\n",
      "tensor([ 1.2012, -1.2048])\n",
      "pre:left true:left 8615/11700\n",
      "tensor([ 0.3722, -0.2663])\n",
      "pre:left true:left 8616/11700\n",
      "tensor([ 1.1559, -1.2314])\n",
      "pre:left true:left 8617/11700\n",
      "tensor([ 1.9533, -1.9581])\n",
      "pre:left true:left 8618/11700\n",
      "tensor([ 0.5391, -0.4851])\n",
      "pre:left true:left 8619/11700\n",
      "tensor([ 0.8647, -0.8969])\n",
      "pre:left true:left 8620/11700\n",
      "tensor([ 0.3934, -0.3976])\n",
      "pre:left true:left 8621/11700\n",
      "tensor([ 0.1392, -0.0606])\n",
      "pre:left true:left 8622/11700\n",
      "tensor([ 0.6113, -0.6317])\n",
      "pre:left true:left 8623/11700\n",
      "tensor([ 0.7176, -0.6400])\n",
      "pre:left true:left 8624/11700\n",
      "tensor([ 0.2193, -0.1953])\n",
      "pre:left true:left 8625/11700\n",
      "tensor([ 1.0403, -1.0526])\n",
      "pre:left true:left 8626/11700\n",
      "tensor([ 1.1499, -1.1949])\n",
      "pre:left true:left 8627/11700\n",
      "tensor([-0.3156,  0.3899])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1270_0_1270_20200412_112616556_4.jpg\n",
      "pre:right true:left 8628/11700\n",
      "tensor([ 0.5236, -0.4856])\n",
      "pre:left true:left 8629/11700\n",
      "tensor([ 0.4083, -0.3941])\n",
      "pre:left true:left 8630/11700\n",
      "tensor([-0.2290,  0.2204])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1565_0_1721_20200412_121255229.jpg\n",
      "pre:right true:left 8631/11700\n",
      "tensor([ 0.1796, -0.2019])\n",
      "pre:left true:left 8632/11700\n",
      "tensor([ 0.3606, -0.2400])\n",
      "pre:left true:left 8633/11700\n",
      "tensor([ 0.6216, -0.6676])\n",
      "pre:left true:left 8634/11700\n",
      "tensor([ 0.5474, -0.5766])\n",
      "pre:left true:left 8635/11700\n",
      "tensor([ 0.4192, -0.4088])\n",
      "pre:left true:left 8636/11700\n",
      "tensor([ 0.1220, -0.1395])\n",
      "pre:left true:left 8637/11700\n",
      "tensor([ 0.2225, -0.1350])\n",
      "pre:left true:left 8638/11700\n",
      "tensor([ 0.2905, -0.2198])\n",
      "pre:left true:left 8639/11700\n",
      "tensor([ 0.0570, -0.1095])\n",
      "pre:left true:left 8640/11700\n",
      "tensor([ 0.6201, -0.6401])\n",
      "pre:left true:left 8641/11700\n",
      "tensor([ 0.4856, -0.5202])\n",
      "pre:left true:left 8642/11700\n",
      "tensor([ 0.8157, -0.7296])\n",
      "pre:left true:left 8643/11700\n",
      "tensor([-0.0827,  0.0872])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左273_0_429_20200412_114451413_2.jpg\n",
      "pre:right true:left 8644/11700\n",
      "tensor([ 1.0089, -1.0405])\n",
      "pre:left true:left 8645/11700\n",
      "tensor([ 0.4789, -0.4948])\n",
      "pre:left true:left 8646/11700\n",
      "tensor([ 1.3241, -1.1907])\n",
      "pre:left true:left 8647/11700\n",
      "tensor([ 0.3137, -0.3113])\n",
      "pre:left true:left 8648/11700\n",
      "tensor([ 1.4818, -1.3798])\n",
      "pre:left true:left 8649/11700\n",
      "tensor([ 0.9617, -0.9729])\n",
      "pre:left true:left 8650/11700\n",
      "tensor([ 0.8843, -0.7872])\n",
      "pre:left true:left 8651/11700\n",
      "tensor([ 0.7588, -0.6185])\n",
      "pre:left true:left 8652/11700\n",
      "tensor([ 0.5174, -0.4768])\n",
      "pre:left true:left 8653/11700\n",
      "tensor([-0.3748,  0.4254])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1236_0_1236_20200412_112532214_6.jpg\n",
      "pre:right true:left 8654/11700\n",
      "tensor([ 0.2813, -0.2848])\n",
      "pre:left true:left 8655/11700\n",
      "tensor([ 0.6240, -0.6287])\n",
      "pre:left true:left 8656/11700\n",
      "tensor([ 0.5254, -0.4866])\n",
      "pre:left true:left 8657/11700\n",
      "tensor([ 1.0287, -0.9957])\n",
      "pre:left true:left 8658/11700\n",
      "tensor([ 0.6089, -0.6439])\n",
      "pre:left true:left 8659/11700\n",
      "tensor([ 0.8750, -0.8887])\n",
      "pre:left true:left 8660/11700\n",
      "tensor([-0.5189,  0.5364])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左892_0_1048_20200412_115818084_7.jpg\n",
      "pre:right true:left 8661/11700\n",
      "tensor([ 0.4603, -0.3674])\n",
      "pre:left true:left 8662/11700\n",
      "tensor([ 0.8066, -0.8203])\n",
      "pre:left true:left 8663/11700\n",
      "tensor([ 0.6811, -0.6945])\n",
      "pre:left true:left 8664/11700\n",
      "tensor([ 0.1337, -0.2008])\n",
      "pre:left true:left 8665/11700\n",
      "tensor([ 0.2290, -0.2688])\n",
      "pre:left true:left 8666/11700\n",
      "tensor([ 0.9303, -0.8782])\n",
      "pre:left true:left 8667/11700\n",
      "tensor([ 0.2334, -0.1811])\n",
      "pre:left true:left 8668/11700\n",
      "tensor([ 0.5040, -0.4371])\n",
      "pre:left true:left 8669/11700\n",
      "tensor([ 0.4814, -0.5139])\n",
      "pre:left true:left 8670/11700\n",
      "tensor([ 0.7017, -0.7244])\n",
      "pre:left true:left 8671/11700\n",
      "tensor([ 1.1754, -1.1730])\n",
      "pre:left true:left 8672/11700\n",
      "tensor([ 0.2290, -0.2688])\n",
      "pre:left true:left 8673/11700\n",
      "tensor([ 0.6750, -0.6078])\n",
      "pre:left true:left 8674/11700\n",
      "tensor([ 0.4238, -0.4265])\n",
      "pre:left true:left 8675/11700\n",
      "tensor([ 0.3857, -0.4535])\n",
      "pre:left true:left 8676/11700\n",
      "tensor([ 0.3779, -0.3232])\n",
      "pre:left true:left 8677/11700\n",
      "tensor([ 0.3494, -0.3463])\n",
      "pre:left true:left 8678/11700\n",
      "tensor([ 0.5480, -0.5156])\n",
      "pre:left true:left 8679/11700\n",
      "tensor([ 0.7652, -0.7568])\n",
      "pre:left true:left 8680/11700\n",
      "tensor([ 0.7410, -0.8071])\n",
      "pre:left true:left 8681/11700\n",
      "tensor([ 0.3016, -0.2514])\n",
      "pre:left true:left 8682/11700\n",
      "tensor([ 0.7304, -0.7619])\n",
      "pre:left true:left 8683/11700\n",
      "tensor([-0.3799,  0.3903])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1331_0_1487_20200412_120750217.jpg\n",
      "pre:right true:left 8684/11700\n",
      "tensor([ 0.4181, -0.3954])\n",
      "pre:left true:left 8685/11700\n",
      "tensor([ 0.7986, -0.7833])\n",
      "pre:left true:left 8686/11700\n",
      "tensor([ 0.6452, -0.6600])\n",
      "pre:left true:left 8687/11700\n",
      "tensor([ 0.5822, -0.6463])\n",
      "pre:left true:left 8688/11700\n",
      "tensor([ 0.4699, -0.5438])\n",
      "pre:left true:left 8689/11700\n",
      "tensor([ 0.3342, -0.2935])\n",
      "pre:left true:left 8690/11700\n",
      "tensor([ 0.4007, -0.4655])\n",
      "pre:left true:left 8691/11700\n",
      "tensor([ 0.8730, -0.9033])\n",
      "pre:left true:left 8692/11700\n",
      "tensor([ 0.5316, -0.5540])\n",
      "pre:left true:left 8693/11700\n",
      "tensor([ 0.7900, -0.8670])\n",
      "pre:left true:left 8694/11700\n",
      "tensor([ 0.5933, -0.5666])\n",
      "pre:left true:left 8695/11700\n",
      "tensor([ 1.0402, -1.0027])\n",
      "pre:left true:left 8696/11700\n",
      "tensor([ 0.3625, -0.3892])\n",
      "pre:left true:left 8697/11700\n",
      "tensor([-0.3799,  0.3903])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1331_0_1487_20200412_120750217_10.jpg\n",
      "pre:right true:left 8698/11700\n",
      "tensor([ 0.8638, -0.9333])\n",
      "pre:left true:left 8699/11700\n",
      "tensor([-0.3535,  0.4028])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左787_0_943_20200412_115601257_1.jpg\n",
      "pre:right true:left 8700/11700\n",
      "tensor([-0.3625,  0.3385])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左528_0_528_20200412_110921885.jpg\n",
      "pre:right true:left 8701/11700\n",
      "tensor([ 0.4787, -0.4947])\n",
      "pre:left true:left 8702/11700\n",
      "tensor([ 0.5737, -0.4259])\n",
      "pre:left true:left 8703/11700\n",
      "tensor([ 0.1860, -0.0761])\n",
      "pre:left true:left 8704/11700\n",
      "tensor([ 0.5488, -0.4452])\n",
      "pre:left true:left 8705/11700\n",
      "tensor([-0.2334,  0.1916])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1489_0_1645_20200412_121116164_4.jpg\n",
      "pre:right true:left 8706/11700\n",
      "tensor([ 0.9902, -0.9508])\n",
      "pre:left true:left 8707/11700\n",
      "tensor([ 0.2094, -0.1753])\n",
      "pre:left true:left 8708/11700\n",
      "tensor([-0.3251,  0.3587])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左425_0_581_20200412_114809477_3.jpg\n",
      "pre:right true:left 8709/11700\n",
      "tensor([ 1.0708, -1.0993])\n",
      "pre:left true:left 8710/11700\n",
      "tensor([ 1.2549, -1.3068])\n",
      "pre:left true:left 8711/11700\n",
      "tensor([ 1.0211, -1.0025])\n",
      "pre:left true:left 8712/11700\n",
      "tensor([ 0.9651, -0.9685])\n",
      "pre:left true:left 8713/11700\n",
      "tensor([ 0.1928, -0.2228])\n",
      "pre:left true:left 8714/11700\n",
      "tensor([-0.7489,  0.7094])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左804_0_960_20200412_115623414_0.jpg\n",
      "pre:right true:left 8715/11700\n",
      "tensor([ 0.1926, -0.1642])\n",
      "pre:left true:left 8716/11700\n",
      "tensor([-0.2144,  0.1418])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左802_0_958_20200412_115620819_5.jpg\n",
      "pre:right true:left 8717/11700\n",
      "tensor([ 1.0970, -1.1172])\n",
      "pre:left true:left 8718/11700\n",
      "tensor([ 0.2638, -0.3018])\n",
      "pre:left true:left 8719/11700\n",
      "tensor([ 0.4912, -0.4713])\n",
      "pre:left true:left 8720/11700\n",
      "tensor([ 0.3159, -0.2891])\n",
      "pre:left true:left 8721/11700\n",
      "tensor([ 0.3210, -0.2619])\n",
      "pre:left true:left 8722/11700\n",
      "tensor([ 1.0997, -1.0476])\n",
      "pre:left true:left 8723/11700\n",
      "tensor([ 0.4558, -0.4555])\n",
      "pre:left true:left 8724/11700\n",
      "tensor([ 0.7564, -0.6973])\n",
      "pre:left true:left 8725/11700\n",
      "tensor([ 0.4241, -0.4688])\n",
      "pre:left true:left 8726/11700\n",
      "tensor([ 0.9741, -0.9775])\n",
      "pre:left true:left 8727/11700\n",
      "tensor([ 0.7256, -0.7622])\n",
      "pre:left true:left 8728/11700\n",
      "tensor([ 0.6258, -0.6228])\n",
      "pre:left true:left 8729/11700\n",
      "tensor([ 1.3507, -1.4239])\n",
      "pre:left true:left 8730/11700\n",
      "tensor([ 0.7962, -0.7349])\n",
      "pre:left true:left 8731/11700\n",
      "tensor([ 0.4926, -0.5819])\n",
      "pre:left true:left 8732/11700\n",
      "tensor([ 0.5716, -0.6086])\n",
      "pre:left true:left 8733/11700\n",
      "tensor([ 1.0780, -1.0022])\n",
      "pre:left true:left 8734/11700\n",
      "tensor([ 0.4286, -0.4066])\n",
      "pre:left true:left 8735/11700\n",
      "tensor([ 0.1400, -0.1844])\n",
      "pre:left true:left 8736/11700\n",
      "tensor([ 0.6442, -0.5132])\n",
      "pre:left true:left 8737/11700\n",
      "tensor([ 0.3215, -0.3511])\n",
      "pre:left true:left 8738/11700\n",
      "tensor([ 0.4504, -0.4706])\n",
      "pre:left true:left 8739/11700\n",
      "tensor([ 0.6596, -0.6822])\n",
      "pre:left true:left 8740/11700\n",
      "tensor([ 0.5421, -0.5670])\n",
      "pre:left true:left 8741/11700\n",
      "tensor([ 0.3358, -0.2704])\n",
      "pre:left true:left 8742/11700\n",
      "tensor([ 1.1393, -0.8966])\n",
      "pre:left true:left 8743/11700\n",
      "tensor([ 1.1919, -1.2166])\n",
      "pre:left true:left 8744/11700\n",
      "tensor([-1.0994,  1.0761])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左600_0_756_20200412_115157535_10.jpg\n",
      "pre:right true:left 8745/11700\n",
      "tensor([ 0.6318, -0.6815])\n",
      "pre:left true:left 8746/11700\n",
      "tensor([ 1.3104, -1.2375])\n",
      "pre:left true:left 8747/11700\n",
      "tensor([ 0.2051, -0.1538])\n",
      "pre:left true:left 8748/11700\n",
      "tensor([ 0.2492, -0.1930])\n",
      "pre:left true:left 8749/11700\n",
      "tensor([ 0.5356, -0.4443])\n",
      "pre:left true:left 8750/11700\n",
      "tensor([ 1.0183, -1.0308])\n",
      "pre:left true:left 8751/11700\n",
      "tensor([ 0.9982, -0.9774])\n",
      "pre:left true:left 8752/11700\n",
      "tensor([ 1.0451, -1.1433])\n",
      "pre:left true:left 8753/11700\n",
      "tensor([ 0.5184, -0.4191])\n",
      "pre:left true:left 8754/11700\n",
      "tensor([ 1.6693, -1.6835])\n",
      "pre:left true:left 8755/11700\n",
      "tensor([ 0.1480, -0.1777])\n",
      "pre:left true:left 8756/11700\n",
      "tensor([ 0.8588, -0.7566])\n",
      "pre:left true:left 8757/11700\n",
      "tensor([ 1.6298, -1.6249])\n",
      "pre:left true:left 8758/11700\n",
      "tensor([ 0.5978, -0.5199])\n",
      "pre:left true:left 8759/11700\n",
      "tensor([ 0.3048, -0.2320])\n",
      "pre:left true:left 8760/11700\n",
      "tensor([ 0.7335, -0.7417])\n",
      "pre:left true:left 8761/11700\n",
      "tensor([ 0.8164, -0.7253])\n",
      "pre:left true:left 8762/11700\n",
      "tensor([ 0.0038, -0.0063])\n",
      "pre:left true:left 8763/11700\n",
      "tensor([ 0.0667, -0.0307])\n",
      "pre:left true:left 8764/11700\n",
      "tensor([ 0.6144, -0.5921])\n",
      "pre:left true:left 8765/11700\n",
      "tensor([ 0.4431, -0.4015])\n",
      "pre:left true:left 8766/11700\n",
      "tensor([ 0.5302, -0.4834])\n",
      "pre:left true:left 8767/11700\n",
      "tensor([ 0.6480, -0.5199])\n",
      "pre:left true:left 8768/11700\n",
      "tensor([ 0.8471, -0.7650])\n",
      "pre:left true:left 8769/11700\n",
      "tensor([ 0.0343, -0.0275])\n",
      "pre:left true:left 8770/11700\n",
      "tensor([ 0.8069, -0.8363])\n",
      "pre:left true:left 8771/11700\n",
      "tensor([ 0.0749, -0.0316])\n",
      "pre:left true:left 8772/11700\n",
      "tensor([ 0.6910, -0.6791])\n",
      "pre:left true:left 8773/11700\n",
      "tensor([ 1.0756, -1.2266])\n",
      "pre:left true:left 8774/11700\n",
      "tensor([ 0.9507, -0.9378])\n",
      "pre:left true:left 8775/11700\n",
      "tensor([ 0.1358, -0.1417])\n",
      "pre:left true:left 8776/11700\n",
      "tensor([ 0.3276, -0.2792])\n",
      "pre:left true:left 8777/11700\n",
      "tensor([ 0.3377, -0.3130])\n",
      "pre:left true:left 8778/11700\n",
      "tensor([-0.0730,  0.1935])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左526_0_526_20200412_110919020_1.jpg\n",
      "pre:right true:left 8779/11700\n",
      "tensor([ 0.1093, -0.1498])\n",
      "pre:left true:left 8780/11700\n",
      "tensor([ 0.5593, -0.5351])\n",
      "pre:left true:left 8781/11700\n",
      "tensor([ 0.6322, -0.5627])\n",
      "pre:left true:left 8782/11700\n",
      "tensor([ 0.7273, -0.7575])\n",
      "pre:left true:left 8783/11700\n",
      "tensor([ 0.7854, -0.7518])\n",
      "pre:left true:left 8784/11700\n",
      "tensor([ 0.6007, -0.5834])\n",
      "pre:left true:left 8785/11700\n",
      "tensor([ 0.7622, -0.7934])\n",
      "pre:left true:left 8786/11700\n",
      "tensor([ 0.1343, -0.0702])\n",
      "pre:left true:left 8787/11700\n",
      "tensor([ 0.1485, -0.2187])\n",
      "pre:left true:left 8788/11700\n",
      "tensor([ 1.1811, -1.0774])\n",
      "pre:left true:left 8789/11700\n",
      "tensor([-0.4395,  0.4526])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左825_0_981_20200412_115650785_8.jpg\n",
      "pre:right true:left 8790/11700\n",
      "tensor([ 0.2903, -0.3257])\n",
      "pre:left true:left 8791/11700\n",
      "tensor([0.0828, 0.0488])\n",
      "pre:left true:left 8792/11700\n",
      "tensor([ 0.8556, -0.8191])\n",
      "pre:left true:left 8793/11700\n",
      "tensor([ 0.5313, -0.5331])\n",
      "pre:left true:left 8794/11700\n",
      "tensor([-0.7413,  0.7653])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左752_0_908_20200412_115515635_5.jpg\n",
      "pre:right true:left 8795/11700\n",
      "tensor([ 0.5999, -0.6617])\n",
      "pre:left true:left 8796/11700\n",
      "tensor([ 1.0593, -1.1069])\n",
      "pre:left true:left 8797/11700\n",
      "tensor([ 0.4931, -0.5185])\n",
      "pre:left true:left 8798/11700\n",
      "tensor([ 0.3712, -0.3756])\n",
      "pre:left true:left 8799/11700\n",
      "tensor([ 1.0426, -1.0254])\n",
      "pre:left true:left 8800/11700\n",
      "tensor([ 0.0500, -0.0652])\n",
      "pre:left true:left 8801/11700\n",
      "tensor([ 0.8149, -0.8994])\n",
      "pre:left true:left 8802/11700\n",
      "tensor([ 0.8511, -0.8640])\n",
      "pre:left true:left 8803/11700\n",
      "tensor([ 0.6173, -0.7087])\n",
      "pre:left true:left 8804/11700\n",
      "tensor([ 0.7271, -0.7625])\n",
      "pre:left true:left 8805/11700\n",
      "tensor([ 1.2533, -1.4089])\n",
      "pre:left true:left 8806/11700\n",
      "tensor([ 0.2678, -0.1196])\n",
      "pre:left true:left 8807/11700\n",
      "tensor([ 0.6310, -0.6670])\n",
      "pre:left true:left 8808/11700\n",
      "tensor([ 1.3249, -1.3290])\n",
      "pre:left true:left 8809/11700\n",
      "tensor([ 0.5517, -0.4349])\n",
      "pre:left true:left 8810/11700\n",
      "tensor([ 1.1929, -1.2034])\n",
      "pre:left true:left 8811/11700\n",
      "tensor([ 0.6357, -0.6004])\n",
      "pre:left true:left 8812/11700\n",
      "tensor([ 0.7482, -0.7648])\n",
      "pre:left true:left 8813/11700\n",
      "tensor([ 0.6186, -0.5764])\n",
      "pre:left true:left 8814/11700\n",
      "tensor([ 0.8433, -0.8311])\n",
      "pre:left true:left 8815/11700\n",
      "tensor([ 0.5317, -0.5107])\n",
      "pre:left true:left 8816/11700\n",
      "tensor([-0.3867,  0.3322])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左650_0_806_20200412_115302697_0.jpg\n",
      "pre:right true:left 8817/11700\n",
      "tensor([ 0.5836, -0.5716])\n",
      "pre:left true:left 8818/11700\n",
      "tensor([ 0.2258, -0.2361])\n",
      "pre:left true:left 8819/11700\n",
      "tensor([ 0.5596, -0.4268])\n",
      "pre:left true:left 8820/11700\n",
      "tensor([ 0.8415, -0.8573])\n",
      "pre:left true:left 8821/11700\n",
      "tensor([ 0.1466, -0.1419])\n",
      "pre:left true:left 8822/11700\n",
      "tensor([ 0.3484, -0.3187])\n",
      "pre:left true:left 8823/11700\n",
      "tensor([-0.2421,  0.2969])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左537_0_693_20200412_115035431_2.jpg\n",
      "pre:right true:left 8824/11700\n",
      "tensor([ 0.3528, -0.2787])\n",
      "pre:left true:left 8825/11700\n",
      "tensor([ 0.4272, -0.3735])\n",
      "pre:left true:left 8826/11700\n",
      "tensor([ 0.5989, -0.6064])\n",
      "pre:left true:left 8827/11700\n",
      "tensor([ 0.1470, -0.1627])\n",
      "pre:left true:left 8828/11700\n",
      "tensor([ 0.1115, -0.0498])\n",
      "pre:left true:left 8829/11700\n",
      "tensor([ 0.7470, -0.7721])\n",
      "pre:left true:left 8830/11700\n",
      "tensor([ 0.4886, -0.4794])\n",
      "pre:left true:left 8831/11700\n",
      "tensor([-0.3505,  0.4645])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左494_0_494_20200412_110833366_5.jpg\n",
      "pre:right true:left 8832/11700\n",
      "tensor([-0.0166,  0.0181])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左429_0_429_20200412_110700666_3.jpg\n",
      "pre:right true:left 8833/11700\n",
      "tensor([ 0.8361, -0.7689])\n",
      "pre:left true:left 8834/11700\n",
      "tensor([ 0.7872, -0.7399])\n",
      "pre:left true:left 8835/11700\n",
      "tensor([ 0.4721, -0.2849])\n",
      "pre:left true:left 8836/11700\n",
      "tensor([ 0.4895, -0.3569])\n",
      "pre:left true:left 8837/11700\n",
      "tensor([ 1.3140, -1.2033])\n",
      "pre:left true:left 8838/11700\n",
      "tensor([ 0.6376, -0.6441])\n",
      "pre:left true:left 8839/11700\n",
      "tensor([ 1.1234, -1.1232])\n",
      "pre:left true:left 8840/11700\n",
      "tensor([ 0.3061, -0.2658])\n",
      "pre:left true:left 8841/11700\n",
      "tensor([ 0.5408, -0.4857])\n",
      "pre:left true:left 8842/11700\n",
      "tensor([ 0.5781, -0.5830])\n",
      "pre:left true:left 8843/11700\n",
      "tensor([-0.0184,  0.0213])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左600_0_600_20200412_111104575_0.jpg\n",
      "pre:right true:left 8844/11700\n",
      "tensor([ 0.2340, -0.1856])\n",
      "pre:left true:left 8845/11700\n",
      "tensor([ 0.0353, -0.0564])\n",
      "pre:left true:left 8846/11700\n",
      "tensor([-0.1281,  0.0748])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左840_0_996_20200412_115710343_1.jpg\n",
      "pre:right true:left 8847/11700\n",
      "tensor([ 0.4595, -0.4470])\n",
      "pre:left true:left 8848/11700\n",
      "tensor([ 0.5184, -0.4828])\n",
      "pre:left true:left 8849/11700\n",
      "tensor([ 0.7692, -0.7757])\n",
      "pre:left true:left 8850/11700\n",
      "tensor([ 0.4471, -0.3898])\n",
      "pre:left true:left 8851/11700\n",
      "tensor([0.0082, 0.0163])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左704_0_860_20200412_115413083_7.jpg\n",
      "pre:right true:left 8852/11700\n",
      "tensor([ 0.8241, -0.8004])\n",
      "pre:left true:left 8853/11700\n",
      "tensor([ 0.2940, -0.3107])\n",
      "pre:left true:left 8854/11700\n",
      "tensor([ 0.4484, -0.4497])\n",
      "pre:left true:left 8855/11700\n",
      "tensor([ 0.5018, -0.4484])\n",
      "pre:left true:left 8856/11700\n",
      "tensor([-0.0239, -0.0423])\n",
      "pre:left true:left 8857/11700\n",
      "tensor([ 0.6779, -0.7157])\n",
      "pre:left true:left 8858/11700\n",
      "tensor([-0.3750,  0.3842])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1575_0_1731_20200412_121308263_6.jpg\n",
      "pre:right true:left 8859/11700\n",
      "tensor([ 0.2531, -0.3007])\n",
      "pre:left true:left 8860/11700\n",
      "tensor([-0.2810,  0.3260])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左516_0_516_20200412_110904773_5.jpg\n",
      "pre:right true:left 8861/11700\n",
      "tensor([ 1.2362, -1.2656])\n",
      "pre:left true:left 8862/11700\n",
      "tensor([ 0.0980, -0.0099])\n",
      "pre:left true:left 8863/11700\n",
      "tensor([ 0.2144, -0.0626])\n",
      "pre:left true:left 8864/11700\n",
      "tensor([ 0.2857, -0.1662])\n",
      "pre:left true:left 8865/11700\n",
      "tensor([ 0.4466, -0.3390])\n",
      "pre:left true:left 8866/11700\n",
      "tensor([ 0.3553, -0.2916])\n",
      "pre:left true:left 8867/11700\n",
      "tensor([-0.1771,  0.3059])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1080_0_1080_20200412_112208942_4.jpg\n",
      "pre:right true:left 8868/11700\n",
      "tensor([ 0.9249, -0.8643])\n",
      "pre:left true:left 8869/11700\n",
      "tensor([ 0.2797, -0.2022])\n",
      "pre:left true:left 8870/11700\n",
      "tensor([ 0.3937, -0.4018])\n",
      "pre:left true:left 8871/11700\n",
      "tensor([ 0.5803, -0.5932])\n",
      "pre:left true:left 8872/11700\n",
      "tensor([ 0.7697, -0.7367])\n",
      "pre:left true:left 8873/11700\n",
      "tensor([ 0.8758, -0.8955])\n",
      "pre:left true:left 8874/11700\n",
      "tensor([ 0.6883, -0.6441])\n",
      "pre:left true:left 8875/11700\n",
      "tensor([ 0.6124, -0.5264])\n",
      "pre:left true:left 8876/11700\n",
      "tensor([ 0.6050, -0.5744])\n",
      "pre:left true:left 8877/11700\n",
      "tensor([ 1.2806, -1.2361])\n",
      "pre:left true:left 8878/11700\n",
      "tensor([ 1.0201, -1.0653])\n",
      "pre:left true:left 8879/11700\n",
      "tensor([ 0.3898, -0.4162])\n",
      "pre:left true:left 8880/11700\n",
      "tensor([ 0.3478, -0.2356])\n",
      "pre:left true:left 8881/11700\n",
      "tensor([ 0.4180, -0.4213])\n",
      "pre:left true:left 8882/11700\n",
      "tensor([ 0.7566, -0.7467])\n",
      "pre:left true:left 8883/11700\n",
      "tensor([ 0.6057, -0.5866])\n",
      "pre:left true:left 8884/11700\n",
      "tensor([ 0.2070, -0.2064])\n",
      "pre:left true:left 8885/11700\n",
      "tensor([ 1.0072, -0.9317])\n",
      "pre:left true:left 8886/11700\n",
      "tensor([-0.5171,  0.5411])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1618_0_1774_20200412_121404313.jpg\n",
      "pre:right true:left 8887/11700\n",
      "tensor([ 1.8629, -1.8971])\n",
      "pre:left true:left 8888/11700\n",
      "tensor([ 0.9294, -0.9377])\n",
      "pre:left true:left 8889/11700\n",
      "tensor([ 1.1802, -1.2254])\n",
      "pre:left true:left 8890/11700\n",
      "tensor([ 0.7162, -0.6438])\n",
      "pre:left true:left 8891/11700\n",
      "tensor([ 0.3342, -0.2695])\n",
      "pre:left true:left 8892/11700\n",
      "tensor([-0.7251,  0.7499])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左614_0_770_20200412_115215786_6.jpg\n",
      "pre:right true:left 8893/11700\n",
      "tensor([0.0702, 0.0434])\n",
      "pre:left true:left 8894/11700\n",
      "tensor([ 0.5196, -0.5364])\n",
      "pre:left true:left 8895/11700\n",
      "tensor([ 0.5435, -0.4136])\n",
      "pre:left true:left 8896/11700\n",
      "tensor([ 0.6339, -0.5768])\n",
      "pre:left true:left 8897/11700\n",
      "tensor([ 0.0934, -0.0479])\n",
      "pre:left true:left 8898/11700\n",
      "tensor([ 0.3114, -0.2858])\n",
      "pre:left true:left 8899/11700\n",
      "tensor([ 0.4572, -0.3566])\n",
      "pre:left true:left 8900/11700\n",
      "tensor([ 0.2517, -0.1732])\n",
      "pre:left true:left 8901/11700\n",
      "tensor([-0.1047,  0.1862])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1402_0_1558_20200412_120922756_7.jpg\n",
      "pre:right true:left 8902/11700\n",
      "tensor([ 1.3728, -1.3612])\n",
      "pre:left true:left 8903/11700\n",
      "tensor([ 0.9447, -0.8680])\n",
      "pre:left true:left 8904/11700\n",
      "tensor([ 0.6341, -0.5470])\n",
      "pre:left true:left 8905/11700\n",
      "tensor([ 0.9203, -0.8754])\n",
      "pre:left true:left 8906/11700\n",
      "tensor([ 0.2389, -0.1650])\n",
      "pre:left true:left 8907/11700\n",
      "tensor([ 0.9713, -1.0190])\n",
      "pre:left true:left 8908/11700\n",
      "tensor([ 1.1827, -1.1296])\n",
      "pre:left true:left 8909/11700\n",
      "tensor([ 0.7423, -0.7896])\n",
      "pre:left true:left 8910/11700\n",
      "tensor([ 0.5803, -0.4988])\n",
      "pre:left true:left 8911/11700\n",
      "tensor([ 0.6374, -0.6899])\n",
      "pre:left true:left 8912/11700\n",
      "tensor([ 0.4285, -0.4444])\n",
      "pre:left true:left 8913/11700\n",
      "tensor([ 0.2139, -0.2099])\n",
      "pre:left true:left 8914/11700\n",
      "tensor([ 0.2273, -0.0483])\n",
      "pre:left true:left 8915/11700\n",
      "tensor([ 0.1145, -0.1296])\n",
      "pre:left true:left 8916/11700\n",
      "tensor([-0.2097,  0.3603])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左306_0_306_20200412_105542285_1.jpg\n",
      "pre:right true:left 8917/11700\n",
      "tensor([ 1.7392, -1.7481])\n",
      "pre:left true:left 8918/11700\n",
      "tensor([ 0.9516, -0.8681])\n",
      "pre:left true:left 8919/11700\n",
      "tensor([ 0.0345, -0.0653])\n",
      "pre:left true:left 8920/11700\n",
      "tensor([ 0.3568, -0.2989])\n",
      "pre:left true:left 8921/11700\n",
      "tensor([ 0.9002, -0.9333])\n",
      "pre:left true:left 8922/11700\n",
      "tensor([ 0.3768, -0.3624])\n",
      "pre:left true:left 8923/11700\n",
      "tensor([-0.4333,  0.3957])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左801_0_801_20200412_111551285_9.jpg\n",
      "pre:right true:left 8924/11700\n",
      "tensor([ 0.7951, -0.7193])\n",
      "pre:left true:left 8925/11700\n",
      "tensor([ 0.2115, -0.2604])\n",
      "pre:left true:left 8926/11700\n",
      "tensor([ 0.3224, -0.3221])\n",
      "pre:left true:left 8927/11700\n",
      "tensor([ 0.5282, -0.5247])\n",
      "pre:left true:left 8928/11700\n",
      "tensor([ 0.1050, -0.1484])\n",
      "pre:left true:left 8929/11700\n",
      "tensor([ 0.8105, -0.7953])\n",
      "pre:left true:left 8930/11700\n",
      "tensor([ 0.1045, -0.0176])\n",
      "pre:left true:left 8931/11700\n",
      "tensor([ 0.8082, -0.8715])\n",
      "pre:left true:left 8932/11700\n",
      "tensor([ 1.3842, -1.4063])\n",
      "pre:left true:left 8933/11700\n",
      "tensor([ 0.2053, -0.1903])\n",
      "pre:left true:left 8934/11700\n",
      "tensor([ 0.5590, -0.5095])\n",
      "pre:left true:left 8935/11700\n",
      "tensor([ 0.7564, -0.8097])\n",
      "pre:left true:left 8936/11700\n",
      "tensor([ 0.4031, -0.3294])\n",
      "pre:left true:left 8937/11700\n",
      "tensor([ 0.8957, -0.8096])\n",
      "pre:left true:left 8938/11700\n",
      "tensor([ 0.9121, -0.9651])\n",
      "pre:left true:left 8939/11700\n",
      "tensor([-0.5151,  0.5082])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左383_0_539_20200412_114714754_5.jpg\n",
      "pre:right true:left 8940/11700\n",
      "tensor([ 0.2808, -0.2126])\n",
      "pre:left true:left 8941/11700\n",
      "tensor([ 0.8116, -0.7852])\n",
      "pre:left true:left 8942/11700\n",
      "tensor([ 0.8396, -0.8480])\n",
      "pre:left true:left 8943/11700\n",
      "tensor([ 0.2680, -0.2405])\n",
      "pre:left true:left 8944/11700\n",
      "tensor([ 0.5376, -0.5816])\n",
      "pre:left true:left 8945/11700\n",
      "tensor([ 0.2487, -0.2295])\n",
      "pre:left true:left 8946/11700\n",
      "tensor([ 0.8810, -0.8231])\n",
      "pre:left true:left 8947/11700\n",
      "tensor([0.0481, 0.0536])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左769_0_925_20200412_115537807_6.jpg\n",
      "pre:right true:left 8948/11700\n",
      "tensor([ 0.1586, -0.1321])\n",
      "pre:left true:left 8949/11700\n",
      "tensor([ 1.2143, -1.2275])\n",
      "pre:left true:left 8950/11700\n",
      "tensor([ 0.2639, -0.3227])\n",
      "pre:left true:left 8951/11700\n",
      "tensor([ 0.4610, -0.5045])\n",
      "pre:left true:left 8952/11700\n",
      "tensor([ 0.8899, -0.9703])\n",
      "pre:left true:left 8953/11700\n",
      "tensor([-0.1309,  0.0421])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左508_0_508_20200412_110853361_10.jpg\n",
      "pre:right true:left 8954/11700\n",
      "tensor([ 1.0698, -1.1020])\n",
      "pre:left true:left 8955/11700\n",
      "tensor([-0.8419,  0.8734])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左633_0_789_20200412_115240544_4.jpg\n",
      "pre:right true:left 8956/11700\n",
      "tensor([ 1.1677, -1.3176])\n",
      "pre:left true:left 8957/11700\n",
      "tensor([ 0.7175, -0.7984])\n",
      "pre:left true:left 8958/11700\n",
      "tensor([ 0.4223, -0.4165])\n",
      "pre:left true:left 8959/11700\n",
      "tensor([-0.4362,  0.3849])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左523_0_679_20200412_115017198_6.jpg\n",
      "pre:right true:left 8960/11700\n",
      "tensor([ 0.7616, -0.8822])\n",
      "pre:left true:left 8961/11700\n",
      "tensor([ 0.4780, -0.3808])\n",
      "pre:left true:left 8962/11700\n",
      "tensor([ 1.1187, -1.1392])\n",
      "pre:left true:left 8963/11700\n",
      "tensor([ 0.4158, -0.4271])\n",
      "pre:left true:left 8964/11700\n",
      "tensor([ 0.5506, -0.5222])\n",
      "pre:left true:left 8965/11700\n",
      "tensor([ 0.3234, -0.1913])\n",
      "pre:left true:left 8966/11700\n",
      "tensor([ 0.7820, -0.8565])\n",
      "pre:left true:left 8967/11700\n",
      "tensor([ 0.3221, -0.2964])\n",
      "pre:left true:left 8968/11700\n",
      "tensor([ 0.3438, -0.2977])\n",
      "pre:left true:left 8969/11700\n",
      "tensor([ 0.5897, -0.6728])\n",
      "pre:left true:left 8970/11700\n",
      "tensor([ 0.1692, -0.0760])\n",
      "pre:left true:left 8971/11700\n",
      "tensor([ 0.5853, -0.5833])\n",
      "pre:left true:left 8972/11700\n",
      "tensor([ 0.5603, -0.5936])\n",
      "pre:left true:left 8973/11700\n",
      "tensor([ 0.6686, -0.6729])\n",
      "pre:left true:left 8974/11700\n",
      "tensor([ 0.9455, -1.0755])\n",
      "pre:left true:left 8975/11700\n",
      "tensor([0.0058, 0.0374])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左967_0_1123_20200412_115955829_0.jpg\n",
      "pre:right true:left 8976/11700\n",
      "tensor([-0.2808,  0.3586])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左95_0_251_20200412_114059450_6.jpg\n",
      "pre:right true:left 8977/11700\n",
      "tensor([ 0.5989, -0.6306])\n",
      "pre:left true:left 8978/11700\n",
      "tensor([ 0.1300, -0.0837])\n",
      "pre:left true:left 8979/11700\n",
      "tensor([ 1.1822, -1.2024])\n",
      "pre:left true:left 8980/11700\n",
      "tensor([ 0.8613, -0.7903])\n",
      "pre:left true:left 8981/11700\n",
      "tensor([ 0.5132, -0.6114])\n",
      "pre:left true:left 8982/11700\n",
      "tensor([ 0.6859, -0.6813])\n",
      "pre:left true:left 8983/11700\n",
      "tensor([ 0.1065, -0.0308])\n",
      "pre:left true:left 8984/11700\n",
      "tensor([ 0.4162, -0.3970])\n",
      "pre:left true:left 8985/11700\n",
      "tensor([ 0.1103, -0.1192])\n",
      "pre:left true:left 8986/11700\n",
      "tensor([-1.4131,  1.4140])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1522_0_1678_20200412_121159184_5.jpg\n",
      "pre:right true:left 8987/11700\n",
      "tensor([ 0.3874, -0.3235])\n",
      "pre:left true:left 8988/11700\n",
      "tensor([ 0.6081, -0.6117])\n",
      "pre:left true:left 8989/11700\n",
      "tensor([-0.1774,  0.1820])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1126_0_1126_20200412_112308896_3.jpg\n",
      "pre:right true:left 8990/11700\n",
      "tensor([ 0.3912, -0.3956])\n",
      "pre:left true:left 8991/11700\n",
      "tensor([ 0.7911, -0.7304])\n",
      "pre:left true:left 8992/11700\n",
      "tensor([ 0.5890, -0.6514])\n",
      "pre:left true:left 8993/11700\n",
      "tensor([ 0.4042, -0.4381])\n",
      "pre:left true:left 8994/11700\n",
      "tensor([ 1.0949, -1.1291])\n",
      "pre:left true:left 8995/11700\n",
      "tensor([ 0.3411, -0.2920])\n",
      "pre:left true:left 8996/11700\n",
      "tensor([ 1.0707, -1.0416])\n",
      "pre:left true:left 8997/11700\n",
      "tensor([-0.2617,  0.2221])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左549_0_705_20200412_115051073_1.jpg\n",
      "pre:right true:left 8998/11700\n",
      "tensor([ 0.2374, -0.1935])\n",
      "pre:left true:left 8999/11700\n",
      "tensor([ 1.3366, -1.3322])\n",
      "pre:left true:left 9000/11700\n",
      "tensor([ 0.7052, -0.7509])\n",
      "pre:left true:left 9001/11700\n",
      "tensor([-0.0112, -0.0761])\n",
      "pre:left true:left 9002/11700\n",
      "tensor([ 1.7293, -1.6642])\n",
      "pre:left true:left 9003/11700\n",
      "tensor([ 0.7970, -0.7880])\n",
      "pre:left true:left 9004/11700\n",
      "tensor([ 0.1906, -0.0843])\n",
      "pre:left true:left 9005/11700\n",
      "tensor([ 0.6156, -0.7043])\n",
      "pre:left true:left 9006/11700\n",
      "tensor([ 0.8105, -0.8051])\n",
      "pre:left true:left 9007/11700\n",
      "tensor([ 0.0829, -0.1024])\n",
      "pre:left true:left 9008/11700\n",
      "tensor([ 1.1964, -1.1686])\n",
      "pre:left true:left 9009/11700\n",
      "tensor([ 0.1708, -0.2026])\n",
      "pre:left true:left 9010/11700\n",
      "tensor([ 0.4687, -0.4974])\n",
      "pre:left true:left 9011/11700\n",
      "tensor([ 0.8951, -0.9096])\n",
      "pre:left true:left 9012/11700\n",
      "tensor([ 0.2192, -0.1916])\n",
      "pre:left true:left 9013/11700\n",
      "tensor([ 1.0982, -1.1109])\n",
      "pre:left true:left 9014/11700\n",
      "tensor([ 0.6598, -0.6128])\n",
      "pre:left true:left 9015/11700\n",
      "tensor([ 0.5917, -0.6190])\n",
      "pre:left true:left 9016/11700\n",
      "tensor([ 1.3224, -1.2828])\n",
      "pre:left true:left 9017/11700\n",
      "tensor([ 0.5080, -0.5015])\n",
      "pre:left true:left 9018/11700\n",
      "tensor([ 0.3406, -0.2806])\n",
      "pre:left true:left 9019/11700\n",
      "tensor([ 0.0333, -0.0227])\n",
      "pre:left true:left 9020/11700\n",
      "tensor([ 0.8366, -0.8207])\n",
      "pre:left true:left 9021/11700\n",
      "tensor([ 0.3120, -0.3026])\n",
      "pre:left true:left 9022/11700\n",
      "tensor([ 0.2490, -0.2924])\n",
      "pre:left true:left 9023/11700\n",
      "tensor([ 0.3698, -0.3300])\n",
      "pre:left true:left 9024/11700\n",
      "tensor([-0.1137,  0.2355])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左719_0_875_20200412_115432635_1.jpg\n",
      "pre:right true:left 9025/11700\n",
      "tensor([ 0.4072, -0.3767])\n",
      "pre:left true:left 9026/11700\n",
      "tensor([ 0.3001, -0.2097])\n",
      "pre:left true:left 9027/11700\n",
      "tensor([ 0.4770, -0.5063])\n",
      "pre:left true:left 9028/11700\n",
      "tensor([ 0.7397, -0.6855])\n",
      "pre:left true:left 9029/11700\n",
      "tensor([ 0.2431, -0.2785])\n",
      "pre:left true:left 9030/11700\n",
      "tensor([-0.5107,  0.4428])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左825_0_825_20200412_111625516_5.jpg\n",
      "pre:right true:left 9031/11700\n",
      "tensor([ 0.5836, -0.6082])\n",
      "pre:left true:left 9032/11700\n",
      "tensor([-0.1513,  0.1986])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左971_0_1127_20200412_120001044_3.jpg\n",
      "pre:right true:left 9033/11700\n",
      "tensor([ 0.5293, -0.5664])\n",
      "pre:left true:left 9034/11700\n",
      "tensor([ 0.9370, -1.0078])\n",
      "pre:left true:left 9035/11700\n",
      "tensor([-0.4893,  0.4844])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左202_0_358_20200412_114318899_1.jpg\n",
      "pre:right true:left 9036/11700\n",
      "tensor([ 0.1706, -0.2111])\n",
      "pre:left true:left 9037/11700\n",
      "tensor([ 0.8182, -0.8289])\n",
      "pre:left true:left 9038/11700\n",
      "tensor([ 1.0153, -1.0611])\n",
      "pre:left true:left 9039/11700\n",
      "tensor([ 0.4431, -0.4317])\n",
      "pre:left true:left 9040/11700\n",
      "tensor([ 0.9144, -0.9098])\n",
      "pre:left true:left 9041/11700\n",
      "tensor([ 0.1027, -0.1027])\n",
      "pre:left true:left 9042/11700\n",
      "tensor([ 0.5795, -0.5572])\n",
      "pre:left true:left 9043/11700\n",
      "tensor([ 0.0996, -0.0250])\n",
      "pre:left true:left 9044/11700\n",
      "tensor([ 0.1099, -0.0647])\n",
      "pre:left true:left 9045/11700\n",
      "tensor([ 0.2192, -0.1995])\n",
      "pre:left true:left 9046/11700\n",
      "tensor([ 0.3519, -0.2520])\n",
      "pre:left true:left 9047/11700\n",
      "tensor([ 0.7255, -0.6595])\n",
      "pre:left true:left 9048/11700\n",
      "tensor([ 0.6953, -0.6826])\n",
      "pre:left true:left 9049/11700\n",
      "tensor([ 0.5245, -0.6085])\n",
      "pre:left true:left 9050/11700\n",
      "tensor([ 0.4279, -0.4494])\n",
      "pre:left true:left 9051/11700\n",
      "tensor([ 0.8771, -0.8570])\n",
      "pre:left true:left 9052/11700\n",
      "tensor([-0.0314,  0.0549])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左431_0_587_20200412_114817293_4.jpg\n",
      "pre:right true:left 9053/11700\n",
      "tensor([ 1.2470, -1.1223])\n",
      "pre:left true:left 9054/11700\n",
      "tensor([ 0.5627, -0.6002])\n",
      "pre:left true:left 9055/11700\n",
      "tensor([ 1.6993, -1.7511])\n",
      "pre:left true:left 9056/11700\n",
      "tensor([-0.1502,  0.1848])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左416_0_572_20200412_114757758_10.jpg\n",
      "pre:right true:left 9057/11700\n",
      "tensor([ 0.3841, -0.4587])\n",
      "pre:left true:left 9058/11700\n",
      "tensor([ 0.8410, -0.8394])\n",
      "pre:left true:left 9059/11700\n",
      "tensor([ 0.0522, -0.0606])\n",
      "pre:left true:left 9060/11700\n",
      "tensor([0.0190, 0.0425])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1200_0_1200_20200412_112445301_7.jpg\n",
      "pre:right true:left 9061/11700\n",
      "tensor([ 0.9952, -0.9325])\n",
      "pre:left true:left 9062/11700\n",
      "tensor([ 0.3924, -0.4070])\n",
      "pre:left true:left 9063/11700\n",
      "tensor([ 0.7348, -0.7897])\n",
      "pre:left true:left 9064/11700\n",
      "tensor([ 0.5894, -0.5909])\n",
      "pre:left true:left 9065/11700\n",
      "tensor([ 0.2822, -0.3498])\n",
      "pre:left true:left 9066/11700\n",
      "tensor([ 1.1824, -1.2144])\n",
      "pre:left true:left 9067/11700\n",
      "tensor([ 0.4751, -0.5110])\n",
      "pre:left true:left 9068/11700\n",
      "tensor([ 1.2669, -1.3330])\n",
      "pre:left true:left 9069/11700\n",
      "tensor([ 0.8476, -0.8509])\n",
      "pre:left true:left 9070/11700\n",
      "tensor([ 0.3982, -0.3418])\n",
      "pre:left true:left 9071/11700\n",
      "tensor([-0.0339,  0.0258])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左451_0_451_20200412_110732049.jpg\n",
      "pre:right true:left 9072/11700\n",
      "tensor([ 0.3199, -0.2489])\n",
      "pre:left true:left 9073/11700\n",
      "tensor([ 1.2856, -1.1890])\n",
      "pre:left true:left 9074/11700\n",
      "tensor([ 0.3720, -0.3064])\n",
      "pre:left true:left 9075/11700\n",
      "tensor([ 0.3256, -0.3765])\n",
      "pre:left true:left 9076/11700\n",
      "tensor([ 1.1076, -1.1405])\n",
      "pre:left true:left 9077/11700\n",
      "tensor([ 0.0189, -0.0370])\n",
      "pre:left true:left 9078/11700\n",
      "tensor([ 0.6832, -0.6428])\n",
      "pre:left true:left 9079/11700\n",
      "tensor([ 0.3468, -0.3826])\n",
      "pre:left true:left 9080/11700\n",
      "tensor([ 0.2831, -0.3274])\n",
      "pre:left true:left 9081/11700\n",
      "tensor([ 0.3641, -0.2932])\n",
      "pre:left true:left 9082/11700\n",
      "tensor([ 0.8165, -0.8282])\n",
      "pre:left true:left 9083/11700\n",
      "tensor([ 0.8015, -0.7974])\n",
      "pre:left true:left 9084/11700\n",
      "tensor([ 1.3457, -1.2881])\n",
      "pre:left true:left 9085/11700\n",
      "tensor([ 0.4607, -0.3961])\n",
      "pre:left true:left 9086/11700\n",
      "tensor([ 0.1676, -0.2013])\n",
      "pre:left true:left 9087/11700\n",
      "tensor([ 1.0788, -1.0670])\n",
      "pre:left true:left 9088/11700\n",
      "tensor([-0.0445,  0.0664])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左843_0_843_20200412_111651177_10.jpg\n",
      "pre:right true:left 9089/11700\n",
      "tensor([ 0.2762, -0.1666])\n",
      "pre:left true:left 9090/11700\n",
      "tensor([ 0.8221, -0.8248])\n",
      "pre:left true:left 9091/11700\n",
      "tensor([ 1.3287, -1.3833])\n",
      "pre:left true:left 9092/11700\n",
      "tensor([ 0.2014, -0.1521])\n",
      "pre:left true:left 9093/11700\n",
      "tensor([ 0.4821, -0.4568])\n",
      "pre:left true:left 9094/11700\n",
      "tensor([ 0.7421, -0.7563])\n",
      "pre:left true:left 9095/11700\n",
      "tensor([-0.1042,  0.1545])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左768_0_768_20200412_111504208_3.jpg\n",
      "pre:right true:left 9096/11700\n",
      "tensor([ 0.9437, -0.9248])\n",
      "pre:left true:left 9097/11700\n",
      "tensor([ 0.6606, -0.6837])\n",
      "pre:left true:left 9098/11700\n",
      "tensor([ 0.6067, -0.5574])\n",
      "pre:left true:left 9099/11700\n",
      "tensor([ 0.4248, -0.4929])\n",
      "pre:left true:left 9100/11700\n",
      "tensor([ 0.5062, -0.4953])\n",
      "pre:left true:left 9101/11700\n",
      "tensor([ 0.3340, -0.3414])\n",
      "pre:left true:left 9102/11700\n",
      "tensor([ 0.1506, -0.1381])\n",
      "pre:left true:left 9103/11700\n",
      "tensor([ 1.3333, -1.1359])\n",
      "pre:left true:left 9104/11700\n",
      "tensor([ 0.7438, -0.8058])\n",
      "pre:left true:left 9105/11700\n",
      "tensor([ 0.5792, -0.5919])\n",
      "pre:left true:left 9106/11700\n",
      "tensor([ 1.1148, -1.0875])\n",
      "pre:left true:left 9107/11700\n",
      "tensor([0.0290, 0.0200])\n",
      "pre:left true:left 9108/11700\n",
      "tensor([ 0.8541, -0.9334])\n",
      "pre:left true:left 9109/11700\n",
      "tensor([-0.1888,  0.2420])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1088_0_1088_20200412_112219368_7.jpg\n",
      "pre:right true:left 9110/11700\n",
      "tensor([ 0.7818, -0.7759])\n",
      "pre:left true:left 9111/11700\n",
      "tensor([ 0.3174, -0.3271])\n",
      "pre:left true:left 9112/11700\n",
      "tensor([ 1.5094, -1.4702])\n",
      "pre:left true:left 9113/11700\n",
      "tensor([ 0.9023, -0.9622])\n",
      "pre:left true:left 9114/11700\n",
      "tensor([-0.0996,  0.1491])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左742_0_742_20200412_111427140_0.jpg\n",
      "pre:right true:left 9115/11700\n",
      "tensor([ 0.5777, -0.5784])\n",
      "pre:left true:left 9116/11700\n",
      "tensor([ 0.3425, -0.4367])\n",
      "pre:left true:left 9117/11700\n",
      "tensor([ 0.4079, -0.4715])\n",
      "pre:left true:left 9118/11700\n",
      "tensor([ 0.1632, -0.2202])\n",
      "pre:left true:left 9119/11700\n",
      "tensor([ 1.0206, -1.0664])\n",
      "pre:left true:left 9120/11700\n",
      "tensor([-0.0869,  0.1113])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左162_0_162_20200412_110039865_9.jpg\n",
      "pre:right true:left 9121/11700\n",
      "tensor([ 0.4843, -0.5658])\n",
      "pre:left true:left 9122/11700\n",
      "tensor([ 0.6710, -0.6108])\n",
      "pre:left true:left 9123/11700\n",
      "tensor([ 0.1619, -0.1974])\n",
      "pre:left true:left 9124/11700\n",
      "tensor([ 1.2015, -1.1613])\n",
      "pre:left true:left 9125/11700\n",
      "tensor([ 0.6500, -0.7308])\n",
      "pre:left true:left 9126/11700\n",
      "tensor([ 0.3795, -0.4006])\n",
      "pre:left true:left 9127/11700\n",
      "tensor([ 0.7377, -0.7738])\n",
      "pre:left true:left 9128/11700\n",
      "tensor([ 0.4094, -0.4522])\n",
      "pre:left true:left 9129/11700\n",
      "tensor([ 0.9373, -0.9061])\n",
      "pre:left true:left 9130/11700\n",
      "tensor([ 0.0878, -0.0777])\n",
      "pre:left true:left 9131/11700\n",
      "tensor([ 0.9595, -0.8370])\n",
      "pre:left true:left 9132/11700\n",
      "tensor([ 0.2923, -0.2893])\n",
      "pre:left true:left 9133/11700\n",
      "tensor([ 0.6537, -0.4811])\n",
      "pre:left true:left 9134/11700\n",
      "tensor([ 0.8663, -0.8347])\n",
      "pre:left true:left 9135/11700\n",
      "tensor([ 0.5869, -0.6090])\n",
      "pre:left true:left 9136/11700\n",
      "tensor([ 0.7568, -0.7623])\n",
      "pre:left true:left 9137/11700\n",
      "tensor([-0.1620,  0.1905])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左690_0_846_20200412_115354827_5.jpg\n",
      "pre:right true:left 9138/11700\n",
      "tensor([ 0.0303, -0.0298])\n",
      "pre:left true:left 9139/11700\n",
      "tensor([ 0.2822, -0.2288])\n",
      "pre:left true:left 9140/11700\n",
      "tensor([ 0.1642, -0.2097])\n",
      "pre:left true:left 9141/11700\n",
      "tensor([ 0.8160, -0.8726])\n",
      "pre:left true:left 9142/11700\n",
      "tensor([ 0.4852, -0.5040])\n",
      "pre:left true:left 9143/11700\n",
      "tensor([ 0.3825, -0.3034])\n",
      "pre:left true:left 9144/11700\n",
      "tensor([ 0.5534, -0.5474])\n",
      "pre:left true:left 9145/11700\n",
      "tensor([ 0.0642, -0.0771])\n",
      "pre:left true:left 9146/11700\n",
      "tensor([-0.0267,  0.0393])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左585_0_741_20200412_115137994_0.jpg\n",
      "pre:right true:left 9147/11700\n",
      "tensor([ 1.1243, -1.1875])\n",
      "pre:left true:left 9148/11700\n",
      "tensor([ 0.7755, -0.8017])\n",
      "pre:left true:left 9149/11700\n",
      "tensor([-0.1617,  0.1749])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左475_0_631_20200412_114914633_7.jpg\n",
      "pre:right true:left 9150/11700\n",
      "tensor([ 0.0973, -0.1533])\n",
      "pre:left true:left 9151/11700\n",
      "tensor([ 0.1238, -0.0262])\n",
      "pre:left true:left 9152/11700\n",
      "tensor([ 0.7564, -0.8097])\n",
      "pre:left true:left 9153/11700\n",
      "tensor([ 0.6940, -0.6425])\n",
      "pre:left true:left 9154/11700\n",
      "tensor([ 1.5628, -1.5907])\n",
      "pre:left true:left 9155/11700\n",
      "tensor([ 0.3678, -0.2398])\n",
      "pre:left true:left 9156/11700\n",
      "tensor([ 0.8356, -0.7565])\n",
      "pre:left true:left 9157/11700\n",
      "tensor([ 0.4476, -0.5775])\n",
      "pre:left true:left 9158/11700\n",
      "tensor([ 1.2194, -1.2551])\n",
      "pre:left true:left 9159/11700\n",
      "tensor([ 0.7151, -0.6640])\n",
      "pre:left true:left 9160/11700\n",
      "tensor([ 1.2228, -1.2292])\n",
      "pre:left true:left 9161/11700\n",
      "tensor([ 0.6654, -0.7164])\n",
      "pre:left true:left 9162/11700\n",
      "tensor([ 0.4766, -0.5305])\n",
      "pre:left true:left 9163/11700\n",
      "tensor([ 0.4914, -0.5190])\n",
      "pre:left true:left 9164/11700\n",
      "tensor([ 2.0054, -2.0065])\n",
      "pre:left true:left 9165/11700\n",
      "tensor([-0.2091,  0.2043])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左697_0_853_20200412_115403965_2.jpg\n",
      "pre:right true:left 9166/11700\n",
      "tensor([ 0.4020, -0.2529])\n",
      "pre:left true:left 9167/11700\n",
      "tensor([-0.0045,  0.0294])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1533_0_1689_20200412_121213509_3.jpg\n",
      "pre:right true:left 9168/11700\n",
      "tensor([ 0.6402, -0.5554])\n",
      "pre:left true:left 9169/11700\n",
      "tensor([-0.4482,  0.3559])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左741_0_741_20200412_111425707_2.jpg\n",
      "pre:right true:left 9170/11700\n",
      "tensor([ 0.3718, -0.3947])\n",
      "pre:left true:left 9171/11700\n",
      "tensor([-0.4796,  0.4740])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左339_0_339_20200412_105621841_3.jpg\n",
      "pre:right true:left 9172/11700\n",
      "tensor([ 1.1010, -1.1212])\n",
      "pre:left true:left 9173/11700\n",
      "tensor([ 0.1408, -0.1934])\n",
      "pre:left true:left 9174/11700\n",
      "tensor([ 0.8103, -0.8046])\n",
      "pre:left true:left 9175/11700\n",
      "tensor([-0.0078, -0.0199])\n",
      "pre:left true:left 9176/11700\n",
      "tensor([-0.0416,  0.0970])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左791_0_947_20200412_115606477_10.jpg\n",
      "pre:right true:left 9177/11700\n",
      "tensor([ 0.6170, -0.5618])\n",
      "pre:left true:left 9178/11700\n",
      "tensor([ 1.0604, -1.0084])\n",
      "pre:left true:left 9179/11700\n",
      "tensor([-0.0094,  0.0547])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左647_0_803_20200412_115258799.jpg\n",
      "pre:right true:left 9180/11700\n",
      "tensor([ 1.1406, -1.0479])\n",
      "pre:left true:left 9181/11700\n",
      "tensor([ 0.6521, -0.5515])\n",
      "pre:left true:left 9182/11700\n",
      "tensor([ 0.4457, -0.5019])\n",
      "pre:left true:left 9183/11700\n",
      "tensor([ 0.8692, -0.8344])\n",
      "pre:left true:left 9184/11700\n",
      "tensor([-0.4390,  0.4415])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左712_0_868_20200412_115423513_9.jpg\n",
      "pre:right true:left 9185/11700\n",
      "tensor([ 1.0854, -0.9860])\n",
      "pre:left true:left 9186/11700\n",
      "tensor([ 0.9149, -0.9618])\n",
      "pre:left true:left 9187/11700\n",
      "tensor([ 1.1428, -1.1977])\n",
      "pre:left true:left 9188/11700\n",
      "tensor([ 0.6521, -0.6872])\n",
      "pre:left true:left 9189/11700\n",
      "tensor([ 0.9023, -0.8552])\n",
      "pre:left true:left 9190/11700\n",
      "tensor([ 0.3386, -0.3166])\n",
      "pre:left true:left 9191/11700\n",
      "tensor([ 0.5230, -0.5344])\n",
      "pre:left true:left 9192/11700\n",
      "tensor([ 0.6291, -0.6160])\n",
      "pre:left true:left 9193/11700\n",
      "tensor([ 1.2698, -1.3190])\n",
      "pre:left true:left 9194/11700\n",
      "tensor([ 0.9294, -0.9217])\n",
      "pre:left true:left 9195/11700\n",
      "tensor([ 0.4445, -0.5038])\n",
      "pre:left true:left 9196/11700\n",
      "tensor([ 0.5656, -0.5050])\n",
      "pre:left true:left 9197/11700\n",
      "tensor([ 0.6766, -0.5844])\n",
      "pre:left true:left 9198/11700\n",
      "tensor([ 1.0898, -1.0401])\n",
      "pre:left true:left 9199/11700\n",
      "tensor([ 1.0311, -1.0083])\n",
      "pre:left true:left 9200/11700\n",
      "tensor([ 0.8489, -0.8201])\n",
      "pre:left true:left 9201/11700\n",
      "tensor([ 0.8763, -0.9146])\n",
      "pre:left true:left 9202/11700\n",
      "tensor([ 0.2647, -0.2811])\n",
      "pre:left true:left 9203/11700\n",
      "tensor([ 0.3801, -0.4183])\n",
      "pre:left true:left 9204/11700\n",
      "tensor([ 0.0248, -0.1123])\n",
      "pre:left true:left 9205/11700\n",
      "tensor([ 1.8797, -1.8481])\n",
      "pre:left true:left 9206/11700\n",
      "tensor([ 0.8037, -0.7657])\n",
      "pre:left true:left 9207/11700\n",
      "tensor([-0.6648,  0.5979])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左744_0_900_20200412_115505217_3.jpg\n",
      "pre:right true:left 9208/11700\n",
      "tensor([ 0.3340, -0.3719])\n",
      "pre:left true:left 9209/11700\n",
      "tensor([ 1.1620, -1.2507])\n",
      "pre:left true:left 9210/11700\n",
      "tensor([ 0.4685, -0.4204])\n",
      "pre:left true:left 9211/11700\n",
      "tensor([ 0.8487, -0.7286])\n",
      "pre:left true:left 9212/11700\n",
      "tensor([ 1.3104, -1.2332])\n",
      "pre:left true:left 9213/11700\n",
      "tensor([ 0.5752, -0.5473])\n",
      "pre:left true:left 9214/11700\n",
      "tensor([ 0.3052, -0.2325])\n",
      "pre:left true:left 9215/11700\n",
      "tensor([ 0.1051, -0.0474])\n",
      "pre:left true:left 9216/11700\n",
      "tensor([ 0.5876, -0.6183])\n",
      "pre:left true:left 9217/11700\n",
      "tensor([ 1.2168, -1.1811])\n",
      "pre:left true:left 9218/11700\n",
      "tensor([ 0.0253, -0.0137])\n",
      "pre:left true:left 9219/11700\n",
      "tensor([ 0.8755, -0.8559])\n",
      "pre:left true:left 9220/11700\n",
      "tensor([ 0.8691, -0.8594])\n",
      "pre:left true:left 9221/11700\n",
      "tensor([ 0.8933, -0.8238])\n",
      "pre:left true:left 9222/11700\n",
      "tensor([ 0.5872, -0.6384])\n",
      "pre:left true:left 9223/11700\n",
      "tensor([ 0.5512, -0.5948])\n",
      "pre:left true:left 9224/11700\n",
      "tensor([ 0.4749, -0.4634])\n",
      "pre:left true:left 9225/11700\n",
      "tensor([ 0.7576, -0.7192])\n",
      "pre:left true:left 9226/11700\n",
      "tensor([ 0.7737, -0.7881])\n",
      "pre:left true:left 9227/11700\n",
      "tensor([ 0.2622, -0.2971])\n",
      "pre:left true:left 9228/11700\n",
      "tensor([ 0.4864, -0.4584])\n",
      "pre:left true:left 9229/11700\n",
      "tensor([ 0.4249, -0.3837])\n",
      "pre:left true:left 9230/11700\n",
      "tensor([ 0.3390, -0.4171])\n",
      "pre:left true:left 9231/11700\n",
      "tensor([ 0.8225, -0.7713])\n",
      "pre:left true:left 9232/11700\n",
      "tensor([ 0.3966, -0.2255])\n",
      "pre:left true:left 9233/11700\n",
      "tensor([ 0.3454, -0.3831])\n",
      "pre:left true:left 9234/11700\n",
      "tensor([ 0.8930, -0.8824])\n",
      "pre:left true:left 9235/11700\n",
      "tensor([ 0.1654, -0.1498])\n",
      "pre:left true:left 9236/11700\n",
      "tensor([ 0.6635, -0.6696])\n",
      "pre:left true:left 9237/11700\n",
      "tensor([ 0.1272, -0.0778])\n",
      "pre:left true:left 9238/11700\n",
      "tensor([ 0.4019, -0.3783])\n",
      "pre:left true:left 9239/11700\n",
      "tensor([ 0.8797, -0.9132])\n",
      "pre:left true:left 9240/11700\n",
      "tensor([ 1.4479, -1.4064])\n",
      "pre:left true:left 9241/11700\n",
      "tensor([0.0255, 0.0468])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1329_0_1329_20200412_112743331_7.jpg\n",
      "pre:right true:left 9242/11700\n",
      "tensor([-0.0206, -0.0767])\n",
      "pre:left true:left 9243/11700\n",
      "tensor([ 0.0826, -0.1223])\n",
      "pre:left true:left 9244/11700\n",
      "tensor([ 0.8416, -0.9666])\n",
      "pre:left true:left 9245/11700\n",
      "tensor([-0.1164,  0.0620])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1196_0_1352_20200412_120454296_3.jpg\n",
      "pre:right true:left 9246/11700\n",
      "tensor([ 0.4135, -0.3013])\n",
      "pre:left true:left 9247/11700\n",
      "tensor([ 0.2517, -0.2570])\n",
      "pre:left true:left 9248/11700\n",
      "tensor([ 0.1681, -0.1302])\n",
      "pre:left true:left 9249/11700\n",
      "tensor([ 0.5764, -0.5537])\n",
      "pre:left true:left 9250/11700\n",
      "tensor([ 0.5195, -0.4590])\n",
      "pre:left true:left 9251/11700\n",
      "tensor([ 0.1466, -0.1599])\n",
      "pre:left true:left 9252/11700\n",
      "tensor([ 0.3225, -0.2171])\n",
      "pre:left true:left 9253/11700\n",
      "tensor([ 0.6794, -0.6447])\n",
      "pre:left true:left 9254/11700\n",
      "tensor([-0.4811,  0.5996])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左306_0_306_20200412_105542285_2.jpg\n",
      "pre:right true:left 9255/11700\n",
      "tensor([ 0.3399, -0.2676])\n",
      "pre:left true:left 9256/11700\n",
      "tensor([ 0.3126, -0.2624])\n",
      "pre:left true:left 9257/11700\n",
      "tensor([ 1.3883, -1.2647])\n",
      "pre:left true:left 9258/11700\n",
      "tensor([ 0.2220, -0.1180])\n",
      "pre:left true:left 9259/11700\n",
      "tensor([ 0.1978, -0.2621])\n",
      "pre:left true:left 9260/11700\n",
      "tensor([ 0.8872, -0.9102])\n",
      "pre:left true:left 9261/11700\n",
      "tensor([-0.2446,  0.3164])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1329_0_1485_20200412_120747629_2.jpg\n",
      "pre:right true:left 9262/11700\n",
      "tensor([ 1.1115, -1.0786])\n",
      "pre:left true:left 9263/11700\n",
      "tensor([ 0.2596, -0.1423])\n",
      "pre:left true:left 9264/11700\n",
      "tensor([ 1.4415, -1.4425])\n",
      "pre:left true:left 9265/11700\n",
      "tensor([ 0.6233, -0.6380])\n",
      "pre:left true:left 9266/11700\n",
      "tensor([-0.5086,  0.5722])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左671_0_671_20200412_111245857_5.jpg\n",
      "pre:right true:left 9267/11700\n",
      "tensor([ 0.5352, -0.5507])\n",
      "pre:left true:left 9268/11700\n",
      "tensor([ 0.5564, -0.5835])\n",
      "pre:left true:left 9269/11700\n",
      "tensor([ 1.0863, -1.1375])\n",
      "pre:left true:left 9270/11700\n",
      "tensor([ 0.9538, -0.9472])\n",
      "pre:left true:left 9271/11700\n",
      "tensor([ 1.1443, -1.1168])\n",
      "pre:left true:left 9272/11700\n",
      "tensor([-0.4699,  0.4808])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左893_0_1049_20200412_115819396_6.jpg\n",
      "pre:right true:left 9273/11700\n",
      "tensor([ 0.3370, -0.2816])\n",
      "pre:left true:left 9274/11700\n",
      "tensor([ 0.3770, -0.2788])\n",
      "pre:left true:left 9275/11700\n",
      "tensor([-0.0877,  0.0069])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左435_0_591_20200412_114822525_6.jpg\n",
      "pre:right true:left 9276/11700\n",
      "tensor([ 0.8517, -0.7675])\n",
      "pre:left true:left 9277/11700\n",
      "tensor([ 1.0068, -1.0281])\n",
      "pre:left true:left 9278/11700\n",
      "tensor([ 0.7058, -0.7049])\n",
      "pre:left true:left 9279/11700\n",
      "tensor([ 0.3841, -0.3389])\n",
      "pre:left true:left 9280/11700\n",
      "tensor([ 0.7414, -0.7671])\n",
      "pre:left true:left 9281/11700\n",
      "tensor([ 0.5954, -0.6972])\n",
      "pre:left true:left 9282/11700\n",
      "tensor([-0.0227, -0.0259])\n",
      "pre:left true:left 9283/11700\n",
      "tensor([ 1.2036, -1.2447])\n",
      "pre:left true:left 9284/11700\n",
      "tensor([ 0.8015, -0.7608])\n",
      "pre:left true:left 9285/11700\n",
      "tensor([ 1.1500, -1.1128])\n",
      "pre:left true:left 9286/11700\n",
      "tensor([ 0.8566, -0.8442])\n",
      "pre:left true:left 9287/11700\n",
      "tensor([ 0.5688, -0.5620])\n",
      "pre:left true:left 9288/11700\n",
      "tensor([ 0.8896, -0.8391])\n",
      "pre:left true:left 9289/11700\n",
      "tensor([-0.9557,  0.9233])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左828_0_984_20200412_115654687_2.jpg\n",
      "pre:right true:left 9290/11700\n",
      "tensor([ 0.6316, -0.5863])\n",
      "pre:left true:left 9291/11700\n",
      "tensor([ 0.0601, -0.0152])\n",
      "pre:left true:left 9292/11700\n",
      "tensor([ 0.8387, -0.8308])\n",
      "pre:left true:left 9293/11700\n",
      "tensor([ 0.2946, -0.2228])\n",
      "pre:left true:left 9294/11700\n",
      "tensor([ 1.3570, -1.3867])\n",
      "pre:left true:left 9295/11700\n",
      "tensor([ 0.7632, -0.6696])\n",
      "pre:left true:left 9296/11700\n",
      "tensor([ 0.8937, -0.9315])\n",
      "pre:left true:left 9297/11700\n",
      "tensor([ 0.9711, -1.0528])\n",
      "pre:left true:left 9298/11700\n",
      "tensor([ 0.1255, -0.0660])\n",
      "pre:left true:left 9299/11700\n",
      "tensor([ 0.8591, -0.8217])\n",
      "pre:left true:left 9300/11700\n",
      "tensor([ 0.9463, -0.9883])\n",
      "pre:left true:left 9301/11700\n",
      "tensor([-0.5180,  0.5939])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左296_0_296_20200412_110350973_6.jpg\n",
      "pre:right true:left 9302/11700\n",
      "tensor([ 0.3650, -0.2494])\n",
      "pre:left true:left 9303/11700\n",
      "tensor([ 0.6097, -0.5508])\n",
      "pre:left true:left 9304/11700\n",
      "tensor([ 0.4899, -0.5307])\n",
      "pre:left true:left 9305/11700\n",
      "tensor([-0.4878,  0.6821])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左789_0_945_20200412_115603865_6.jpg\n",
      "pre:right true:left 9306/11700\n",
      "tensor([-0.2304,  0.2046])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左404_0_560_20200412_114742117_7.jpg\n",
      "pre:right true:left 9307/11700\n",
      "tensor([ 0.7317, -0.6788])\n",
      "pre:left true:left 9308/11700\n",
      "tensor([-0.6401,  0.7526])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左853_0_1009_20200412_115727284_1.jpg\n",
      "pre:right true:left 9309/11700\n",
      "tensor([ 1.2602, -1.2460])\n",
      "pre:left true:left 9310/11700\n",
      "tensor([ 0.1620, -0.1875])\n",
      "pre:left true:left 9311/11700\n",
      "tensor([ 0.2870, -0.2749])\n",
      "pre:left true:left 9312/11700\n",
      "tensor([ 0.5300, -0.4803])\n",
      "pre:left true:left 9313/11700\n",
      "tensor([ 0.5424, -0.5636])\n",
      "pre:left true:left 9314/11700\n",
      "tensor([ 0.5728, -0.5524])\n",
      "pre:left true:left 9315/11700\n",
      "tensor([ 0.2035, -0.1591])\n",
      "pre:left true:left 9316/11700\n",
      "tensor([ 0.6792, -0.5865])\n",
      "pre:left true:left 9317/11700\n",
      "tensor([ 0.7011, -0.6456])\n",
      "pre:left true:left 9318/11700\n",
      "tensor([ 0.8240, -0.7907])\n",
      "pre:left true:left 9319/11700\n",
      "tensor([ 0.2505, -0.2798])\n",
      "pre:left true:left 9320/11700\n",
      "tensor([ 0.4500, -0.4372])\n",
      "pre:left true:left 9321/11700\n",
      "tensor([ 0.6773, -0.6925])\n",
      "pre:left true:left 9322/11700\n",
      "tensor([-0.2845,  0.2635])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左975_0_975_20200412_111952130_0.jpg\n",
      "pre:right true:left 9323/11700\n",
      "tensor([ 0.1589, -0.1941])\n",
      "pre:left true:left 9324/11700\n",
      "tensor([ 0.1417, -0.1972])\n",
      "pre:left true:left 9325/11700\n",
      "tensor([ 0.7721, -0.7818])\n",
      "pre:left true:left 9326/11700\n",
      "tensor([ 0.5083, -0.5272])\n",
      "pre:left true:left 9327/11700\n",
      "tensor([ 0.8404, -0.8044])\n",
      "pre:left true:left 9328/11700\n",
      "tensor([ 0.6163, -0.6526])\n",
      "pre:left true:left 9329/11700\n",
      "tensor([ 0.8076, -0.8319])\n",
      "pre:left true:left 9330/11700\n",
      "tensor([ 0.7901, -0.7289])\n",
      "pre:left true:left 9331/11700\n",
      "tensor([ 0.4586, -0.4650])\n",
      "pre:left true:left 9332/11700\n",
      "tensor([ 1.1640, -1.1846])\n",
      "pre:left true:left 9333/11700\n",
      "tensor([ 0.5482, -0.5820])\n",
      "pre:left true:left 9334/11700\n",
      "tensor([ 0.5335, -0.4837])\n",
      "pre:left true:left 9335/11700\n",
      "tensor([ 0.7593, -0.6536])\n",
      "pre:left true:left 9336/11700\n",
      "tensor([ 0.3577, -0.3530])\n",
      "pre:left true:left 9337/11700\n",
      "tensor([ 0.8141, -0.8389])\n",
      "pre:left true:left 9338/11700\n",
      "tensor([ 0.3950, -0.4374])\n",
      "pre:left true:left 9339/11700\n",
      "tensor([ 0.4471, -0.4408])\n",
      "pre:left true:left 9340/11700\n",
      "tensor([ 0.4415, -0.4044])\n",
      "pre:left true:left 9341/11700\n",
      "tensor([ 0.4856, -0.4892])\n",
      "pre:left true:left 9342/11700\n",
      "tensor([ 0.4092, -0.3813])\n",
      "pre:left true:left 9343/11700\n",
      "tensor([ 1.2058, -1.1152])\n",
      "pre:left true:left 9344/11700\n",
      "tensor([ 0.0596, -0.0179])\n",
      "pre:left true:left 9345/11700\n",
      "tensor([ 1.0539, -1.0789])\n",
      "pre:left true:left 9346/11700\n",
      "tensor([ 0.2748, -0.3073])\n",
      "pre:left true:left 9347/11700\n",
      "tensor([ 0.3484, -0.2504])\n",
      "pre:left true:left 9348/11700\n",
      "tensor([ 0.7932, -0.8095])\n",
      "pre:left true:left 9349/11700\n",
      "tensor([ 1.3331, -1.4434])\n",
      "pre:left true:left 9350/11700\n",
      "tensor([ 0.5839, -0.5932])\n",
      "pre:left true:left 9351/11700\n",
      "tensor([ 0.2106, -0.2853])\n",
      "pre:left true:left 9352/11700\n",
      "tensor([-0.0182,  0.0029])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左355_0_511_20200412_114638266_5.jpg\n",
      "pre:right true:left 9353/11700\n",
      "tensor([ 0.3653, -0.3862])\n",
      "pre:left true:left 9354/11700\n",
      "tensor([ 0.6270, -0.5934])\n",
      "pre:left true:left 9355/11700\n",
      "tensor([ 0.8160, -0.8233])\n",
      "pre:left true:left 9356/11700\n",
      "tensor([ 1.0685, -1.0172])\n",
      "pre:left true:left 9357/11700\n",
      "tensor([ 0.0609, -0.0876])\n",
      "pre:left true:left 9358/11700\n",
      "tensor([ 0.7224, -0.7340])\n",
      "pre:left true:left 9359/11700\n",
      "tensor([ 0.2961, -0.3398])\n",
      "pre:left true:left 9360/11700\n",
      "tensor([ 0.4267, -0.3815])\n",
      "pre:left true:left 9361/11700\n",
      "tensor([ 0.8662, -0.9518])\n",
      "pre:left true:left 9362/11700\n",
      "tensor([ 0.1367, -0.1341])\n",
      "pre:left true:left 9363/11700\n",
      "tensor([ 1.1313, -1.1285])\n",
      "pre:left true:left 9364/11700\n",
      "tensor([ 1.8675, -1.8222])\n",
      "pre:left true:left 9365/11700\n",
      "tensor([ 0.7477, -0.6930])\n",
      "pre:left true:left 9366/11700\n",
      "tensor([ 0.4358, -0.4804])\n",
      "pre:left true:left 9367/11700\n",
      "tensor([ 0.7424, -0.7251])\n",
      "pre:left true:left 9368/11700\n",
      "tensor([ 0.6893, -0.7521])\n",
      "pre:left true:left 9369/11700\n",
      "tensor([ 0.5319, -0.5091])\n",
      "pre:left true:left 9370/11700\n",
      "tensor([-0.0025, -0.0347])\n",
      "pre:left true:left 9371/11700\n",
      "tensor([ 0.1292, -0.1968])\n",
      "pre:left true:left 9372/11700\n",
      "tensor([ 0.0892, -0.0841])\n",
      "pre:left true:left 9373/11700\n",
      "tensor([ 0.1210, -0.1635])\n",
      "pre:left true:left 9374/11700\n",
      "tensor([ 0.1134, -0.1024])\n",
      "pre:left true:left 9375/11700\n",
      "tensor([ 0.3608, -0.4516])\n",
      "pre:left true:left 9376/11700\n",
      "tensor([ 0.4659, -0.3963])\n",
      "pre:left true:left 9377/11700\n",
      "tensor([ 0.8982, -0.8981])\n",
      "pre:left true:left 9378/11700\n",
      "tensor([ 0.5999, -0.5799])\n",
      "pre:left true:left 9379/11700\n",
      "tensor([ 0.7129, -0.6387])\n",
      "pre:left true:left 9380/11700\n",
      "tensor([ 0.1331, -0.0782])\n",
      "pre:left true:left 9381/11700\n",
      "tensor([ 0.3493, -0.2196])\n",
      "pre:left true:left 9382/11700\n",
      "tensor([ 1.6087, -1.7528])\n",
      "pre:left true:left 9383/11700\n",
      "tensor([-0.1110,  0.2687])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左585_0_585_20200412_111043191_2.jpg\n",
      "pre:right true:left 9384/11700\n",
      "tensor([ 1.2145, -1.2391])\n",
      "pre:left true:left 9385/11700\n",
      "tensor([ 0.1650, -0.1783])\n",
      "pre:left true:left 9386/11700\n",
      "tensor([ 0.4448, -0.4418])\n",
      "pre:left true:left 9387/11700\n",
      "tensor([ 0.6152, -0.6122])\n",
      "pre:left true:left 9388/11700\n",
      "tensor([ 0.1155, -0.0435])\n",
      "pre:left true:left 9389/11700\n",
      "tensor([ 0.1545, -0.1094])\n",
      "pre:left true:left 9390/11700\n",
      "tensor([ 1.2509, -1.2235])\n",
      "pre:left true:left 9391/11700\n",
      "tensor([-0.1677,  0.2097])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左807_0_963_20200412_115627339_6.jpg\n",
      "pre:right true:left 9392/11700\n",
      "tensor([ 1.0618, -1.0978])\n",
      "pre:left true:left 9393/11700\n",
      "tensor([ 0.4394, -0.4454])\n",
      "pre:left true:left 9394/11700\n",
      "tensor([ 0.0917, -0.0492])\n",
      "pre:left true:left 9395/11700\n",
      "tensor([ 0.5922, -0.4979])\n",
      "pre:left true:left 9396/11700\n",
      "tensor([ 1.4104, -1.4068])\n",
      "pre:left true:left 9397/11700\n",
      "tensor([ 0.9492, -0.8555])\n",
      "pre:left true:left 9398/11700\n",
      "tensor([ 1.1255, -1.1180])\n",
      "pre:left true:left 9399/11700\n",
      "tensor([ 0.5793, -0.5487])\n",
      "pre:left true:left 9400/11700\n",
      "tensor([ 0.6321, -0.6313])\n",
      "pre:left true:left 9401/11700\n",
      "tensor([ 0.4333, -0.3740])\n",
      "pre:left true:left 9402/11700\n",
      "tensor([ 0.5289, -0.3247])\n",
      "pre:left true:left 9403/11700\n",
      "tensor([ 0.1610, -0.2915])\n",
      "pre:left true:left 9404/11700\n",
      "tensor([ 0.7233, -0.7041])\n",
      "pre:left true:left 9405/11700\n",
      "tensor([ 0.2640, -0.2737])\n",
      "pre:left true:left 9406/11700\n",
      "tensor([ 0.4027, -0.3257])\n",
      "pre:left true:left 9407/11700\n",
      "tensor([ 0.9449, -0.9791])\n",
      "pre:left true:left 9408/11700\n",
      "tensor([ 1.2277, -1.1190])\n",
      "pre:left true:left 9409/11700\n",
      "tensor([ 0.4858, -0.4587])\n",
      "pre:left true:left 9410/11700\n",
      "tensor([ 0.5953, -0.5196])\n",
      "pre:left true:left 9411/11700\n",
      "tensor([ 0.8616, -0.8162])\n",
      "pre:left true:left 9412/11700\n",
      "tensor([ 0.5060, -0.3656])\n",
      "pre:left true:left 9413/11700\n",
      "tensor([ 0.1250, -0.0823])\n",
      "pre:left true:left 9414/11700\n",
      "tensor([ 2.1390, -2.1770])\n",
      "pre:left true:left 9415/11700\n",
      "tensor([ 0.1787, -0.1862])\n",
      "pre:left true:left 9416/11700\n",
      "tensor([ 0.4955, -0.5291])\n",
      "pre:left true:left 9417/11700\n",
      "tensor([ 0.5781, -0.5614])\n",
      "pre:left true:left 9418/11700\n",
      "tensor([ 0.9488, -0.9437])\n",
      "pre:left true:left 9419/11700\n",
      "tensor([-0.1893,  0.2115])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1302_0_1458_20200412_120712431_3.jpg\n",
      "pre:right true:left 9420/11700\n",
      "tensor([ 0.3912, -0.3598])\n",
      "pre:left true:left 9421/11700\n",
      "tensor([ 1.0706, -1.0337])\n",
      "pre:left true:left 9422/11700\n",
      "tensor([ 1.4289, -1.4288])\n",
      "pre:left true:left 9423/11700\n",
      "tensor([ 0.9919, -0.9576])\n",
      "pre:left true:left 9424/11700\n",
      "tensor([ 0.4262, -0.4721])\n",
      "pre:left true:left 9425/11700\n",
      "tensor([ 0.7847, -0.8092])\n",
      "pre:left true:left 9426/11700\n",
      "tensor([ 0.9676, -1.0518])\n",
      "pre:left true:left 9427/11700\n",
      "tensor([ 0.4905, -0.3713])\n",
      "pre:left true:left 9428/11700\n",
      "tensor([-0.1035,  0.2058])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1592_0_1748_20200412_121330413_6.jpg\n",
      "pre:right true:left 9429/11700\n",
      "tensor([-0.0129, -0.0327])\n",
      "pre:left true:left 9430/11700\n",
      "tensor([ 0.6036, -0.5931])\n",
      "pre:left true:left 9431/11700\n",
      "tensor([ 0.0997, -0.1268])\n",
      "pre:left true:left 9432/11700\n",
      "tensor([ 0.6004, -0.6062])\n",
      "pre:left true:left 9433/11700\n",
      "tensor([ 1.0369, -1.0313])\n",
      "pre:left true:left 9434/11700\n",
      "tensor([ 1.0819, -1.1081])\n",
      "pre:left true:left 9435/11700\n",
      "tensor([ 0.6824, -0.5890])\n",
      "pre:left true:left 9436/11700\n",
      "tensor([ 0.5409, -0.5300])\n",
      "pre:left true:left 9437/11700\n",
      "tensor([ 1.1328, -1.2468])\n",
      "pre:left true:left 9438/11700\n",
      "tensor([-0.3905,  0.3813])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1311_0_1311_20200412_112709972_3.jpg\n",
      "pre:right true:left 9439/11700\n",
      "tensor([ 0.7025, -0.6481])\n",
      "pre:left true:left 9440/11700\n",
      "tensor([ 0.8091, -0.7283])\n",
      "pre:left true:left 9441/11700\n",
      "tensor([ 0.0924, -0.0844])\n",
      "pre:left true:left 9442/11700\n",
      "tensor([-0.4214,  0.4143])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左679_0_679_20200412_111257259_4.jpg\n",
      "pre:right true:left 9443/11700\n",
      "tensor([ 0.8194, -0.9094])\n",
      "pre:left true:left 9444/11700\n",
      "tensor([ 0.1646, -0.2284])\n",
      "pre:left true:left 9445/11700\n",
      "tensor([ 1.2167, -1.2749])\n",
      "pre:left true:left 9446/11700\n",
      "tensor([ 0.5367, -0.5143])\n",
      "pre:left true:left 9447/11700\n",
      "tensor([ 0.9060, -0.9319])\n",
      "pre:left true:left 9448/11700\n",
      "tensor([ 0.7790, -0.7888])\n",
      "pre:left true:left 9449/11700\n",
      "tensor([ 0.5514, -0.6289])\n",
      "pre:left true:left 9450/11700\n",
      "tensor([ 1.0591, -1.0169])\n",
      "pre:left true:left 9451/11700\n",
      "tensor([ 0.5224, -0.5666])\n",
      "pre:left true:left 9452/11700\n",
      "tensor([ 0.4827, -0.5121])\n",
      "pre:left true:left 9453/11700\n",
      "tensor([ 0.6909, -0.6583])\n",
      "pre:left true:left 9454/11700\n",
      "tensor([-0.1652,  0.1007])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左74_0_230_20200412_114032091.jpg\n",
      "pre:right true:left 9455/11700\n",
      "tensor([ 0.1123, -0.1865])\n",
      "pre:left true:left 9456/11700\n",
      "tensor([ 0.8317, -0.8095])\n",
      "pre:left true:left 9457/11700\n",
      "tensor([ 0.7368, -0.6897])\n",
      "pre:left true:left 9458/11700\n",
      "tensor([ 0.7044, -0.7445])\n",
      "pre:left true:left 9459/11700\n",
      "tensor([ 0.5388, -0.4667])\n",
      "pre:left true:left 9460/11700\n",
      "tensor([ 0.4467, -0.5056])\n",
      "pre:left true:left 9461/11700\n",
      "tensor([ 2.1457, -2.2124])\n",
      "pre:left true:left 9462/11700\n",
      "tensor([-0.0537,  0.1115])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左570_0_726_20200412_115118431_4.jpg\n",
      "pre:right true:left 9463/11700\n",
      "tensor([ 0.1670, -0.2047])\n",
      "pre:left true:left 9464/11700\n",
      "tensor([ 0.5708, -0.5354])\n",
      "pre:left true:left 9465/11700\n",
      "tensor([-0.1684,  0.2128])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左625_0_781_20200412_115230120.jpg\n",
      "pre:right true:left 9466/11700\n",
      "tensor([ 0.6110, -0.6639])\n",
      "pre:left true:left 9467/11700\n",
      "tensor([ 1.3934, -1.5761])\n",
      "pre:left true:left 9468/11700\n",
      "tensor([ 0.6585, -0.6148])\n",
      "pre:left true:left 9469/11700\n",
      "tensor([ 0.2192, -0.1306])\n",
      "pre:left true:left 9470/11700\n",
      "tensor([ 0.4252, -0.3849])\n",
      "pre:left true:left 9471/11700\n",
      "tensor([ 0.8982, -0.9534])\n",
      "pre:left true:left 9472/11700\n",
      "tensor([ 0.9371, -0.8665])\n",
      "pre:left true:left 9473/11700\n",
      "tensor([ 0.4239, -0.4701])\n",
      "pre:left true:left 9474/11700\n",
      "tensor([ 0.2488, -0.2507])\n",
      "pre:left true:left 9475/11700\n",
      "tensor([ 0.2894, -0.2977])\n",
      "pre:left true:left 9476/11700\n",
      "tensor([ 0.2721, -0.3339])\n",
      "pre:left true:left 9477/11700\n",
      "tensor([ 0.3339, -0.3682])\n",
      "pre:left true:left 9478/11700\n",
      "tensor([ 0.4367, -0.5034])\n",
      "pre:left true:left 9479/11700\n",
      "tensor([ 0.4037, -0.4474])\n",
      "pre:left true:left 9480/11700\n",
      "tensor([-0.0292,  0.0766])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左369_0_525_20200412_114656522_4.jpg\n",
      "pre:right true:left 9481/11700\n",
      "tensor([ 0.6016, -0.5931])\n",
      "pre:left true:left 9482/11700\n",
      "tensor([ 1.1756, -1.0464])\n",
      "pre:left true:left 9483/11700\n",
      "tensor([ 0.4388, -0.4995])\n",
      "pre:left true:left 9484/11700\n",
      "tensor([ 0.3398, -0.2885])\n",
      "pre:left true:left 9485/11700\n",
      "tensor([-0.3455,  0.3662])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左320_0_476_20200412_114552663_6.jpg\n",
      "pre:right true:left 9486/11700\n",
      "tensor([-0.1182,  0.1270])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1522_0_1678_20200412_121159184_10.jpg\n",
      "pre:right true:left 9487/11700\n",
      "tensor([ 0.3842, -0.4470])\n",
      "pre:left true:left 9488/11700\n",
      "tensor([ 0.2291, -0.1691])\n",
      "pre:left true:left 9489/11700\n",
      "tensor([ 1.3031, -1.2243])\n",
      "pre:left true:left 9490/11700\n",
      "tensor([ 0.4757, -0.5537])\n",
      "pre:left true:left 9491/11700\n",
      "tensor([ 0.2356, -0.0537])\n",
      "pre:left true:left 9492/11700\n",
      "tensor([-0.3737,  0.4623])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左412_0_412_20200412_110636409_3.jpg\n",
      "pre:right true:left 9493/11700\n",
      "tensor([ 0.6679, -0.6529])\n",
      "pre:left true:left 9494/11700\n",
      "tensor([ 0.2697, -0.2650])\n",
      "pre:left true:left 9495/11700\n",
      "tensor([ 0.5925, -0.5411])\n",
      "pre:left true:left 9496/11700\n",
      "tensor([ 0.0148, -0.0239])\n",
      "pre:left true:left 9497/11700\n",
      "tensor([ 0.0986, -0.0899])\n",
      "pre:left true:left 9498/11700\n",
      "tensor([-0.4212,  0.4463])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左802_0_958_20200412_115620819_0.jpg\n",
      "pre:right true:left 9499/11700\n",
      "tensor([ 0.2563, -0.1980])\n",
      "pre:left true:left 9500/11700\n",
      "tensor([ 0.5370, -0.5147])\n",
      "pre:left true:left 9501/11700\n",
      "tensor([ 0.1508, -0.1741])\n",
      "pre:left true:left 9502/11700\n",
      "tensor([ 0.0469, -0.0044])\n",
      "pre:left true:left 9503/11700\n",
      "tensor([ 0.4160, -0.4297])\n",
      "pre:left true:left 9504/11700\n",
      "tensor([ 0.9195, -0.9810])\n",
      "pre:left true:left 9505/11700\n",
      "tensor([ 0.8376, -0.7489])\n",
      "pre:left true:left 9506/11700\n",
      "tensor([ 1.1410, -1.2602])\n",
      "pre:left true:left 9507/11700\n",
      "tensor([ 0.6416, -0.6034])\n",
      "pre:left true:left 9508/11700\n",
      "tensor([0.0657, 0.0333])\n",
      "pre:left true:left 9509/11700\n",
      "tensor([ 0.7482, -0.7648])\n",
      "pre:left true:left 9510/11700\n",
      "tensor([ 0.4748, -0.4849])\n",
      "pre:left true:left 9511/11700\n",
      "tensor([ 0.5889, -0.5790])\n",
      "pre:left true:left 9512/11700\n",
      "tensor([ 0.9360, -0.8298])\n",
      "pre:left true:left 9513/11700\n",
      "tensor([ 1.0202, -1.1615])\n",
      "pre:left true:left 9514/11700\n",
      "tensor([ 0.1605, -0.1069])\n",
      "pre:left true:left 9515/11700\n",
      "tensor([ 0.7028, -0.7668])\n",
      "pre:left true:left 9516/11700\n",
      "tensor([ 0.1374, -0.1561])\n",
      "pre:left true:left 9517/11700\n",
      "tensor([ 0.9393, -0.9191])\n",
      "pre:left true:left 9518/11700\n",
      "tensor([ 1.0343, -1.1477])\n",
      "pre:left true:left 9519/11700\n",
      "tensor([ 0.3434, -0.3219])\n",
      "pre:left true:left 9520/11700\n",
      "tensor([ 0.3403, -0.2710])\n",
      "pre:left true:left 9521/11700\n",
      "tensor([ 0.3695, -0.2161])\n",
      "pre:left true:left 9522/11700\n",
      "tensor([-0.0051,  0.0381])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左648_0_804_20200412_115300105_5.jpg\n",
      "pre:right true:left 9523/11700\n",
      "tensor([-0.0919,  0.0331])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左606_0_762_20200412_115205352.jpg\n",
      "pre:right true:left 9524/11700\n",
      "tensor([ 0.9147, -1.0315])\n",
      "pre:left true:left 9525/11700\n",
      "tensor([ 1.0536, -1.1256])\n",
      "pre:left true:left 9526/11700\n",
      "tensor([-0.0919,  0.0331])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左606_0_762_20200412_115205352_10.jpg\n",
      "pre:right true:left 9527/11700\n",
      "tensor([ 0.1540, -0.1564])\n",
      "pre:left true:left 9528/11700\n",
      "tensor([ 0.1070, -0.1420])\n",
      "pre:left true:left 9529/11700\n",
      "tensor([ 0.5101, -0.5363])\n",
      "pre:left true:left 9530/11700\n",
      "tensor([ 0.6061, -0.5898])\n",
      "pre:left true:left 9531/11700\n",
      "tensor([ 0.4182, -0.4420])\n",
      "pre:left true:left 9532/11700\n",
      "tensor([ 1.2588, -1.3083])\n",
      "pre:left true:left 9533/11700\n",
      "tensor([ 1.0238, -1.0178])\n",
      "pre:left true:left 9534/11700\n",
      "tensor([ 0.7748, -0.6698])\n",
      "pre:left true:left 9535/11700\n",
      "tensor([ 0.3378, -0.4051])\n",
      "pre:left true:left 9536/11700\n",
      "tensor([ 0.7033, -0.7397])\n",
      "pre:left true:left 9537/11700\n",
      "tensor([ 0.2385, -0.1988])\n",
      "pre:left true:left 9538/11700\n",
      "tensor([ 0.9670, -0.9367])\n",
      "pre:left true:left 9539/11700\n",
      "tensor([ 0.4480, -0.4838])\n",
      "pre:left true:left 9540/11700\n",
      "tensor([ 0.2269, -0.3445])\n",
      "pre:left true:left 9541/11700\n",
      "tensor([ 1.5874, -1.5245])\n",
      "pre:left true:left 9542/11700\n",
      "tensor([ 0.0353, -0.0564])\n",
      "pre:left true:left 9543/11700\n",
      "tensor([ 0.9548, -0.9539])\n",
      "pre:left true:left 9544/11700\n",
      "tensor([ 1.2743, -1.1951])\n",
      "pre:left true:left 9545/11700\n",
      "tensor([-0.1374,  0.1015])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1595_0_1751_20200412_121334340_7.jpg\n",
      "pre:right true:left 9546/11700\n",
      "tensor([-0.4271,  0.5067])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左789_0_945_20200412_115603865_9.jpg\n",
      "pre:right true:left 9547/11700\n",
      "tensor([ 1.6578, -1.5707])\n",
      "pre:left true:left 9548/11700\n",
      "tensor([ 0.0787, -0.0468])\n",
      "pre:left true:left 9549/11700\n",
      "tensor([ 0.9347, -0.8917])\n",
      "pre:left true:left 9550/11700\n",
      "tensor([ 0.4994, -0.4031])\n",
      "pre:left true:left 9551/11700\n",
      "tensor([ 0.4830, -0.5310])\n",
      "pre:left true:left 9552/11700\n",
      "tensor([ 0.4350, -0.4326])\n",
      "pre:left true:left 9553/11700\n",
      "tensor([ 0.5711, -0.5845])\n",
      "pre:left true:left 9554/11700\n",
      "tensor([ 0.5841, -0.5699])\n",
      "pre:left true:left 9555/11700\n",
      "tensor([ 0.1064, -0.1607])\n",
      "pre:left true:left 9556/11700\n",
      "tensor([ 0.2056, -0.0854])\n",
      "pre:left true:left 9557/11700\n",
      "tensor([ 0.0402, -0.0016])\n",
      "pre:left true:left 9558/11700\n",
      "tensor([ 0.5038, -0.5044])\n",
      "pre:left true:left 9559/11700\n",
      "tensor([ 1.5947, -1.6384])\n",
      "pre:left true:left 9560/11700\n",
      "tensor([ 0.4037, -0.3993])\n",
      "pre:left true:left 9561/11700\n",
      "tensor([ 0.3751, -0.5117])\n",
      "pre:left true:left 9562/11700\n",
      "tensor([ 0.7018, -0.7046])\n",
      "pre:left true:left 9563/11700\n",
      "tensor([ 0.9032, -1.0499])\n",
      "pre:left true:left 9564/11700\n",
      "tensor([-0.1752,  0.1923])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左302_0_458_20200412_114529212_9.jpg\n",
      "pre:right true:left 9565/11700\n",
      "tensor([ 0.7804, -0.7302])\n",
      "pre:left true:left 9566/11700\n",
      "tensor([ 0.1705, -0.1775])\n",
      "pre:left true:left 9567/11700\n",
      "tensor([-0.1629,  0.1908])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左441_0_597_20200412_114830349_5.jpg\n",
      "pre:right true:left 9568/11700\n",
      "tensor([ 0.5193, -0.6437])\n",
      "pre:left true:left 9569/11700\n",
      "tensor([ 1.0691, -1.1791])\n",
      "pre:left true:left 9570/11700\n",
      "tensor([-0.0479,  0.0016])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左329_0_329_20200412_110438029_10.jpg\n",
      "pre:right true:left 9571/11700\n",
      "tensor([ 0.0999, -0.0187])\n",
      "pre:left true:left 9572/11700\n",
      "tensor([ 0.6117, -0.5907])\n",
      "pre:left true:left 9573/11700\n",
      "tensor([ 1.2293, -1.1700])\n",
      "pre:left true:left 9574/11700\n",
      "tensor([ 0.1558, -0.2037])\n",
      "pre:left true:left 9575/11700\n",
      "tensor([ 0.3363, -0.3538])\n",
      "pre:left true:left 9576/11700\n",
      "tensor([ 0.3985, -0.3693])\n",
      "pre:left true:left 9577/11700\n",
      "tensor([ 1.2459, -1.2994])\n",
      "pre:left true:left 9578/11700\n",
      "tensor([ 1.2839, -1.2042])\n",
      "pre:left true:left 9579/11700\n",
      "tensor([ 0.5935, -0.5684])\n",
      "pre:left true:left 9580/11700\n",
      "tensor([ 0.4429, -0.4919])\n",
      "pre:left true:left 9581/11700\n",
      "tensor([ 0.5450, -0.3935])\n",
      "pre:left true:left 9582/11700\n",
      "tensor([ 1.0650, -1.0945])\n",
      "pre:left true:left 9583/11700\n",
      "tensor([ 0.2214, -0.1550])\n",
      "pre:left true:left 9584/11700\n",
      "tensor([ 1.3336, -1.3275])\n",
      "pre:left true:left 9585/11700\n",
      "tensor([ 0.5738, -0.6264])\n",
      "pre:left true:left 9586/11700\n",
      "tensor([ 0.1295, -0.1458])\n",
      "pre:left true:left 9587/11700\n",
      "tensor([ 0.1989, -0.1690])\n",
      "pre:left true:left 9588/11700\n",
      "tensor([ 0.8289, -0.8102])\n",
      "pre:left true:left 9589/11700\n",
      "tensor([ 0.1403, -0.0342])\n",
      "pre:left true:left 9590/11700\n",
      "tensor([-0.3924,  0.4388])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1329_0_1485_20200412_120747629_1.jpg\n",
      "pre:right true:left 9591/11700\n",
      "tensor([-0.7768,  0.8623])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1573_0_1729_20200412_121305657_9.jpg\n",
      "pre:right true:left 9592/11700\n",
      "tensor([ 0.1379, -0.0982])\n",
      "pre:left true:left 9593/11700\n",
      "tensor([ 0.1139, -0.0767])\n",
      "pre:left true:left 9594/11700\n",
      "tensor([-0.5004,  0.5677])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左737_0_893_20200412_115456089_0.jpg\n",
      "pre:right true:left 9595/11700\n",
      "tensor([ 0.0666, -0.0404])\n",
      "pre:left true:left 9596/11700\n",
      "tensor([ 0.2725, -0.0829])\n",
      "pre:left true:left 9597/11700\n",
      "tensor([ 0.2065, -0.2312])\n",
      "pre:left true:left 9598/11700\n",
      "tensor([-0.1082,  0.1664])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左755_0_911_20200412_115519560_2.jpg\n",
      "pre:right true:left 9599/11700\n",
      "tensor([ 0.3896, -0.3559])\n",
      "pre:left true:left 9600/11700\n",
      "tensor([ 0.9018, -0.8238])\n",
      "pre:left true:left 9601/11700\n",
      "tensor([-0.4099,  0.5201])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左457_0_457_20200412_110740603_8.jpg\n",
      "pre:right true:left 9602/11700\n",
      "tensor([ 0.8561, -0.8013])\n",
      "pre:left true:left 9603/11700\n",
      "tensor([ 0.5450, -0.4872])\n",
      "pre:left true:left 9604/11700\n",
      "tensor([ 0.8220, -0.8573])\n",
      "pre:left true:left 9605/11700\n",
      "tensor([ 0.1238, -0.0262])\n",
      "pre:left true:left 9606/11700\n",
      "tensor([-0.4661,  0.5501])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左316_0_316_20200412_105554268_9.jpg\n",
      "pre:right true:left 9607/11700\n",
      "tensor([-0.4416,  0.5851])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左607_0_763_20200412_115206661_0.jpg\n",
      "pre:right true:left 9608/11700\n",
      "tensor([ 0.5069, -0.5688])\n",
      "pre:left true:left 9609/11700\n",
      "tensor([ 0.6423, -0.6598])\n",
      "pre:left true:left 9610/11700\n",
      "tensor([ 1.0113, -1.0206])\n",
      "pre:left true:left 9611/11700\n",
      "tensor([ 0.6128, -0.6278])\n",
      "pre:left true:left 9612/11700\n",
      "tensor([-0.2566,  0.1478])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1518_0_1674_20200412_121153960_1.jpg\n",
      "pre:right true:left 9613/11700\n",
      "tensor([ 0.2538, -0.2417])\n",
      "pre:left true:left 9614/11700\n",
      "tensor([ 0.0812, -0.1375])\n",
      "pre:left true:left 9615/11700\n",
      "tensor([ 0.2962, -0.3062])\n",
      "pre:left true:left 9616/11700\n",
      "tensor([ 0.5766, -0.5504])\n",
      "pre:left true:left 9617/11700\n",
      "tensor([ 0.9059, -0.8824])\n",
      "pre:left true:left 9618/11700\n",
      "tensor([ 0.4664, -0.4377])\n",
      "pre:left true:left 9619/11700\n",
      "tensor([ 0.8972, -0.9097])\n",
      "pre:left true:left 9620/11700\n",
      "tensor([-0.6520,  0.8423])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左566_0_722_20200412_115113231_10.jpg\n",
      "pre:right true:left 9621/11700\n",
      "tensor([ 0.3089, -0.3965])\n",
      "pre:left true:left 9622/11700\n",
      "tensor([ 0.3525, -0.2915])\n",
      "pre:left true:left 9623/11700\n",
      "tensor([ 1.0645, -1.0182])\n",
      "pre:left true:left 9624/11700\n",
      "tensor([ 1.8617, -1.7771])\n",
      "pre:left true:left 9625/11700\n",
      "tensor([ 0.3451, -0.3382])\n",
      "pre:left true:left 9626/11700\n",
      "tensor([ 0.5784, -0.5938])\n",
      "pre:left true:left 9627/11700\n",
      "tensor([ 0.6063, -0.7039])\n",
      "pre:left true:left 9628/11700\n",
      "tensor([ 0.3801, -0.3879])\n",
      "pre:left true:left 9629/11700\n",
      "tensor([-0.2458,  0.3314])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左673_0_673_20200412_111248699_5.jpg\n",
      "pre:right true:left 9630/11700\n",
      "tensor([ 0.7920, -0.8664])\n",
      "pre:left true:left 9631/11700\n",
      "tensor([ 0.4075, -0.5114])\n",
      "pre:left true:left 9632/11700\n",
      "tensor([ 1.0091, -0.8452])\n",
      "pre:left true:left 9633/11700\n",
      "tensor([ 0.4581, -0.4988])\n",
      "pre:left true:left 9634/11700\n",
      "tensor([ 1.3759, -1.3041])\n",
      "pre:left true:left 9635/11700\n",
      "tensor([-0.1379,  0.1998])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左617_0_773_20200412_115219705_3.jpg\n",
      "pre:right true:left 9636/11700\n",
      "tensor([ 1.0665, -0.8288])\n",
      "pre:left true:left 9637/11700\n",
      "tensor([ 0.3414, -0.4096])\n",
      "pre:left true:left 9638/11700\n",
      "tensor([ 0.2277, -0.2414])\n",
      "pre:left true:left 9639/11700\n",
      "tensor([ 1.0848, -1.0634])\n",
      "pre:left true:left 9640/11700\n",
      "tensor([ 0.9396, -0.9147])\n",
      "pre:left true:left 9641/11700\n",
      "tensor([ 0.6271, -0.5921])\n",
      "pre:left true:left 9642/11700\n",
      "tensor([ 0.9195, -0.9810])\n",
      "pre:left true:left 9643/11700\n",
      "tensor([ 0.7258, -0.7080])\n",
      "pre:left true:left 9644/11700\n",
      "tensor([ 0.7279, -0.6999])\n",
      "pre:left true:left 9645/11700\n",
      "tensor([ 0.6775, -0.6568])\n",
      "pre:left true:left 9646/11700\n",
      "tensor([-0.1383,  0.1985])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左449_0_449_20200412_110729197_9.jpg\n",
      "pre:right true:left 9647/11700\n",
      "tensor([ 0.5024, -0.4803])\n",
      "pre:left true:left 9648/11700\n",
      "tensor([ 0.0250, -0.0410])\n",
      "pre:left true:left 9649/11700\n",
      "tensor([ 0.3232, -0.3021])\n",
      "pre:left true:left 9650/11700\n",
      "tensor([ 0.7072, -0.6841])\n",
      "pre:left true:left 9651/11700\n",
      "tensor([ 0.2691, -0.2092])\n",
      "pre:left true:left 9652/11700\n",
      "tensor([ 0.7492, -0.6064])\n",
      "pre:left true:left 9653/11700\n",
      "tensor([ 0.3890, -0.3666])\n",
      "pre:left true:left 9654/11700\n",
      "tensor([ 0.0881, -0.1118])\n",
      "pre:left true:left 9655/11700\n",
      "tensor([ 0.5623, -0.6114])\n",
      "pre:left true:left 9656/11700\n",
      "tensor([ 0.7562, -0.7874])\n",
      "pre:left true:left 9657/11700\n",
      "tensor([ 0.1058, -0.1360])\n",
      "pre:left true:left 9658/11700\n",
      "tensor([ 1.6403, -1.6436])\n",
      "pre:left true:left 9659/11700\n",
      "tensor([ 0.8523, -0.8170])\n",
      "pre:left true:left 9660/11700\n",
      "tensor([ 0.6592, -0.6459])\n",
      "pre:left true:left 9661/11700\n",
      "tensor([ 0.6384, -0.6466])\n",
      "pre:left true:left 9662/11700\n",
      "tensor([ 0.8738, -0.9789])\n",
      "pre:left true:left 9663/11700\n",
      "tensor([-0.0011,  0.0326])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左475_0_475_20200412_110806277.jpg\n",
      "pre:right true:left 9664/11700\n",
      "tensor([ 0.0929, -0.0590])\n",
      "pre:left true:left 9665/11700\n",
      "tensor([ 0.3088, -0.3098])\n",
      "pre:left true:left 9666/11700\n",
      "tensor([ 0.4970, -0.3883])\n",
      "pre:left true:left 9667/11700\n",
      "tensor([ 0.7099, -0.5461])\n",
      "pre:left true:left 9668/11700\n",
      "tensor([ 0.8128, -0.7856])\n",
      "pre:left true:left 9669/11700\n",
      "tensor([ 0.1557, -0.2296])\n",
      "pre:left true:left 9670/11700\n",
      "tensor([-0.0401,  0.0980])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左570_0_570_20200412_111021790_1.jpg\n",
      "pre:right true:left 9671/11700\n",
      "tensor([ 0.4131, -0.4038])\n",
      "pre:left true:left 9672/11700\n",
      "tensor([ 0.1130, -0.1150])\n",
      "pre:left true:left 9673/11700\n",
      "tensor([ 0.6923, -0.6860])\n",
      "pre:left true:left 9674/11700\n",
      "tensor([ 0.8409, -0.9332])\n",
      "pre:left true:left 9675/11700\n",
      "tensor([ 0.7261, -0.7465])\n",
      "pre:left true:left 9676/11700\n",
      "tensor([ 0.4787, -0.4315])\n",
      "pre:left true:left 9677/11700\n",
      "tensor([ 0.5649, -0.5767])\n",
      "pre:left true:left 9678/11700\n",
      "tensor([ 0.6166, -0.5987])\n",
      "pre:left true:left 9679/11700\n",
      "tensor([ 0.5511, -0.5018])\n",
      "pre:left true:left 9680/11700\n",
      "tensor([ 1.0200, -0.9311])\n",
      "pre:left true:left 9681/11700\n",
      "tensor([ 0.4491, -0.5180])\n",
      "pre:left true:left 9682/11700\n",
      "tensor([ 0.8141, -0.8265])\n",
      "pre:left true:left 9683/11700\n",
      "tensor([-0.7966,  0.7625])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左549_0_705_20200412_115051073_7.jpg\n",
      "pre:right true:left 9684/11700\n",
      "tensor([ 0.6524, -0.6217])\n",
      "pre:left true:left 9685/11700\n",
      "tensor([ 0.7380, -0.7443])\n",
      "pre:left true:left 9686/11700\n",
      "tensor([ 0.2797, -0.2668])\n",
      "pre:left true:left 9687/11700\n",
      "tensor([ 0.7625, -0.7060])\n",
      "pre:left true:left 9688/11700\n",
      "tensor([ 0.4798, -0.4449])\n",
      "pre:left true:left 9689/11700\n",
      "tensor([ 0.2668, -0.1381])\n",
      "pre:left true:left 9690/11700\n",
      "tensor([ 0.1858, -0.0765])\n",
      "pre:left true:left 9691/11700\n",
      "tensor([ 0.6507, -0.6208])\n",
      "pre:left true:left 9692/11700\n",
      "tensor([ 0.2604, -0.2361])\n",
      "pre:left true:left 9693/11700\n",
      "tensor([ 1.3107, -1.3287])\n",
      "pre:left true:left 9694/11700\n",
      "tensor([ 0.9353, -1.0298])\n",
      "pre:left true:left 9695/11700\n",
      "tensor([-0.7742,  0.8087])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1059_0_1059_20200412_112141573_9.jpg\n",
      "pre:right true:left 9696/11700\n",
      "tensor([ 1.0744, -1.1355])\n",
      "pre:left true:left 9697/11700\n",
      "tensor([-0.0331, -0.0579])\n",
      "pre:left true:left 9698/11700\n",
      "tensor([ 0.8732, -0.8914])\n",
      "pre:left true:left 9699/11700\n",
      "tensor([ 0.6893, -0.7415])\n",
      "pre:left true:left 9700/11700\n",
      "tensor([ 0.7634, -0.8084])\n",
      "pre:left true:left 9701/11700\n",
      "tensor([ 0.5480, -0.4548])\n",
      "pre:left true:left 9702/11700\n",
      "tensor([ 0.9409, -0.8951])\n",
      "pre:left true:left 9703/11700\n",
      "tensor([ 0.5685, -0.5587])\n",
      "pre:left true:left 9704/11700\n",
      "tensor([ 1.2693, -1.2234])\n",
      "pre:left true:left 9705/11700\n",
      "tensor([ 1.6074, -1.5631])\n",
      "pre:left true:left 9706/11700\n",
      "tensor([ 0.7623, -0.7347])\n",
      "pre:left true:left 9707/11700\n",
      "tensor([-0.3241,  0.2253])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左768_0_768_20200412_111504208_5.jpg\n",
      "pre:right true:left 9708/11700\n",
      "tensor([ 0.4179, -0.4152])\n",
      "pre:left true:left 9709/11700\n",
      "tensor([ 0.4020, -0.3858])\n",
      "pre:left true:left 9710/11700\n",
      "tensor([ 0.5271, -0.5340])\n",
      "pre:left true:left 9711/11700\n",
      "tensor([ 0.6128, -0.6506])\n",
      "pre:left true:left 9712/11700\n",
      "tensor([ 0.0108, -0.0431])\n",
      "pre:left true:left 9713/11700\n",
      "tensor([ 0.4620, -0.4396])\n",
      "pre:left true:left 9714/11700\n",
      "tensor([-0.2890,  0.2785])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左526_0_526_20200412_110919020_6.jpg\n",
      "pre:right true:left 9715/11700\n",
      "tensor([ 0.8151, -0.8356])\n",
      "pre:left true:left 9716/11700\n",
      "tensor([ 0.8806, -0.9677])\n",
      "pre:left true:left 9717/11700\n",
      "tensor([ 0.8797, -0.8955])\n",
      "pre:left true:left 9718/11700\n",
      "tensor([ 0.6655, -0.6387])\n",
      "pre:left true:left 9719/11700\n",
      "tensor([ 0.8286, -0.8044])\n",
      "pre:left true:left 9720/11700\n",
      "tensor([ 0.1637, -0.2371])\n",
      "pre:left true:left 9721/11700\n",
      "tensor([ 0.2522, -0.1934])\n",
      "pre:left true:left 9722/11700\n",
      "tensor([ 0.3680, -0.3631])\n",
      "pre:left true:left 9723/11700\n",
      "tensor([ 0.5507, -0.6505])\n",
      "pre:left true:left 9724/11700\n",
      "tensor([ 0.5399, -0.5913])\n",
      "pre:left true:left 9725/11700\n",
      "tensor([ 0.4943, -0.4710])\n",
      "pre:left true:left 9726/11700\n",
      "tensor([ 0.7443, -0.8295])\n",
      "pre:left true:left 9727/11700\n",
      "tensor([ 0.4401, -0.4173])\n",
      "pre:left true:left 9728/11700\n",
      "tensor([-0.3432,  0.2628])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左544_0_700_20200412_115044561_1.jpg\n",
      "pre:right true:left 9729/11700\n",
      "tensor([ 0.7461, -0.6958])\n",
      "pre:left true:left 9730/11700\n",
      "tensor([ 0.9461, -0.9771])\n",
      "pre:left true:left 9731/11700\n",
      "tensor([ 0.8860, -0.8529])\n",
      "pre:left true:left 9732/11700\n",
      "tensor([ 0.3286, -0.3454])\n",
      "pre:left true:left 9733/11700\n",
      "tensor([ 0.4027, -0.3674])\n",
      "pre:left true:left 9734/11700\n",
      "tensor([ 1.6218, -1.6547])\n",
      "pre:left true:left 9735/11700\n",
      "tensor([ 1.3589, -1.3421])\n",
      "pre:left true:left 9736/11700\n",
      "tensor([ 0.3623, -0.3289])\n",
      "pre:left true:left 9737/11700\n",
      "tensor([ 0.5956, -0.5653])\n",
      "pre:left true:left 9738/11700\n",
      "tensor([ 0.8033, -0.7179])\n",
      "pre:left true:left 9739/11700\n",
      "tensor([ 0.4227, -0.4695])\n",
      "pre:left true:left 9740/11700\n",
      "tensor([ 1.1649, -1.1640])\n",
      "pre:left true:left 9741/11700\n",
      "tensor([ 1.0320, -1.0485])\n",
      "pre:left true:left 9742/11700\n",
      "tensor([ 0.7356, -0.8045])\n",
      "pre:left true:left 9743/11700\n",
      "tensor([ 0.7491, -0.7196])\n",
      "pre:left true:left 9744/11700\n",
      "tensor([ 0.6455, -0.6271])\n",
      "pre:left true:left 9745/11700\n",
      "tensor([ 0.5920, -0.5756])\n",
      "pre:left true:left 9746/11700\n",
      "tensor([ 1.0501, -1.0275])\n",
      "pre:left true:left 9747/11700\n",
      "tensor([ 0.7198, -0.7241])\n",
      "pre:left true:left 9748/11700\n",
      "tensor([ 0.2935, -0.2620])\n",
      "pre:left true:left 9749/11700\n",
      "tensor([ 0.4046, -0.3595])\n",
      "pre:left true:left 9750/11700\n",
      "tensor([ 0.3260, -0.4052])\n",
      "pre:left true:left 9751/11700\n",
      "tensor([ 0.6954, -0.7335])\n",
      "pre:left true:left 9752/11700\n",
      "tensor([ 0.7715, -0.6933])\n",
      "pre:left true:left 9753/11700\n",
      "tensor([ 0.8081, -0.7974])\n",
      "pre:left true:left 9754/11700\n",
      "tensor([ 0.4819, -0.4676])\n",
      "pre:left true:left 9755/11700\n",
      "tensor([ 0.5958, -0.6012])\n",
      "pre:left true:left 9756/11700\n",
      "tensor([ 0.1076, -0.0665])\n",
      "pre:left true:left 9757/11700\n",
      "tensor([ 0.9933, -1.0462])\n",
      "pre:left true:left 9758/11700\n",
      "tensor([ 0.4732, -0.3680])\n",
      "pre:left true:left 9759/11700\n",
      "tensor([ 0.5797, -0.5906])\n",
      "pre:left true:left 9760/11700\n",
      "tensor([ 0.1687, -0.1248])\n",
      "pre:left true:left 9761/11700\n",
      "tensor([ 0.9281, -0.9143])\n",
      "pre:left true:left 9762/11700\n",
      "tensor([ 1.2147, -1.2755])\n",
      "pre:left true:left 9763/11700\n",
      "tensor([ 0.4745, -0.4583])\n",
      "pre:left true:left 9764/11700\n",
      "tensor([ 0.7499, -0.7544])\n",
      "pre:left true:left 9765/11700\n",
      "tensor([ 0.8176, -0.8021])\n",
      "pre:left true:left 9766/11700\n",
      "tensor([ 1.5942, -1.5347])\n",
      "pre:left true:left 9767/11700\n",
      "tensor([ 0.1800, -0.1587])\n",
      "pre:left true:left 9768/11700\n",
      "tensor([ 0.5299, -0.5767])\n",
      "pre:left true:left 9769/11700\n",
      "tensor([ 1.0316, -1.0489])\n",
      "pre:left true:left 9770/11700\n",
      "tensor([ 0.6969, -0.6111])\n",
      "pre:left true:left 9771/11700\n",
      "tensor([ 1.1766, -0.9896])\n",
      "pre:left true:left 9772/11700\n",
      "tensor([ 0.1020, -0.0079])\n",
      "pre:left true:left 9773/11700\n",
      "tensor([ 0.3930, -0.3917])\n",
      "pre:left true:left 9774/11700\n",
      "tensor([ 0.2669, -0.2425])\n",
      "pre:left true:left 9775/11700\n",
      "tensor([ 1.3950, -1.2834])\n",
      "pre:left true:left 9776/11700\n",
      "tensor([ 0.4253, -0.4415])\n",
      "pre:left true:left 9777/11700\n",
      "tensor([ 0.3648, -0.3152])\n",
      "pre:left true:left 9778/11700\n",
      "tensor([0.0506, 0.0643])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1199_0_1199_20200412_112444000_9.jpg\n",
      "pre:right true:left 9779/11700\n",
      "tensor([ 0.1276, -0.1100])\n",
      "pre:left true:left 9780/11700\n",
      "tensor([-0.2077,  0.1988])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1171_0_1171_20200412_112407524_7.jpg\n",
      "pre:right true:left 9781/11700\n",
      "tensor([ 0.8405, -0.8248])\n",
      "pre:left true:left 9782/11700\n",
      "tensor([ 0.2142, -0.2047])\n",
      "pre:left true:left 9783/11700\n",
      "tensor([ 0.8223, -0.8810])\n",
      "pre:left true:left 9784/11700\n",
      "tensor([ 0.7259, -0.7162])\n",
      "pre:left true:left 9785/11700\n",
      "tensor([0.1687, 0.0009])\n",
      "pre:left true:left 9786/11700\n",
      "tensor([ 0.8105, -0.8222])\n",
      "pre:left true:left 9787/11700\n",
      "tensor([ 0.5016, -0.4747])\n",
      "pre:left true:left 9788/11700\n",
      "tensor([ 1.0924, -1.0043])\n",
      "pre:left true:left 9789/11700\n",
      "tensor([ 0.3720, -0.4146])\n",
      "pre:left true:left 9790/11700\n",
      "tensor([ 0.2648, -0.2259])\n",
      "pre:left true:left 9791/11700\n",
      "tensor([ 0.4213, -0.4048])\n",
      "pre:left true:left 9792/11700\n",
      "tensor([ 0.6026, -0.6722])\n",
      "pre:left true:left 9793/11700\n",
      "tensor([ 0.6157, -0.5577])\n",
      "pre:left true:left 9794/11700\n",
      "tensor([ 0.5538, -0.5364])\n",
      "pre:left true:left 9795/11700\n",
      "tensor([ 0.7540, -0.6893])\n",
      "pre:left true:left 9796/11700\n",
      "tensor([ 1.3246, -1.2811])\n",
      "pre:left true:left 9797/11700\n",
      "tensor([ 0.9721, -0.9751])\n",
      "pre:left true:left 9798/11700\n",
      "tensor([0.0025, 0.0342])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左65_0_65_20200412_105821839_2.jpg\n",
      "pre:right true:left 9799/11700\n",
      "tensor([ 1.3831, -1.4200])\n",
      "pre:left true:left 9800/11700\n",
      "tensor([ 0.0287, -0.0653])\n",
      "pre:left true:left 9801/11700\n",
      "tensor([ 0.5839, -0.6034])\n",
      "pre:left true:left 9802/11700\n",
      "tensor([ 0.2587, -0.3024])\n",
      "pre:left true:left 9803/11700\n",
      "tensor([ 0.9280, -0.9264])\n",
      "pre:left true:left 9804/11700\n",
      "tensor([ 0.1856, -0.1311])\n",
      "pre:left true:left 9805/11700\n",
      "tensor([ 0.3097, -0.3531])\n",
      "pre:left true:left 9806/11700\n",
      "tensor([ 0.7861, -0.7909])\n",
      "pre:left true:left 9807/11700\n",
      "tensor([ 1.1793, -1.1774])\n",
      "pre:left true:left 9808/11700\n",
      "tensor([ 1.5778, -1.4996])\n",
      "pre:left true:left 9809/11700\n",
      "tensor([ 0.9888, -1.0568])\n",
      "pre:left true:left 9810/11700\n",
      "tensor([ 0.1116, -0.0793])\n",
      "pre:left true:left 9811/11700\n",
      "tensor([ 0.4312, -0.3305])\n",
      "pre:left true:left 9812/11700\n",
      "tensor([ 0.8013, -0.7804])\n",
      "pre:left true:left 9813/11700\n",
      "tensor([ 0.7014, -0.7578])\n",
      "pre:left true:left 9814/11700\n",
      "tensor([ 1.4500, -1.4841])\n",
      "pre:left true:left 9815/11700\n",
      "tensor([ 0.2118, -0.0965])\n",
      "pre:left true:left 9816/11700\n",
      "tensor([ 1.6975, -1.7171])\n",
      "pre:left true:left 9817/11700\n",
      "tensor([ 0.2843, -0.2832])\n",
      "pre:left true:left 9818/11700\n",
      "tensor([ 0.7931, -0.7524])\n",
      "pre:left true:left 9819/11700\n",
      "tensor([0.0625, 0.1781])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左457_0_613_20200412_114851184_9.jpg\n",
      "pre:right true:left 9820/11700\n",
      "tensor([ 0.9037, -0.9880])\n",
      "pre:left true:left 9821/11700\n",
      "tensor([-0.3446,  0.3472])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1512_0_1668_20200412_121146147.jpg\n",
      "pre:right true:left 9822/11700\n",
      "tensor([ 0.3274, -0.1924])\n",
      "pre:left true:left 9823/11700\n",
      "tensor([ 0.6344, -0.5883])\n",
      "pre:left true:left 9824/11700\n",
      "tensor([-0.5787,  0.6046])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左479_0_635_20200412_114919868_4.jpg\n",
      "pre:right true:left 9825/11700\n",
      "tensor([ 0.9013, -0.9056])\n",
      "pre:left true:left 9826/11700\n",
      "tensor([ 0.5248, -0.5600])\n",
      "pre:left true:left 9827/11700\n",
      "tensor([ 0.6877, -0.7660])\n",
      "pre:left true:left 9828/11700\n",
      "tensor([ 0.2180, -0.1686])\n",
      "pre:left true:left 9829/11700\n",
      "tensor([ 0.5935, -0.5515])\n",
      "pre:left true:left 9830/11700\n",
      "tensor([ 0.8557, -0.8438])\n",
      "pre:left true:left 9831/11700\n",
      "tensor([ 0.1151, -0.1604])\n",
      "pre:left true:left 9832/11700\n",
      "tensor([-0.3730,  0.3756])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左522_0_678_20200412_115015870_10.jpg\n",
      "pre:right true:left 9833/11700\n",
      "tensor([ 0.9423, -0.8816])\n",
      "pre:left true:left 9834/11700\n",
      "tensor([ 0.5986, -0.5705])\n",
      "pre:left true:left 9835/11700\n",
      "tensor([ 0.3725, -0.3778])\n",
      "pre:left true:left 9836/11700\n",
      "tensor([ 1.0345, -1.0041])\n",
      "pre:left true:left 9837/11700\n",
      "tensor([ 0.7718, -0.7372])\n",
      "pre:left true:left 9838/11700\n",
      "tensor([ 0.8461, -0.9335])\n",
      "pre:left true:left 9839/11700\n",
      "tensor([ 0.2186, -0.1919])\n",
      "pre:left true:left 9840/11700\n",
      "tensor([-0.3042,  0.3017])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左341_0_341_20200412_110455144_10.jpg\n",
      "pre:right true:left 9841/11700\n",
      "tensor([-0.0734,  0.1607])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左519_0_675_20200412_115011993_1.jpg\n",
      "pre:right true:left 9842/11700\n",
      "tensor([ 0.1586, -0.0436])\n",
      "pre:left true:left 9843/11700\n",
      "tensor([ 0.5190, -0.5513])\n",
      "pre:left true:left 9844/11700\n",
      "tensor([ 0.8041, -0.7013])\n",
      "pre:left true:left 9845/11700\n",
      "tensor([ 0.7573, -0.7844])\n",
      "pre:left true:left 9846/11700\n",
      "tensor([ 0.9429, -1.0134])\n",
      "pre:left true:left 9847/11700\n",
      "tensor([ 0.2517, -0.3265])\n",
      "pre:left true:left 9848/11700\n",
      "tensor([ 0.4479, -0.4744])\n",
      "pre:left true:left 9849/11700\n",
      "tensor([0.0079, 0.0554])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左563_0_719_20200412_115109319_7.jpg\n",
      "pre:right true:left 9850/11700\n",
      "tensor([ 0.7023, -0.6550])\n",
      "pre:left true:left 9851/11700\n",
      "tensor([ 0.3937, -0.2918])\n",
      "pre:left true:left 9852/11700\n",
      "tensor([ 0.0651, -0.1345])\n",
      "pre:left true:left 9853/11700\n",
      "tensor([ 0.0330, -0.0067])\n",
      "pre:left true:left 9854/11700\n",
      "tensor([ 0.6537, -0.4811])\n",
      "pre:left true:left 9855/11700\n",
      "tensor([ 0.7509, -0.7070])\n",
      "pre:left true:left 9856/11700\n",
      "tensor([ 0.3538, -0.2680])\n",
      "pre:left true:left 9857/11700\n",
      "tensor([ 0.5552, -0.4323])\n",
      "pre:left true:left 9858/11700\n",
      "tensor([ 0.2029, -0.1518])\n",
      "pre:left true:left 9859/11700\n",
      "tensor([ 0.8920, -0.9271])\n",
      "pre:left true:left 9860/11700\n",
      "tensor([ 0.1538, -0.0890])\n",
      "pre:left true:left 9861/11700\n",
      "tensor([ 0.9118, -0.9014])\n",
      "pre:left true:left 9862/11700\n",
      "tensor([ 0.2804, -0.1984])\n",
      "pre:left true:left 9863/11700\n",
      "tensor([-0.4988,  0.5682])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1211_0_1211_20200412_112459647_8.jpg\n",
      "pre:right true:left 9864/11700\n",
      "tensor([-0.6754,  0.7333])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1257_0_1413_20200412_120613774_6.jpg\n",
      "pre:right true:left 9865/11700\n",
      "tensor([ 0.6139, -0.4871])\n",
      "pre:left true:left 9866/11700\n",
      "tensor([ 0.3856, -0.3546])\n",
      "pre:left true:left 9867/11700\n",
      "tensor([ 0.6055, -0.6452])\n",
      "pre:left true:left 9868/11700\n",
      "tensor([-0.3196,  0.3156])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左85_0_85_20200412_105850041_2.jpg\n",
      "pre:right true:left 9869/11700\n",
      "tensor([ 0.1201, -0.0680])\n",
      "pre:left true:left 9870/11700\n",
      "tensor([ 0.6926, -0.6981])\n",
      "pre:left true:left 9871/11700\n",
      "tensor([ 1.0381, -1.0449])\n",
      "pre:left true:left 9872/11700\n",
      "tensor([ 0.6528, -0.6533])\n",
      "pre:left true:left 9873/11700\n",
      "tensor([-0.0874, -0.0188])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左305_0_461_20200412_114533116_3.jpg\n",
      "pre:right true:left 9874/11700\n",
      "tensor([ 0.9749, -1.0053])\n",
      "pre:left true:left 9875/11700\n",
      "tensor([ 0.4852, -0.5040])\n",
      "pre:left true:left 9876/11700\n",
      "tensor([ 0.9689, -0.9540])\n",
      "pre:left true:left 9877/11700\n",
      "tensor([ 0.3002, -0.2204])\n",
      "pre:left true:left 9878/11700\n",
      "tensor([ 0.3799, -0.2969])\n",
      "pre:left true:left 9879/11700\n",
      "tensor([ 0.5991, -0.6199])\n",
      "pre:left true:left 9880/11700\n",
      "tensor([ 1.0036, -1.0265])\n",
      "pre:left true:left 9881/11700\n",
      "tensor([ 0.5714, -0.5899])\n",
      "pre:left true:left 9882/11700\n",
      "tensor([ 0.1128, -0.0504])\n",
      "pre:left true:left 9883/11700\n",
      "tensor([ 0.9145, -0.8999])\n",
      "pre:left true:left 9884/11700\n",
      "tensor([ 0.5796, -0.6388])\n",
      "pre:left true:left 9885/11700\n",
      "tensor([ 0.4837, -0.4980])\n",
      "pre:left true:left 9886/11700\n",
      "tensor([-0.0339,  0.0258])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左451_0_451_20200412_110732049_10.jpg\n",
      "pre:right true:left 9887/11700\n",
      "tensor([ 0.4569, -0.4362])\n",
      "pre:left true:left 9888/11700\n",
      "tensor([ 0.5732, -0.4759])\n",
      "pre:left true:left 9889/11700\n",
      "tensor([0.0962, 0.0052])\n",
      "pre:left true:left 9890/11700\n",
      "tensor([ 0.6898, -0.7181])\n",
      "pre:left true:left 9891/11700\n",
      "tensor([ 0.7202, -0.6968])\n",
      "pre:left true:left 9892/11700\n",
      "tensor([ 0.5802, -0.4903])\n",
      "pre:left true:left 9893/11700\n",
      "tensor([-0.7398,  0.8223])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左534_0_534_20200412_110930432_1.jpg\n",
      "pre:right true:left 9894/11700\n",
      "tensor([ 0.3017, -0.2299])\n",
      "pre:left true:left 9895/11700\n",
      "tensor([ 0.9876, -1.0505])\n",
      "pre:left true:left 9896/11700\n",
      "tensor([-0.2488,  0.2215])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1537_0_1693_20200412_121218732_9.jpg\n",
      "pre:right true:left 9897/11700\n",
      "tensor([ 0.7298, -0.6594])\n",
      "pre:left true:left 9898/11700\n",
      "tensor([ 0.3532, -0.3968])\n",
      "pre:left true:left 9899/11700\n",
      "tensor([ 0.5391, -0.5875])\n",
      "pre:left true:left 9900/11700\n",
      "tensor([ 0.3939, -0.3773])\n",
      "pre:left true:left 9901/11700\n",
      "tensor([ 0.7438, -0.7422])\n",
      "pre:left true:left 9902/11700\n",
      "tensor([ 0.5311, -0.5247])\n",
      "pre:left true:left 9903/11700\n",
      "tensor([ 0.5187, -0.5262])\n",
      "pre:left true:left 9904/11700\n",
      "tensor([-0.0066,  0.1503])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1448_0_1604_20200412_121022709_3.jpg\n",
      "pre:right true:left 9905/11700\n",
      "tensor([ 1.1238, -1.1973])\n",
      "pre:left true:left 9906/11700\n",
      "tensor([ 0.0065, -0.0755])\n",
      "pre:left true:left 9907/11700\n",
      "tensor([ 0.6155, -0.6026])\n",
      "pre:left true:left 9908/11700\n",
      "tensor([ 1.1182, -1.0592])\n",
      "pre:left true:left 9909/11700\n",
      "tensor([ 0.4346, -0.4688])\n",
      "pre:left true:left 9910/11700\n",
      "tensor([ 1.1598, -1.1913])\n",
      "pre:left true:left 9911/11700\n",
      "tensor([ 0.5226, -0.4135])\n",
      "pre:left true:left 9912/11700\n",
      "tensor([ 0.3943, -0.3970])\n",
      "pre:left true:left 9913/11700\n",
      "tensor([ 0.7121, -0.6527])\n",
      "pre:left true:left 9914/11700\n",
      "tensor([ 0.6121, -0.5271])\n",
      "pre:left true:left 9915/11700\n",
      "tensor([ 1.0853, -1.0301])\n",
      "pre:left true:left 9916/11700\n",
      "tensor([ 1.0811, -0.9406])\n",
      "pre:left true:left 9917/11700\n",
      "tensor([ 0.8633, -0.8504])\n",
      "pre:left true:left 9918/11700\n",
      "tensor([ 0.2676, -0.2788])\n",
      "pre:left true:left 9919/11700\n",
      "tensor([ 0.2764, -0.2690])\n",
      "pre:left true:left 9920/11700\n",
      "tensor([ 0.7062, -0.6519])\n",
      "pre:left true:left 9921/11700\n",
      "tensor([ 0.0993, -0.1202])\n",
      "pre:left true:left 9922/11700\n",
      "tensor([ 0.2733, -0.1845])\n",
      "pre:left true:left 9923/11700\n",
      "tensor([ 0.7595, -0.8438])\n",
      "pre:left true:left 9924/11700\n",
      "tensor([ 0.8087, -0.7125])\n",
      "pre:left true:left 9925/11700\n",
      "tensor([ 0.1920, -0.1918])\n",
      "pre:left true:left 9926/11700\n",
      "tensor([ 0.8077, -0.7387])\n",
      "pre:left true:left 9927/11700\n",
      "tensor([ 0.6412, -0.6644])\n",
      "pre:left true:left 9928/11700\n",
      "tensor([ 0.9193, -0.9018])\n",
      "pre:left true:left 9929/11700\n",
      "tensor([ 0.8196, -0.8214])\n",
      "pre:left true:left 9930/11700\n",
      "tensor([ 0.1492, -0.2148])\n",
      "pre:left true:left 9931/11700\n",
      "tensor([ 0.8861, -0.8339])\n",
      "pre:left true:left 9932/11700\n",
      "tensor([ 0.3585, -0.4209])\n",
      "pre:left true:left 9933/11700\n",
      "tensor([ 0.6259, -0.6287])\n",
      "pre:left true:left 9934/11700\n",
      "tensor([ 0.4617, -0.4842])\n",
      "pre:left true:left 9935/11700\n",
      "tensor([ 1.2154, -1.1864])\n",
      "pre:left true:left 9936/11700\n",
      "tensor([ 0.4616, -0.4343])\n",
      "pre:left true:left 9937/11700\n",
      "tensor([ 0.0863, -0.0721])\n",
      "pre:left true:left 9938/11700\n",
      "tensor([ 0.8743, -0.7772])\n",
      "pre:left true:left 9939/11700\n",
      "tensor([ 0.9949, -1.1016])\n",
      "pre:left true:left 9940/11700\n",
      "tensor([ 0.2642, -0.2143])\n",
      "pre:left true:left 9941/11700\n",
      "tensor([ 0.2617, -0.2032])\n",
      "pre:left true:left 9942/11700\n",
      "tensor([ 0.7198, -0.6813])\n",
      "pre:left true:left 9943/11700\n",
      "tensor([ 0.6763, -0.6466])\n",
      "pre:left true:left 9944/11700\n",
      "tensor([ 0.0483, -0.1086])\n",
      "pre:left true:left 9945/11700\n",
      "tensor([ 0.5069, -0.5688])\n",
      "pre:left true:left 9946/11700\n",
      "tensor([ 0.4079, -0.3552])\n",
      "pre:left true:left 9947/11700\n",
      "tensor([ 0.0708, -0.1436])\n",
      "pre:left true:left 9948/11700\n",
      "tensor([-0.0784,  0.0179])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左674_0_674_20200412_111250129_5.jpg\n",
      "pre:right true:left 9949/11700\n",
      "tensor([ 0.7909, -0.7916])\n",
      "pre:left true:left 9950/11700\n",
      "tensor([ 0.0685, -0.0183])\n",
      "pre:left true:left 9951/11700\n",
      "tensor([ 0.4894, -0.4629])\n",
      "pre:left true:left 9952/11700\n",
      "tensor([ 0.2474, -0.1533])\n",
      "pre:left true:left 9953/11700\n",
      "tensor([ 0.6694, -0.7830])\n",
      "pre:left true:left 9954/11700\n",
      "tensor([-0.1618,  0.1499])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左420_0_576_20200412_114802970.jpg\n",
      "pre:right true:left 9955/11700\n",
      "tensor([ 0.3854, -0.3413])\n",
      "pre:left true:left 9956/11700\n",
      "tensor([ 0.7358, -0.8148])\n",
      "pre:left true:left 9957/11700\n",
      "tensor([ 0.7066, -0.7109])\n",
      "pre:left true:left 9958/11700\n",
      "tensor([ 1.1571, -1.2429])\n",
      "pre:left true:left 9959/11700\n",
      "tensor([ 0.7131, -0.7545])\n",
      "pre:left true:left 9960/11700\n",
      "tensor([ 0.7821, -0.8382])\n",
      "pre:left true:left 9961/11700\n",
      "tensor([ 0.5215, -0.6043])\n",
      "pre:left true:left 9962/11700\n",
      "tensor([ 0.4013, -0.4237])\n",
      "pre:left true:left 9963/11700\n",
      "tensor([ 0.5367, -0.5140])\n",
      "pre:left true:left 9964/11700\n",
      "tensor([ 0.2540, -0.2308])\n",
      "pre:left true:left 9965/11700\n",
      "tensor([ 0.7221, -0.7533])\n",
      "pre:left true:left 9966/11700\n",
      "tensor([ 0.7236, -0.6650])\n",
      "pre:left true:left 9967/11700\n",
      "tensor([ 0.0705, -0.1690])\n",
      "pre:left true:left 9968/11700\n",
      "tensor([ 0.5825, -0.6327])\n",
      "pre:left true:left 9969/11700\n",
      "tensor([ 0.7134, -0.7715])\n",
      "pre:left true:left 9970/11700\n",
      "tensor([ 0.6187, -0.6551])\n",
      "pre:left true:left 9971/11700\n",
      "tensor([ 1.1978, -1.1448])\n",
      "pre:left true:left 9972/11700\n",
      "tensor([-0.1432,  0.2430])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1521_0_1677_20200412_121157876_3.jpg\n",
      "pre:right true:left 9973/11700\n",
      "tensor([ 0.0988, -0.0544])\n",
      "pre:left true:left 9974/11700\n",
      "tensor([ 0.7353, -0.7306])\n",
      "pre:left true:left 9975/11700\n",
      "tensor([ 1.1971, -1.2315])\n",
      "pre:left true:left 9976/11700\n",
      "tensor([ 0.2449, -0.2458])\n",
      "pre:left true:left 9977/11700\n",
      "tensor([-0.1180,  0.2116])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左65_0_65_20200412_105821839_0.jpg\n",
      "pre:right true:left 9978/11700\n",
      "tensor([ 1.2028, -1.2312])\n",
      "pre:left true:left 9979/11700\n",
      "tensor([ 0.2915, -0.2234])\n",
      "pre:left true:left 9980/11700\n",
      "tensor([ 0.4837, -0.4690])\n",
      "pre:left true:left 9981/11700\n",
      "tensor([ 0.1470, -0.2231])\n",
      "pre:left true:left 9982/11700\n",
      "tensor([ 1.1634, -1.2365])\n",
      "pre:left true:left 9983/11700\n",
      "tensor([-0.3307,  0.2565])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1078_0_1078_20200412_112206327_0.jpg\n",
      "pre:right true:left 9984/11700\n",
      "tensor([-0.0885,  0.0848])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左895_0_895_20200412_111805343_2.jpg\n",
      "pre:right true:left 9985/11700\n",
      "tensor([ 0.8610, -0.8796])\n",
      "pre:left true:left 9986/11700\n",
      "tensor([ 0.3710, -0.3149])\n",
      "pre:left true:left 9987/11700\n",
      "tensor([ 1.0237, -0.9705])\n",
      "pre:left true:left 9988/11700\n",
      "tensor([ 0.9147, -0.9263])\n",
      "pre:left true:left 9989/11700\n",
      "tensor([ 0.5793, -0.5900])\n",
      "pre:left true:left 9990/11700\n",
      "tensor([ 0.6851, -0.6366])\n",
      "pre:left true:left 9991/11700\n",
      "tensor([ 1.1873, -1.2588])\n",
      "pre:left true:left 9992/11700\n",
      "tensor([ 0.5509, -0.5097])\n",
      "pre:left true:left 9993/11700\n",
      "tensor([ 0.8435, -0.6999])\n",
      "pre:left true:left 9994/11700\n",
      "tensor([ 1.2469, -1.1527])\n",
      "pre:left true:left 9995/11700\n",
      "tensor([-0.1443,  0.0975])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/右1394_0_1550_20200412_120912332_3.jpg\n",
      "pre:right true:left 9996/11700\n",
      "tensor([-0.2391,  0.1973])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左284_0_440_20200412_114505749_4.jpg\n",
      "pre:right true:left 9997/11700\n",
      "tensor([ 0.6691, -0.5603])\n",
      "pre:left true:left 9998/11700\n",
      "tensor([ 0.4205, -0.4213])\n",
      "pre:left true:left 9999/11700\n",
      "tensor([ 0.7227, -0.7893])\n",
      "pre:left true:left 10000/11700\n",
      "tensor([ 0.4614, -0.4344])\n",
      "pre:left true:left 10001/11700\n",
      "tensor([ 0.2180, -0.2154])\n",
      "pre:left true:left 10002/11700\n",
      "tensor([ 0.0781, -0.0032])\n",
      "pre:left true:left 10003/11700\n",
      "tensor([-0.2689,  0.3260])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左603_0_603_20200412_111108855_8.jpg\n",
      "pre:right true:left 10004/11700\n",
      "tensor([ 0.5660, -0.4673])\n",
      "pre:left true:left 10005/11700\n",
      "tensor([-0.2137,  0.3273])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左965_0_1121_20200412_115953229_6.jpg\n",
      "pre:right true:left 10006/11700\n",
      "tensor([ 0.3770, -0.4306])\n",
      "pre:left true:left 10007/11700\n",
      "tensor([0.0697, 0.0297])\n",
      "pre:left true:left 10008/11700\n",
      "tensor([ 0.4094, -0.4279])\n",
      "pre:left true:left 10009/11700\n",
      "tensor([-0.0746,  0.0469])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左690_0_846_20200412_115354827_4.jpg\n",
      "pre:right true:left 10010/11700\n",
      "tensor([0.0487, 0.0279])\n",
      "pre:left true:left 10011/11700\n",
      "tensor([ 0.6667, -0.7049])\n",
      "pre:left true:left 10012/11700\n",
      "tensor([-0.0036, -0.0232])\n",
      "pre:left true:left 10013/11700\n",
      "tensor([ 0.5891, -0.5003])\n",
      "pre:left true:left 10014/11700\n",
      "tensor([ 2.1138, -2.1833])\n",
      "pre:left true:left 10015/11700\n",
      "tensor([ 0.4918, -0.5145])\n",
      "pre:left true:left 10016/11700\n",
      "tensor([ 0.1113, -0.0691])\n",
      "pre:left true:left 10017/11700\n",
      "tensor([ 0.6493, -0.5707])\n",
      "pre:left true:left 10018/11700\n",
      "tensor([ 0.5600, -0.5938])\n",
      "pre:left true:left 10019/11700\n",
      "tensor([ 0.5201, -0.6333])\n",
      "pre:left true:left 10020/11700\n",
      "tensor([ 0.3916, -0.2903])\n",
      "pre:left true:left 10021/11700\n",
      "tensor([-0.0790,  0.0252])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左621_0_621_20200412_111134536_3.jpg\n",
      "pre:right true:left 10022/11700\n",
      "tensor([ 0.6120, -0.6089])\n",
      "pre:left true:left 10023/11700\n",
      "tensor([ 0.7207, -0.6026])\n",
      "pre:left true:left 10024/11700\n",
      "tensor([ 0.1654, -0.2402])\n",
      "pre:left true:left 10025/11700\n",
      "tensor([ 0.9244, -0.9723])\n",
      "pre:left true:left 10026/11700\n",
      "tensor([ 0.4741, -0.3722])\n",
      "pre:left true:left 10027/11700\n",
      "tensor([ 0.3592, -0.1510])\n",
      "pre:left true:left 10028/11700\n",
      "tensor([ 1.3211, -1.2792])\n",
      "pre:left true:left 10029/11700\n",
      "tensor([ 0.1684, -0.1202])\n",
      "pre:left true:left 10030/11700\n",
      "tensor([ 0.8784, -0.8275])\n",
      "pre:left true:left 10031/11700\n",
      "tensor([ 0.3030, -0.2642])\n",
      "pre:left true:left 10032/11700\n",
      "tensor([ 0.3664, -0.4097])\n",
      "pre:left true:left 10033/11700\n",
      "tensor([ 0.1969, -0.1312])\n",
      "pre:left true:left 10034/11700\n",
      "tensor([ 0.2272, -0.2041])\n",
      "pre:left true:left 10035/11700\n",
      "tensor([ 0.9103, -0.8018])\n",
      "pre:left true:left 10036/11700\n",
      "tensor([-0.3432,  0.3309])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左523_0_679_20200412_115017198_1.jpg\n",
      "pre:right true:left 10037/11700\n",
      "tensor([ 1.7778, -1.8754])\n",
      "pre:left true:left 10038/11700\n",
      "tensor([ 0.7225, -0.7105])\n",
      "pre:left true:left 10039/11700\n",
      "tensor([ 0.4660, -0.4492])\n",
      "pre:left true:left 10040/11700\n",
      "tensor([ 1.1246, -1.1356])\n",
      "pre:left true:left 10041/11700\n",
      "tensor([ 0.1430, -0.0936])\n",
      "pre:left true:left 10042/11700\n",
      "tensor([ 0.0510, -0.0986])\n",
      "pre:left true:left 10043/11700\n",
      "tensor([ 0.7158, -0.5999])\n",
      "pre:left true:left 10044/11700\n",
      "tensor([ 0.6134, -0.5625])\n",
      "pre:left true:left 10045/11700\n",
      "tensor([ 0.4024, -0.3970])\n",
      "pre:left true:left 10046/11700\n",
      "tensor([ 0.6231, -0.5719])\n",
      "pre:left true:left 10047/11700\n",
      "tensor([ 0.3111, -0.2097])\n",
      "pre:left true:left 10048/11700\n",
      "tensor([ 0.7125, -0.6516])\n",
      "pre:left true:left 10049/11700\n",
      "tensor([ 0.3327, -0.3681])\n",
      "pre:left true:left 10050/11700\n",
      "tensor([ 0.6351, -0.5717])\n",
      "pre:left true:left 10051/11700\n",
      "tensor([-0.1438,  0.2089])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1297_0_1453_20200412_120705914_9.jpg\n",
      "pre:right true:left 10052/11700\n",
      "tensor([ 0.7368, -0.7210])\n",
      "pre:left true:left 10053/11700\n",
      "tensor([ 0.8610, -0.9189])\n",
      "pre:left true:left 10054/11700\n",
      "tensor([ 1.1243, -1.1162])\n",
      "pre:left true:left 10055/11700\n",
      "tensor([ 0.6568, -0.6301])\n",
      "pre:left true:left 10056/11700\n",
      "tensor([ 1.2055, -1.2533])\n",
      "pre:left true:left 10057/11700\n",
      "tensor([ 0.3531, -0.3419])\n",
      "pre:left true:left 10058/11700\n",
      "tensor([ 0.9147, -0.9302])\n",
      "pre:left true:left 10059/11700\n",
      "tensor([-0.0839,  0.0529])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1079_0_1079_20200412_112207633_2.jpg\n",
      "pre:right true:left 10060/11700\n",
      "tensor([ 0.3031, -0.2850])\n",
      "pre:left true:left 10061/11700\n",
      "tensor([-0.2637,  0.2964])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左593_0_749_20200412_115148414_7.jpg\n",
      "pre:right true:left 10062/11700\n",
      "tensor([-0.0361,  0.0325])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1078_0_1078_20200412_112206327_10.jpg\n",
      "pre:right true:left 10063/11700\n",
      "tensor([ 0.3250, -0.4165])\n",
      "pre:left true:left 10064/11700\n",
      "tensor([ 0.7645, -0.7622])\n",
      "pre:left true:left 10065/11700\n",
      "tensor([ 0.6688, -0.7636])\n",
      "pre:left true:left 10066/11700\n",
      "tensor([ 0.3671, -0.2904])\n",
      "pre:left true:left 10067/11700\n",
      "tensor([ 0.0748, -0.0085])\n",
      "pre:left true:left 10068/11700\n",
      "tensor([ 0.7613, -0.8304])\n",
      "pre:left true:left 10069/11700\n",
      "tensor([ 0.4244, -0.4424])\n",
      "pre:left true:left 10070/11700\n",
      "tensor([ 0.0038, -0.0063])\n",
      "pre:left true:left 10071/11700\n",
      "tensor([ 0.2652, -0.1824])\n",
      "pre:left true:left 10072/11700\n",
      "tensor([ 0.1607, -0.0970])\n",
      "pre:left true:left 10073/11700\n",
      "tensor([ 0.8354, -0.8613])\n",
      "pre:left true:left 10074/11700\n",
      "tensor([ 0.9669, -0.9563])\n",
      "pre:left true:left 10075/11700\n",
      "tensor([ 2.4291, -2.4813])\n",
      "pre:left true:left 10076/11700\n",
      "tensor([ 0.8432, -0.8370])\n",
      "pre:left true:left 10077/11700\n",
      "tensor([ 0.6697, -0.6032])\n",
      "pre:left true:left 10078/11700\n",
      "tensor([ 0.0392, -0.0949])\n",
      "pre:left true:left 10079/11700\n",
      "tensor([ 0.6264, -0.6843])\n",
      "pre:left true:left 10080/11700\n",
      "tensor([ 0.6480, -0.6782])\n",
      "pre:left true:left 10081/11700\n",
      "tensor([ 0.8353, -0.7848])\n",
      "pre:left true:left 10082/11700\n",
      "tensor([ 0.3950, -0.4233])\n",
      "pre:left true:left 10083/11700\n",
      "tensor([ 0.6076, -0.5725])\n",
      "pre:left true:left 10084/11700\n",
      "tensor([ 0.3212, -0.3515])\n",
      "pre:left true:left 10085/11700\n",
      "tensor([ 0.2391, -0.3326])\n",
      "pre:left true:left 10086/11700\n",
      "tensor([-0.0251,  0.0738])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左982_0_982_20200412_112001271_7.jpg\n",
      "pre:right true:left 10087/11700\n",
      "tensor([ 0.6629, -0.6605])\n",
      "pre:left true:left 10088/11700\n",
      "tensor([ 0.4898, -0.4467])\n",
      "pre:left true:left 10089/11700\n",
      "tensor([ 0.8564, -0.9469])\n",
      "pre:left true:left 10090/11700\n",
      "tensor([ 0.5571, -0.5700])\n",
      "pre:left true:left 10091/11700\n",
      "tensor([ 0.3232, -0.4363])\n",
      "pre:left true:left 10092/11700\n",
      "tensor([ 0.7850, -0.8445])\n",
      "pre:left true:left 10093/11700\n",
      "tensor([ 0.5210, -0.6067])\n",
      "pre:left true:left 10094/11700\n",
      "tensor([ 0.6508, -0.6423])\n",
      "pre:left true:left 10095/11700\n",
      "tensor([ 0.2790, -0.3475])\n",
      "pre:left true:left 10096/11700\n",
      "tensor([ 0.9199, -0.7728])\n",
      "pre:left true:left 10097/11700\n",
      "tensor([ 0.2074, -0.2801])\n",
      "pre:left true:left 10098/11700\n",
      "tensor([ 0.7351, -0.7197])\n",
      "pre:left true:left 10099/11700\n",
      "tensor([ 0.1504, -0.1401])\n",
      "pre:left true:left 10100/11700\n",
      "tensor([ 0.1519, -0.1228])\n",
      "pre:left true:left 10101/11700\n",
      "tensor([ 1.5163, -1.5217])\n",
      "pre:left true:left 10102/11700\n",
      "tensor([ 0.5791, -0.5370])\n",
      "pre:left true:left 10103/11700\n",
      "tensor([ 0.1736, -0.1743])\n",
      "pre:left true:left 10104/11700\n",
      "tensor([ 1.1954, -1.1293])\n",
      "pre:left true:left 10105/11700\n",
      "tensor([ 0.1614, -0.1931])\n",
      "pre:left true:left 10106/11700\n",
      "tensor([ 0.4624, -0.4713])\n",
      "pre:left true:left 10107/11700\n",
      "tensor([ 0.9580, -0.9701])\n",
      "pre:left true:left 10108/11700\n",
      "tensor([ 0.9938, -1.0319])\n",
      "pre:left true:left 10109/11700\n",
      "tensor([ 0.2069, -0.1874])\n",
      "pre:left true:left 10110/11700\n",
      "tensor([-0.0838,  0.0884])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左171_0_171_20200412_110052681_9.jpg\n",
      "pre:right true:left 10111/11700\n",
      "tensor([ 0.4362, -0.2694])\n",
      "pre:left true:left 10112/11700\n",
      "tensor([-0.1449,  0.2038])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左320_0_476_20200412_114552663_8.jpg\n",
      "pre:right true:left 10113/11700\n",
      "tensor([ 0.6623, -0.6437])\n",
      "pre:left true:left 10114/11700\n",
      "tensor([ 0.8817, -0.7700])\n",
      "pre:left true:left 10115/11700\n",
      "tensor([ 0.7846, -0.7969])\n",
      "pre:left true:left 10116/11700\n",
      "tensor([ 0.7517, -0.7492])\n",
      "pre:left true:left 10117/11700\n",
      "tensor([ 0.4907, -0.4786])\n",
      "pre:left true:left 10118/11700\n",
      "tensor([ 0.9777, -0.9565])\n",
      "pre:left true:left 10119/11700\n",
      "tensor([-0.4550,  0.4916])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左331_0_487_20200412_114606994.jpg\n",
      "pre:right true:left 10120/11700\n",
      "tensor([ 0.2647, -0.2617])\n",
      "pre:left true:left 10121/11700\n",
      "tensor([ 0.8364, -0.7654])\n",
      "pre:left true:left 10122/11700\n",
      "tensor([-0.1329,  0.0335])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左593_0_593_20200412_111054604_7.jpg\n",
      "pre:right true:left 10123/11700\n",
      "tensor([ 0.5100, -0.4982])\n",
      "pre:left true:left 10124/11700\n",
      "tensor([-0.1911,  0.2815])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左616_0_772_20200412_115218396_5.jpg\n",
      "pre:right true:left 10125/11700\n",
      "tensor([ 0.4911, -0.5274])\n",
      "pre:left true:left 10126/11700\n",
      "tensor([-0.1199,  0.1262])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左793_0_949_20200412_115609081_5.jpg\n",
      "pre:right true:left 10127/11700\n",
      "tensor([ 1.0211, -1.0347])\n",
      "pre:left true:left 10128/11700\n",
      "tensor([ 1.0987, -1.1543])\n",
      "pre:left true:left 10129/11700\n",
      "tensor([ 0.6718, -0.6869])\n",
      "pre:left true:left 10130/11700\n",
      "tensor([ 0.6325, -0.6740])\n",
      "pre:left true:left 10131/11700\n",
      "tensor([ 0.0839, -0.1041])\n",
      "pre:left true:left 10132/11700\n",
      "tensor([ 1.0460, -1.0939])\n",
      "pre:left true:left 10133/11700\n",
      "tensor([ 0.5717, -0.5492])\n",
      "pre:left true:left 10134/11700\n",
      "tensor([-0.1094,  0.1262])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1401_0_1557_20200412_120921450_10.jpg\n",
      "pre:right true:left 10135/11700\n",
      "tensor([ 0.8328, -0.8210])\n",
      "pre:left true:left 10136/11700\n",
      "tensor([ 2.0789, -2.1010])\n",
      "pre:left true:left 10137/11700\n",
      "tensor([ 0.3300, -0.2318])\n",
      "pre:left true:left 10138/11700\n",
      "tensor([-0.0768,  0.0335])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1314_0_1314_20200412_112713869_9.jpg\n",
      "pre:right true:left 10139/11700\n",
      "tensor([ 0.9417, -0.9495])\n",
      "pre:left true:left 10140/11700\n",
      "tensor([ 0.4202, -0.4302])\n",
      "pre:left true:left 10141/11700\n",
      "tensor([ 0.9653, -0.9669])\n",
      "pre:left true:left 10142/11700\n",
      "tensor([ 0.5505, -0.6356])\n",
      "pre:left true:left 10143/11700\n",
      "tensor([ 0.3994, -0.3574])\n",
      "pre:left true:left 10144/11700\n",
      "tensor([0.1073, 0.1431])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左367_0_367_20200412_110532242_0.jpg\n",
      "pre:right true:left 10145/11700\n",
      "tensor([ 1.4900, -1.4177])\n",
      "pre:left true:left 10146/11700\n",
      "tensor([ 0.1392, -0.0606])\n",
      "pre:left true:left 10147/11700\n",
      "tensor([ 0.7235, -0.7080])\n",
      "pre:left true:left 10148/11700\n",
      "tensor([ 0.4853, -0.4245])\n",
      "pre:left true:left 10149/11700\n",
      "tensor([ 1.2330, -1.2253])\n",
      "pre:left true:left 10150/11700\n",
      "tensor([ 0.6635, -0.7157])\n",
      "pre:left true:left 10151/11700\n",
      "tensor([ 1.6056, -1.5239])\n",
      "pre:left true:left 10152/11700\n",
      "tensor([ 0.9712, -1.0087])\n",
      "pre:left true:left 10153/11700\n",
      "tensor([ 1.1202, -1.0912])\n",
      "pre:left true:left 10154/11700\n",
      "tensor([-1.0994,  1.0761])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左600_0_756_20200412_115157535.jpg\n",
      "pre:right true:left 10155/11700\n",
      "tensor([ 0.2097, -0.2572])\n",
      "pre:left true:left 10156/11700\n",
      "tensor([ 0.2351, -0.2659])\n",
      "pre:left true:left 10157/11700\n",
      "tensor([0.0045, 0.0287])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左780_0_936_20200412_115552136_7.jpg\n",
      "pre:right true:left 10158/11700\n",
      "tensor([-0.1114,  0.2031])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左768_0_768_20200412_111504208_8.jpg\n",
      "pre:right true:left 10159/11700\n",
      "tensor([ 0.5978, -0.6689])\n",
      "pre:left true:left 10160/11700\n",
      "tensor([ 0.5072, -0.3273])\n",
      "pre:left true:left 10161/11700\n",
      "tensor([ 0.9519, -1.0237])\n",
      "pre:left true:left 10162/11700\n",
      "tensor([ 1.0953, -1.1304])\n",
      "pre:left true:left 10163/11700\n",
      "tensor([ 0.2482, -0.2289])\n",
      "pre:left true:left 10164/11700\n",
      "tensor([ 0.8833, -0.8411])\n",
      "pre:left true:left 10165/11700\n",
      "tensor([0.0053, 0.0274])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1586_0_1742_20200412_121322604_7.jpg\n",
      "pre:right true:left 10166/11700\n",
      "tensor([ 0.2741, -0.2922])\n",
      "pre:left true:left 10167/11700\n",
      "tensor([ 0.4024, -0.4042])\n",
      "pre:left true:left 10168/11700\n",
      "tensor([ 0.2666, -0.2197])\n",
      "pre:left true:left 10169/11700\n",
      "tensor([ 0.1751, -0.1603])\n",
      "pre:left true:left 10170/11700\n",
      "tensor([ 0.7275, -0.7761])\n",
      "pre:left true:left 10171/11700\n",
      "tensor([ 0.7366, -0.7558])\n",
      "pre:left true:left 10172/11700\n",
      "tensor([0.0169, 0.0400])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左548_0_704_20200412_115049781.jpg\n",
      "pre:right true:left 10173/11700\n",
      "tensor([ 0.7783, -0.6988])\n",
      "pre:left true:left 10174/11700\n",
      "tensor([ 0.1330, -0.0441])\n",
      "pre:left true:left 10175/11700\n",
      "tensor([-0.0601,  0.1849])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左613_0_769_20200412_115214488_6.jpg\n",
      "pre:right true:left 10176/11700\n",
      "tensor([ 0.6488, -0.6744])\n",
      "pre:left true:left 10177/11700\n",
      "tensor([ 0.5782, -0.6122])\n",
      "pre:left true:left 10178/11700\n",
      "tensor([ 0.2437, -0.2541])\n",
      "pre:left true:left 10179/11700\n",
      "tensor([ 0.6060, -0.5559])\n",
      "pre:left true:left 10180/11700\n",
      "tensor([ 0.9044, -0.9505])\n",
      "pre:left true:left 10181/11700\n",
      "tensor([ 0.7795, -0.8237])\n",
      "pre:left true:left 10182/11700\n",
      "tensor([ 1.1020, -1.1715])\n",
      "pre:left true:left 10183/11700\n",
      "tensor([ 0.5920, -0.5953])\n",
      "pre:left true:left 10184/11700\n",
      "tensor([ 0.7786, -0.6745])\n",
      "pre:left true:left 10185/11700\n",
      "tensor([ 0.5159, -0.5212])\n",
      "pre:left true:left 10186/11700\n",
      "tensor([-0.5963,  0.5813])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左503_0_659_20200412_114951128_6.jpg\n",
      "pre:right true:left 10187/11700\n",
      "tensor([ 0.3941, -0.3897])\n",
      "pre:left true:left 10188/11700\n",
      "tensor([ 0.6077, -0.5953])\n",
      "pre:left true:left 10189/11700\n",
      "tensor([ 0.4899, -0.4736])\n",
      "pre:left true:left 10190/11700\n",
      "tensor([ 0.1116, -0.0793])\n",
      "pre:left true:left 10191/11700\n",
      "tensor([ 0.4354, -0.4023])\n",
      "pre:left true:left 10192/11700\n",
      "tensor([-0.0040, -0.1422])\n",
      "pre:left true:left 10193/11700\n",
      "tensor([ 0.3817, -0.4217])\n",
      "pre:left true:left 10194/11700\n",
      "tensor([ 1.4421, -1.4630])\n",
      "pre:left true:left 10195/11700\n",
      "tensor([ 0.3464, -0.3558])\n",
      "pre:left true:left 10196/11700\n",
      "tensor([-0.0927,  0.0403])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左689_0_689_20200412_111311531.jpg\n",
      "pre:right true:left 10197/11700\n",
      "tensor([ 0.5049, -0.5656])\n",
      "pre:left true:left 10198/11700\n",
      "tensor([ 0.1862, -0.2378])\n",
      "pre:left true:left 10199/11700\n",
      "tensor([ 0.6445, -0.5106])\n",
      "pre:left true:left 10200/11700\n",
      "tensor([ 0.0012, -0.0550])\n",
      "pre:left true:left 10201/11700\n",
      "tensor([ 0.2573, -0.2682])\n",
      "pre:left true:left 10202/11700\n",
      "tensor([ 0.4279, -0.3522])\n",
      "pre:left true:left 10203/11700\n",
      "tensor([ 0.3967, -0.3947])\n",
      "pre:left true:left 10204/11700\n",
      "tensor([ 0.4111, -0.4513])\n",
      "pre:left true:left 10205/11700\n",
      "tensor([-0.2515,  0.2863])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左447_0_603_20200412_114838168_1.jpg\n",
      "pre:right true:left 10206/11700\n",
      "tensor([ 0.1269, -0.1653])\n",
      "pre:left true:left 10207/11700\n",
      "tensor([ 0.1849, -0.2156])\n",
      "pre:left true:left 10208/11700\n",
      "tensor([ 0.7977, -0.8799])\n",
      "pre:left true:left 10209/11700\n",
      "tensor([ 0.0171, -0.0631])\n",
      "pre:left true:left 10210/11700\n",
      "tensor([ 0.3516, -0.2756])\n",
      "pre:left true:left 10211/11700\n",
      "tensor([ 0.9647, -0.7409])\n",
      "pre:left true:left 10212/11700\n",
      "tensor([ 0.5175, -0.4410])\n",
      "pre:left true:left 10213/11700\n",
      "tensor([ 0.1321, -0.1244])\n",
      "pre:left true:left 10214/11700\n",
      "tensor([ 0.3059, -0.3286])\n",
      "pre:left true:left 10215/11700\n",
      "tensor([ 0.5924, -0.5859])\n",
      "pre:left true:left 10216/11700\n",
      "tensor([ 0.3350, -0.4077])\n",
      "pre:left true:left 10217/11700\n",
      "tensor([-0.1601,  0.1748])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左223_0_223_20200412_110206863_4.jpg\n",
      "pre:right true:left 10218/11700\n",
      "tensor([ 0.7253, -0.7353])\n",
      "pre:left true:left 10219/11700\n",
      "tensor([-0.0648,  0.0252])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左416_0_572_20200412_114757758_9.jpg\n",
      "pre:right true:left 10220/11700\n",
      "tensor([ 1.4147, -1.4188])\n",
      "pre:left true:left 10221/11700\n",
      "tensor([ 0.6138, -0.7107])\n",
      "pre:left true:left 10222/11700\n",
      "tensor([-0.1598,  0.1542])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左760_0_760_20200412_111452809_10.jpg\n",
      "pre:right true:left 10223/11700\n",
      "tensor([-0.1567,  0.1448])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左721_0_877_20200412_115435244_9.jpg\n",
      "pre:right true:left 10224/11700\n",
      "tensor([ 1.1839, -1.2689])\n",
      "pre:left true:left 10225/11700\n",
      "tensor([ 0.1073, -0.1753])\n",
      "pre:left true:left 10226/11700\n",
      "tensor([ 0.7133, -0.7567])\n",
      "pre:left true:left 10227/11700\n",
      "tensor([-0.1226,  0.1279])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左845_0_845_20200412_111654048_3.jpg\n",
      "pre:right true:left 10228/11700\n",
      "tensor([-0.1432,  0.1406])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1350_0_1506_20200412_120814979_4.jpg\n",
      "pre:right true:left 10229/11700\n",
      "tensor([ 0.3928, -0.2739])\n",
      "pre:left true:left 10230/11700\n",
      "tensor([ 0.8427, -0.7990])\n",
      "pre:left true:left 10231/11700\n",
      "tensor([ 0.8228, -0.8286])\n",
      "pre:left true:left 10232/11700\n",
      "tensor([-0.3498,  0.4278])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左296_0_296_20200412_110350973_1.jpg\n",
      "pre:right true:left 10233/11700\n",
      "tensor([ 0.1219, -0.0166])\n",
      "pre:left true:left 10234/11700\n",
      "tensor([ 0.2577, -0.2403])\n",
      "pre:left true:left 10235/11700\n",
      "tensor([-0.0648,  0.0573])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1401_0_1557_20200412_120921450_4.jpg\n",
      "pre:right true:left 10236/11700\n",
      "tensor([ 0.2234, -0.1820])\n",
      "pre:left true:left 10237/11700\n",
      "tensor([ 0.6473, -0.6805])\n",
      "pre:left true:left 10238/11700\n",
      "tensor([ 0.7442, -0.6713])\n",
      "pre:left true:left 10239/11700\n",
      "tensor([ 0.6956, -0.6830])\n",
      "pre:left true:left 10240/11700\n",
      "tensor([ 1.1335, -1.1959])\n",
      "pre:left true:left 10241/11700\n",
      "tensor([ 0.7475, -0.7477])\n",
      "pre:left true:left 10242/11700\n",
      "tensor([ 0.3205, -0.3644])\n",
      "pre:left true:left 10243/11700\n",
      "tensor([ 0.6191, -0.5245])\n",
      "pre:left true:left 10244/11700\n",
      "tensor([ 1.0505, -1.0834])\n",
      "pre:left true:left 10245/11700\n",
      "tensor([ 1.0159, -1.0467])\n",
      "pre:left true:left 10246/11700\n",
      "tensor([-0.1249,  0.1297])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左257_0_257_20200412_110255351_7.jpg\n",
      "pre:right true:left 10247/11700\n",
      "tensor([ 0.3072, -0.3303])\n",
      "pre:left true:left 10248/11700\n",
      "tensor([ 0.5732, -0.5322])\n",
      "pre:left true:left 10249/11700\n",
      "tensor([ 0.2456, -0.2440])\n",
      "pre:left true:left 10250/11700\n",
      "tensor([0.0707, 0.0055])\n",
      "pre:left true:left 10251/11700\n",
      "tensor([ 0.6039, -0.5411])\n",
      "pre:left true:left 10252/11700\n",
      "tensor([-0.0520,  0.0808])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左853_0_1009_20200412_115727284_2.jpg\n",
      "pre:right true:left 10253/11700\n",
      "tensor([-0.4153,  0.5199])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左616_0_616_20200412_111127404_5.jpg\n",
      "pre:right true:left 10254/11700\n",
      "tensor([ 0.9017, -0.8725])\n",
      "pre:left true:left 10255/11700\n",
      "tensor([ 0.5035, -0.5559])\n",
      "pre:left true:left 10256/11700\n",
      "tensor([ 1.0297, -0.9713])\n",
      "pre:left true:left 10257/11700\n",
      "tensor([ 1.3290, -1.3589])\n",
      "pre:left true:left 10258/11700\n",
      "tensor([ 1.5380, -1.4049])\n",
      "pre:left true:left 10259/11700\n",
      "tensor([ 0.2236, -0.1536])\n",
      "pre:left true:left 10260/11700\n",
      "tensor([ 0.2815, -0.2710])\n",
      "pre:left true:left 10261/11700\n",
      "tensor([ 0.4828, -0.4100])\n",
      "pre:left true:left 10262/11700\n",
      "tensor([ 0.0643, -0.0649])\n",
      "pre:left true:left 10263/11700\n",
      "tensor([ 1.5406, -1.4766])\n",
      "pre:left true:left 10264/11700\n",
      "tensor([ 0.4940, -0.5793])\n",
      "pre:left true:left 10265/11700\n",
      "tensor([ 0.4093, -0.4192])\n",
      "pre:left true:left 10266/11700\n",
      "tensor([-0.3543,  0.3229])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左811_0_811_20200412_111605535_9.jpg\n",
      "pre:right true:left 10267/11700\n",
      "tensor([ 0.5957, -0.5884])\n",
      "pre:left true:left 10268/11700\n",
      "tensor([ 0.1895, -0.2410])\n",
      "pre:left true:left 10269/11700\n",
      "tensor([ 0.9651, -0.9821])\n",
      "pre:left true:left 10270/11700\n",
      "tensor([ 0.3143, -0.3263])\n",
      "pre:left true:left 10271/11700\n",
      "tensor([ 0.1554, -0.1476])\n",
      "pre:left true:left 10272/11700\n",
      "tensor([-0.0313,  0.0456])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左534_0_690_20200412_115031527_10.jpg\n",
      "pre:right true:left 10273/11700\n",
      "tensor([ 0.1605, -0.1069])\n",
      "pre:left true:left 10274/11700\n",
      "tensor([ 0.6315, -0.6089])\n",
      "pre:left true:left 10275/11700\n",
      "tensor([ 0.5879, -0.5641])\n",
      "pre:left true:left 10276/11700\n",
      "tensor([ 0.6144, -0.4665])\n",
      "pre:left true:left 10277/11700\n",
      "tensor([ 0.2525, -0.1606])\n",
      "pre:left true:left 10278/11700\n",
      "tensor([ 0.4025, -0.3564])\n",
      "pre:left true:left 10279/11700\n",
      "tensor([ 0.7818, -0.7175])\n",
      "pre:left true:left 10280/11700\n",
      "tensor([ 0.9730, -1.1400])\n",
      "pre:left true:left 10281/11700\n",
      "tensor([ 0.2608, -0.1306])\n",
      "pre:left true:left 10282/11700\n",
      "tensor([ 0.9184, -0.8397])\n",
      "pre:left true:left 10283/11700\n",
      "tensor([ 1.0400, -1.0319])\n",
      "pre:left true:left 10284/11700\n",
      "tensor([ 1.1173, -0.9769])\n",
      "pre:left true:left 10285/11700\n",
      "tensor([ 0.3512, -0.2980])\n",
      "pre:left true:left 10286/11700\n",
      "tensor([ 0.4829, -0.4919])\n",
      "pre:left true:left 10287/11700\n",
      "tensor([ 0.5776, -0.4663])\n",
      "pre:left true:left 10288/11700\n",
      "tensor([-0.0929,  0.0472])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左470_0_470_20200412_110759149_0.jpg\n",
      "pre:right true:left 10289/11700\n",
      "tensor([ 0.1281, -0.0999])\n",
      "pre:left true:left 10290/11700\n",
      "tensor([ 0.9378, -0.8967])\n",
      "pre:left true:left 10291/11700\n",
      "tensor([ 0.3863, -0.4205])\n",
      "pre:left true:left 10292/11700\n",
      "tensor([-0.1837,  0.1954])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左888_0_888_20200412_111755369_1.jpg\n",
      "pre:right true:left 10293/11700\n",
      "tensor([ 1.1937, -1.2271])\n",
      "pre:left true:left 10294/11700\n",
      "tensor([ 0.1960, -0.1779])\n",
      "pre:left true:left 10295/11700\n",
      "tensor([ 1.0342, -1.0271])\n",
      "pre:left true:left 10296/11700\n",
      "tensor([ 0.1951, -0.0760])\n",
      "pre:left true:left 10297/11700\n",
      "tensor([ 0.1383, -0.2101])\n",
      "pre:left true:left 10298/11700\n",
      "tensor([ 0.4539, -0.4561])\n",
      "pre:left true:left 10299/11700\n",
      "tensor([ 0.3824, -0.3160])\n",
      "pre:left true:left 10300/11700\n",
      "tensor([ 0.4207, -0.3900])\n",
      "pre:left true:left 10301/11700\n",
      "tensor([ 1.1592, -1.2859])\n",
      "pre:left true:left 10302/11700\n",
      "tensor([-0.3902,  0.5146])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左156_0_156_20200412_110031305_5.jpg\n",
      "pre:right true:left 10303/11700\n",
      "tensor([ 0.2281, -0.0555])\n",
      "pre:left true:left 10304/11700\n",
      "tensor([0.0195, 0.0200])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左698_0_854_20200412_115405273.jpg\n",
      "pre:right true:left 10305/11700\n",
      "tensor([ 0.3329, -0.2276])\n",
      "pre:left true:left 10306/11700\n",
      "tensor([ 0.5752, -0.5737])\n",
      "pre:left true:left 10307/11700\n",
      "tensor([ 0.4657, -0.5317])\n",
      "pre:left true:left 10308/11700\n",
      "tensor([ 1.0391, -1.0414])\n",
      "pre:left true:left 10309/11700\n",
      "tensor([ 1.4090, -1.4285])\n",
      "pre:left true:left 10310/11700\n",
      "tensor([ 0.4077, -0.3669])\n",
      "pre:left true:left 10311/11700\n",
      "tensor([ 0.2510, -0.2430])\n",
      "pre:left true:left 10312/11700\n",
      "tensor([ 0.5600, -0.5891])\n",
      "pre:left true:left 10313/11700\n",
      "tensor([ 0.2679, -0.3420])\n",
      "pre:left true:left 10314/11700\n",
      "tensor([ 0.9062, -0.9463])\n",
      "pre:left true:left 10315/11700\n",
      "tensor([ 0.0212, -0.0001])\n",
      "pre:left true:left 10316/11700\n",
      "tensor([ 0.5122, -0.4077])\n",
      "pre:left true:left 10317/11700\n",
      "tensor([ 0.8663, -0.8918])\n",
      "pre:left true:left 10318/11700\n",
      "tensor([ 1.1816, -1.2002])\n",
      "pre:left true:left 10319/11700\n",
      "tensor([ 0.6268, -0.6667])\n",
      "pre:left true:left 10320/11700\n",
      "tensor([-0.1243,  0.1276])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左407_0_407_20200412_110629294_7.jpg\n",
      "pre:right true:left 10321/11700\n",
      "tensor([ 0.3183, -0.3082])\n",
      "pre:left true:left 10322/11700\n",
      "tensor([ 0.3339, -0.2996])\n",
      "pre:left true:left 10323/11700\n",
      "tensor([-0.2214,  0.3235])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1610_0_1766_20200412_121353880_4.jpg\n",
      "pre:right true:left 10324/11700\n",
      "tensor([ 0.9537, -0.7864])\n",
      "pre:left true:left 10325/11700\n",
      "tensor([ 0.3891, -0.3515])\n",
      "pre:left true:left 10326/11700\n",
      "tensor([-0.0058,  0.0806])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左735_0_891_20200412_115453481_0.jpg\n",
      "pre:right true:left 10327/11700\n",
      "tensor([ 1.0873, -0.9887])\n",
      "pre:left true:left 10328/11700\n",
      "tensor([ 0.3585, -0.3715])\n",
      "pre:left true:left 10329/11700\n",
      "tensor([ 0.4562, -0.4467])\n",
      "pre:left true:left 10330/11700\n",
      "tensor([ 0.6802, -0.5595])\n",
      "pre:left true:left 10331/11700\n",
      "tensor([ 0.6214, -0.5291])\n",
      "pre:left true:left 10332/11700\n",
      "tensor([ 0.4585, -0.4911])\n",
      "pre:left true:left 10333/11700\n",
      "tensor([ 0.2690, -0.3087])\n",
      "pre:left true:left 10334/11700\n",
      "tensor([-0.1753,  0.0894])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1155_0_1311_20200412_120400838_1.jpg\n",
      "pre:right true:left 10335/11700\n",
      "tensor([ 0.3701, -0.3534])\n",
      "pre:left true:left 10336/11700\n",
      "tensor([ 0.5067, -0.5113])\n",
      "pre:left true:left 10337/11700\n",
      "tensor([ 1.4130, -1.5144])\n",
      "pre:left true:left 10338/11700\n",
      "tensor([ 0.2677, -0.2267])\n",
      "pre:left true:left 10339/11700\n",
      "tensor([ 0.2720, -0.2874])\n",
      "pre:left true:left 10340/11700\n",
      "tensor([-0.2220,  0.3071])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左702_0_702_20200412_111330079_8.jpg\n",
      "pre:right true:left 10341/11700\n",
      "tensor([ 0.2222, -0.2300])\n",
      "pre:left true:left 10342/11700\n",
      "tensor([ 0.2564, -0.1791])\n",
      "pre:left true:left 10343/11700\n",
      "tensor([ 0.7387, -0.7422])\n",
      "pre:left true:left 10344/11700\n",
      "tensor([ 0.9599, -0.9931])\n",
      "pre:left true:left 10345/11700\n",
      "tensor([ 0.7080, -0.6388])\n",
      "pre:left true:left 10346/11700\n",
      "tensor([ 0.3802, -0.4186])\n",
      "pre:left true:left 10347/11700\n",
      "tensor([ 0.9171, -0.9976])\n",
      "pre:left true:left 10348/11700\n",
      "tensor([ 0.2605, -0.1985])\n",
      "pre:left true:left 10349/11700\n",
      "tensor([ 0.2619, -0.3331])\n",
      "pre:left true:left 10350/11700\n",
      "tensor([ 0.8579, -0.7326])\n",
      "pre:left true:left 10351/11700\n",
      "tensor([ 1.3919, -1.3904])\n",
      "pre:left true:left 10352/11700\n",
      "tensor([ 0.5886, -0.4912])\n",
      "pre:left true:left 10353/11700\n",
      "tensor([ 0.4213, -0.4048])\n",
      "pre:left true:left 10354/11700\n",
      "tensor([ 0.3632, -0.2538])\n",
      "pre:left true:left 10355/11700\n",
      "tensor([ 0.5225, -0.5555])\n",
      "pre:left true:left 10356/11700\n",
      "tensor([ 0.6801, -0.6636])\n",
      "pre:left true:left 10357/11700\n",
      "tensor([-0.0317,  0.0528])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1533_0_1689_20200412_121213509_7.jpg\n",
      "pre:right true:left 10358/11700\n",
      "tensor([ 0.7120, -0.7351])\n",
      "pre:left true:left 10359/11700\n",
      "tensor([ 0.7643, -0.6890])\n",
      "pre:left true:left 10360/11700\n",
      "tensor([ 0.6476, -0.6353])\n",
      "pre:left true:left 10361/11700\n",
      "tensor([ 0.6761, -0.6846])\n",
      "pre:left true:left 10362/11700\n",
      "tensor([-0.6109,  0.6185])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左808_0_964_20200412_115628626_1.jpg\n",
      "pre:right true:left 10363/11700\n",
      "tensor([ 0.5038, -0.5710])\n",
      "pre:left true:left 10364/11700\n",
      "tensor([ 0.6117, -0.5023])\n",
      "pre:left true:left 10365/11700\n",
      "tensor([ 0.5531, -0.4941])\n",
      "pre:left true:left 10366/11700\n",
      "tensor([ 0.5839, -0.5932])\n",
      "pre:left true:left 10367/11700\n",
      "tensor([ 0.4000, -0.3524])\n",
      "pre:left true:left 10368/11700\n",
      "tensor([ 0.8605, -0.8920])\n",
      "pre:left true:left 10369/11700\n",
      "tensor([ 1.1754, -1.2044])\n",
      "pre:left true:left 10370/11700\n",
      "tensor([ 0.4956, -0.4822])\n",
      "pre:left true:left 10371/11700\n",
      "tensor([ 1.6312, -1.6407])\n",
      "pre:left true:left 10372/11700\n",
      "tensor([ 0.9659, -0.9978])\n",
      "pre:left true:left 10373/11700\n",
      "tensor([ 0.1262, -0.2252])\n",
      "pre:left true:left 10374/11700\n",
      "tensor([ 0.5017, -0.5035])\n",
      "pre:left true:left 10375/11700\n",
      "tensor([ 0.1722, -0.1382])\n",
      "pre:left true:left 10376/11700\n",
      "tensor([ 0.8752, -0.8679])\n",
      "pre:left true:left 10377/11700\n",
      "tensor([ 0.3155, -0.2477])\n",
      "pre:left true:left 10378/11700\n",
      "tensor([ 0.2114, -0.2503])\n",
      "pre:left true:left 10379/11700\n",
      "tensor([ 0.6032, -0.5720])\n",
      "pre:left true:left 10380/11700\n",
      "tensor([ 0.5096, -0.4938])\n",
      "pre:left true:left 10381/11700\n",
      "tensor([-0.0397,  0.2614])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1562_0_1718_20200412_121251317_6.jpg\n",
      "pre:right true:left 10382/11700\n",
      "tensor([ 0.9926, -0.9616])\n",
      "pre:left true:left 10383/11700\n",
      "tensor([-0.0374,  0.1188])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左761_0_761_20200412_111454231_1.jpg\n",
      "pre:right true:left 10384/11700\n",
      "tensor([ 0.2790, -0.3475])\n",
      "pre:left true:left 10385/11700\n",
      "tensor([ 0.0777, -0.0316])\n",
      "pre:left true:left 10386/11700\n",
      "tensor([ 0.2919, -0.2885])\n",
      "pre:left true:left 10387/11700\n",
      "tensor([ 1.2262, -1.1690])\n",
      "pre:left true:left 10388/11700\n",
      "tensor([ 0.1055, -0.1418])\n",
      "pre:left true:left 10389/11700\n",
      "tensor([ 0.2814, -0.2200])\n",
      "pre:left true:left 10390/11700\n",
      "tensor([ 0.6225, -0.5940])\n",
      "pre:left true:left 10391/11700\n",
      "tensor([ 0.6019, -0.5106])\n",
      "pre:left true:left 10392/11700\n",
      "tensor([-0.4183,  0.3798])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左348_0_504_20200412_114629148.jpg\n",
      "pre:right true:left 10393/11700\n",
      "tensor([ 0.9934, -0.9622])\n",
      "pre:left true:left 10394/11700\n",
      "tensor([ 0.0796, -0.0460])\n",
      "pre:left true:left 10395/11700\n",
      "tensor([ 0.4863, -0.4960])\n",
      "pre:left true:left 10396/11700\n",
      "tensor([ 0.4290, -0.3541])\n",
      "pre:left true:left 10397/11700\n",
      "tensor([ 0.6564, -0.6405])\n",
      "pre:left true:left 10398/11700\n",
      "tensor([ 0.5054, -0.4807])\n",
      "pre:left true:left 10399/11700\n",
      "tensor([ 0.0529, -0.0932])\n",
      "pre:left true:left 10400/11700\n",
      "tensor([ 0.7103, -0.6232])\n",
      "pre:left true:left 10401/11700\n",
      "tensor([-0.0306,  0.1244])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/右443_0_443_20200412_110720642_1.jpg\n",
      "pre:right true:left 10402/11700\n",
      "tensor([ 1.3608, -1.3278])\n",
      "pre:left true:left 10403/11700\n",
      "tensor([ 0.7709, -0.7615])\n",
      "pre:left true:left 10404/11700\n",
      "tensor([ 0.4419, -0.4408])\n",
      "pre:left true:left 10405/11700\n",
      "tensor([ 0.5283, -0.3270])\n",
      "pre:left true:left 10406/11700\n",
      "tensor([ 0.5972, -0.6073])\n",
      "pre:left true:left 10407/11700\n",
      "tensor([ 0.3101, -0.2532])\n",
      "pre:left true:left 10408/11700\n",
      "tensor([ 1.1042, -0.9938])\n",
      "pre:left true:left 10409/11700\n",
      "tensor([ 0.4979, -0.6035])\n",
      "pre:left true:left 10410/11700\n",
      "tensor([-0.9145,  0.8790])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左809_0_965_20200412_115629938_2.jpg\n",
      "pre:right true:left 10411/11700\n",
      "tensor([ 0.7774, -0.7327])\n",
      "pre:left true:left 10412/11700\n",
      "tensor([ 0.4274, -0.3532])\n",
      "pre:left true:left 10413/11700\n",
      "tensor([ 0.7207, -0.6748])\n",
      "pre:left true:left 10414/11700\n",
      "tensor([ 0.6025, -0.5115])\n",
      "pre:left true:left 10415/11700\n",
      "tensor([ 0.5125, -0.5596])\n",
      "pre:left true:left 10416/11700\n",
      "tensor([ 0.7855, -0.7450])\n",
      "pre:left true:left 10417/11700\n",
      "tensor([ 0.2029, -0.1611])\n",
      "pre:left true:left 10418/11700\n",
      "tensor([ 1.0213, -0.9436])\n",
      "pre:left true:left 10419/11700\n",
      "tensor([ 1.0764, -1.0477])\n",
      "pre:left true:left 10420/11700\n",
      "tensor([ 0.0506, -0.0238])\n",
      "pre:left true:left 10421/11700\n",
      "tensor([ 0.4656, -0.4725])\n",
      "pre:left true:left 10422/11700\n",
      "tensor([ 0.4079, -0.3476])\n",
      "pre:left true:left 10423/11700\n",
      "tensor([ 0.2948, -0.3771])\n",
      "pre:left true:left 10424/11700\n",
      "tensor([ 0.7610, -0.7395])\n",
      "pre:left true:left 10425/11700\n",
      "tensor([ 0.2059, -0.1582])\n",
      "pre:left true:left 10426/11700\n",
      "tensor([ 0.8756, -0.8399])\n",
      "pre:left true:left 10427/11700\n",
      "tensor([ 0.4345, -0.3377])\n",
      "pre:left true:left 10428/11700\n",
      "tensor([ 0.6455, -0.5609])\n",
      "pre:left true:left 10429/11700\n",
      "tensor([ 0.4556, -0.4090])\n",
      "pre:left true:left 10430/11700\n",
      "tensor([ 0.1801, -0.1903])\n",
      "pre:left true:left 10431/11700\n",
      "tensor([ 0.5718, -0.6012])\n",
      "pre:left true:left 10432/11700\n",
      "tensor([-0.4613,  0.6011])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左346_0_502_20200412_114626545_2.jpg\n",
      "pre:right true:left 10433/11700\n",
      "tensor([ 0.9555, -0.9457])\n",
      "pre:left true:left 10434/11700\n",
      "tensor([ 0.2089, -0.1544])\n",
      "pre:left true:left 10435/11700\n",
      "tensor([ 1.3005, -1.3691])\n",
      "pre:left true:left 10436/11700\n",
      "tensor([ 0.2987, -0.2022])\n",
      "pre:left true:left 10437/11700\n",
      "tensor([ 0.2330, -0.1851])\n",
      "pre:left true:left 10438/11700\n",
      "tensor([ 0.8241, -0.8004])\n",
      "pre:left true:left 10439/11700\n",
      "tensor([ 0.3710, -0.3509])\n",
      "pre:left true:left 10440/11700\n",
      "tensor([ 1.1992, -1.2060])\n",
      "pre:left true:left 10441/11700\n",
      "tensor([-0.1274,  0.1025])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左339_0_339_20200412_110452288_10.jpg\n",
      "pre:right true:left 10442/11700\n",
      "tensor([ 0.6310, -0.5798])\n",
      "pre:left true:left 10443/11700\n",
      "tensor([-0.0192, -0.0340])\n",
      "pre:left true:left 10444/11700\n",
      "tensor([ 0.5543, -0.5221])\n",
      "pre:left true:left 10445/11700\n",
      "tensor([ 1.0974, -1.1378])\n",
      "pre:left true:left 10446/11700\n",
      "tensor([-0.0012, -0.0160])\n",
      "pre:left true:left 10447/11700\n",
      "tensor([ 0.7122, -0.5129])\n",
      "pre:left true:left 10448/11700\n",
      "tensor([ 0.4008, -0.3323])\n",
      "pre:left true:left 10449/11700\n",
      "tensor([-0.0772, -0.0056])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左838_0_994_20200412_115707742_6.jpg\n",
      "pre:right true:left 10450/11700\n",
      "tensor([ 1.1369, -1.1459])\n",
      "pre:left true:left 10451/11700\n",
      "tensor([ 0.1267, -0.2286])\n",
      "pre:left true:left 10452/11700\n",
      "tensor([ 0.2913, -0.2488])\n",
      "pre:left true:left 10453/11700\n",
      "tensor([-0.0661,  0.0349])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左350_0_350_20200412_110507973_6.jpg\n",
      "pre:right true:left 10454/11700\n",
      "tensor([ 0.9118, -0.8188])\n",
      "pre:left true:left 10455/11700\n",
      "tensor([ 0.2262, -0.1774])\n",
      "pre:left true:left 10456/11700\n",
      "tensor([ 0.2914, -0.2728])\n",
      "pre:left true:left 10457/11700\n",
      "tensor([0.0212, 0.0175])\n",
      "pre:left true:left 10458/11700\n",
      "tensor([ 1.2929, -1.3058])\n",
      "pre:left true:left 10459/11700\n",
      "tensor([ 0.8210, -0.8989])\n",
      "pre:left true:left 10460/11700\n",
      "tensor([ 1.1264, -1.2125])\n",
      "pre:left true:left 10461/11700\n",
      "tensor([ 0.2170, -0.1968])\n",
      "pre:left true:left 10462/11700\n",
      "tensor([ 0.9573, -0.9789])\n",
      "pre:left true:left 10463/11700\n",
      "tensor([ 0.4738, -0.3886])\n",
      "pre:left true:left 10464/11700\n",
      "tensor([ 0.8331, -0.7883])\n",
      "pre:left true:left 10465/11700\n",
      "tensor([ 0.4546, -0.4378])\n",
      "pre:left true:left 10466/11700\n",
      "tensor([ 0.3035, -0.3309])\n",
      "pre:left true:left 10467/11700\n",
      "tensor([ 0.8809, -0.9395])\n",
      "pre:left true:left 10468/11700\n",
      "tensor([ 0.3193, -0.2342])\n",
      "pre:left true:left 10469/11700\n",
      "tensor([ 0.8302, -0.9144])\n",
      "pre:left true:left 10470/11700\n",
      "tensor([ 0.4935, -0.5421])\n",
      "pre:left true:left 10471/11700\n",
      "tensor([ 0.0959, -0.1655])\n",
      "pre:left true:left 10472/11700\n",
      "tensor([ 1.2426, -1.1674])\n",
      "pre:left true:left 10473/11700\n",
      "tensor([ 0.5104, -0.5200])\n",
      "pre:left true:left 10474/11700\n",
      "tensor([ 0.4542, -0.3725])\n",
      "pre:left true:left 10475/11700\n",
      "tensor([ 1.0601, -0.9572])\n",
      "pre:left true:left 10476/11700\n",
      "tensor([ 0.1553, -0.0855])\n",
      "pre:left true:left 10477/11700\n",
      "tensor([ 0.7260, -0.7319])\n",
      "pre:left true:left 10478/11700\n",
      "tensor([ 0.4225, -0.3571])\n",
      "pre:left true:left 10479/11700\n",
      "tensor([0.0677, 0.0203])\n",
      "pre:left true:left 10480/11700\n",
      "tensor([ 0.3534, -0.4073])\n",
      "pre:left true:left 10481/11700\n",
      "tensor([ 0.2265, -0.0380])\n",
      "pre:left true:left 10482/11700\n",
      "tensor([ 0.8667, -0.8967])\n",
      "pre:left true:left 10483/11700\n",
      "tensor([ 0.9382, -0.8192])\n",
      "pre:left true:left 10484/11700\n",
      "tensor([ 0.7887, -0.6821])\n",
      "pre:left true:left 10485/11700\n",
      "tensor([ 0.7207, -0.7606])\n",
      "pre:left true:left 10486/11700\n",
      "tensor([ 0.8246, -0.8926])\n",
      "pre:left true:left 10487/11700\n",
      "tensor([ 0.9684, -0.9869])\n",
      "pre:left true:left 10488/11700\n",
      "tensor([ 0.3813, -0.3480])\n",
      "pre:left true:left 10489/11700\n",
      "tensor([ 0.7796, -0.7624])\n",
      "pre:left true:left 10490/11700\n",
      "tensor([ 0.2376, -0.2734])\n",
      "pre:left true:left 10491/11700\n",
      "tensor([ 0.3689, -0.3871])\n",
      "pre:left true:left 10492/11700\n",
      "tensor([ 0.9401, -1.0649])\n",
      "pre:left true:left 10493/11700\n",
      "tensor([ 0.9255, -0.9187])\n",
      "pre:left true:left 10494/11700\n",
      "tensor([ 1.1235, -1.0374])\n",
      "pre:left true:left 10495/11700\n",
      "tensor([ 1.0868, -0.9969])\n",
      "pre:left true:left 10496/11700\n",
      "tensor([ 0.4825, -0.4881])\n",
      "pre:left true:left 10497/11700\n",
      "tensor([ 0.8487, -0.8882])\n",
      "pre:left true:left 10498/11700\n",
      "tensor([ 1.0659, -1.1179])\n",
      "pre:left true:left 10499/11700\n",
      "tensor([ 0.9024, -0.9105])\n",
      "pre:left true:left 10500/11700\n",
      "tensor([ 0.3565, -0.3170])\n",
      "pre:left true:left 10501/11700\n",
      "tensor([ 1.0465, -1.0136])\n",
      "pre:left true:left 10502/11700\n",
      "tensor([ 1.1394, -1.0843])\n",
      "pre:left true:left 10503/11700\n",
      "tensor([ 0.7287, -0.5603])\n",
      "pre:left true:left 10504/11700\n",
      "tensor([-0.0288, -0.0251])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左843_0_999_20200412_115714249_1.jpg\n",
      "pre:right true:left 10505/11700\n",
      "tensor([ 1.2330, -1.2253])\n",
      "pre:left true:left 10506/11700\n",
      "tensor([ 0.0476, -0.1143])\n",
      "pre:left true:left 10507/11700\n",
      "tensor([ 0.1015, -0.1016])\n",
      "pre:left true:left 10508/11700\n",
      "tensor([ 1.2358, -1.1027])\n",
      "pre:left true:left 10509/11700\n",
      "tensor([ 0.6517, -0.6172])\n",
      "pre:left true:left 10510/11700\n",
      "tensor([ 0.2733, -0.3037])\n",
      "pre:left true:left 10511/11700\n",
      "tensor([ 1.0984, -1.1250])\n",
      "pre:left true:left 10512/11700\n",
      "tensor([ 0.5709, -0.5174])\n",
      "pre:left true:left 10513/11700\n",
      "tensor([ 1.0979, -1.1349])\n",
      "pre:left true:left 10514/11700\n",
      "tensor([-0.0640,  0.2251])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左95_0_251_20200412_114059450_5.jpg\n",
      "pre:right true:left 10515/11700\n",
      "tensor([ 0.6572, -0.6404])\n",
      "pre:left true:left 10516/11700\n",
      "tensor([ 0.6290, -0.7325])\n",
      "pre:left true:left 10517/11700\n",
      "tensor([-0.1173,  0.2331])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左792_0_792_20200412_111538448_4.jpg\n",
      "pre:right true:left 10518/11700\n",
      "tensor([0.0451, 0.0684])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1067_0_1067_20200412_112151999_2.jpg\n",
      "pre:right true:left 10519/11700\n",
      "tensor([ 0.2482, -0.2459])\n",
      "pre:left true:left 10520/11700\n",
      "tensor([ 0.8832, -0.8657])\n",
      "pre:left true:left 10521/11700\n",
      "tensor([ 0.8562, -0.7738])\n",
      "pre:left true:left 10522/11700\n",
      "tensor([ 1.0066, -1.0130])\n",
      "pre:left true:left 10523/11700\n",
      "tensor([ 0.0983, -0.1154])\n",
      "pre:left true:left 10524/11700\n",
      "tensor([ 0.5638, -0.5715])\n",
      "pre:left true:left 10525/11700\n",
      "tensor([ 0.1839, -0.1308])\n",
      "pre:left true:left 10526/11700\n",
      "tensor([-0.2874,  0.4027])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左474_0_474_20200412_110804847_4.jpg\n",
      "pre:right true:left 10527/11700\n",
      "tensor([ 0.1027, -0.0427])\n",
      "pre:left true:left 10528/11700\n",
      "tensor([-0.1112,  0.0918])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左341_0_341_20200412_105624228_3.jpg\n",
      "pre:right true:left 10529/11700\n",
      "tensor([ 1.0633, -1.1168])\n",
      "pre:left true:left 10530/11700\n",
      "tensor([ 0.6499, -0.6511])\n",
      "pre:left true:left 10531/11700\n",
      "tensor([ 1.0852, -1.0325])\n",
      "pre:left true:left 10532/11700\n",
      "tensor([ 0.2136, -0.2265])\n",
      "pre:left true:left 10533/11700\n",
      "tensor([-0.3126,  0.3483])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1196_0_1352_20200412_120454296_8.jpg\n",
      "pre:right true:left 10534/11700\n",
      "tensor([-0.5847,  0.4959])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左350_0_350_20200412_110507973_4.jpg\n",
      "pre:right true:left 10535/11700\n",
      "tensor([ 0.8111, -0.8034])\n",
      "pre:left true:left 10536/11700\n",
      "tensor([ 0.4149, -0.4082])\n",
      "pre:left true:left 10537/11700\n",
      "tensor([ 0.1498, -0.1619])\n",
      "pre:left true:left 10538/11700\n",
      "tensor([ 0.8421, -0.7894])\n",
      "pre:left true:left 10539/11700\n",
      "tensor([ 0.5051, -0.4822])\n",
      "pre:left true:left 10540/11700\n",
      "tensor([ 0.9467, -0.9589])\n",
      "pre:left true:left 10541/11700\n",
      "tensor([ 0.6974, -0.7072])\n",
      "pre:left true:left 10542/11700\n",
      "tensor([ 0.9430, -0.9796])\n",
      "pre:left true:left 10543/11700\n",
      "tensor([ 0.2521, -0.1332])\n",
      "pre:left true:left 10544/11700\n",
      "tensor([ 0.0803, -0.0961])\n",
      "pre:left true:left 10545/11700\n",
      "tensor([ 0.6473, -0.6805])\n",
      "pre:left true:left 10546/11700\n",
      "tensor([ 1.0239, -0.9731])\n",
      "pre:left true:left 10547/11700\n",
      "tensor([-0.5352,  0.6025])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左223_0_223_20200412_110206863.jpg\n",
      "pre:right true:left 10548/11700\n",
      "tensor([-1.0347,  1.0674])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左606_0_762_20200412_115205352_0.jpg\n",
      "pre:right true:left 10549/11700\n",
      "tensor([ 0.5094, -0.4716])\n",
      "pre:left true:left 10550/11700\n",
      "tensor([ 0.9062, -0.9463])\n",
      "pre:left true:left 10551/11700\n",
      "tensor([ 0.1588, -0.2077])\n",
      "pre:left true:left 10552/11700\n",
      "tensor([ 0.2879, -0.1476])\n",
      "pre:left true:left 10553/11700\n",
      "tensor([ 1.5016, -1.4192])\n",
      "pre:left true:left 10554/11700\n",
      "tensor([ 0.6872, -0.6176])\n",
      "pre:left true:left 10555/11700\n",
      "tensor([ 1.3479, -1.4720])\n",
      "pre:left true:left 10556/11700\n",
      "tensor([ 0.3061, -0.3476])\n",
      "pre:left true:left 10557/11700\n",
      "tensor([-0.1429,  0.1737])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1494_0_1650_20200412_121122671_0.jpg\n",
      "pre:right true:left 10558/11700\n",
      "tensor([ 0.5410, -0.5631])\n",
      "pre:left true:left 10559/11700\n",
      "tensor([-0.0184, -0.0434])\n",
      "pre:left true:left 10560/11700\n",
      "tensor([ 1.3645, -1.3760])\n",
      "pre:left true:left 10561/11700\n",
      "tensor([ 0.5830, -0.6449])\n",
      "pre:left true:left 10562/11700\n",
      "tensor([ 0.8389, -0.7930])\n",
      "pre:left true:left 10563/11700\n",
      "tensor([ 0.3426, -0.3780])\n",
      "pre:left true:left 10564/11700\n",
      "tensor([ 0.0948, -0.1470])\n",
      "pre:left true:left 10565/11700\n",
      "tensor([0.0145, 0.0034])\n",
      "pre:left true:left 10566/11700\n",
      "tensor([-0.1626,  0.0942])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左596_0_752_20200412_115152325_0.jpg\n",
      "pre:right true:left 10567/11700\n",
      "tensor([-0.2381,  0.3088])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1410_0_1566_20200412_120933194_9.jpg\n",
      "pre:right true:left 10568/11700\n",
      "tensor([ 0.4064, -0.3947])\n",
      "pre:left true:left 10569/11700\n",
      "tensor([ 0.7298, -0.6737])\n",
      "pre:left true:left 10570/11700\n",
      "tensor([-0.2345,  0.1965])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左413_0_569_20200412_114753840_7.jpg\n",
      "pre:right true:left 10571/11700\n",
      "tensor([-0.1355,  0.1782])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左779_0_935_20200412_115550833_5.jpg\n",
      "pre:right true:left 10572/11700\n",
      "tensor([ 1.4787, -1.4787])\n",
      "pre:left true:left 10573/11700\n",
      "tensor([ 0.1481, -0.1975])\n",
      "pre:left true:left 10574/11700\n",
      "tensor([ 0.3393, -0.3003])\n",
      "pre:left true:left 10575/11700\n",
      "tensor([-0.4855,  0.4967])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左687_0_843_20200412_115350916_4.jpg\n",
      "pre:right true:left 10576/11700\n",
      "tensor([ 0.9351, -0.9098])\n",
      "pre:left true:left 10577/11700\n",
      "tensor([-0.2891,  0.3616])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左393_0_393_20200412_110609318_0.jpg\n",
      "pre:right true:left 10578/11700\n",
      "tensor([ 0.4104, -0.4029])\n",
      "pre:left true:left 10579/11700\n",
      "tensor([ 0.6794, -0.6163])\n",
      "pre:left true:left 10580/11700\n",
      "tensor([-0.3031,  0.3088])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左446_0_602_20200412_114836836_10.jpg\n",
      "pre:right true:left 10581/11700\n",
      "tensor([ 0.6148, -0.5836])\n",
      "pre:left true:left 10582/11700\n",
      "tensor([ 1.1822, -1.2452])\n",
      "pre:left true:left 10583/11700\n",
      "tensor([ 0.5108, -0.4754])\n",
      "pre:left true:left 10584/11700\n",
      "tensor([ 0.3291, -0.3294])\n",
      "pre:left true:left 10585/11700\n",
      "tensor([ 0.2972, -0.3562])\n",
      "pre:left true:left 10586/11700\n",
      "tensor([ 1.0267, -1.0220])\n",
      "pre:left true:left 10587/11700\n",
      "tensor([ 0.6521, -0.6897])\n",
      "pre:left true:left 10588/11700\n",
      "tensor([-0.5983,  0.6012])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左850_0_1006_20200412_115723362_0.jpg\n",
      "pre:right true:left 10589/11700\n",
      "tensor([ 0.9329, -0.9612])\n",
      "pre:left true:left 10590/11700\n",
      "tensor([ 0.2126, -0.2209])\n",
      "pre:left true:left 10591/11700\n",
      "tensor([ 0.7195, -0.6706])\n",
      "pre:left true:left 10592/11700\n",
      "tensor([ 0.7822, -0.7355])\n",
      "pre:left true:left 10593/11700\n",
      "tensor([ 0.4460, -0.4488])\n",
      "pre:left true:left 10594/11700\n",
      "tensor([ 1.0213, -1.0110])\n",
      "pre:left true:left 10595/11700\n",
      "tensor([ 0.8615, -0.8529])\n",
      "pre:left true:left 10596/11700\n",
      "tensor([ 0.5169, -0.4696])\n",
      "pre:left true:left 10597/11700\n",
      "tensor([ 0.6153, -0.7182])\n",
      "pre:left true:left 10598/11700\n",
      "tensor([ 0.1501, -0.1974])\n",
      "pre:left true:left 10599/11700\n",
      "tensor([-0.0686,  0.0817])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左210_0_210_20200412_110148309_7.jpg\n",
      "pre:right true:left 10600/11700\n",
      "tensor([ 0.4363, -0.4312])\n",
      "pre:left true:left 10601/11700\n",
      "tensor([ 1.0402, -1.0027])\n",
      "pre:left true:left 10602/11700\n",
      "tensor([-0.0620,  0.0152])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左929_0_929_20200412_111852226_2.jpg\n",
      "pre:right true:left 10603/11700\n",
      "tensor([ 0.1160, -0.0347])\n",
      "pre:left true:left 10604/11700\n",
      "tensor([ 1.3045, -1.2553])\n",
      "pre:left true:left 10605/11700\n",
      "tensor([ 0.4290, -0.3988])\n",
      "pre:left true:left 10606/11700\n",
      "tensor([ 0.5845, -0.6227])\n",
      "pre:left true:left 10607/11700\n",
      "tensor([-0.0744,  0.0021])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左892_0_1048_20200412_115818084.jpg\n",
      "pre:right true:left 10608/11700\n",
      "tensor([-0.7910,  0.7500])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左344_0_500_20200412_114623927_3.jpg\n",
      "pre:right true:left 10609/11700\n",
      "tensor([ 0.8677, -0.6802])\n",
      "pre:left true:left 10610/11700\n",
      "tensor([ 0.8355, -0.7739])\n",
      "pre:left true:left 10611/11700\n",
      "tensor([ 1.0203, -0.9905])\n",
      "pre:left true:left 10612/11700\n",
      "tensor([ 0.5164, -0.5799])\n",
      "pre:left true:left 10613/11700\n",
      "tensor([ 0.6292, -0.5782])\n",
      "pre:left true:left 10614/11700\n",
      "tensor([ 0.3123, -0.3182])\n",
      "pre:left true:left 10615/11700\n",
      "tensor([ 0.8908, -0.8514])\n",
      "pre:left true:left 10616/11700\n",
      "tensor([ 0.5609, -0.5489])\n",
      "pre:left true:left 10617/11700\n",
      "tensor([ 0.5995, -0.6642])\n",
      "pre:left true:left 10618/11700\n",
      "tensor([-0.4011,  0.4740])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1110_0_1266_20200412_120302191_10.jpg\n",
      "pre:right true:left 10619/11700\n",
      "tensor([ 0.7549, -0.7275])\n",
      "pre:left true:left 10620/11700\n",
      "tensor([ 0.9661, -1.0434])\n",
      "pre:left true:left 10621/11700\n",
      "tensor([ 0.7781, -0.7712])\n",
      "pre:left true:left 10622/11700\n",
      "tensor([ 0.4786, -0.3666])\n",
      "pre:left true:left 10623/11700\n",
      "tensor([ 0.2045, -0.0955])\n",
      "pre:left true:left 10624/11700\n",
      "tensor([ 0.4765, -0.3792])\n",
      "pre:left true:left 10625/11700\n",
      "tensor([-0.0179, -0.0037])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左408_0_564_20200412_114747327_2.jpg\n",
      "pre:right true:left 10626/11700\n",
      "tensor([ 1.0416, -1.1327])\n",
      "pre:left true:left 10627/11700\n",
      "tensor([ 0.6987, -0.6996])\n",
      "pre:left true:left 10628/11700\n",
      "tensor([ 0.6029, -0.7031])\n",
      "pre:left true:left 10629/11700\n",
      "tensor([-0.3805,  0.4741])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左393_0_393_20200412_110609318_9.jpg\n",
      "pre:right true:left 10630/11700\n",
      "tensor([ 0.3695, -0.2161])\n",
      "pre:left true:left 10631/11700\n",
      "tensor([ 0.1455, -0.1110])\n",
      "pre:left true:left 10632/11700\n",
      "tensor([-0.1517,  0.1781])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左891_0_891_20200412_111759650_1.jpg\n",
      "pre:right true:left 10633/11700\n",
      "tensor([ 0.3572, -0.3360])\n",
      "pre:left true:left 10634/11700\n",
      "tensor([ 1.1383, -1.0171])\n",
      "pre:left true:left 10635/11700\n",
      "tensor([ 0.6850, -0.6144])\n",
      "pre:left true:left 10636/11700\n",
      "tensor([-0.7785,  0.8508])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左755_0_911_20200412_115519560_1.jpg\n",
      "pre:right true:left 10637/11700\n",
      "tensor([ 0.1648, -0.2864])\n",
      "pre:left true:left 10638/11700\n",
      "tensor([ 0.6398, -0.5774])\n",
      "pre:left true:left 10639/11700\n",
      "tensor([ 1.1395, -1.1380])\n",
      "pre:left true:left 10640/11700\n",
      "tensor([-0.6490,  0.5769])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左671_0_671_20200412_111245857_3.jpg\n",
      "pre:right true:left 10641/11700\n",
      "tensor([ 0.6658, -0.7420])\n",
      "pre:left true:left 10642/11700\n",
      "tensor([ 0.3926, -0.3843])\n",
      "pre:left true:left 10643/11700\n",
      "tensor([ 0.2558, -0.2062])\n",
      "pre:left true:left 10644/11700\n",
      "tensor([0.0570, 0.0916])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1538_0_1694_20200412_121220028_9.jpg\n",
      "pre:right true:left 10645/11700\n",
      "tensor([ 0.8240, -0.7166])\n",
      "pre:left true:left 10646/11700\n",
      "tensor([0.0482, 0.0102])\n",
      "pre:left true:left 10647/11700\n",
      "tensor([ 1.2083, -1.1323])\n",
      "pre:left true:left 10648/11700\n",
      "tensor([ 0.4345, -0.5459])\n",
      "pre:left true:left 10649/11700\n",
      "tensor([ 1.1815, -1.0877])\n",
      "pre:left true:left 10650/11700\n",
      "tensor([ 0.2046, -0.2608])\n",
      "pre:left true:left 10651/11700\n",
      "tensor([ 1.0741, -1.0105])\n",
      "pre:left true:left 10652/11700\n",
      "tensor([ 0.3619, -0.3678])\n",
      "pre:left true:left 10653/11700\n",
      "tensor([-0.0055,  0.0794])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左847_0_1003_20200412_115719460_4.jpg\n",
      "pre:right true:left 10654/11700\n",
      "tensor([ 1.0845, -1.0488])\n",
      "pre:left true:left 10655/11700\n",
      "tensor([ 0.2868, -0.3412])\n",
      "pre:left true:left 10656/11700\n",
      "tensor([ 0.2626, -0.2641])\n",
      "pre:left true:left 10657/11700\n",
      "tensor([ 0.4757, -0.4751])\n",
      "pre:left true:left 10658/11700\n",
      "tensor([ 0.3644, -0.4077])\n",
      "pre:left true:left 10659/11700\n",
      "tensor([ 0.7224, -0.5677])\n",
      "pre:left true:left 10660/11700\n",
      "tensor([ 0.8309, -0.7927])\n",
      "pre:left true:left 10661/11700\n",
      "tensor([ 0.3932, -0.3604])\n",
      "pre:left true:left 10662/11700\n",
      "tensor([ 0.0631, -0.0490])\n",
      "pre:left true:left 10663/11700\n",
      "tensor([ 1.2154, -1.1864])\n",
      "pre:left true:left 10664/11700\n",
      "tensor([ 0.6661, -0.6336])\n",
      "pre:left true:left 10665/11700\n",
      "tensor([ 0.4492, -0.4053])\n",
      "pre:left true:left 10666/11700\n",
      "tensor([ 0.8785, -0.8932])\n",
      "pre:left true:left 10667/11700\n",
      "tensor([ 0.6979, -0.6427])\n",
      "pre:left true:left 10668/11700\n",
      "tensor([ 0.7476, -0.6910])\n",
      "pre:left true:left 10669/11700\n",
      "tensor([ 0.1834, -0.1436])\n",
      "pre:left true:left 10670/11700\n",
      "tensor([ 0.5206, -0.4293])\n",
      "pre:left true:left 10671/11700\n",
      "tensor([ 0.2085, -0.2260])\n",
      "pre:left true:left 10672/11700\n",
      "tensor([ 0.2927, -0.2453])\n",
      "pre:left true:left 10673/11700\n",
      "tensor([-0.0807,  0.0560])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左629_0_785_20200412_115235324.jpg\n",
      "pre:right true:left 10674/11700\n",
      "tensor([ 0.2439, -0.2105])\n",
      "pre:left true:left 10675/11700\n",
      "tensor([ 0.9250, -1.0100])\n",
      "pre:left true:left 10676/11700\n",
      "tensor([ 0.8998, -0.8696])\n",
      "pre:left true:left 10677/11700\n",
      "tensor([ 0.2697, -0.2417])\n",
      "pre:left true:left 10678/11700\n",
      "tensor([-0.4534,  0.5461])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左291_0_447_20200412_114514872_4.jpg\n",
      "pre:right true:left 10679/11700\n",
      "tensor([ 1.3070, -1.2405])\n",
      "pre:left true:left 10680/11700\n",
      "tensor([ 0.7690, -0.7867])\n",
      "pre:left true:left 10681/11700\n",
      "tensor([-0.1670,  0.2366])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左96_0_252_20200412_114100770_6.jpg\n",
      "pre:right true:left 10682/11700\n",
      "tensor([ 0.6357, -0.6004])\n",
      "pre:left true:left 10683/11700\n",
      "tensor([ 0.3387, -0.3079])\n",
      "pre:left true:left 10684/11700\n",
      "tensor([ 0.8654, -0.8119])\n",
      "pre:left true:left 10685/11700\n",
      "tensor([ 0.1918, -0.1770])\n",
      "pre:left true:left 10686/11700\n",
      "tensor([ 0.3783, -0.3694])\n",
      "pre:left true:left 10687/11700\n",
      "tensor([ 0.1168, -0.1048])\n",
      "pre:left true:left 10688/11700\n",
      "tensor([ 1.4433, -1.5059])\n",
      "pre:left true:left 10689/11700\n",
      "tensor([ 1.2473, -1.2467])\n",
      "pre:left true:left 10690/11700\n",
      "tensor([ 0.5272, -0.3289])\n",
      "pre:left true:left 10691/11700\n",
      "tensor([-0.1158,  0.1148])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1053_0_1053_20200412_112133776_2.jpg\n",
      "pre:right true:left 10692/11700\n",
      "tensor([ 0.0848, -0.1371])\n",
      "pre:left true:left 10693/11700\n",
      "tensor([ 0.5368, -0.4881])\n",
      "pre:left true:left 10694/11700\n",
      "tensor([-0.2171,  0.3000])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左375_0_375_20200412_110543633_2.jpg\n",
      "pre:right true:left 10695/11700\n",
      "tensor([ 1.0870, -1.1205])\n",
      "pre:left true:left 10696/11700\n",
      "tensor([ 0.2757, -0.3433])\n",
      "pre:left true:left 10697/11700\n",
      "tensor([ 0.1539, -0.1210])\n",
      "pre:left true:left 10698/11700\n",
      "tensor([ 1.3138, -1.3553])\n",
      "pre:left true:left 10699/11700\n",
      "tensor([ 1.0618, -1.0643])\n",
      "pre:left true:left 10700/11700\n",
      "tensor([ 0.1194, -0.0782])\n",
      "pre:left true:left 10701/11700\n",
      "tensor([-0.0013, -0.0618])\n",
      "pre:left true:left 10702/11700\n",
      "tensor([-0.3654,  0.2438])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左754_0_754_20200412_111444252_0.jpg\n",
      "pre:right true:left 10703/11700\n",
      "tensor([ 0.7175, -0.7984])\n",
      "pre:left true:left 10704/11700\n",
      "tensor([ 0.7800, -0.7906])\n",
      "pre:left true:left 10705/11700\n",
      "tensor([ 1.4074, -1.4321])\n",
      "pre:left true:left 10706/11700\n",
      "tensor([ 1.1490, -1.1852])\n",
      "pre:left true:left 10707/11700\n",
      "tensor([ 0.2639, -0.2194])\n",
      "pre:left true:left 10708/11700\n",
      "tensor([ 1.2842, -1.2347])\n",
      "pre:left true:left 10709/11700\n",
      "tensor([ 0.4053, -0.3293])\n",
      "pre:left true:left 10710/11700\n",
      "tensor([ 0.4219, -0.4061])\n",
      "pre:left true:left 10711/11700\n",
      "tensor([ 0.4512, -0.4372])\n",
      "pre:left true:left 10712/11700\n",
      "tensor([ 0.8051, -0.6281])\n",
      "pre:left true:left 10713/11700\n",
      "tensor([-0.0591,  0.0815])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左717_0_717_20200412_111351468_9.jpg\n",
      "pre:right true:left 10714/11700\n",
      "tensor([ 0.6546, -0.6027])\n",
      "pre:left true:left 10715/11700\n",
      "tensor([ 0.5952, -0.6154])\n",
      "pre:left true:left 10716/11700\n",
      "tensor([ 0.1279, -0.1339])\n",
      "pre:left true:left 10717/11700\n",
      "tensor([ 0.7406, -0.7591])\n",
      "pre:left true:left 10718/11700\n",
      "tensor([ 0.8750, -0.8143])\n",
      "pre:left true:left 10719/11700\n",
      "tensor([ 0.3405, -0.2834])\n",
      "pre:left true:left 10720/11700\n",
      "tensor([ 0.1910, -0.1715])\n",
      "pre:left true:left 10721/11700\n",
      "tensor([-0.0599,  0.1065])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左311_0_467_20200412_114540917_9.jpg\n",
      "pre:right true:left 10722/11700\n",
      "tensor([ 0.5503, -0.6014])\n",
      "pre:left true:left 10723/11700\n",
      "tensor([-0.0484,  0.1266])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左473_0_629_20200412_114912034_5.jpg\n",
      "pre:right true:left 10724/11700\n",
      "tensor([-0.1065, -0.0009])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1573_0_1729_20200412_121305657_10.jpg\n",
      "pre:right true:left 10725/11700\n",
      "tensor([ 0.9768, -1.0020])\n",
      "pre:left true:left 10726/11700\n",
      "tensor([ 1.0744, -1.1287])\n",
      "pre:left true:left 10727/11700\n",
      "tensor([ 0.3944, -0.3792])\n",
      "pre:left true:left 10728/11700\n",
      "tensor([ 1.0530, -1.0257])\n",
      "pre:left true:left 10729/11700\n",
      "tensor([ 0.4814, -0.5139])\n",
      "pre:left true:left 10730/11700\n",
      "tensor([ 1.0029, -0.9401])\n",
      "pre:left true:left 10731/11700\n",
      "tensor([-0.2389,  0.3080])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1257_0_1257_20200412_112559575_7.jpg\n",
      "pre:right true:left 10732/11700\n",
      "tensor([ 1.0967, -1.0896])\n",
      "pre:left true:left 10733/11700\n",
      "tensor([ 0.3259, -0.2512])\n",
      "pre:left true:left 10734/11700\n",
      "tensor([ 0.7580, -0.7394])\n",
      "pre:left true:left 10735/11700\n",
      "tensor([ 0.8576, -0.8090])\n",
      "pre:left true:left 10736/11700\n",
      "tensor([ 0.6516, -0.5982])\n",
      "pre:left true:left 10737/11700\n",
      "tensor([ 0.4031, -0.4552])\n",
      "pre:left true:left 10738/11700\n",
      "tensor([ 0.8966, -0.7568])\n",
      "pre:left true:left 10739/11700\n",
      "tensor([ 0.6323, -0.5326])\n",
      "pre:left true:left 10740/11700\n",
      "tensor([ 0.5353, -0.4362])\n",
      "pre:left true:left 10741/11700\n",
      "tensor([ 0.5146, -0.5130])\n",
      "pre:left true:left 10742/11700\n",
      "tensor([ 0.3253, -0.3647])\n",
      "pre:left true:left 10743/11700\n",
      "tensor([ 0.8960, -0.9108])\n",
      "pre:left true:left 10744/11700\n",
      "tensor([ 0.3068, -0.3271])\n",
      "pre:left true:left 10745/11700\n",
      "tensor([ 0.2407, -0.1831])\n",
      "pre:left true:left 10746/11700\n",
      "tensor([ 1.1531, -1.1144])\n",
      "pre:left true:left 10747/11700\n",
      "tensor([ 1.1123, -1.1475])\n",
      "pre:left true:left 10748/11700\n",
      "tensor([ 0.4271, -0.5178])\n",
      "pre:left true:left 10749/11700\n",
      "tensor([ 0.8071, -0.8383])\n",
      "pre:left true:left 10750/11700\n",
      "tensor([ 0.5276, -0.4808])\n",
      "pre:left true:left 10751/11700\n",
      "tensor([ 0.8719, -0.8309])\n",
      "pre:left true:left 10752/11700\n",
      "tensor([ 0.3592, -0.2794])\n",
      "pre:left true:left 10753/11700\n",
      "tensor([ 1.1938, -1.2422])\n",
      "pre:left true:left 10754/11700\n",
      "tensor([ 0.6757, -0.6343])\n",
      "pre:left true:left 10755/11700\n",
      "tensor([ 0.3542, -0.4263])\n",
      "pre:left true:left 10756/11700\n",
      "tensor([ 0.1668, -0.0857])\n",
      "pre:left true:left 10757/11700\n",
      "tensor([ 0.6602, -0.7461])\n",
      "pre:left true:left 10758/11700\n",
      "tensor([ 1.1719, -1.2555])\n",
      "pre:left true:left 10759/11700\n",
      "tensor([ 0.9260, -0.9495])\n",
      "pre:left true:left 10760/11700\n",
      "tensor([ 0.3535, -0.3884])\n",
      "pre:left true:left 10761/11700\n",
      "tensor([ 0.4681, -0.5155])\n",
      "pre:left true:left 10762/11700\n",
      "tensor([ 0.5750, -0.5096])\n",
      "pre:left true:left 10763/11700\n",
      "tensor([ 0.6030, -0.5396])\n",
      "pre:left true:left 10764/11700\n",
      "tensor([ 1.2588, -1.2851])\n",
      "pre:left true:left 10765/11700\n",
      "tensor([ 0.8616, -0.9604])\n",
      "pre:left true:left 10766/11700\n",
      "tensor([ 1.1789, -1.2044])\n",
      "pre:left true:left 10767/11700\n",
      "tensor([ 0.8663, -0.7931])\n",
      "pre:left true:left 10768/11700\n",
      "tensor([ 0.5464, -0.6061])\n",
      "pre:left true:left 10769/11700\n",
      "tensor([0.0003, 0.1856])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左571_0_571_20200412_111023207_6.jpg\n",
      "pre:right true:left 10770/11700\n",
      "tensor([ 0.1950, -0.2122])\n",
      "pre:left true:left 10771/11700\n",
      "tensor([ 0.0877, -0.1395])\n",
      "pre:left true:left 10772/11700\n",
      "tensor([ 0.8201, -0.7407])\n",
      "pre:left true:left 10773/11700\n",
      "tensor([ 0.2501, -0.1621])\n",
      "pre:left true:left 10774/11700\n",
      "tensor([ 0.5803, -0.5838])\n",
      "pre:left true:left 10775/11700\n",
      "tensor([ 0.8830, -0.8917])\n",
      "pre:left true:left 10776/11700\n",
      "tensor([ 1.8909, -1.9094])\n",
      "pre:left true:left 10777/11700\n",
      "tensor([ 0.7592, -0.8656])\n",
      "pre:left true:left 10778/11700\n",
      "tensor([ 0.7901, -0.7688])\n",
      "pre:left true:left 10779/11700\n",
      "tensor([ 0.5523, -0.5268])\n",
      "pre:left true:left 10780/11700\n",
      "tensor([ 1.3796, -1.3315])\n",
      "pre:left true:left 10781/11700\n",
      "tensor([ 0.3419, -0.3024])\n",
      "pre:left true:left 10782/11700\n",
      "tensor([ 0.0792, -0.0793])\n",
      "pre:left true:left 10783/11700\n",
      "tensor([ 1.2747, -1.0810])\n",
      "pre:left true:left 10784/11700\n",
      "tensor([ 0.1145, -0.1606])\n",
      "pre:left true:left 10785/11700\n",
      "tensor([ 0.6655, -0.7785])\n",
      "pre:left true:left 10786/11700\n",
      "tensor([ 1.0532, -1.0268])\n",
      "pre:left true:left 10787/11700\n",
      "tensor([ 0.3605, -0.3204])\n",
      "pre:left true:left 10788/11700\n",
      "tensor([ 0.7439, -0.6522])\n",
      "pre:left true:left 10789/11700\n",
      "tensor([ 0.4188, -0.4125])\n",
      "pre:left true:left 10790/11700\n",
      "tensor([ 0.9923, -1.0623])\n",
      "pre:left true:left 10791/11700\n",
      "tensor([ 0.3742, -0.3478])\n",
      "pre:left true:left 10792/11700\n",
      "tensor([ 0.4697, -0.4916])\n",
      "pre:left true:left 10793/11700\n",
      "tensor([-0.0130,  0.1277])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左422_0_578_20200412_114805569_8.jpg\n",
      "pre:right true:left 10794/11700\n",
      "tensor([ 0.7526, -0.8121])\n",
      "pre:left true:left 10795/11700\n",
      "tensor([ 0.9285, -0.9839])\n",
      "pre:left true:left 10796/11700\n",
      "tensor([-0.5637,  0.6129])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左285_0_441_20200412_114507035_6.jpg\n",
      "pre:right true:left 10797/11700\n",
      "tensor([ 0.6092, -0.5957])\n",
      "pre:left true:left 10798/11700\n",
      "tensor([ 1.0226, -0.9509])\n",
      "pre:left true:left 10799/11700\n",
      "tensor([ 0.7894, -0.8277])\n",
      "pre:left true:left 10800/11700\n",
      "tensor([ 0.5650, -0.6012])\n",
      "pre:left true:left 10801/11700\n",
      "tensor([ 0.0400, -0.0745])\n",
      "pre:left true:left 10802/11700\n",
      "tensor([ 0.4662, -0.5362])\n",
      "pre:left true:left 10803/11700\n",
      "tensor([ 0.7622, -0.7934])\n",
      "pre:left true:left 10804/11700\n",
      "tensor([ 0.4286, -0.3170])\n",
      "pre:left true:left 10805/11700\n",
      "tensor([ 0.1237, -0.0449])\n",
      "pre:left true:left 10806/11700\n",
      "tensor([ 0.2177, -0.1767])\n",
      "pre:left true:left 10807/11700\n",
      "tensor([ 0.4986, -0.5622])\n",
      "pre:left true:left 10808/11700\n",
      "tensor([ 0.4344, -0.4277])\n",
      "pre:left true:left 10809/11700\n",
      "tensor([ 0.5107, -0.4021])\n",
      "pre:left true:left 10810/11700\n",
      "tensor([ 0.3046, -0.3134])\n",
      "pre:left true:left 10811/11700\n",
      "tensor([ 0.5437, -0.3869])\n",
      "pre:left true:left 10812/11700\n",
      "tensor([ 0.3734, -0.3210])\n",
      "pre:left true:left 10813/11700\n",
      "tensor([ 0.7190, -0.6388])\n",
      "pre:left true:left 10814/11700\n",
      "tensor([-0.0335,  0.0801])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左544_0_544_20200412_110944711_2.jpg\n",
      "pre:right true:left 10815/11700\n",
      "tensor([ 0.8448, -0.7963])\n",
      "pre:left true:left 10816/11700\n",
      "tensor([ 0.1115, -0.0981])\n",
      "pre:left true:left 10817/11700\n",
      "tensor([ 0.8588, -0.7813])\n",
      "pre:left true:left 10818/11700\n",
      "tensor([ 0.0462, -0.0389])\n",
      "pre:left true:left 10819/11700\n",
      "tensor([ 1.7701, -1.7693])\n",
      "pre:left true:left 10820/11700\n",
      "tensor([ 0.9516, -0.8681])\n",
      "pre:left true:left 10821/11700\n",
      "tensor([ 1.0697, -1.1115])\n",
      "pre:left true:left 10822/11700\n",
      "tensor([-0.1976,  0.2771])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左475_0_475_20200412_110806277_6.jpg\n",
      "pre:right true:left 10823/11700\n",
      "tensor([ 0.5923, -0.5851])\n",
      "pre:left true:left 10824/11700\n",
      "tensor([ 1.1267, -1.0289])\n",
      "pre:left true:left 10825/11700\n",
      "tensor([ 0.7528, -0.7672])\n",
      "pre:left true:left 10826/11700\n",
      "tensor([-0.1871,  0.2021])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左781_0_937_20200412_115553445_5.jpg\n",
      "pre:right true:left 10827/11700\n",
      "tensor([ 0.3918, -0.3696])\n",
      "pre:left true:left 10828/11700\n",
      "tensor([ 0.5877, -0.6987])\n",
      "pre:left true:left 10829/11700\n",
      "tensor([-0.0301,  0.1125])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左316_0_316_20200412_105554268.jpg\n",
      "pre:right true:left 10830/11700\n",
      "tensor([ 0.7452, -0.8094])\n",
      "pre:left true:left 10831/11700\n",
      "tensor([ 1.0620, -1.0601])\n",
      "pre:left true:left 10832/11700\n",
      "tensor([ 0.8890, -0.7880])\n",
      "pre:left true:left 10833/11700\n",
      "tensor([-0.0392, -0.0067])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左261_0_261_20200412_110301071_0.jpg\n",
      "pre:right true:left 10834/11700\n",
      "tensor([ 0.5063, -0.4188])\n",
      "pre:left true:left 10835/11700\n",
      "tensor([ 0.2672, -0.3591])\n",
      "pre:left true:left 10836/11700\n",
      "tensor([ 1.2847, -1.2996])\n",
      "pre:left true:left 10837/11700\n",
      "tensor([ 0.1793, -0.0931])\n",
      "pre:left true:left 10838/11700\n",
      "tensor([ 1.0508, -1.0832])\n",
      "pre:left true:left 10839/11700\n",
      "tensor([ 0.4785, -0.4632])\n",
      "pre:left true:left 10840/11700\n",
      "tensor([ 0.2049, -0.2223])\n",
      "pre:left true:left 10841/11700\n",
      "tensor([ 0.3111, -0.2333])\n",
      "pre:left true:left 10842/11700\n",
      "tensor([ 0.6507, -0.6208])\n",
      "pre:left true:left 10843/11700\n",
      "tensor([ 0.9158, -0.8189])\n",
      "pre:left true:left 10844/11700\n",
      "tensor([ 0.3280, -0.3894])\n",
      "pre:left true:left 10845/11700\n",
      "tensor([ 0.8811, -0.9367])\n",
      "pre:left true:left 10846/11700\n",
      "tensor([ 0.7699, -0.8642])\n",
      "pre:left true:left 10847/11700\n",
      "tensor([ 0.4512, -0.4372])\n",
      "pre:left true:left 10848/11700\n",
      "tensor([ 0.6514, -0.6391])\n",
      "pre:left true:left 10849/11700\n",
      "tensor([ 0.3727, -0.4030])\n",
      "pre:left true:left 10850/11700\n",
      "tensor([-1.1917,  1.2603])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1139_0_1139_20200412_112325821_10.jpg\n",
      "pre:right true:left 10851/11700\n",
      "tensor([ 0.3379, -0.2531])\n",
      "pre:left true:left 10852/11700\n",
      "tensor([ 0.4800, -0.5080])\n",
      "pre:left true:left 10853/11700\n",
      "tensor([ 1.2039, -1.2154])\n",
      "pre:left true:left 10854/11700\n",
      "tensor([ 0.4536, -0.5221])\n",
      "pre:left true:left 10855/11700\n",
      "tensor([ 0.1154, -0.0842])\n",
      "pre:left true:left 10856/11700\n",
      "tensor([ 0.6609, -0.5656])\n",
      "pre:left true:left 10857/11700\n",
      "tensor([ 0.6868, -0.6821])\n",
      "pre:left true:left 10858/11700\n",
      "tensor([ 0.8094, -0.7971])\n",
      "pre:left true:left 10859/11700\n",
      "tensor([ 1.0846, -0.9239])\n",
      "pre:left true:left 10860/11700\n",
      "tensor([ 0.1070, -0.1878])\n",
      "pre:left true:left 10861/11700\n",
      "tensor([ 0.1499, -0.2376])\n",
      "pre:left true:left 10862/11700\n",
      "tensor([-0.0633,  0.0689])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左198_0_198_20200412_110131204_10.jpg\n",
      "pre:right true:left 10863/11700\n",
      "tensor([ 0.5478, -0.4858])\n",
      "pre:left true:left 10864/11700\n",
      "tensor([ 0.0862, -0.0686])\n",
      "pre:left true:left 10865/11700\n",
      "tensor([ 0.4163, -0.4199])\n",
      "pre:left true:left 10866/11700\n",
      "tensor([ 0.2551, -0.2418])\n",
      "pre:left true:left 10867/11700\n",
      "tensor([ 0.3438, -0.2945])\n",
      "pre:left true:left 10868/11700\n",
      "tensor([ 0.8718, -0.8046])\n",
      "pre:left true:left 10869/11700\n",
      "tensor([ 0.1099, -0.0687])\n",
      "pre:left true:left 10870/11700\n",
      "tensor([ 0.9821, -0.9997])\n",
      "pre:left true:left 10871/11700\n",
      "tensor([ 0.4841, -0.4419])\n",
      "pre:left true:left 10872/11700\n",
      "tensor([ 0.7588, -0.6331])\n",
      "pre:left true:left 10873/11700\n",
      "tensor([-0.2947,  0.3611])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左441_0_597_20200412_114830349_1.jpg\n",
      "pre:right true:left 10874/11700\n",
      "tensor([ 0.9214, -0.8867])\n",
      "pre:left true:left 10875/11700\n",
      "tensor([ 0.4247, -0.3761])\n",
      "pre:left true:left 10876/11700\n",
      "tensor([ 0.3326, -0.4760])\n",
      "pre:left true:left 10877/11700\n",
      "tensor([-0.2336,  0.3074])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左342_0_498_20200412_114621335_3.jpg\n",
      "pre:right true:left 10878/11700\n",
      "tensor([-0.0003, -0.0935])\n",
      "pre:left true:left 10879/11700\n",
      "tensor([ 0.1969, -0.1624])\n",
      "pre:left true:left 10880/11700\n",
      "tensor([-0.3082,  0.3441])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左215_0_215_20200412_110155445_1.jpg\n",
      "pre:right true:left 10881/11700\n",
      "tensor([ 0.2830, -0.2702])\n",
      "pre:left true:left 10882/11700\n",
      "tensor([ 0.3535, -0.3089])\n",
      "pre:left true:left 10883/11700\n",
      "tensor([ 1.1563, -0.9623])\n",
      "pre:left true:left 10884/11700\n",
      "tensor([-0.1843,  0.1745])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左720_0_720_20200412_111355758_9.jpg\n",
      "pre:right true:left 10885/11700\n",
      "tensor([ 0.3091, -0.3122])\n",
      "pre:left true:left 10886/11700\n",
      "tensor([-0.1577,  0.0200])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左451_0_607_20200412_114843369_2.jpg\n",
      "pre:right true:left 10887/11700\n",
      "tensor([ 0.8450, -0.9207])\n",
      "pre:left true:left 10888/11700\n",
      "tensor([ 0.9940, -0.9904])\n",
      "pre:left true:left 10889/11700\n",
      "tensor([-0.1943,  0.1326])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左470_0_470_20200412_110759149_1.jpg\n",
      "pre:right true:left 10890/11700\n",
      "tensor([ 0.2407, -0.2659])\n",
      "pre:left true:left 10891/11700\n",
      "tensor([ 0.3424, -0.3821])\n",
      "pre:left true:left 10892/11700\n",
      "tensor([ 0.8205, -0.8558])\n",
      "pre:left true:left 10893/11700\n",
      "tensor([ 0.9830, -0.8640])\n",
      "pre:left true:left 10894/11700\n",
      "tensor([ 0.5512, -0.5129])\n",
      "pre:left true:left 10895/11700\n",
      "tensor([ 0.3640, -0.3629])\n",
      "pre:left true:left 10896/11700\n",
      "tensor([ 1.1354, -1.1307])\n",
      "pre:left true:left 10897/11700\n",
      "tensor([ 0.0031, -0.0293])\n",
      "pre:left true:left 10898/11700\n",
      "tensor([ 0.5560, -0.5719])\n",
      "pre:left true:left 10899/11700\n",
      "tensor([ 0.9152, -0.8805])\n",
      "pre:left true:left 10900/11700\n",
      "tensor([ 0.7846, -0.7018])\n",
      "pre:left true:left 10901/11700\n",
      "tensor([-0.3246,  0.2685])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左381_0_381_20200412_110552198_10.jpg\n",
      "pre:right true:left 10902/11700\n",
      "tensor([ 1.3352, -1.3735])\n",
      "pre:left true:left 10903/11700\n",
      "tensor([ 0.1645, -0.1740])\n",
      "pre:left true:left 10904/11700\n",
      "tensor([-0.2890,  0.3788])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左853_0_1009_20200412_115727284_0.jpg\n",
      "pre:right true:left 10905/11700\n",
      "tensor([ 0.4044, -0.3237])\n",
      "pre:left true:left 10906/11700\n",
      "tensor([ 0.2555, -0.0719])\n",
      "pre:left true:left 10907/11700\n",
      "tensor([ 0.6380, -0.4958])\n",
      "pre:left true:left 10908/11700\n",
      "tensor([ 0.7718, -0.7372])\n",
      "pre:left true:left 10909/11700\n",
      "tensor([ 0.1792, -0.1928])\n",
      "pre:left true:left 10910/11700\n",
      "tensor([ 0.5858, -0.6191])\n",
      "pre:left true:left 10911/11700\n",
      "tensor([ 0.5716, -0.5606])\n",
      "pre:left true:left 10912/11700\n",
      "tensor([ 0.0479, -0.0708])\n",
      "pre:left true:left 10913/11700\n",
      "tensor([-0.3377,  0.3157])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1286_0_1286_20200412_112637374_4.jpg\n",
      "pre:right true:left 10914/11700\n",
      "tensor([ 0.6538, -0.7419])\n",
      "pre:left true:left 10915/11700\n",
      "tensor([ 0.1283, -0.0856])\n",
      "pre:left true:left 10916/11700\n",
      "tensor([ 0.8598, -0.9280])\n",
      "pre:left true:left 10917/11700\n",
      "tensor([ 1.3574, -1.3327])\n",
      "pre:left true:left 10918/11700\n",
      "tensor([0.0338, 0.0042])\n",
      "pre:left true:left 10919/11700\n",
      "tensor([ 0.5819, -0.6291])\n",
      "pre:left true:left 10920/11700\n",
      "tensor([ 0.1691, -0.1503])\n",
      "pre:left true:left 10921/11700\n",
      "tensor([-0.2685,  0.3307])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左356_0_356_20200412_110516529_2.jpg\n",
      "pre:right true:left 10922/11700\n",
      "tensor([ 0.2220, -0.1619])\n",
      "pre:left true:left 10923/11700\n",
      "tensor([ 0.6709, -0.6571])\n",
      "pre:left true:left 10924/11700\n",
      "tensor([ 0.9560, -0.9753])\n",
      "pre:left true:left 10925/11700\n",
      "tensor([ 0.1711, -0.1804])\n",
      "pre:left true:left 10926/11700\n",
      "tensor([-0.1301,  0.0860])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左375_0_531_20200412_114704342_9.jpg\n",
      "pre:right true:left 10927/11700\n",
      "tensor([ 0.5476, -0.4817])\n",
      "pre:left true:left 10928/11700\n",
      "tensor([ 0.3299, -0.3283])\n",
      "pre:left true:left 10929/11700\n",
      "tensor([ 0.7359, -0.8099])\n",
      "pre:left true:left 10930/11700\n",
      "tensor([-0.1381,  0.2694])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左916_0_916_20200412_111835274_0.jpg\n",
      "pre:right true:left 10931/11700\n",
      "tensor([ 0.7634, -0.7150])\n",
      "pre:left true:left 10932/11700\n",
      "tensor([-0.1525,  0.2624])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左494_0_494_20200412_110833366_4.jpg\n",
      "pre:right true:left 10933/11700\n",
      "tensor([ 0.2002, -0.2204])\n",
      "pre:left true:left 10934/11700\n",
      "tensor([ 0.5179, -0.5478])\n",
      "pre:left true:left 10935/11700\n",
      "tensor([ 0.3749, -0.3506])\n",
      "pre:left true:left 10936/11700\n",
      "tensor([ 2.4843, -2.5871])\n",
      "pre:left true:left 10937/11700\n",
      "tensor([ 0.9693, -1.0321])\n",
      "pre:left true:left 10938/11700\n",
      "tensor([ 0.9418, -0.9494])\n",
      "pre:left true:left 10939/11700\n",
      "tensor([ 0.8906, -0.8865])\n",
      "pre:left true:left 10940/11700\n",
      "tensor([ 0.7116, -0.7708])\n",
      "pre:left true:left 10941/11700\n",
      "tensor([ 0.5044, -0.5601])\n",
      "pre:left true:left 10942/11700\n",
      "tensor([ 1.0404, -0.9818])\n",
      "pre:left true:left 10943/11700\n",
      "tensor([ 1.4311, -1.4257])\n",
      "pre:left true:left 10944/11700\n",
      "tensor([ 0.6293, -0.6311])\n",
      "pre:left true:left 10945/11700\n",
      "tensor([ 1.2798, -1.2725])\n",
      "pre:left true:left 10946/11700\n",
      "tensor([0.0200, 0.0167])\n",
      "pre:left true:left 10947/11700\n",
      "tensor([ 0.8691, -0.9125])\n",
      "pre:left true:left 10948/11700\n",
      "tensor([ 0.4617, -0.5514])\n",
      "pre:left true:left 10949/11700\n",
      "tensor([-0.8309,  0.8965])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左494_0_650_20200412_114939397_2.jpg\n",
      "pre:right true:left 10950/11700\n",
      "tensor([-0.0305,  0.0864])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1620_0_1776_20200412_121406923_1.jpg\n",
      "pre:right true:left 10951/11700\n",
      "tensor([ 0.6318, -0.6116])\n",
      "pre:left true:left 10952/11700\n",
      "tensor([ 0.3056, -0.1025])\n",
      "pre:left true:left 10953/11700\n",
      "tensor([ 0.7426, -0.7308])\n",
      "pre:left true:left 10954/11700\n",
      "tensor([ 0.9357, -0.9325])\n",
      "pre:left true:left 10955/11700\n",
      "tensor([ 0.6878, -0.6373])\n",
      "pre:left true:left 10956/11700\n",
      "tensor([ 0.8901, -0.9123])\n",
      "pre:left true:left 10957/11700\n",
      "tensor([ 0.9716, -1.0203])\n",
      "pre:left true:left 10958/11700\n",
      "tensor([ 0.6175, -0.5432])\n",
      "pre:left true:left 10959/11700\n",
      "tensor([ 0.2954, -0.2849])\n",
      "pre:left true:left 10960/11700\n",
      "tensor([ 0.4406, -0.5769])\n",
      "pre:left true:left 10961/11700\n",
      "tensor([ 0.3305, -0.2614])\n",
      "pre:left true:left 10962/11700\n",
      "tensor([ 0.5829, -0.5552])\n",
      "pre:left true:left 10963/11700\n",
      "tensor([ 0.7986, -0.7513])\n",
      "pre:left true:left 10964/11700\n",
      "tensor([ 0.1809, -0.1141])\n",
      "pre:left true:left 10965/11700\n",
      "tensor([ 0.7469, -0.7392])\n",
      "pre:left true:left 10966/11700\n",
      "tensor([ 0.4628, -0.4838])\n",
      "pre:left true:left 10967/11700\n",
      "tensor([ 0.0613, -0.0710])\n",
      "pre:left true:left 10968/11700\n",
      "tensor([ 0.5884, -0.6126])\n",
      "pre:left true:left 10969/11700\n",
      "tensor([ 1.4639, -1.4661])\n",
      "pre:left true:left 10970/11700\n",
      "tensor([ 1.2844, -1.2636])\n",
      "pre:left true:left 10971/11700\n",
      "tensor([ 0.5924, -0.5430])\n",
      "pre:left true:left 10972/11700\n",
      "tensor([ 0.6131, -0.6330])\n",
      "pre:left true:left 10973/11700\n",
      "tensor([ 0.2313, -0.2788])\n",
      "pre:left true:left 10974/11700\n",
      "tensor([ 0.5949, -0.5718])\n",
      "pre:left true:left 10975/11700\n",
      "tensor([ 0.5248, -0.4941])\n",
      "pre:left true:left 10976/11700\n",
      "tensor([ 0.2279, -0.2790])\n",
      "pre:left true:left 10977/11700\n",
      "tensor([-0.4547,  0.5085])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左279_0_279_20200412_110326727_3.jpg\n",
      "pre:right true:left 10978/11700\n",
      "tensor([-0.4941,  0.5015])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左421_0_577_20200412_114804268_2.jpg\n",
      "pre:right true:left 10979/11700\n",
      "tensor([ 0.5178, -0.4797])\n",
      "pre:left true:left 10980/11700\n",
      "tensor([ 0.5949, -0.4790])\n",
      "pre:left true:left 10981/11700\n",
      "tensor([ 0.7972, -0.7910])\n",
      "pre:left true:left 10982/11700\n",
      "tensor([ 0.1413, -0.0132])\n",
      "pre:left true:left 10983/11700\n",
      "tensor([ 0.5144, -0.5044])\n",
      "pre:left true:left 10984/11700\n",
      "tensor([-0.6194,  0.6951])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左519_0_519_20200412_110909041_2.jpg\n",
      "pre:right true:left 10985/11700\n",
      "tensor([ 0.6945, -0.7190])\n",
      "pre:left true:left 10986/11700\n",
      "tensor([ 0.5782, -0.5257])\n",
      "pre:left true:left 10987/11700\n",
      "tensor([ 0.2633, -0.2424])\n",
      "pre:left true:left 10988/11700\n",
      "tensor([ 0.3341, -0.4191])\n",
      "pre:left true:left 10989/11700\n",
      "tensor([ 1.0657, -1.1485])\n",
      "pre:left true:left 10990/11700\n",
      "tensor([ 0.5678, -0.5050])\n",
      "pre:left true:left 10991/11700\n",
      "tensor([ 0.4536, -0.4553])\n",
      "pre:left true:left 10992/11700\n",
      "tensor([-0.4825,  0.4365])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左472_0_628_20200412_114910718.jpg\n",
      "pre:right true:left 10993/11700\n",
      "tensor([-0.5171,  0.5411])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1618_0_1774_20200412_121404313_10.jpg\n",
      "pre:right true:left 10994/11700\n",
      "tensor([ 1.0665, -1.0141])\n",
      "pre:left true:left 10995/11700\n",
      "tensor([ 0.5493, -0.5568])\n",
      "pre:left true:left 10996/11700\n",
      "tensor([ 0.1043, -0.1393])\n",
      "pre:left true:left 10997/11700\n",
      "tensor([ 0.3313, -0.2242])\n",
      "pre:left true:left 10998/11700\n",
      "tensor([ 0.9917, -1.0617])\n",
      "pre:left true:left 10999/11700\n",
      "tensor([ 0.1415, -0.0272])\n",
      "pre:left true:left 11000/11700\n",
      "tensor([ 0.8889, -0.8834])\n",
      "pre:left true:left 11001/11700\n",
      "tensor([ 1.0740, -1.0832])\n",
      "pre:left true:left 11002/11700\n",
      "tensor([ 0.1144, -0.1439])\n",
      "pre:left true:left 11003/11700\n",
      "tensor([ 0.9939, -0.9893])\n",
      "pre:left true:left 11004/11700\n",
      "tensor([-0.2218,  0.2955])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左599_0_755_20200412_115156230.jpg\n",
      "pre:right true:left 11005/11700\n",
      "tensor([ 0.7245, -0.7471])\n",
      "pre:left true:left 11006/11700\n",
      "tensor([ 0.4633, -0.2714])\n",
      "pre:left true:left 11007/11700\n",
      "tensor([ 0.6120, -0.6335])\n",
      "pre:left true:left 11008/11700\n",
      "tensor([ 0.3424, -0.2188])\n",
      "pre:left true:left 11009/11700\n",
      "tensor([ 0.8718, -0.9527])\n",
      "pre:left true:left 11010/11700\n",
      "tensor([ 0.3998, -0.4841])\n",
      "pre:left true:left 11011/11700\n",
      "tensor([ 0.1574, -0.1590])\n",
      "pre:left true:left 11012/11700\n",
      "tensor([ 0.8140, -0.8385])\n",
      "pre:left true:left 11013/11700\n",
      "tensor([ 1.1723, -1.1218])\n",
      "pre:left true:left 11014/11700\n",
      "tensor([ 0.2593, -0.2847])\n",
      "pre:left true:left 11015/11700\n",
      "tensor([-0.0362, -0.1766])\n",
      "pre:left true:left 11016/11700\n",
      "tensor([ 0.7203, -0.6655])\n",
      "pre:left true:left 11017/11700\n",
      "tensor([ 0.2868, -0.2114])\n",
      "pre:left true:left 11018/11700\n",
      "tensor([-0.2128,  0.3579])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左393_0_393_20200412_110609318_10.jpg\n",
      "pre:right true:left 11019/11700\n",
      "tensor([ 1.6965, -1.7199])\n",
      "pre:left true:left 11020/11700\n",
      "tensor([ 0.8779, -0.9516])\n",
      "pre:left true:left 11021/11700\n",
      "tensor([ 0.2899, -0.1837])\n",
      "pre:left true:left 11022/11700\n",
      "tensor([ 1.2842, -1.2619])\n",
      "pre:left true:left 11023/11700\n",
      "tensor([ 0.1554, -0.1505])\n",
      "pre:left true:left 11024/11700\n",
      "tensor([ 1.8937, -1.8712])\n",
      "pre:left true:left 11025/11700\n",
      "tensor([ 0.8662, -0.9275])\n",
      "pre:left true:left 11026/11700\n",
      "tensor([ 0.2127, -0.2113])\n",
      "pre:left true:left 11027/11700\n",
      "tensor([ 0.4367, -0.4132])\n",
      "pre:left true:left 11028/11700\n",
      "tensor([ 0.6672, -0.6553])\n",
      "pre:left true:left 11029/11700\n",
      "tensor([ 0.8341, -0.7975])\n",
      "pre:left true:left 11030/11700\n",
      "tensor([-0.4220,  0.3802])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左842_0_998_20200412_115712939.jpg\n",
      "pre:right true:left 11031/11700\n",
      "tensor([ 1.0359, -0.9448])\n",
      "pre:left true:left 11032/11700\n",
      "tensor([ 0.4335, -0.4145])\n",
      "pre:left true:left 11033/11700\n",
      "tensor([ 0.2024, -0.2172])\n",
      "pre:left true:left 11034/11700\n",
      "tensor([ 0.1570, -0.1406])\n",
      "pre:left true:left 11035/11700\n",
      "tensor([ 0.4631, -0.4666])\n",
      "pre:left true:left 11036/11700\n",
      "tensor([ 0.7782, -0.6989])\n",
      "pre:left true:left 11037/11700\n",
      "tensor([ 0.9009, -0.8861])\n",
      "pre:left true:left 11038/11700\n",
      "tensor([ 1.0530, -1.0294])\n",
      "pre:left true:left 11039/11700\n",
      "tensor([ 0.5486, -0.4708])\n",
      "pre:left true:left 11040/11700\n",
      "tensor([ 0.6235, -0.6504])\n",
      "pre:left true:left 11041/11700\n",
      "tensor([ 1.2779, -1.2317])\n",
      "pre:left true:left 11042/11700\n",
      "tensor([ 0.2813, -0.2848])\n",
      "pre:left true:left 11043/11700\n",
      "tensor([ 0.4979, -0.4603])\n",
      "pre:left true:left 11044/11700\n",
      "tensor([ 0.6724, -0.6426])\n",
      "pre:left true:left 11045/11700\n",
      "tensor([ 0.9723, -0.9682])\n",
      "pre:left true:left 11046/11700\n",
      "tensor([ 0.1917, -0.1952])\n",
      "pre:left true:left 11047/11700\n",
      "tensor([ 0.5144, -0.4740])\n",
      "pre:left true:left 11048/11700\n",
      "tensor([ 0.1144, -0.0882])\n",
      "pre:left true:left 11049/11700\n",
      "tensor([ 0.1610, -0.0870])\n",
      "pre:left true:left 11050/11700\n",
      "tensor([ 0.8474, -0.7684])\n",
      "pre:left true:left 11051/11700\n",
      "tensor([ 0.3082, -0.3702])\n",
      "pre:left true:left 11052/11700\n",
      "tensor([0.0984, 0.0196])\n",
      "pre:left true:left 11053/11700\n",
      "tensor([ 0.1427, -0.1279])\n",
      "pre:left true:left 11054/11700\n",
      "tensor([ 0.4469, -0.3445])\n",
      "pre:left true:left 11055/11700\n",
      "tensor([ 1.3157, -1.3794])\n",
      "pre:left true:left 11056/11700\n",
      "tensor([ 0.6834, -0.7310])\n",
      "pre:left true:left 11057/11700\n",
      "tensor([ 0.7331, -0.7777])\n",
      "pre:left true:left 11058/11700\n",
      "tensor([ 0.4358, -0.3759])\n",
      "pre:left true:left 11059/11700\n",
      "tensor([ 0.1924, -0.1470])\n",
      "pre:left true:left 11060/11700\n",
      "tensor([-0.0144,  0.0697])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左410_0_410_20200412_110633567.jpg\n",
      "pre:right true:left 11061/11700\n",
      "tensor([ 0.4472, -0.4768])\n",
      "pre:left true:left 11062/11700\n",
      "tensor([ 0.9030, -0.8616])\n",
      "pre:left true:left 11063/11700\n",
      "tensor([ 0.1762, -0.2054])\n",
      "pre:left true:left 11064/11700\n",
      "tensor([ 0.3581, -0.1667])\n",
      "pre:left true:left 11065/11700\n",
      "tensor([ 0.9475, -0.9938])\n",
      "pre:left true:left 11066/11700\n",
      "tensor([ 0.7100, -0.6726])\n",
      "pre:left true:left 11067/11700\n",
      "tensor([ 0.7748, -0.8247])\n",
      "pre:left true:left 11068/11700\n",
      "tensor([ 1.0706, -1.0337])\n",
      "pre:left true:left 11069/11700\n",
      "tensor([ 0.2162, -0.2612])\n",
      "pre:left true:left 11070/11700\n",
      "tensor([ 0.2452, -0.2497])\n",
      "pre:left true:left 11071/11700\n",
      "tensor([ 1.0231, -1.0940])\n",
      "pre:left true:left 11072/11700\n",
      "tensor([ 0.7866, -0.8157])\n",
      "pre:left true:left 11073/11700\n",
      "tensor([ 0.7800, -0.7906])\n",
      "pre:left true:left 11074/11700\n",
      "tensor([ 0.3804, -0.3198])\n",
      "pre:left true:left 11075/11700\n",
      "tensor([ 0.3718, -0.3449])\n",
      "pre:left true:left 11076/11700\n",
      "tensor([-0.2715,  0.3217])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左826_0_982_20200412_115652071_1.jpg\n",
      "pre:right true:left 11077/11700\n",
      "tensor([ 0.6125, -0.5695])\n",
      "pre:left true:left 11078/11700\n",
      "tensor([ 0.9367, -0.9307])\n",
      "pre:left true:left 11079/11700\n",
      "tensor([ 0.3533, -0.2656])\n",
      "pre:left true:left 11080/11700\n",
      "tensor([ 0.9401, -0.8830])\n",
      "pre:left true:left 11081/11700\n",
      "tensor([ 0.7384, -0.7980])\n",
      "pre:left true:left 11082/11700\n",
      "tensor([ 0.7110, -0.7380])\n",
      "pre:left true:left 11083/11700\n",
      "tensor([ 0.4424, -0.4350])\n",
      "pre:left true:left 11084/11700\n",
      "tensor([ 1.5408, -1.6195])\n",
      "pre:left true:left 11085/11700\n",
      "tensor([-0.0113, -0.0301])\n",
      "pre:left true:left 11086/11700\n",
      "tensor([ 1.2267, -1.2458])\n",
      "pre:left true:left 11087/11700\n",
      "tensor([ 1.2368, -1.2598])\n",
      "pre:left true:left 11088/11700\n",
      "tensor([ 0.5443, -0.6685])\n",
      "pre:left true:left 11089/11700\n",
      "tensor([ 0.7305, -0.8391])\n",
      "pre:left true:left 11090/11700\n",
      "tensor([0.1426, 0.0166])\n",
      "pre:left true:left 11091/11700\n",
      "tensor([ 0.8810, -0.8330])\n",
      "pre:left true:left 11092/11700\n",
      "tensor([ 0.8344, -0.8022])\n",
      "pre:left true:left 11093/11700\n",
      "tensor([ 0.5072, -0.3273])\n",
      "pre:left true:left 11094/11700\n",
      "tensor([ 0.4245, -0.3669])\n",
      "pre:left true:left 11095/11700\n",
      "tensor([-0.2873,  0.3630])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左634_0_634_20200412_111153081_2.jpg\n",
      "pre:right true:left 11096/11700\n",
      "tensor([ 0.4303, -0.4549])\n",
      "pre:left true:left 11097/11700\n",
      "tensor([ 0.9693, -0.9453])\n",
      "pre:left true:left 11098/11700\n",
      "tensor([-0.1670,  0.2193])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左534_0_534_20200412_110930432_3.jpg\n",
      "pre:right true:left 11099/11700\n",
      "tensor([-0.1386,  0.1713])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左752_0_908_20200412_115515635_9.jpg\n",
      "pre:right true:left 11100/11700\n",
      "tensor([-0.1632,  0.1420])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左423_0_579_20200412_114806868_2.jpg\n",
      "pre:right true:left 11101/11700\n",
      "tensor([-0.1500,  0.2485])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左184_0_184_20200412_110111233_2.jpg\n",
      "pre:right true:left 11102/11700\n",
      "tensor([ 0.3811, -0.3220])\n",
      "pre:left true:left 11103/11700\n",
      "tensor([ 0.6628, -0.6578])\n",
      "pre:left true:left 11104/11700\n",
      "tensor([ 0.2702, -0.2425])\n",
      "pre:left true:left 11105/11700\n",
      "tensor([ 1.1131, -1.0888])\n",
      "pre:left true:left 11106/11700\n",
      "tensor([ 1.3093, -1.3151])\n",
      "pre:left true:left 11107/11700\n",
      "tensor([ 0.2356, -0.2481])\n",
      "pre:left true:left 11108/11700\n",
      "tensor([ 0.3639, -0.3237])\n",
      "pre:left true:left 11109/11700\n",
      "tensor([ 0.1986, -0.2232])\n",
      "pre:left true:left 11110/11700\n",
      "tensor([ 1.2117, -1.2198])\n",
      "pre:left true:left 11111/11700\n",
      "tensor([ 0.6132, -0.6811])\n",
      "pre:left true:left 11112/11700\n",
      "tensor([ 0.2555, -0.2071])\n",
      "pre:left true:left 11113/11700\n",
      "tensor([0.0261, 0.0091])\n",
      "pre:left true:left 11114/11700\n",
      "tensor([ 0.3924, -0.3202])\n",
      "pre:left true:left 11115/11700\n",
      "tensor([-0.0576,  0.0431])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1407_0_1563_20200412_120929273_8.jpg\n",
      "pre:right true:left 11116/11700\n",
      "tensor([ 0.3306, -0.3072])\n",
      "pre:left true:left 11117/11700\n",
      "tensor([-0.1665,  0.1530])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左703_0_859_20200412_115411771.jpg\n",
      "pre:right true:left 11118/11700\n",
      "tensor([ 0.2299, -0.1541])\n",
      "pre:left true:left 11119/11700\n",
      "tensor([ 0.8715, -0.7851])\n",
      "pre:left true:left 11120/11700\n",
      "tensor([ 1.4483, -1.4112])\n",
      "pre:left true:left 11121/11700\n",
      "tensor([ 0.4090, -0.4525])\n",
      "pre:left true:left 11122/11700\n",
      "tensor([ 0.0780, -0.1256])\n",
      "pre:left true:left 11123/11700\n",
      "tensor([ 0.7377, -0.7738])\n",
      "pre:left true:left 11124/11700\n",
      "tensor([ 0.3478, -0.3414])\n",
      "pre:left true:left 11125/11700\n",
      "tensor([ 0.2403, -0.2337])\n",
      "pre:left true:left 11126/11700\n",
      "tensor([ 0.7737, -0.8406])\n",
      "pre:left true:left 11127/11700\n",
      "tensor([-0.5746,  0.4475])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左324_0_480_20200412_114557880_4.jpg\n",
      "pre:right true:left 11128/11700\n",
      "tensor([ 0.4395, -0.3877])\n",
      "pre:left true:left 11129/11700\n",
      "tensor([ 0.5677, -0.6376])\n",
      "pre:left true:left 11130/11700\n",
      "tensor([ 0.5165, -0.4985])\n",
      "pre:left true:left 11131/11700\n",
      "tensor([ 0.7924, -0.7916])\n",
      "pre:left true:left 11132/11700\n",
      "tensor([ 0.6058, -0.6079])\n",
      "pre:left true:left 11133/11700\n",
      "tensor([ 0.8552, -0.8239])\n",
      "pre:left true:left 11134/11700\n",
      "tensor([ 0.5219, -0.5868])\n",
      "pre:left true:left 11135/11700\n",
      "tensor([ 0.5519, -0.4857])\n",
      "pre:left true:left 11136/11700\n",
      "tensor([ 0.7311, -0.7811])\n",
      "pre:left true:left 11137/11700\n",
      "tensor([ 0.7841, -0.6996])\n",
      "pre:left true:left 11138/11700\n",
      "tensor([ 0.5919, -0.5857])\n",
      "pre:left true:left 11139/11700\n",
      "tensor([ 0.3367, -0.2662])\n",
      "pre:left true:left 11140/11700\n",
      "tensor([ 0.7573, -0.6175])\n",
      "pre:left true:left 11141/11700\n",
      "tensor([-0.2500,  0.3447])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左675_0_675_20200412_111251560_9.jpg\n",
      "pre:right true:left 11142/11700\n",
      "tensor([-0.2809,  0.3395])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1433_0_1589_20200412_121003157_6.jpg\n",
      "pre:right true:left 11143/11700\n",
      "tensor([ 0.2388, -0.2231])\n",
      "pre:left true:left 11144/11700\n",
      "tensor([ 0.3301, -0.2322])\n",
      "pre:left true:left 11145/11700\n",
      "tensor([ 0.9847, -0.9528])\n",
      "pre:left true:left 11146/11700\n",
      "tensor([ 1.3684, -1.3650])\n",
      "pre:left true:left 11147/11700\n",
      "tensor([ 0.5057, -0.5537])\n",
      "pre:left true:left 11148/11700\n",
      "tensor([ 1.1192, -1.1160])\n",
      "pre:left true:left 11149/11700\n",
      "tensor([ 0.5213, -0.4893])\n",
      "pre:left true:left 11150/11700\n",
      "tensor([-0.2244,  0.2158])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左430_0_586_20200412_114815979_3.jpg\n",
      "pre:right true:left 11151/11700\n",
      "tensor([ 0.4282, -0.4824])\n",
      "pre:left true:left 11152/11700\n",
      "tensor([ 0.3659, -0.3392])\n",
      "pre:left true:left 11153/11700\n",
      "tensor([ 0.6324, -0.6003])\n",
      "pre:left true:left 11154/11700\n",
      "tensor([ 0.7748, -0.6698])\n",
      "pre:left true:left 11155/11700\n",
      "tensor([ 1.4124, -1.4781])\n",
      "pre:left true:left 11156/11700\n",
      "tensor([ 0.3541, -0.2205])\n",
      "pre:left true:left 11157/11700\n",
      "tensor([ 0.5997, -0.5190])\n",
      "pre:left true:left 11158/11700\n",
      "tensor([-0.1736,  0.1029])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左351_0_507_20200412_114633054_4.jpg\n",
      "pre:right true:left 11159/11700\n",
      "tensor([ 0.5896, -0.4960])\n",
      "pre:left true:left 11160/11700\n",
      "tensor([ 0.4905, -0.4896])\n",
      "pre:left true:left 11161/11700\n",
      "tensor([ 0.7234, -0.7890])\n",
      "pre:left true:left 11162/11700\n",
      "tensor([ 1.1988, -1.1661])\n",
      "pre:left true:left 11163/11700\n",
      "tensor([ 0.5179, -0.4924])\n",
      "pre:left true:left 11164/11700\n",
      "tensor([ 0.1724, -0.1840])\n",
      "pre:left true:left 11165/11700\n",
      "tensor([ 0.3514, -0.3243])\n",
      "pre:left true:left 11166/11700\n",
      "tensor([-0.0161,  0.1420])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左430_0_586_20200412_114815979_7.jpg\n",
      "pre:right true:left 11167/11700\n",
      "tensor([ 0.4461, -0.3786])\n",
      "pre:left true:left 11168/11700\n",
      "tensor([ 0.8798, -0.8845])\n",
      "pre:left true:left 11169/11700\n",
      "tensor([ 0.7145, -0.6852])\n",
      "pre:left true:left 11170/11700\n",
      "tensor([-0.2701,  0.2785])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左725_0_881_20200412_115440452_1.jpg\n",
      "pre:right true:left 11171/11700\n",
      "tensor([-0.4364,  0.5047])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左697_0_853_20200412_115403965_6.jpg\n",
      "pre:right true:left 11172/11700\n",
      "tensor([ 0.1480, -0.0421])\n",
      "pre:left true:left 11173/11700\n",
      "tensor([-0.5449,  0.5271])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1229_0_1229_20200412_112523087_0.jpg\n",
      "pre:right true:left 11174/11700\n",
      "tensor([ 1.2850, -1.2881])\n",
      "pre:left true:left 11175/11700\n",
      "tensor([ 0.8438, -0.7976])\n",
      "pre:left true:left 11176/11700\n",
      "tensor([ 0.5587, -0.5480])\n",
      "pre:left true:left 11177/11700\n",
      "tensor([ 0.6300, -0.5832])\n",
      "pre:left true:left 11178/11700\n",
      "tensor([ 0.6223, -0.5825])\n",
      "pre:left true:left 11179/11700\n",
      "tensor([ 0.2288, -0.1631])\n",
      "pre:left true:left 11180/11700\n",
      "tensor([ 0.1488, -0.1144])\n",
      "pre:left true:left 11181/11700\n",
      "tensor([ 1.2139, -1.1767])\n",
      "pre:left true:left 11182/11700\n",
      "tensor([ 1.1255, -1.1813])\n",
      "pre:left true:left 11183/11700\n",
      "tensor([ 0.7959, -0.7468])\n",
      "pre:left true:left 11184/11700\n",
      "tensor([ 0.5997, -0.5190])\n",
      "pre:left true:left 11185/11700\n",
      "tensor([ 0.9132, -0.8825])\n",
      "pre:left true:left 11186/11700\n",
      "tensor([ 0.6572, -0.6672])\n",
      "pre:left true:left 11187/11700\n",
      "tensor([ 1.1221, -1.0513])\n",
      "pre:left true:left 11188/11700\n",
      "tensor([ 1.0955, -1.0501])\n",
      "pre:left true:left 11189/11700\n",
      "tensor([ 0.2459, -0.2230])\n",
      "pre:left true:left 11190/11700\n",
      "tensor([ 1.0090, -1.0034])\n",
      "pre:left true:left 11191/11700\n",
      "tensor([ 0.4811, -0.3998])\n",
      "pre:left true:left 11192/11700\n",
      "tensor([ 0.5627, -0.5653])\n",
      "pre:left true:left 11193/11700\n",
      "tensor([ 0.7716, -0.7435])\n",
      "pre:left true:left 11194/11700\n",
      "tensor([ 1.0517, -1.0853])\n",
      "pre:left true:left 11195/11700\n",
      "tensor([0.0657, 0.0133])\n",
      "pre:left true:left 11196/11700\n",
      "tensor([ 0.6766, -0.6826])\n",
      "pre:left true:left 11197/11700\n",
      "tensor([ 0.6757, -0.5733])\n",
      "pre:left true:left 11198/11700\n",
      "tensor([ 0.3425, -0.3066])\n",
      "pre:left true:left 11199/11700\n",
      "tensor([ 0.0901, -0.0592])\n",
      "pre:left true:left 11200/11700\n",
      "tensor([ 0.3313, -0.2147])\n",
      "pre:left true:left 11201/11700\n",
      "tensor([ 0.3105, -0.2070])\n",
      "pre:left true:left 11202/11700\n",
      "tensor([ 1.2008, -1.2605])\n",
      "pre:left true:left 11203/11700\n",
      "tensor([ 0.1893, -0.0331])\n",
      "pre:left true:left 11204/11700\n",
      "tensor([ 1.0608, -0.9324])\n",
      "pre:left true:left 11205/11700\n",
      "tensor([ 0.5132, -0.5315])\n",
      "pre:left true:left 11206/11700\n",
      "tensor([ 0.5657, -0.5950])\n",
      "pre:left true:left 11207/11700\n",
      "tensor([ 0.0875, -0.0568])\n",
      "pre:left true:left 11208/11700\n",
      "tensor([ 0.2740, -0.3276])\n",
      "pre:left true:left 11209/11700\n",
      "tensor([ 0.7170, -0.7014])\n",
      "pre:left true:left 11210/11700\n",
      "tensor([ 0.6347, -0.7158])\n",
      "pre:left true:left 11211/11700\n",
      "tensor([ 0.6659, -0.6232])\n",
      "pre:left true:left 11212/11700\n",
      "tensor([ 0.3427, -0.3038])\n",
      "pre:left true:left 11213/11700\n",
      "tensor([ 0.1105, -0.0447])\n",
      "pre:left true:left 11214/11700\n",
      "tensor([ 1.3268, -1.2351])\n",
      "pre:left true:left 11215/11700\n",
      "tensor([ 0.0531, -0.1581])\n",
      "pre:left true:left 11216/11700\n",
      "tensor([ 0.2093, -0.2968])\n",
      "pre:left true:left 11217/11700\n",
      "tensor([ 1.1776, -1.1402])\n",
      "pre:left true:left 11218/11700\n",
      "tensor([ 0.9018, -0.8565])\n",
      "pre:left true:left 11219/11700\n",
      "tensor([ 0.1643, -0.0873])\n",
      "pre:left true:left 11220/11700\n",
      "tensor([ 0.5522, -0.5869])\n",
      "pre:left true:left 11221/11700\n",
      "tensor([ 0.8671, -0.9102])\n",
      "pre:left true:left 11222/11700\n",
      "tensor([ 0.4768, -0.5382])\n",
      "pre:left true:left 11223/11700\n",
      "tensor([ 1.1067, -1.1161])\n",
      "pre:left true:left 11224/11700\n",
      "tensor([ 1.0217, -1.1292])\n",
      "pre:left true:left 11225/11700\n",
      "tensor([ 0.8332, -0.9184])\n",
      "pre:left true:left 11226/11700\n",
      "tensor([ 0.0539, -0.1113])\n",
      "pre:left true:left 11227/11700\n",
      "tensor([-0.0322,  0.0949])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左628_0_784_20200412_115234036_1.jpg\n",
      "pre:right true:left 11228/11700\n",
      "tensor([ 0.1747, -0.1582])\n",
      "pre:left true:left 11229/11700\n",
      "tensor([ 0.7925, -0.8648])\n",
      "pre:left true:left 11230/11700\n",
      "tensor([ 0.7098, -0.6904])\n",
      "pre:left true:left 11231/11700\n",
      "tensor([-0.0279,  0.0157])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左625_0_781_20200412_115230120_4.jpg\n",
      "pre:right true:left 11232/11700\n",
      "tensor([ 0.3494, -0.3463])\n",
      "pre:left true:left 11233/11700\n",
      "tensor([ 0.5307, -0.5450])\n",
      "pre:left true:left 11234/11700\n",
      "tensor([ 0.7503, -0.6464])\n",
      "pre:left true:left 11235/11700\n",
      "tensor([ 0.1442, -0.0847])\n",
      "pre:left true:left 11236/11700\n",
      "tensor([ 0.6942, -0.6892])\n",
      "pre:left true:left 11237/11700\n",
      "tensor([ 0.8908, -0.8452])\n",
      "pre:left true:left 11238/11700\n",
      "tensor([ 0.5470, -0.5786])\n",
      "pre:left true:left 11239/11700\n",
      "tensor([ 0.0943, -0.0364])\n",
      "pre:left true:left 11240/11700\n",
      "tensor([ 0.8909, -0.8359])\n",
      "pre:left true:left 11241/11700\n",
      "tensor([ 1.1418, -1.1345])\n",
      "pre:left true:left 11242/11700\n",
      "tensor([ 1.5640, -1.5860])\n",
      "pre:left true:left 11243/11700\n",
      "tensor([ 1.2173, -1.1845])\n",
      "pre:left true:left 11244/11700\n",
      "tensor([ 0.7193, -0.7439])\n",
      "pre:left true:left 11245/11700\n",
      "tensor([ 1.1093, -1.0976])\n",
      "pre:left true:left 11246/11700\n",
      "tensor([ 0.7283, -0.7315])\n",
      "pre:left true:left 11247/11700\n",
      "tensor([-0.7871,  0.8106])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左431_0_587_20200412_114817293_8.jpg\n",
      "pre:right true:left 11248/11700\n",
      "tensor([ 0.2018, -0.1285])\n",
      "pre:left true:left 11249/11700\n",
      "tensor([ 0.9818, -1.0469])\n",
      "pre:left true:left 11250/11700\n",
      "tensor([ 0.0877, -0.1122])\n",
      "pre:left true:left 11251/11700\n",
      "tensor([ 0.6252, -0.6437])\n",
      "pre:left true:left 11252/11700\n",
      "tensor([ 1.7701, -1.7103])\n",
      "pre:left true:left 11253/11700\n",
      "tensor([ 1.0614, -0.9947])\n",
      "pre:left true:left 11254/11700\n",
      "tensor([ 1.4212, -1.3302])\n",
      "pre:left true:left 11255/11700\n",
      "tensor([ 0.8659, -0.8386])\n",
      "pre:left true:left 11256/11700\n",
      "tensor([ 0.4731, -0.4916])\n",
      "pre:left true:left 11257/11700\n",
      "tensor([ 0.7151, -0.6136])\n",
      "pre:left true:left 11258/11700\n",
      "tensor([ 0.0355, -0.0976])\n",
      "pre:left true:left 11259/11700\n",
      "tensor([ 0.1804, -0.1950])\n",
      "pre:left true:left 11260/11700\n",
      "tensor([ 0.7644, -0.7908])\n",
      "pre:left true:left 11261/11700\n",
      "tensor([ 0.7942, -0.7854])\n",
      "pre:left true:left 11262/11700\n",
      "tensor([ 0.9968, -0.9882])\n",
      "pre:left true:left 11263/11700\n",
      "tensor([ 0.8231, -0.7680])\n",
      "pre:left true:left 11264/11700\n",
      "tensor([ 0.2351, -0.2013])\n",
      "pre:left true:left 11265/11700\n",
      "tensor([ 0.6850, -0.6237])\n",
      "pre:left true:left 11266/11700\n",
      "tensor([ 0.8703, -0.8685])\n",
      "pre:left true:left 11267/11700\n",
      "tensor([ 0.7984, -0.8047])\n",
      "pre:left true:left 11268/11700\n",
      "tensor([ 0.4943, -0.4480])\n",
      "pre:left true:left 11269/11700\n",
      "tensor([ 0.7582, -0.7507])\n",
      "pre:left true:left 11270/11700\n",
      "tensor([ 1.1866, -1.0913])\n",
      "pre:left true:left 11271/11700\n",
      "tensor([ 0.4970, -0.5144])\n",
      "pre:left true:left 11272/11700\n",
      "tensor([ 0.1710, -0.1663])\n",
      "pre:left true:left 11273/11700\n",
      "tensor([ 0.4325, -0.4520])\n",
      "pre:left true:left 11274/11700\n",
      "tensor([ 0.0983, -0.0448])\n",
      "pre:left true:left 11275/11700\n",
      "tensor([ 0.4874, -0.4849])\n",
      "pre:left true:left 11276/11700\n",
      "tensor([0.0587, 0.0086])\n",
      "pre:left true:left 11277/11700\n",
      "tensor([ 1.1051, -1.1179])\n",
      "pre:left true:left 11278/11700\n",
      "tensor([ 0.9395, -0.9056])\n",
      "pre:left true:left 11279/11700\n",
      "tensor([ 0.3497, -0.3201])\n",
      "pre:left true:left 11280/11700\n",
      "tensor([ 0.9438, -0.9216])\n",
      "pre:left true:left 11281/11700\n",
      "tensor([ 0.2941, -0.2051])\n",
      "pre:left true:left 11282/11700\n",
      "tensor([ 0.5199, -0.5354])\n",
      "pre:left true:left 11283/11700\n",
      "tensor([ 0.4359, -0.4054])\n",
      "pre:left true:left 11284/11700\n",
      "tensor([ 0.2853, -0.3450])\n",
      "pre:left true:left 11285/11700\n",
      "tensor([ 0.6249, -0.7021])\n",
      "pre:left true:left 11286/11700\n",
      "tensor([-0.5653,  0.5031])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左446_0_602_20200412_114836836_0.jpg\n",
      "pre:right true:left 11287/11700\n",
      "tensor([ 0.2163, -0.2035])\n",
      "pre:left true:left 11288/11700\n",
      "tensor([-0.2908,  0.2923])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左755_0_911_20200412_115519560_4.jpg\n",
      "pre:right true:left 11289/11700\n",
      "tensor([ 1.0495, -1.0583])\n",
      "pre:left true:left 11290/11700\n",
      "tensor([ 0.7200, -0.6670])\n",
      "pre:left true:left 11291/11700\n",
      "tensor([ 0.9534, -0.9593])\n",
      "pre:left true:left 11292/11700\n",
      "tensor([-0.5945,  0.5958])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左193_0_193_20200412_110124081_3.jpg\n",
      "pre:right true:left 11293/11700\n",
      "tensor([ 0.2954, -0.2559])\n",
      "pre:left true:left 11294/11700\n",
      "tensor([ 0.2832, -0.0609])\n",
      "pre:left true:left 11295/11700\n",
      "tensor([ 0.7635, -0.5817])\n",
      "pre:left true:left 11296/11700\n",
      "tensor([ 0.9876, -1.0505])\n",
      "pre:left true:left 11297/11700\n",
      "tensor([ 0.7507, -0.6865])\n",
      "pre:left true:left 11298/11700\n",
      "tensor([-0.0423, -0.0039])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1599_0_1755_20200412_121339559_3.jpg\n",
      "pre:right true:left 11299/11700\n",
      "tensor([ 1.3312, -1.3684])\n",
      "pre:left true:left 11300/11700\n",
      "tensor([ 0.5795, -0.6182])\n",
      "pre:left true:left 11301/11700\n",
      "tensor([ 0.4821, -0.3499])\n",
      "pre:left true:left 11302/11700\n",
      "tensor([ 0.3942, -0.3518])\n",
      "pre:left true:left 11303/11700\n",
      "tensor([ 0.3299, -0.2822])\n",
      "pre:left true:left 11304/11700\n",
      "tensor([ 0.4829, -0.4023])\n",
      "pre:left true:left 11305/11700\n",
      "tensor([ 1.3960, -1.4319])\n",
      "pre:left true:left 11306/11700\n",
      "tensor([ 1.6985, -1.6516])\n",
      "pre:left true:left 11307/11700\n",
      "tensor([0.0361, 0.0220])\n",
      "pre:left true:left 11308/11700\n",
      "tensor([ 1.1177, -1.0847])\n",
      "pre:left true:left 11309/11700\n",
      "tensor([ 0.8594, -0.9573])\n",
      "pre:left true:left 11310/11700\n",
      "tensor([ 0.7190, -0.7340])\n",
      "pre:left true:left 11311/11700\n",
      "tensor([ 0.2888, -0.2261])\n",
      "pre:left true:left 11312/11700\n",
      "tensor([0.0174, 0.0106])\n",
      "pre:left true:left 11313/11700\n",
      "tensor([ 0.6719, -0.6002])\n",
      "pre:left true:left 11314/11700\n",
      "tensor([-0.0445,  0.0664])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左843_0_843_20200412_111651177.jpg\n",
      "pre:right true:left 11315/11700\n",
      "tensor([ 0.1284, -0.1126])\n",
      "pre:left true:left 11316/11700\n",
      "tensor([ 0.2180, -0.1686])\n",
      "pre:left true:left 11317/11700\n",
      "tensor([ 0.1878, -0.2044])\n",
      "pre:left true:left 11318/11700\n",
      "tensor([ 0.1811, -0.1488])\n",
      "pre:left true:left 11319/11700\n",
      "tensor([ 1.3167, -1.3438])\n",
      "pre:left true:left 11320/11700\n",
      "tensor([ 0.1641, -0.1154])\n",
      "pre:left true:left 11321/11700\n",
      "tensor([-0.0419,  0.1207])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1200_0_1200_20200412_112445301_5.jpg\n",
      "pre:right true:left 11322/11700\n",
      "tensor([ 0.6997, -0.7438])\n",
      "pre:left true:left 11323/11700\n",
      "tensor([ 0.3347, -0.3624])\n",
      "pre:left true:left 11324/11700\n",
      "tensor([ 0.7056, -0.6966])\n",
      "pre:left true:left 11325/11700\n",
      "tensor([ 0.4496, -0.4236])\n",
      "pre:left true:left 11326/11700\n",
      "tensor([ 0.0832, -0.0923])\n",
      "pre:left true:left 11327/11700\n",
      "tensor([ 0.8803, -0.8424])\n",
      "pre:left true:left 11328/11700\n",
      "tensor([ 0.5539, -0.5982])\n",
      "pre:left true:left 11329/11700\n",
      "tensor([ 0.9958, -1.0050])\n",
      "pre:left true:left 11330/11700\n",
      "tensor([-0.0713,  0.0942])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左453_0_609_20200412_114845959_5.jpg\n",
      "pre:right true:left 11331/11700\n",
      "tensor([ 0.6340, -0.5067])\n",
      "pre:left true:left 11332/11700\n",
      "tensor([ 1.1719, -1.2155])\n",
      "pre:left true:left 11333/11700\n",
      "tensor([ 0.1406, -0.0043])\n",
      "pre:left true:left 11334/11700\n",
      "tensor([ 0.5977, -0.5361])\n",
      "pre:left true:left 11335/11700\n",
      "tensor([ 0.3058, -0.3869])\n",
      "pre:left true:left 11336/11700\n",
      "tensor([ 1.0771, -1.0670])\n",
      "pre:left true:left 11337/11700\n",
      "tensor([ 0.7375, -0.6509])\n",
      "pre:left true:left 11338/11700\n",
      "tensor([ 0.6331, -0.5672])\n",
      "pre:left true:left 11339/11700\n",
      "tensor([ 0.8754, -0.9176])\n",
      "pre:left true:left 11340/11700\n",
      "tensor([ 0.2789, -0.3117])\n",
      "pre:left true:left 11341/11700\n",
      "tensor([0.1060, 0.0051])\n",
      "pre:left true:left 11342/11700\n",
      "tensor([ 0.6823, -0.7519])\n",
      "pre:left true:left 11343/11700\n",
      "tensor([ 0.9388, -0.9814])\n",
      "pre:left true:left 11344/11700\n",
      "tensor([ 0.0915, -0.2038])\n",
      "pre:left true:left 11345/11700\n",
      "tensor([ 0.4462, -0.4757])\n",
      "pre:left true:left 11346/11700\n",
      "tensor([ 0.6134, -0.6208])\n",
      "pre:left true:left 11347/11700\n",
      "tensor([ 0.7038, -0.5441])\n",
      "pre:left true:left 11348/11700\n",
      "tensor([ 0.5625, -0.4856])\n",
      "pre:left true:left 11349/11700\n",
      "tensor([ 0.6479, -0.3682])\n",
      "pre:left true:left 11350/11700\n",
      "tensor([ 0.4027, -0.3647])\n",
      "pre:left true:left 11351/11700\n",
      "tensor([ 0.5866, -0.4245])\n",
      "pre:left true:left 11352/11700\n",
      "tensor([ 0.4789, -0.3992])\n",
      "pre:left true:left 11353/11700\n",
      "tensor([ 0.4570, -0.4906])\n",
      "pre:left true:left 11354/11700\n",
      "tensor([ 1.0684, -1.0273])\n",
      "pre:left true:left 11355/11700\n",
      "tensor([ 0.6582, -0.6347])\n",
      "pre:left true:left 11356/11700\n",
      "tensor([ 0.8861, -0.7892])\n",
      "pre:left true:left 11357/11700\n",
      "tensor([-0.1302,  0.1618])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左657_0_657_20200412_111225902_7.jpg\n",
      "pre:right true:left 11358/11700\n",
      "tensor([-0.7370,  0.8504])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左808_0_964_20200412_115628626_9.jpg\n",
      "pre:right true:left 11359/11700\n",
      "tensor([ 0.3628, -0.2728])\n",
      "pre:left true:left 11360/11700\n",
      "tensor([ 0.5685, -0.5570])\n",
      "pre:left true:left 11361/11700\n",
      "tensor([ 0.8137, -0.7521])\n",
      "pre:left true:left 11362/11700\n",
      "tensor([ 0.6378, -0.7562])\n",
      "pre:left true:left 11363/11700\n",
      "tensor([ 0.3355, -0.4059])\n",
      "pre:left true:left 11364/11700\n",
      "tensor([ 0.0318, -0.0223])\n",
      "pre:left true:left 11365/11700\n",
      "tensor([ 0.3284, -0.2208])\n",
      "pre:left true:left 11366/11700\n",
      "tensor([ 0.3438, -0.2977])\n",
      "pre:left true:left 11367/11700\n",
      "tensor([ 0.5392, -0.6040])\n",
      "pre:left true:left 11368/11700\n",
      "tensor([ 0.2106, -0.2816])\n",
      "pre:left true:left 11369/11700\n",
      "tensor([ 0.3056, -0.1025])\n",
      "pre:left true:left 11370/11700\n",
      "tensor([ 0.1838, -0.1611])\n",
      "pre:left true:left 11371/11700\n",
      "tensor([ 0.7562, -0.6683])\n",
      "pre:left true:left 11372/11700\n",
      "tensor([ 1.2379, -1.0701])\n",
      "pre:left true:left 11373/11700\n",
      "tensor([ 0.3626, -0.3741])\n",
      "pre:left true:left 11374/11700\n",
      "tensor([ 0.3538, -0.3407])\n",
      "pre:left true:left 11375/11700\n",
      "tensor([ 1.9630, -1.9327])\n",
      "pre:left true:left 11376/11700\n",
      "tensor([ 0.7194, -0.7767])\n",
      "pre:left true:left 11377/11700\n",
      "tensor([ 0.4566, -0.4881])\n",
      "pre:left true:left 11378/11700\n",
      "tensor([ 0.8652, -0.9196])\n",
      "pre:left true:left 11379/11700\n",
      "tensor([ 0.2158, -0.2322])\n",
      "pre:left true:left 11380/11700\n",
      "tensor([ 0.0688, -0.1011])\n",
      "pre:left true:left 11381/11700\n",
      "tensor([-0.1302,  0.1948])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左788_0_944_20200412_115602559_6.jpg\n",
      "pre:right true:left 11382/11700\n",
      "tensor([ 0.7477, -0.7663])\n",
      "pre:left true:left 11383/11700\n",
      "tensor([ 0.3910, -0.4325])\n",
      "pre:left true:left 11384/11700\n",
      "tensor([ 0.5550, -0.5513])\n",
      "pre:left true:left 11385/11700\n",
      "tensor([ 0.4275, -0.4385])\n",
      "pre:left true:left 11386/11700\n",
      "tensor([ 0.6883, -0.6885])\n",
      "pre:left true:left 11387/11700\n",
      "tensor([ 0.3766, -0.2454])\n",
      "pre:left true:left 11388/11700\n",
      "tensor([ 0.1066, -0.0714])\n",
      "pre:left true:left 11389/11700\n",
      "tensor([-0.0008, -0.0390])\n",
      "pre:left true:left 11390/11700\n",
      "tensor([ 0.5240, -0.4775])\n",
      "pre:left true:left 11391/11700\n",
      "tensor([-0.4507,  0.4685])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1260_0_1260_20200412_112603502_0.jpg\n",
      "pre:right true:left 11392/11700\n",
      "tensor([-0.1325,  0.0966])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左625_0_781_20200412_115230120_1.jpg\n",
      "pre:right true:left 11393/11700\n",
      "tensor([ 0.4257, -0.4672])\n",
      "pre:left true:left 11394/11700\n",
      "tensor([-0.0024, -0.0583])\n",
      "pre:left true:left 11395/11700\n",
      "tensor([ 0.5969, -0.5627])\n",
      "pre:left true:left 11396/11700\n",
      "tensor([ 1.6706, -1.6807])\n",
      "pre:left true:left 11397/11700\n",
      "tensor([ 0.1354, -0.1354])\n",
      "pre:left true:left 11398/11700\n",
      "tensor([ 0.6215, -0.5525])\n",
      "pre:left true:left 11399/11700\n",
      "tensor([ 0.1520, -0.2219])\n",
      "pre:left true:left 11400/11700\n",
      "tensor([-0.0306,  0.1722])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左485_0_641_20200412_114927678_7.jpg\n",
      "pre:right true:left 11401/11700\n",
      "tensor([-0.5369,  0.5468])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左667_0_823_20200412_115324859_8.jpg\n",
      "pre:right true:left 11402/11700\n",
      "tensor([ 0.5976, -0.6423])\n",
      "pre:left true:left 11403/11700\n",
      "tensor([ 0.2162, -0.2242])\n",
      "pre:left true:left 11404/11700\n",
      "tensor([ 0.9159, -0.9040])\n",
      "pre:left true:left 11405/11700\n",
      "tensor([ 0.7354, -0.7283])\n",
      "pre:left true:left 11406/11700\n",
      "tensor([ 0.7243, -0.7296])\n",
      "pre:left true:left 11407/11700\n",
      "tensor([ 0.4987, -0.5003])\n",
      "pre:left true:left 11408/11700\n",
      "tensor([ 1.7162, -1.7175])\n",
      "pre:left true:left 11409/11700\n",
      "tensor([ 0.5410, -0.5154])\n",
      "pre:left true:left 11410/11700\n",
      "tensor([ 0.5357, -0.5170])\n",
      "pre:left true:left 11411/11700\n",
      "tensor([ 0.7169, -0.6985])\n",
      "pre:left true:left 11412/11700\n",
      "tensor([ 0.7145, -0.5930])\n",
      "pre:left true:left 11413/11700\n",
      "tensor([-0.8178,  0.8686])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左657_0_813_20200412_115311824_6.jpg\n",
      "pre:right true:left 11414/11700\n",
      "tensor([ 1.0509, -0.9632])\n",
      "pre:left true:left 11415/11700\n",
      "tensor([ 0.3740, -0.3362])\n",
      "pre:left true:left 11416/11700\n",
      "tensor([ 1.2152, -1.2884])\n",
      "pre:left true:left 11417/11700\n",
      "tensor([ 0.7578, -0.7202])\n",
      "pre:left true:left 11418/11700\n",
      "tensor([-0.0914,  0.0605])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左280_0_280_20200412_110328165_10.jpg\n",
      "pre:right true:left 11419/11700\n",
      "tensor([ 0.7986, -0.7090])\n",
      "pre:left true:left 11420/11700\n",
      "tensor([ 0.2641, -0.2609])\n",
      "pre:left true:left 11421/11700\n",
      "tensor([ 0.3094, -0.2849])\n",
      "pre:left true:left 11422/11700\n",
      "tensor([ 0.4164, -0.3331])\n",
      "pre:left true:left 11423/11700\n",
      "tensor([-0.3792,  0.3914])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左599_0_755_20200412_115156230_3.jpg\n",
      "pre:right true:left 11424/11700\n",
      "tensor([0.0040, 0.0153])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左617_0_773_20200412_115219705_10.jpg\n",
      "pre:right true:left 11425/11700\n",
      "tensor([0.0297, 0.0293])\n",
      "pre:left true:left 11426/11700\n",
      "tensor([ 1.0646, -1.0176])\n",
      "pre:left true:left 11427/11700\n",
      "tensor([ 0.4164, -0.4257])\n",
      "pre:left true:left 11428/11700\n",
      "tensor([ 1.4230, -1.4752])\n",
      "pre:left true:left 11429/11700\n",
      "tensor([ 0.4369, -0.3832])\n",
      "pre:left true:left 11430/11700\n",
      "tensor([ 0.5368, -0.6080])\n",
      "pre:left true:left 11431/11700\n",
      "tensor([ 0.2564, -0.2417])\n",
      "pre:left true:left 11432/11700\n",
      "tensor([ 0.0669, -0.1104])\n",
      "pre:left true:left 11433/11700\n",
      "tensor([ 0.8171, -0.8029])\n",
      "pre:left true:left 11434/11700\n",
      "tensor([ 0.9081, -0.8574])\n",
      "pre:left true:left 11435/11700\n",
      "tensor([ 0.4137, -0.4502])\n",
      "pre:left true:left 11436/11700\n",
      "tensor([ 0.1021, -0.1078])\n",
      "pre:left true:left 11437/11700\n",
      "tensor([ 0.8861, -0.8433])\n",
      "pre:left true:left 11438/11700\n",
      "tensor([ 1.0686, -1.0133])\n",
      "pre:left true:left 11439/11700\n",
      "tensor([-0.2525,  0.3231])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1314_0_1314_20200412_112713869_4.jpg\n",
      "pre:right true:left 11440/11700\n",
      "tensor([ 0.3826, -0.3907])\n",
      "pre:left true:left 11441/11700\n",
      "tensor([-0.0667,  0.1370])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左759_0_915_20200412_115524760.jpg\n",
      "pre:right true:left 11442/11700\n",
      "tensor([ 0.7396, -0.7982])\n",
      "pre:left true:left 11443/11700\n",
      "tensor([ 0.8674, -0.9212])\n",
      "pre:left true:left 11444/11700\n",
      "tensor([ 0.3850, -0.4184])\n",
      "pre:left true:left 11445/11700\n",
      "tensor([ 0.8408, -0.7838])\n",
      "pre:left true:left 11446/11700\n",
      "tensor([ 0.4425, -0.4954])\n",
      "pre:left true:left 11447/11700\n",
      "tensor([ 1.2707, -1.1735])\n",
      "pre:left true:left 11448/11700\n",
      "tensor([ 0.6285, -0.5766])\n",
      "pre:left true:left 11449/11700\n",
      "tensor([ 0.9936, -0.9799])\n",
      "pre:left true:left 11450/11700\n",
      "tensor([ 0.9022, -0.9435])\n",
      "pre:left true:left 11451/11700\n",
      "tensor([ 0.6159, -0.6709])\n",
      "pre:left true:left 11452/11700\n",
      "tensor([ 1.0200, -1.0186])\n",
      "pre:left true:left 11453/11700\n",
      "tensor([0.0903, 0.0229])\n",
      "pre:left true:left 11454/11700\n",
      "tensor([ 0.6909, -0.6756])\n",
      "pre:left true:left 11455/11700\n",
      "tensor([ 0.1992, -0.1700])\n",
      "pre:left true:left 11456/11700\n",
      "tensor([ 0.8917, -0.8966])\n",
      "pre:left true:left 11457/11700\n",
      "tensor([ 1.0495, -1.1605])\n",
      "pre:left true:left 11458/11700\n",
      "tensor([ 1.1007, -1.0496])\n",
      "pre:left true:left 11459/11700\n",
      "tensor([ 0.2890, -0.1780])\n",
      "pre:left true:left 11460/11700\n",
      "tensor([ 0.4056, -0.4878])\n",
      "pre:left true:left 11461/11700\n",
      "tensor([ 0.9107, -0.9522])\n",
      "pre:left true:left 11462/11700\n",
      "tensor([0.0311, 0.0493])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左454_0_610_20200412_114847282_9.jpg\n",
      "pre:right true:left 11463/11700\n",
      "tensor([ 0.5037, -0.5658])\n",
      "pre:left true:left 11464/11700\n",
      "tensor([ 0.7359, -0.7816])\n",
      "pre:left true:left 11465/11700\n",
      "tensor([-0.0666, -0.0317])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左244_0_244_20200412_110236813_10.jpg\n",
      "pre:right true:left 11466/11700\n",
      "tensor([ 0.6592, -0.6120])\n",
      "pre:left true:left 11467/11700\n",
      "tensor([ 0.4003, -0.3307])\n",
      "pre:left true:left 11468/11700\n",
      "tensor([ 0.2631, -0.1796])\n",
      "pre:left true:left 11469/11700\n",
      "tensor([-0.2242,  0.2878])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左316_0_316_20200412_110419502_2.jpg\n",
      "pre:right true:left 11470/11700\n",
      "tensor([ 0.7131, -0.7537])\n",
      "pre:left true:left 11471/11700\n",
      "tensor([ 0.2510, -0.2430])\n",
      "pre:left true:left 11472/11700\n",
      "tensor([ 0.7410, -0.6984])\n",
      "pre:left true:left 11473/11700\n",
      "tensor([ 1.1107, -1.1092])\n",
      "pre:left true:left 11474/11700\n",
      "tensor([ 1.0660, -1.1083])\n",
      "pre:left true:left 11475/11700\n",
      "tensor([ 1.2680, -1.2093])\n",
      "pre:left true:left 11476/11700\n",
      "tensor([ 1.2751, -1.0527])\n",
      "pre:left true:left 11477/11700\n",
      "tensor([ 0.5642, -0.5787])\n",
      "pre:left true:left 11478/11700\n",
      "tensor([-0.1423,  0.1366])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1146_0_1146_20200412_112334945_3.jpg\n",
      "pre:right true:left 11479/11700\n",
      "tensor([ 0.6489, -0.6509])\n",
      "pre:left true:left 11480/11700\n",
      "tensor([ 1.7493, -1.7493])\n",
      "pre:left true:left 11481/11700\n",
      "tensor([ 1.0890, -1.0149])\n",
      "pre:left true:left 11482/11700\n",
      "tensor([ 0.7858, -0.8152])\n",
      "pre:left true:left 11483/11700\n",
      "tensor([ 0.2542, -0.2402])\n",
      "pre:left true:left 11484/11700\n",
      "tensor([ 0.9874, -0.9347])\n",
      "pre:left true:left 11485/11700\n",
      "tensor([ 0.0106, -0.0141])\n",
      "pre:left true:left 11486/11700\n",
      "tensor([ 0.9204, -0.8985])\n",
      "pre:left true:left 11487/11700\n",
      "tensor([ 0.7105, -0.7356])\n",
      "pre:left true:left 11488/11700\n",
      "tensor([ 0.7225, -0.6969])\n",
      "pre:left true:left 11489/11700\n",
      "tensor([ 1.3131, -1.3518])\n",
      "pre:left true:left 11490/11700\n",
      "tensor([ 1.0708, -1.0993])\n",
      "pre:left true:left 11491/11700\n",
      "tensor([ 0.0347, -0.0610])\n",
      "pre:left true:left 11492/11700\n",
      "tensor([ 0.9723, -0.9645])\n",
      "pre:left true:left 11493/11700\n",
      "tensor([-0.3342,  0.5019])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左643_0_799_20200412_115253573_10.jpg\n",
      "pre:right true:left 11494/11700\n",
      "tensor([ 0.5037, -0.5658])\n",
      "pre:left true:left 11495/11700\n",
      "tensor([ 0.4900, -0.4385])\n",
      "pre:left true:left 11496/11700\n",
      "tensor([-0.1970,  0.2386])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左798_0_954_20200412_115615583_3.jpg\n",
      "pre:right true:left 11497/11700\n",
      "tensor([ 0.4561, -0.4430])\n",
      "pre:left true:left 11498/11700\n",
      "tensor([ 0.2605, -0.1985])\n",
      "pre:left true:left 11499/11700\n",
      "tensor([ 0.0498, -0.0247])\n",
      "pre:left true:left 11500/11700\n",
      "tensor([ 0.1563, -0.1263])\n",
      "pre:left true:left 11501/11700\n",
      "tensor([ 0.3276, -0.2792])\n",
      "pre:left true:left 11502/11700\n",
      "tensor([ 0.6362, -0.6464])\n",
      "pre:left true:left 11503/11700\n",
      "tensor([ 0.4173, -0.3736])\n",
      "pre:left true:left 11504/11700\n",
      "tensor([ 0.3489, -0.2728])\n",
      "pre:left true:left 11505/11700\n",
      "tensor([ 0.1475, -0.0960])\n",
      "pre:left true:left 11506/11700\n",
      "tensor([ 1.2744, -1.2479])\n",
      "pre:left true:left 11507/11700\n",
      "tensor([ 0.7096, -0.6980])\n",
      "pre:left true:left 11508/11700\n",
      "tensor([ 0.4670, -0.4496])\n",
      "pre:left true:left 11509/11700\n",
      "tensor([ 1.0917, -0.9935])\n",
      "pre:left true:left 11510/11700\n",
      "tensor([ 0.5151, -0.4650])\n",
      "pre:left true:left 11511/11700\n",
      "tensor([ 0.8314, -0.7739])\n",
      "pre:left true:left 11512/11700\n",
      "tensor([-0.1599,  0.1897])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1440_0_1596_20200412_121012283_7.jpg\n",
      "pre:right true:left 11513/11700\n",
      "tensor([ 0.2191, -0.2399])\n",
      "pre:left true:left 11514/11700\n",
      "tensor([-0.2353,  0.3027])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1362_0_1518_20200412_120830617_1.jpg\n",
      "pre:right true:left 11515/11700\n",
      "tensor([ 0.5497, -0.4504])\n",
      "pre:left true:left 11516/11700\n",
      "tensor([ 0.4270, -0.2943])\n",
      "pre:left true:left 11517/11700\n",
      "tensor([ 0.7063, -0.6966])\n",
      "pre:left true:left 11518/11700\n",
      "tensor([ 0.6030, -0.5469])\n",
      "pre:left true:left 11519/11700\n",
      "tensor([ 0.9447, -0.8925])\n",
      "pre:left true:left 11520/11700\n",
      "tensor([ 0.4250, -0.4211])\n",
      "pre:left true:left 11521/11700\n",
      "tensor([ 0.9414, -1.0094])\n",
      "pre:left true:left 11522/11700\n",
      "tensor([ 0.1903, -0.2296])\n",
      "pre:left true:left 11523/11700\n",
      "tensor([ 0.5493, -0.6252])\n",
      "pre:left true:left 11524/11700\n",
      "tensor([ 0.6752, -0.6157])\n",
      "pre:left true:left 11525/11700\n",
      "tensor([ 0.7526, -0.7594])\n",
      "pre:left true:left 11526/11700\n",
      "tensor([ 0.5063, -0.5166])\n",
      "pre:left true:left 11527/11700\n",
      "tensor([ 1.5957, -1.6448])\n",
      "pre:left true:left 11528/11700\n",
      "tensor([ 0.8846, -0.9026])\n",
      "pre:left true:left 11529/11700\n",
      "tensor([-0.8054,  0.6912])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左130_0_130_20200412_105954227_7.jpg\n",
      "pre:right true:left 11530/11700\n",
      "tensor([ 0.9715, -0.9436])\n",
      "pre:left true:left 11531/11700\n",
      "tensor([ 0.6089, -0.6793])\n",
      "pre:left true:left 11532/11700\n",
      "tensor([0.0805, 0.0236])\n",
      "pre:left true:left 11533/11700\n",
      "tensor([ 1.0662, -1.0302])\n",
      "pre:left true:left 11534/11700\n",
      "tensor([ 1.0048, -0.8531])\n",
      "pre:left true:left 11535/11700\n",
      "tensor([ 0.9495, -0.8034])\n",
      "pre:left true:left 11536/11700\n",
      "tensor([-0.2955,  0.2093])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左954_0_954_20200412_111924786_2.jpg\n",
      "pre:right true:left 11537/11700\n",
      "tensor([ 0.7639, -0.7166])\n",
      "pre:left true:left 11538/11700\n",
      "tensor([ 0.7029, -0.7539])\n",
      "pre:left true:left 11539/11700\n",
      "tensor([ 0.0752, -0.1308])\n",
      "pre:left true:left 11540/11700\n",
      "tensor([ 1.2159, -1.0715])\n",
      "pre:left true:left 11541/11700\n",
      "tensor([ 0.8353, -0.7848])\n",
      "pre:left true:left 11542/11700\n",
      "tensor([ 0.7334, -0.7292])\n",
      "pre:left true:left 11543/11700\n",
      "tensor([ 1.4302, -1.4160])\n",
      "pre:left true:left 11544/11700\n",
      "tensor([ 0.6849, -0.6542])\n",
      "pre:left true:left 11545/11700\n",
      "tensor([ 0.6252, -0.7005])\n",
      "pre:left true:left 11546/11700\n",
      "tensor([0.1029, 0.0034])\n",
      "pre:left true:left 11547/11700\n",
      "tensor([ 0.0773, -0.0379])\n",
      "pre:left true:left 11548/11700\n",
      "tensor([ 0.6195, -0.5221])\n",
      "pre:left true:left 11549/11700\n",
      "tensor([ 0.8154, -0.8361])\n",
      "pre:left true:left 11550/11700\n",
      "tensor([ 0.4849, -0.4342])\n",
      "pre:left true:left 11551/11700\n",
      "tensor([ 0.4899, -0.5108])\n",
      "pre:left true:left 11552/11700\n",
      "tensor([ 1.1130, -1.0899])\n",
      "pre:left true:left 11553/11700\n",
      "tensor([ 1.0319, -1.1195])\n",
      "pre:left true:left 11554/11700\n",
      "tensor([ 0.4472, -0.4768])\n",
      "pre:left true:left 11555/11700\n",
      "tensor([ 0.3242, -0.1996])\n",
      "pre:left true:left 11556/11700\n",
      "tensor([ 0.3172, -0.3720])\n",
      "pre:left true:left 11557/11700\n",
      "tensor([ 0.2692, -0.3124])\n",
      "pre:left true:left 11558/11700\n",
      "tensor([-0.1058,  0.1239])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1329_0_1485_20200412_120747629_8.jpg\n",
      "pre:right true:left 11559/11700\n",
      "tensor([ 0.7165, -0.7141])\n",
      "pre:left true:left 11560/11700\n",
      "tensor([-0.0217,  0.1665])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左432_0_432_20200412_110704949_4.jpg\n",
      "pre:right true:left 11561/11700\n",
      "tensor([ 1.0166, -1.0563])\n",
      "pre:left true:left 11562/11700\n",
      "tensor([ 0.8195, -0.8599])\n",
      "pre:left true:left 11563/11700\n",
      "tensor([ 0.2958, -0.2718])\n",
      "pre:left true:left 11564/11700\n",
      "tensor([ 0.1817, -0.0795])\n",
      "pre:left true:left 11565/11700\n",
      "tensor([ 0.6477, -0.6348])\n",
      "pre:left true:left 11566/11700\n",
      "tensor([ 0.5214, -0.4755])\n",
      "pre:left true:left 11567/11700\n",
      "tensor([-0.2392,  0.2746])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左591_0_747_20200412_115145811_9.jpg\n",
      "pre:right true:left 11568/11700\n",
      "tensor([ 0.6202, -0.5556])\n",
      "pre:left true:left 11569/11700\n",
      "tensor([ 0.3789, -0.3010])\n",
      "pre:left true:left 11570/11700\n",
      "tensor([ 0.3380, -0.2835])\n",
      "pre:left true:left 11571/11700\n",
      "tensor([ 0.3132, -0.2853])\n",
      "pre:left true:left 11572/11700\n",
      "tensor([0.0015, 0.0577])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左457_0_613_20200412_114851184_7.jpg\n",
      "pre:right true:left 11573/11700\n",
      "tensor([ 0.4342, -0.4764])\n",
      "pre:left true:left 11574/11700\n",
      "tensor([ 0.3493, -0.3341])\n",
      "pre:left true:left 11575/11700\n",
      "tensor([ 0.8372, -0.7548])\n",
      "pre:left true:left 11576/11700\n",
      "tensor([ 0.7460, -0.8256])\n",
      "pre:left true:left 11577/11700\n",
      "tensor([ 0.6285, -0.5758])\n",
      "pre:left true:left 11578/11700\n",
      "tensor([-0.1605,  0.2212])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左72_0_72_20200412_105831500_3.jpg\n",
      "pre:right true:left 11579/11700\n",
      "tensor([ 1.1001, -1.1412])\n",
      "pre:left true:left 11580/11700\n",
      "tensor([ 0.8523, -0.9005])\n",
      "pre:left true:left 11581/11700\n",
      "tensor([ 1.2599, -1.2841])\n",
      "pre:left true:left 11582/11700\n",
      "tensor([ 1.6632, -1.7359])\n",
      "pre:left true:left 11583/11700\n",
      "tensor([ 0.0636, -0.1124])\n",
      "pre:left true:left 11584/11700\n",
      "tensor([ 0.8279, -0.7974])\n",
      "pre:left true:left 11585/11700\n",
      "tensor([ 1.0744, -1.1355])\n",
      "pre:left true:left 11586/11700\n",
      "tensor([ 0.3626, -0.2702])\n",
      "pre:left true:left 11587/11700\n",
      "tensor([ 0.1504, -0.0904])\n",
      "pre:left true:left 11588/11700\n",
      "tensor([ 0.3259, -0.2512])\n",
      "pre:left true:left 11589/11700\n",
      "tensor([ 0.2090, -0.1682])\n",
      "pre:left true:left 11590/11700\n",
      "tensor([ 1.4047, -1.4147])\n",
      "pre:left true:left 11591/11700\n",
      "tensor([ 1.0482, -1.0203])\n",
      "pre:left true:left 11592/11700\n",
      "tensor([ 0.5479, -0.5601])\n",
      "pre:left true:left 11593/11700\n",
      "tensor([ 0.8099, -0.7818])\n",
      "pre:left true:left 11594/11700\n",
      "tensor([ 0.6271, -0.7107])\n",
      "pre:left true:left 11595/11700\n",
      "tensor([ 0.7894, -0.8247])\n",
      "pre:left true:left 11596/11700\n",
      "tensor([ 0.6154, -0.5598])\n",
      "pre:left true:left 11597/11700\n",
      "tensor([ 0.9181, -0.9703])\n",
      "pre:left true:left 11598/11700\n",
      "tensor([ 0.2809, -0.4315])\n",
      "pre:left true:left 11599/11700\n",
      "tensor([ 0.6639, -0.6842])\n",
      "pre:left true:left 11600/11700\n",
      "tensor([ 0.6691, -0.5603])\n",
      "pre:left true:left 11601/11700\n",
      "tensor([ 1.1890, -1.2395])\n",
      "pre:left true:left 11602/11700\n",
      "tensor([ 0.8679, -0.9033])\n",
      "pre:left true:left 11603/11700\n",
      "tensor([ 0.5996, -0.5079])\n",
      "pre:left true:left 11604/11700\n",
      "tensor([ 0.4005, -0.3909])\n",
      "pre:left true:left 11605/11700\n",
      "tensor([ 0.4864, -0.4339])\n",
      "pre:left true:left 11606/11700\n",
      "tensor([ 0.2423, -0.1955])\n",
      "pre:left true:left 11607/11700\n",
      "tensor([ 0.7105, -0.7683])\n",
      "pre:left true:left 11608/11700\n",
      "tensor([ 0.1311, -0.1129])\n",
      "pre:left true:left 11609/11700\n",
      "tensor([ 1.3755, -1.2725])\n",
      "pre:left true:left 11610/11700\n",
      "tensor([ 1.0856, -1.0507])\n",
      "pre:left true:left 11611/11700\n",
      "tensor([ 0.1547, -0.0342])\n",
      "pre:left true:left 11612/11700\n",
      "tensor([ 0.3852, -0.4207])\n",
      "pre:left true:left 11613/11700\n",
      "tensor([ 0.7850, -0.8203])\n",
      "pre:left true:left 11614/11700\n",
      "tensor([ 0.3425, -0.3066])\n",
      "pre:left true:left 11615/11700\n",
      "tensor([ 0.2935, -0.2965])\n",
      "pre:left true:left 11616/11700\n",
      "tensor([ 0.3624, -0.4384])\n",
      "pre:left true:left 11617/11700\n",
      "tensor([ 0.4737, -0.5604])\n",
      "pre:left true:left 11618/11700\n",
      "tensor([ 0.6564, -0.6920])\n",
      "pre:left true:left 11619/11700\n",
      "tensor([ 0.6719, -0.6495])\n",
      "pre:left true:left 11620/11700\n",
      "tensor([ 0.4947, -0.4957])\n",
      "pre:left true:left 11621/11700\n",
      "tensor([ 1.1590, -1.0280])\n",
      "pre:left true:left 11622/11700\n",
      "tensor([ 0.6684, -0.6598])\n",
      "pre:left true:left 11623/11700\n",
      "tensor([0.0018, 0.0727])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左257_0_257_20200412_110255351_8.jpg\n",
      "pre:right true:left 11624/11700\n",
      "tensor([ 0.8719, -0.8246])\n",
      "pre:left true:left 11625/11700\n",
      "tensor([ 0.4055, -0.3628])\n",
      "pre:left true:left 11626/11700\n",
      "tensor([ 1.1571, -1.2429])\n",
      "pre:left true:left 11627/11700\n",
      "tensor([ 0.6299, -0.5504])\n",
      "pre:left true:left 11628/11700\n",
      "tensor([ 0.4241, -0.3766])\n",
      "pre:left true:left 11629/11700\n",
      "tensor([ 0.2429, -0.2067])\n",
      "pre:left true:left 11630/11700\n",
      "tensor([ 1.1451, -1.1946])\n",
      "pre:left true:left 11631/11700\n",
      "tensor([-0.4325,  0.5048])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1134_0_1134_20200412_112319312_9.jpg\n",
      "pre:right true:left 11632/11700\n",
      "tensor([ 0.7672, -0.7766])\n",
      "pre:left true:left 11633/11700\n",
      "tensor([ 1.0466, -1.0317])\n",
      "pre:left true:left 11634/11700\n",
      "tensor([ 0.7745, -0.8330])\n",
      "pre:left true:left 11635/11700\n",
      "tensor([ 0.9174, -0.8238])\n",
      "pre:left true:left 11636/11700\n",
      "tensor([ 0.7150, -0.7317])\n",
      "pre:left true:left 11637/11700\n",
      "tensor([ 0.6240, -0.5166])\n",
      "pre:left true:left 11638/11700\n",
      "tensor([ 0.4754, -0.5227])\n",
      "pre:left true:left 11639/11700\n",
      "tensor([ 0.7291, -0.6981])\n",
      "pre:left true:left 11640/11700\n",
      "tensor([ 0.4051, -0.3602])\n",
      "pre:left true:left 11641/11700\n",
      "tensor([ 0.4129, -0.4017])\n",
      "pre:left true:left 11642/11700\n",
      "tensor([ 0.6666, -0.7181])\n",
      "pre:left true:left 11643/11700\n",
      "tensor([ 0.8337, -0.8181])\n",
      "pre:left true:left 11644/11700\n",
      "tensor([ 0.7135, -0.6943])\n",
      "pre:left true:left 11645/11700\n",
      "tensor([ 0.1234, -0.1321])\n",
      "pre:left true:left 11646/11700\n",
      "tensor([ 0.4089, -0.3481])\n",
      "pre:left true:left 11647/11700\n",
      "tensor([ 0.5705, -0.5019])\n",
      "pre:left true:left 11648/11700\n",
      "tensor([ 0.5561, -0.5564])\n",
      "pre:left true:left 11649/11700\n",
      "tensor([ 1.1178, -1.1819])\n",
      "pre:left true:left 11650/11700\n",
      "tensor([ 0.7320, -0.7082])\n",
      "pre:left true:left 11651/11700\n",
      "tensor([ 0.6380, -0.7287])\n",
      "pre:left true:left 11652/11700\n",
      "tensor([ 0.2393, -0.2962])\n",
      "pre:left true:left 11653/11700\n",
      "tensor([ 0.0659, -0.0496])\n",
      "pre:left true:left 11654/11700\n",
      "tensor([ 0.0584, -0.1569])\n",
      "pre:left true:left 11655/11700\n",
      "tensor([ 0.6985, -0.7928])\n",
      "pre:left true:left 11656/11700\n",
      "tensor([ 0.5619, -0.5907])\n",
      "pre:left true:left 11657/11700\n",
      "tensor([ 0.5248, -0.5255])\n",
      "pre:left true:left 11658/11700\n",
      "tensor([ 0.2090, -0.1855])\n",
      "pre:left true:left 11659/11700\n",
      "tensor([ 0.2052, -0.1953])\n",
      "pre:left true:left 11660/11700\n",
      "tensor([ 0.3271, -0.2494])\n",
      "pre:left true:left 11661/11700\n",
      "tensor([ 0.6666, -0.5814])\n",
      "pre:left true:left 11662/11700\n",
      "tensor([ 0.7646, -0.8158])\n",
      "pre:left true:left 11663/11700\n",
      "tensor([ 0.9569, -0.9093])\n",
      "pre:left true:left 11664/11700\n",
      "tensor([ 0.3310, -0.3278])\n",
      "pre:left true:left 11665/11700\n",
      "tensor([-0.4350,  0.4425])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左96_0_252_20200412_114100770.jpg\n",
      "pre:right true:left 11666/11700\n",
      "tensor([-0.0953,  0.1412])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左112_0_268_20200412_114121619_5.jpg\n",
      "pre:right true:left 11667/11700\n",
      "tensor([-0.3633,  0.4007])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1174_0_1174_20200412_112411433_10.jpg\n",
      "pre:right true:left 11668/11700\n",
      "tensor([ 0.9484, -0.8873])\n",
      "pre:left true:left 11669/11700\n",
      "tensor([-0.2271,  0.2589])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左1556_0_1712_20200412_121243498_9.jpg\n",
      "pre:right true:left 11670/11700\n",
      "tensor([ 1.4017, -1.4284])\n",
      "pre:left true:left 11671/11700\n",
      "tensor([ 1.0013, -0.9316])\n",
      "pre:left true:left 11672/11700\n",
      "tensor([ 0.8207, -0.8665])\n",
      "pre:left true:left 11673/11700\n",
      "tensor([ 0.9509, -0.9675])\n",
      "pre:left true:left 11674/11700\n",
      "tensor([ 1.1555, -1.1609])\n",
      "pre:left true:left 11675/11700\n",
      "tensor([ 0.4242, -0.3974])\n",
      "pre:left true:left 11676/11700\n",
      "tensor([ 0.1374, -0.1561])\n",
      "pre:left true:left 11677/11700\n",
      "tensor([ 0.4485, -0.5779])\n",
      "pre:left true:left 11678/11700\n",
      "tensor([ 0.8521, -0.8049])\n",
      "pre:left true:left 11679/11700\n",
      "tensor([ 0.7326, -0.7266])\n",
      "pre:left true:left 11680/11700\n",
      "tensor([ 0.6267, -0.5954])\n",
      "pre:left true:left 11681/11700\n",
      "tensor([ 0.5548, -0.6201])\n",
      "pre:left true:left 11682/11700\n",
      "tensor([ 0.2949, -0.2798])\n",
      "pre:left true:left 11683/11700\n",
      "tensor([ 1.1021, -1.0607])\n",
      "pre:left true:left 11684/11700\n",
      "tensor([ 0.2020, -0.0933])\n",
      "pre:left true:left 11685/11700\n",
      "tensor([ 1.0955, -1.0146])\n",
      "pre:left true:left 11686/11700\n",
      "tensor([ 0.2188, -0.3386])\n",
      "pre:left true:left 11687/11700\n",
      "tensor([ 0.3844, -0.2891])\n",
      "pre:left true:left 11688/11700\n",
      "tensor([ 1.3411, -1.2457])\n",
      "pre:left true:left 11689/11700\n",
      "tensor([-0.2308,  0.1311])\n",
      "pre:right true:left /home/feng/deeplearning/deeplearning/Projects/Classify/1_images_folder/images_gloves_picked_202009/train/left/左938_0_938_20200412_111903938_5.jpg\n",
      "pre:right true:left 11690/11700\n",
      "tensor([ 0.6295, -0.5221])\n",
      "pre:left true:left 11691/11700\n",
      "tensor([ 0.9996, -1.0354])\n",
      "pre:left true:left 11692/11700\n",
      "tensor([ 0.0274, -0.1646])\n",
      "pre:left true:left 11693/11700\n",
      "tensor([ 1.1187, -1.0973])\n",
      "pre:left true:left 11694/11700\n",
      "tensor([ 1.2714, -1.3023])\n",
      "pre:left true:left 11695/11700\n",
      "tensor([ 0.3785, -0.4231])\n",
      "pre:left true:left 11696/11700\n",
      "tensor([ 0.6347, -0.6116])\n",
      "pre:left true:left 11697/11700\n",
      "tensor([ 0.8273, -0.7769])\n",
      "pre:left true:left 11698/11700\n",
      "tensor([ 0.3306, -0.3161])\n",
      "pre:left true:left 11699/11700\n",
      "tensor([ 0.8000, -0.7107])\n",
      "pre:left true:left 11700/11700\n",
      "-----------------------------------ERRcount----------------------------------------\n",
      "1411\n",
      "CPU times: user 6.51 s, sys: 1.26 s, total: 7.77 s\n",
      "Wall time: 4min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python predict/predict_folders.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101d726c-9240-4616-baf4-df727cbbd986",
   "metadata": {},
   "source": [
    "# Export ONNX\n",
    "\n",
    "read model-*.pth and convert to efficientnetV2_917.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbdc2650-c61c-4e8e-850a-cf095fe8959c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cuda:0),\n",
      "      %blocks.10.se.conv_reduce.weight : Float(16, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.10.se.conv_reduce.bias : Float(16, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.10.se.conv_expand.weight : Float(256, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.10.se.conv_expand.bias : Float(256, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.11.se.conv_reduce.weight : Float(32, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.11.se.conv_reduce.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.11.se.conv_expand.weight : Float(512, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.11.se.conv_expand.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.12.se.conv_reduce.weight : Float(32, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.12.se.conv_reduce.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.12.se.conv_expand.weight : Float(512, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.12.se.conv_expand.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.13.se.conv_reduce.weight : Float(32, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.13.se.conv_reduce.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.13.se.conv_expand.weight : Float(512, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.13.se.conv_expand.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.14.se.conv_reduce.weight : Float(32, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.14.se.conv_reduce.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.14.se.conv_expand.weight : Float(512, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.14.se.conv_expand.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.15.se.conv_reduce.weight : Float(32, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.15.se.conv_reduce.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.15.se.conv_expand.weight : Float(512, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.15.se.conv_expand.bias : Float(512, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.16.se.conv_reduce.weight : Float(32, 768, 1, 1, strides=[768, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.16.se.conv_reduce.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.16.se.conv_expand.weight : Float(768, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.16.se.conv_expand.bias : Float(768, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.17.se.conv_reduce.weight : Float(40, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.17.se.conv_reduce.bias : Float(40, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.17.se.conv_expand.weight : Float(960, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.17.se.conv_expand.bias : Float(960, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.18.se.conv_reduce.weight : Float(40, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.18.se.conv_reduce.bias : Float(40, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.18.se.conv_expand.weight : Float(960, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.18.se.conv_expand.bias : Float(960, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.19.se.conv_reduce.weight : Float(40, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.19.se.conv_reduce.bias : Float(40, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.19.se.conv_expand.weight : Float(960, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.19.se.conv_expand.bias : Float(960, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.20.se.conv_reduce.weight : Float(40, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.20.se.conv_reduce.bias : Float(40, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.20.se.conv_expand.weight : Float(960, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.20.se.conv_expand.bias : Float(960, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.21.se.conv_reduce.weight : Float(40, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.21.se.conv_reduce.bias : Float(40, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.21.se.conv_expand.weight : Float(960, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.21.se.conv_expand.bias : Float(960, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.22.se.conv_reduce.weight : Float(40, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.22.se.conv_reduce.bias : Float(40, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.22.se.conv_expand.weight : Float(960, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.22.se.conv_expand.bias : Float(960, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.23.se.conv_reduce.weight : Float(40, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.23.se.conv_reduce.bias : Float(40, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.23.se.conv_expand.weight : Float(960, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.23.se.conv_expand.bias : Float(960, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.24.se.conv_reduce.weight : Float(40, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.24.se.conv_reduce.bias : Float(40, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.24.se.conv_expand.weight : Float(960, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.24.se.conv_expand.bias : Float(960, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.25.se.conv_reduce.weight : Float(40, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.25.se.conv_reduce.bias : Float(40, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.25.se.conv_expand.weight : Float(960, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.25.se.conv_expand.bias : Float(960, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.26.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.26.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.26.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.26.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.27.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.27.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.27.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.27.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.28.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.28.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.28.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.28.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.29.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.29.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.29.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.29.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.30.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.30.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.30.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.30.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.31.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.31.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.31.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.31.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.32.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.32.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.32.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.32.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.33.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.33.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.33.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.33.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.34.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.34.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.34.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.34.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.35.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.35.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.35.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.35.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.36.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.36.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.36.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.36.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.37.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.37.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.37.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.37.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.38.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.38.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.38.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.38.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.39.se.conv_reduce.weight : Float(64, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.39.se.conv_reduce.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.39.se.conv_expand.weight : Float(1536, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0),\n",
      "      %blocks.39.se.conv_expand.bias : Float(1536, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %head.classifier.weight : Float(2, 1280, strides=[1280, 1], requires_grad=1, device=cuda:0),\n",
      "      %head.classifier.bias : Float(2, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %1396 : Float(24, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1397 : Float(24, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1399 : Float(24, 24, 3, 3, strides=[216, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1400 : Float(24, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1402 : Float(24, 24, 3, 3, strides=[216, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1403 : Float(24, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1405 : Float(96, 24, 3, 3, strides=[216, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1406 : Float(96, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1408 : Float(48, 96, 1, 1, strides=[96, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1409 : Float(48, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1411 : Float(192, 48, 3, 3, strides=[432, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1412 : Float(192, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1414 : Float(48, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1415 : Float(48, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1417 : Float(192, 48, 3, 3, strides=[432, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1418 : Float(192, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1420 : Float(48, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1421 : Float(48, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1423 : Float(192, 48, 3, 3, strides=[432, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1424 : Float(192, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1426 : Float(48, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1427 : Float(48, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1429 : Float(192, 48, 3, 3, strides=[432, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1430 : Float(192, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1432 : Float(64, 192, 1, 1, strides=[192, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1433 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1435 : Float(256, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1436 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1438 : Float(64, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1439 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1441 : Float(256, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1442 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1444 : Float(64, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1445 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1447 : Float(256, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1448 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1450 : Float(64, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1451 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1453 : Float(256, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1454 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1456 : Float(256, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1457 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1459 : Float(128, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1460 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1462 : Float(512, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1463 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1465 : Float(512, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1466 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1468 : Float(128, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1469 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1471 : Float(512, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1472 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1474 : Float(512, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1475 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1477 : Float(128, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1478 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1480 : Float(512, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1481 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1483 : Float(512, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1484 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1486 : Float(128, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1487 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1489 : Float(512, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1490 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1492 : Float(512, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1493 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1495 : Float(128, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1496 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1498 : Float(512, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1499 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1501 : Float(512, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1502 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1504 : Float(128, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1505 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1507 : Float(768, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1508 : Float(768, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1510 : Float(768, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1511 : Float(768, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1513 : Float(160, 768, 1, 1, strides=[768, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1514 : Float(160, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1516 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1517 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1519 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1520 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1522 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1523 : Float(160, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1525 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1526 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1528 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1529 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1531 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1532 : Float(160, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1534 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1535 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1537 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1538 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1540 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1541 : Float(160, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1543 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1544 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1546 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1547 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1549 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1550 : Float(160, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1552 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1553 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1555 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1556 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1558 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1559 : Float(160, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1561 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1562 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1564 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1565 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1567 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1568 : Float(160, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1570 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1571 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1573 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1574 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1576 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1577 : Float(160, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1579 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1580 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1582 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1583 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1585 : Float(160, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1586 : Float(160, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1588 : Float(960, 160, 1, 1, strides=[160, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1589 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1591 : Float(960, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1592 : Float(960, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1594 : Float(256, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1595 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1597 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1598 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1600 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1601 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1603 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1604 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1606 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1607 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1609 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1610 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1612 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1613 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1615 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1616 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1618 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1619 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1621 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1622 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1624 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1625 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1627 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1628 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1630 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1631 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1633 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1634 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1636 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1637 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1639 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1640 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1642 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1643 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1645 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1646 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1648 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1649 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1651 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1652 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1654 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1655 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1657 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1658 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1660 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1661 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1663 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1664 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1666 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1667 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1669 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1670 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1672 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1673 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1675 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1676 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1678 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1679 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1681 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1682 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1684 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1685 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1687 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1688 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1690 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1691 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1693 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1694 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1696 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1697 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1699 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1700 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1702 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1703 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1705 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1706 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1708 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1709 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1711 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1712 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1714 : Float(1536, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1715 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1717 : Float(1536, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %1718 : Float(1536, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1720 : Float(256, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1721 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %1723 : Float(1280, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %1724 : Float(1280, strides=[1], requires_grad=0, device=cuda:0)):\n",
      "  %1395 : Float(1, 24, 112, 112, strides=[301056, 12544, 112, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%input, %1396, %1397)\n",
      "  %785 : Float(1, 24, 112, 112, strides=[301056, 12544, 112, 1], device=cpu) = onnx::Sigmoid(%1395)\n",
      "  %786 : Float(1, 24, 112, 112, strides=[301056, 12544, 112, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1395, %785)\n",
      "  %1398 : Float(1, 24, 112, 112, strides=[301056, 12544, 112, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%786, %1399, %1400)\n",
      "  %789 : Float(1, 24, 112, 112, strides=[301056, 12544, 112, 1], device=cpu) = onnx::Sigmoid(%1398)\n",
      "  %790 : Float(1, 24, 112, 112, strides=[301056, 12544, 112, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1398, %789) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %791 : Float(1, 24, 112, 112, strides=[301056, 12544, 112, 1], requires_grad=1, device=cuda:0) = onnx::Add(%790, %786)\n",
      "  %1401 : Float(1, 24, 112, 112, strides=[301056, 12544, 112, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%791, %1402, %1403)\n",
      "  %794 : Float(1, 24, 112, 112, strides=[301056, 12544, 112, 1], device=cpu) = onnx::Sigmoid(%1401)\n",
      "  %795 : Float(1, 24, 112, 112, strides=[301056, 12544, 112, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1401, %794) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %796 : Float(1, 24, 112, 112, strides=[301056, 12544, 112, 1], requires_grad=1, device=cuda:0) = onnx::Add(%795, %791) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:232:0\n",
      "  %1404 : Float(1, 96, 56, 56, strides=[301056, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%796, %1405, %1406)\n",
      "  %799 : Float(1, 96, 56, 56, strides=[301056, 3136, 56, 1], device=cpu) = onnx::Sigmoid(%1404)\n",
      "  %800 : Float(1, 96, 56, 56, strides=[301056, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1404, %799) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1407 : Float(1, 48, 56, 56, strides=[150528, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%800, %1408, %1409)\n",
      "  %1410 : Float(1, 192, 56, 56, strides=[602112, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1407, %1411, %1412)\n",
      "  %805 : Float(1, 192, 56, 56, strides=[602112, 3136, 56, 1], device=cpu) = onnx::Sigmoid(%1410)\n",
      "  %806 : Float(1, 192, 56, 56, strides=[602112, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1410, %805) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1413 : Float(1, 48, 56, 56, strides=[150528, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%806, %1414, %1415)\n",
      "  %809 : Float(1, 48, 56, 56, strides=[150528, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1413, %1407)\n",
      "  %1416 : Float(1, 192, 56, 56, strides=[602112, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%809, %1417, %1418)\n",
      "  %812 : Float(1, 192, 56, 56, strides=[602112, 3136, 56, 1], device=cpu) = onnx::Sigmoid(%1416)\n",
      "  %813 : Float(1, 192, 56, 56, strides=[602112, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1416, %812) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1419 : Float(1, 48, 56, 56, strides=[150528, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%813, %1420, %1421)\n",
      "  %816 : Float(1, 48, 56, 56, strides=[150528, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1419, %809)\n",
      "  %1422 : Float(1, 192, 56, 56, strides=[602112, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%816, %1423, %1424)\n",
      "  %819 : Float(1, 192, 56, 56, strides=[602112, 3136, 56, 1], device=cpu) = onnx::Sigmoid(%1422)\n",
      "  %820 : Float(1, 192, 56, 56, strides=[602112, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1422, %819) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1425 : Float(1, 48, 56, 56, strides=[150528, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%820, %1426, %1427)\n",
      "  %823 : Float(1, 48, 56, 56, strides=[150528, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1425, %816) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:232:0\n",
      "  %1428 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%823, %1429, %1430)\n",
      "  %826 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], device=cpu) = onnx::Sigmoid(%1428)\n",
      "  %827 : Float(1, 192, 28, 28, strides=[150528, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1428, %826) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1431 : Float(1, 64, 28, 28, strides=[50176, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%827, %1432, %1433)\n",
      "  %1434 : Float(1, 256, 28, 28, strides=[200704, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1431, %1435, %1436)\n",
      "  %832 : Float(1, 256, 28, 28, strides=[200704, 784, 28, 1], device=cpu) = onnx::Sigmoid(%1434)\n",
      "  %833 : Float(1, 256, 28, 28, strides=[200704, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1434, %832) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1437 : Float(1, 64, 28, 28, strides=[50176, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%833, %1438, %1439)\n",
      "  %836 : Float(1, 64, 28, 28, strides=[50176, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1437, %1431)\n",
      "  %1440 : Float(1, 256, 28, 28, strides=[200704, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%836, %1441, %1442)\n",
      "  %839 : Float(1, 256, 28, 28, strides=[200704, 784, 28, 1], device=cpu) = onnx::Sigmoid(%1440)\n",
      "  %840 : Float(1, 256, 28, 28, strides=[200704, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1440, %839) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1443 : Float(1, 64, 28, 28, strides=[50176, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%840, %1444, %1445)\n",
      "  %843 : Float(1, 64, 28, 28, strides=[50176, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1443, %836)\n",
      "  %1446 : Float(1, 256, 28, 28, strides=[200704, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%843, %1447, %1448)\n",
      "  %846 : Float(1, 256, 28, 28, strides=[200704, 784, 28, 1], device=cpu) = onnx::Sigmoid(%1446)\n",
      "  %847 : Float(1, 256, 28, 28, strides=[200704, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1446, %846) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1449 : Float(1, 64, 28, 28, strides=[50176, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%847, %1450, %1451)\n",
      "  %850 : Float(1, 64, 28, 28, strides=[50176, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1449, %843) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:232:0\n",
      "  %1452 : Float(1, 256, 28, 28, strides=[200704, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%850, %1453, %1454)\n",
      "  %853 : Float(1, 256, 28, 28, strides=[200704, 784, 28, 1], device=cpu) = onnx::Sigmoid(%1452)\n",
      "  %854 : Float(1, 256, 28, 28, strides=[200704, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1452, %853) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1455 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=256, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%854, %1456, %1457)\n",
      "  %857 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1455)\n",
      "  %858 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1455, %857) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %859 : Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%858) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %860 : Float(1, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%859, %blocks.10.se.conv_reduce.weight, %blocks.10.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %861 : Float(1, 16, 1, 1, strides=[16, 1, 1, 1], device=cpu) = onnx::Sigmoid(%860)\n",
      "  %862 : Float(1, 16, 1, 1, strides=[16, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%860, %861) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %863 : Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%862, %blocks.10.se.conv_expand.weight, %blocks.10.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %864 : Float(1, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%863) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %865 : Float(1, 256, 14, 14, strides=[50176, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%864, %858) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1458 : Float(1, 128, 14, 14, strides=[25088, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%865, %1459, %1460)\n",
      "  %1461 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1458, %1462, %1463)\n",
      "  %870 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1461)\n",
      "  %871 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1461, %870) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1464 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=512, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%871, %1465, %1466)\n",
      "  %874 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1464)\n",
      "  %875 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1464, %874) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %876 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%875) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %877 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%876, %blocks.11.se.conv_reduce.weight, %blocks.11.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %878 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], device=cpu) = onnx::Sigmoid(%877)\n",
      "  %879 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%877, %878) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %880 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%879, %blocks.11.se.conv_expand.weight, %blocks.11.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %881 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%880) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %882 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%881, %875) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1467 : Float(1, 128, 14, 14, strides=[25088, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%882, %1468, %1469)\n",
      "  %885 : Float(1, 128, 14, 14, strides=[25088, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1467, %1458)\n",
      "  %1470 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%885, %1471, %1472)\n",
      "  %888 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1470)\n",
      "  %889 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1470, %888) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1473 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=512, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%889, %1474, %1475)\n",
      "  %892 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1473)\n",
      "  %893 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1473, %892) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %894 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%893) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %895 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%894, %blocks.12.se.conv_reduce.weight, %blocks.12.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %896 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], device=cpu) = onnx::Sigmoid(%895)\n",
      "  %897 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%895, %896) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %898 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%897, %blocks.12.se.conv_expand.weight, %blocks.12.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %899 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%898) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %900 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%899, %893) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1476 : Float(1, 128, 14, 14, strides=[25088, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%900, %1477, %1478)\n",
      "  %903 : Float(1, 128, 14, 14, strides=[25088, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1476, %885)\n",
      "  %1479 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%903, %1480, %1481)\n",
      "  %906 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1479)\n",
      "  %907 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1479, %906) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1482 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=512, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%907, %1483, %1484)\n",
      "  %910 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1482)\n",
      "  %911 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1482, %910) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %912 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%911) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %913 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%912, %blocks.13.se.conv_reduce.weight, %blocks.13.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %914 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], device=cpu) = onnx::Sigmoid(%913)\n",
      "  %915 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%913, %914) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %916 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%915, %blocks.13.se.conv_expand.weight, %blocks.13.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %917 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%916) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %918 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%917, %911) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1485 : Float(1, 128, 14, 14, strides=[25088, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%918, %1486, %1487)\n",
      "  %921 : Float(1, 128, 14, 14, strides=[25088, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1485, %903)\n",
      "  %1488 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%921, %1489, %1490)\n",
      "  %924 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1488)\n",
      "  %925 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1488, %924) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1491 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=512, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%925, %1492, %1493)\n",
      "  %928 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1491)\n",
      "  %929 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1491, %928) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %930 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%929) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %931 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%930, %blocks.14.se.conv_reduce.weight, %blocks.14.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %932 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], device=cpu) = onnx::Sigmoid(%931)\n",
      "  %933 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%931, %932) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %934 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%933, %blocks.14.se.conv_expand.weight, %blocks.14.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %935 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%934) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %936 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%935, %929) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1494 : Float(1, 128, 14, 14, strides=[25088, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%936, %1495, %1496)\n",
      "  %939 : Float(1, 128, 14, 14, strides=[25088, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1494, %921)\n",
      "  %1497 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%939, %1498, %1499)\n",
      "  %942 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1497)\n",
      "  %943 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1497, %942) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1500 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=512, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%943, %1501, %1502)\n",
      "  %946 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1500)\n",
      "  %947 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1500, %946) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %948 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%947) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %949 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%948, %blocks.15.se.conv_reduce.weight, %blocks.15.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %950 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], device=cpu) = onnx::Sigmoid(%949)\n",
      "  %951 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%949, %950) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %952 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%951, %blocks.15.se.conv_expand.weight, %blocks.15.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %953 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%952) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %954 : Float(1, 512, 14, 14, strides=[100352, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%953, %947) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1503 : Float(1, 128, 14, 14, strides=[25088, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%954, %1504, %1505)\n",
      "  %957 : Float(1, 128, 14, 14, strides=[25088, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1503, %939) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:162:0\n",
      "  %1506 : Float(1, 768, 14, 14, strides=[150528, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%957, %1507, %1508)\n",
      "  %960 : Float(1, 768, 14, 14, strides=[150528, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1506)\n",
      "  %961 : Float(1, 768, 14, 14, strides=[150528, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1506, %960) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1509 : Float(1, 768, 14, 14, strides=[150528, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=768, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%961, %1510, %1511)\n",
      "  %964 : Float(1, 768, 14, 14, strides=[150528, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1509)\n",
      "  %965 : Float(1, 768, 14, 14, strides=[150528, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1509, %964) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %966 : Float(1, 768, 1, 1, strides=[768, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%965) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %967 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%966, %blocks.16.se.conv_reduce.weight, %blocks.16.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %968 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], device=cpu) = onnx::Sigmoid(%967)\n",
      "  %969 : Float(1, 32, 1, 1, strides=[32, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%967, %968) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %970 : Float(1, 768, 1, 1, strides=[768, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%969, %blocks.16.se.conv_expand.weight, %blocks.16.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %971 : Float(1, 768, 1, 1, strides=[768, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%970) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %972 : Float(1, 768, 14, 14, strides=[150528, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%971, %965) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1512 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%972, %1513, %1514)\n",
      "  %1515 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1512, %1516, %1517)\n",
      "  %977 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1515)\n",
      "  %978 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1515, %977) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1518 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%978, %1519, %1520)\n",
      "  %981 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1518)\n",
      "  %982 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1518, %981) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %983 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%982) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %984 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%983, %blocks.17.se.conv_reduce.weight, %blocks.17.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %985 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], device=cpu) = onnx::Sigmoid(%984)\n",
      "  %986 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%984, %985) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %987 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%986, %blocks.17.se.conv_expand.weight, %blocks.17.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %988 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%987) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %989 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%988, %982) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1521 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%989, %1522, %1523)\n",
      "  %992 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1521, %1512)\n",
      "  %1524 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%992, %1525, %1526)\n",
      "  %995 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1524)\n",
      "  %996 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1524, %995) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1527 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%996, %1528, %1529)\n",
      "  %999 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1527)\n",
      "  %1000 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1527, %999) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1001 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1000) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1002 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1001, %blocks.18.se.conv_reduce.weight, %blocks.18.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1003 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1002)\n",
      "  %1004 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1002, %1003) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1005 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1004, %blocks.18.se.conv_expand.weight, %blocks.18.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1006 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1005) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1007 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1006, %1000) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1530 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1007, %1531, %1532)\n",
      "  %1010 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1530, %992)\n",
      "  %1533 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1010, %1534, %1535)\n",
      "  %1013 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1533)\n",
      "  %1014 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1533, %1013) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1536 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1014, %1537, %1538)\n",
      "  %1017 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1536)\n",
      "  %1018 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1536, %1017) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1019 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1018) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1020 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1019, %blocks.19.se.conv_reduce.weight, %blocks.19.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1021 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1020)\n",
      "  %1022 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1020, %1021) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1023 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1022, %blocks.19.se.conv_expand.weight, %blocks.19.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1024 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1023) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1025 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1024, %1018) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1539 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1025, %1540, %1541)\n",
      "  %1028 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1539, %1010)\n",
      "  %1542 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1028, %1543, %1544)\n",
      "  %1031 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1542)\n",
      "  %1032 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1542, %1031) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1545 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1032, %1546, %1547)\n",
      "  %1035 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1545)\n",
      "  %1036 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1545, %1035) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1037 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1036) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1038 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1037, %blocks.20.se.conv_reduce.weight, %blocks.20.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1039 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1038)\n",
      "  %1040 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1038, %1039) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1041 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1040, %blocks.20.se.conv_expand.weight, %blocks.20.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1042 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1041) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1043 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1042, %1036) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1548 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1043, %1549, %1550)\n",
      "  %1046 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1548, %1028)\n",
      "  %1551 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1046, %1552, %1553)\n",
      "  %1049 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1551)\n",
      "  %1050 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1551, %1049) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1554 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1050, %1555, %1556)\n",
      "  %1053 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1554)\n",
      "  %1054 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1554, %1053) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1055 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1054) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1056 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1055, %blocks.21.se.conv_reduce.weight, %blocks.21.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1057 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1056)\n",
      "  %1058 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1056, %1057) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1059 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1058, %blocks.21.se.conv_expand.weight, %blocks.21.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1060 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1059) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1061 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1060, %1054) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1557 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1061, %1558, %1559)\n",
      "  %1064 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1557, %1046)\n",
      "  %1560 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1064, %1561, %1562)\n",
      "  %1067 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1560)\n",
      "  %1068 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1560, %1067) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1563 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1068, %1564, %1565)\n",
      "  %1071 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1563)\n",
      "  %1072 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1563, %1071) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1073 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1072) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1074 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1073, %blocks.22.se.conv_reduce.weight, %blocks.22.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1075 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1074)\n",
      "  %1076 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1074, %1075) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1077 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1076, %blocks.22.se.conv_expand.weight, %blocks.22.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1078 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1077) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1079 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1078, %1072) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1566 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1079, %1567, %1568)\n",
      "  %1082 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1566, %1064)\n",
      "  %1569 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1082, %1570, %1571)\n",
      "  %1085 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1569)\n",
      "  %1086 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1569, %1085) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1572 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1086, %1573, %1574)\n",
      "  %1089 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1572)\n",
      "  %1090 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1572, %1089) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1091 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1090) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1092 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1091, %blocks.23.se.conv_reduce.weight, %blocks.23.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1093 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1092)\n",
      "  %1094 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1092, %1093) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1095 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1094, %blocks.23.se.conv_expand.weight, %blocks.23.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1096 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1095) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1097 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1096, %1090) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1575 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1097, %1576, %1577)\n",
      "  %1100 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1575, %1082)\n",
      "  %1578 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1100, %1579, %1580)\n",
      "  %1103 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1578)\n",
      "  %1104 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1578, %1103) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1581 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1104, %1582, %1583)\n",
      "  %1107 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1581)\n",
      "  %1108 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1581, %1107) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1109 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1108) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1110 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1109, %blocks.24.se.conv_reduce.weight, %blocks.24.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1111 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1110)\n",
      "  %1112 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1110, %1111) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1113 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1112, %blocks.24.se.conv_expand.weight, %blocks.24.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1114 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1113) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1115 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1114, %1108) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1584 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1115, %1585, %1586)\n",
      "  %1118 : Float(1, 160, 14, 14, strides=[31360, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1584, %1100) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:162:0\n",
      "  %1587 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1118, %1588, %1589)\n",
      "  %1121 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], device=cpu) = onnx::Sigmoid(%1587)\n",
      "  %1122 : Float(1, 960, 14, 14, strides=[188160, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1587, %1121) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1590 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=960, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%1122, %1591, %1592)\n",
      "  %1125 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1590)\n",
      "  %1126 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1590, %1125) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1127 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1126) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1128 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1127, %blocks.25.se.conv_reduce.weight, %blocks.25.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1129 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1128)\n",
      "  %1130 : Float(1, 40, 1, 1, strides=[40, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1128, %1129) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1131 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1130, %blocks.25.se.conv_expand.weight, %blocks.25.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1132 : Float(1, 960, 1, 1, strides=[960, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1131) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1133 : Float(1, 960, 7, 7, strides=[47040, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1132, %1126) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1593 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1133, %1594, %1595)\n",
      "  %1596 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1593, %1597, %1598)\n",
      "  %1138 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1596)\n",
      "  %1139 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1596, %1138) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1599 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1139, %1600, %1601)\n",
      "  %1142 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1599)\n",
      "  %1143 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1599, %1142) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1144 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1143) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1145 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1144, %blocks.26.se.conv_reduce.weight, %blocks.26.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1146 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1145)\n",
      "  %1147 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1145, %1146) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1148 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1147, %blocks.26.se.conv_expand.weight, %blocks.26.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1149 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1148) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1150 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1149, %1143) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1602 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1150, %1603, %1604)\n",
      "  %1153 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1602, %1593)\n",
      "  %1605 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1153, %1606, %1607)\n",
      "  %1156 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1605)\n",
      "  %1157 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1605, %1156) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1608 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1157, %1609, %1610)\n",
      "  %1160 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1608)\n",
      "  %1161 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1608, %1160) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1162 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1161) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1163 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1162, %blocks.27.se.conv_reduce.weight, %blocks.27.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1164 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1163)\n",
      "  %1165 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1163, %1164) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1166 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1165, %blocks.27.se.conv_expand.weight, %blocks.27.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1167 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1166) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1168 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1167, %1161) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1611 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1168, %1612, %1613)\n",
      "  %1171 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1611, %1153)\n",
      "  %1614 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1171, %1615, %1616)\n",
      "  %1174 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1614)\n",
      "  %1175 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1614, %1174) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1617 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1175, %1618, %1619)\n",
      "  %1178 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1617)\n",
      "  %1179 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1617, %1178) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1180 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1179) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1181 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1180, %blocks.28.se.conv_reduce.weight, %blocks.28.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1182 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1181)\n",
      "  %1183 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1181, %1182) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1184 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1183, %blocks.28.se.conv_expand.weight, %blocks.28.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1185 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1184) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1186 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1185, %1179) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1620 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1186, %1621, %1622)\n",
      "  %1189 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1620, %1171)\n",
      "  %1623 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1189, %1624, %1625)\n",
      "  %1192 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1623)\n",
      "  %1193 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1623, %1192) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1626 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1193, %1627, %1628)\n",
      "  %1196 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1626)\n",
      "  %1197 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1626, %1196) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1198 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1197) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1199 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1198, %blocks.29.se.conv_reduce.weight, %blocks.29.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1200 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1199)\n",
      "  %1201 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1199, %1200) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1202 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1201, %blocks.29.se.conv_expand.weight, %blocks.29.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1203 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1202) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1204 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1203, %1197) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1629 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1204, %1630, %1631)\n",
      "  %1207 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1629, %1189)\n",
      "  %1632 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1207, %1633, %1634)\n",
      "  %1210 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1632)\n",
      "  %1211 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1632, %1210) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1635 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1211, %1636, %1637)\n",
      "  %1214 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1635)\n",
      "  %1215 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1635, %1214) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1216 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1215) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1217 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1216, %blocks.30.se.conv_reduce.weight, %blocks.30.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1218 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1217)\n",
      "  %1219 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1217, %1218) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1220 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1219, %blocks.30.se.conv_expand.weight, %blocks.30.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1221 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1220) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1222 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1221, %1215) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1638 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1222, %1639, %1640)\n",
      "  %1225 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1638, %1207)\n",
      "  %1641 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1225, %1642, %1643)\n",
      "  %1228 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1641)\n",
      "  %1229 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1641, %1228) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1644 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1229, %1645, %1646)\n",
      "  %1232 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1644)\n",
      "  %1233 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1644, %1232) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1234 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1233) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1235 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1234, %blocks.31.se.conv_reduce.weight, %blocks.31.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1236 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1235)\n",
      "  %1237 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1235, %1236) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1238 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1237, %blocks.31.se.conv_expand.weight, %blocks.31.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1239 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1238) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1240 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1239, %1233) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1647 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1240, %1648, %1649)\n",
      "  %1243 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1647, %1225)\n",
      "  %1650 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1243, %1651, %1652)\n",
      "  %1246 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1650)\n",
      "  %1247 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1650, %1246) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1653 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1247, %1654, %1655)\n",
      "  %1250 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1653)\n",
      "  %1251 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1653, %1250) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1252 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1251) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1253 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1252, %blocks.32.se.conv_reduce.weight, %blocks.32.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1254 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1253)\n",
      "  %1255 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1253, %1254) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1256 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1255, %blocks.32.se.conv_expand.weight, %blocks.32.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1257 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1256) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1258 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1257, %1251) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1656 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1258, %1657, %1658)\n",
      "  %1261 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1656, %1243)\n",
      "  %1659 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1261, %1660, %1661)\n",
      "  %1264 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1659)\n",
      "  %1265 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1659, %1264) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1662 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1265, %1663, %1664)\n",
      "  %1268 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1662)\n",
      "  %1269 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1662, %1268) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1270 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1269) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1271 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1270, %blocks.33.se.conv_reduce.weight, %blocks.33.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1272 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1271)\n",
      "  %1273 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1271, %1272) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1274 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1273, %blocks.33.se.conv_expand.weight, %blocks.33.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1275 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1274) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1276 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1275, %1269) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1665 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1276, %1666, %1667)\n",
      "  %1279 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1665, %1261)\n",
      "  %1668 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1279, %1669, %1670)\n",
      "  %1282 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1668)\n",
      "  %1283 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1668, %1282) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1671 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1283, %1672, %1673)\n",
      "  %1286 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1671)\n",
      "  %1287 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1671, %1286) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1288 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1287) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1289 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1288, %blocks.34.se.conv_reduce.weight, %blocks.34.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1290 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1289)\n",
      "  %1291 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1289, %1290) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1292 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1291, %blocks.34.se.conv_expand.weight, %blocks.34.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1293 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1292) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1294 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1293, %1287) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1674 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1294, %1675, %1676)\n",
      "  %1297 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1674, %1279)\n",
      "  %1677 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1297, %1678, %1679)\n",
      "  %1300 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1677)\n",
      "  %1301 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1677, %1300) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1680 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1301, %1681, %1682)\n",
      "  %1304 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1680)\n",
      "  %1305 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1680, %1304) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1306 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1305) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1307 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1306, %blocks.35.se.conv_reduce.weight, %blocks.35.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1308 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1307)\n",
      "  %1309 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1307, %1308) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1310 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1309, %blocks.35.se.conv_expand.weight, %blocks.35.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1311 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1310) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1312 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1311, %1305) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1683 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1312, %1684, %1685)\n",
      "  %1315 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1683, %1297)\n",
      "  %1686 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1315, %1687, %1688)\n",
      "  %1318 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1686)\n",
      "  %1319 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1686, %1318) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1689 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1319, %1690, %1691)\n",
      "  %1322 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1689)\n",
      "  %1323 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1689, %1322) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1324 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1323) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1325 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1324, %blocks.36.se.conv_reduce.weight, %blocks.36.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1326 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1325)\n",
      "  %1327 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1325, %1326) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1328 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1327, %blocks.36.se.conv_expand.weight, %blocks.36.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1329 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1328) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1330 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1329, %1323) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1692 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1330, %1693, %1694)\n",
      "  %1333 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1692, %1315)\n",
      "  %1695 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1333, %1696, %1697)\n",
      "  %1336 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1695)\n",
      "  %1337 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1695, %1336) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1698 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1337, %1699, %1700)\n",
      "  %1340 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1698)\n",
      "  %1341 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1698, %1340) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1342 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1341) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1343 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1342, %blocks.37.se.conv_reduce.weight, %blocks.37.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1344 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1343)\n",
      "  %1345 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1343, %1344) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1346 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1345, %blocks.37.se.conv_expand.weight, %blocks.37.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1347 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1346) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1348 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1347, %1341) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1701 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1348, %1702, %1703)\n",
      "  %1351 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1701, %1333)\n",
      "  %1704 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1351, %1705, %1706)\n",
      "  %1354 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1704)\n",
      "  %1355 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1704, %1354) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1707 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1355, %1708, %1709)\n",
      "  %1358 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1707)\n",
      "  %1359 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1707, %1358) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1360 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1359) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1361 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1360, %blocks.38.se.conv_reduce.weight, %blocks.38.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1362 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1361)\n",
      "  %1363 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1361, %1362) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1364 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1363, %blocks.38.se.conv_expand.weight, %blocks.38.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1365 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1364) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1366 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1365, %1359) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1710 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1366, %1711, %1712)\n",
      "  %1369 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1710, %1351)\n",
      "  %1713 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1369, %1714, %1715)\n",
      "  %1372 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1713)\n",
      "  %1373 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1713, %1372) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1716 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1536, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1373, %1717, %1718)\n",
      "  %1376 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1716)\n",
      "  %1377 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1716, %1376) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1378 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::ReduceMean[axes=[2, 3], keepdims=1](%1377) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:91:0\n",
      "  %1379 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1378, %blocks.39.se.conv_reduce.weight, %blocks.39.se.conv_reduce.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1380 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], device=cpu) = onnx::Sigmoid(%1379)\n",
      "  %1381 : Float(1, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1379, %1380) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1382 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1381, %blocks.39.se.conv_expand.weight, %blocks.39.se.conv_expand.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py:440:0\n",
      "  %1383 : Float(1, 1536, 1, 1, strides=[1536, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::Sigmoid(%1382) # /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py:299:0\n",
      "  %1384 : Float(1, 1536, 7, 7, strides=[75264, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1383, %1377) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:96:0\n",
      "  %1719 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1384, %1720, %1721)\n",
      "  %1387 : Float(1, 256, 7, 7, strides=[12544, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%1719, %1369) # /home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/model.py:162:0\n",
      "  %1722 : Float(1, 1280, 7, 7, strides=[62720, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1387, %1723, %1724)\n",
      "  %1390 : Float(1, 1280, 7, 7, strides=[62720, 49, 7, 1], device=cpu) = onnx::Sigmoid(%1722)\n",
      "  %1391 : Float(1, 1280, 7, 7, strides=[62720, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Mul(%1722, %1390) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1898:0\n",
      "  %1392 : Float(1, 1280, 1, 1, strides=[1280, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::GlobalAveragePool(%1391) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1130:0\n",
      "  %1393 : Float(1, 1280, strides=[1280, 1], requires_grad=1, device=cuda:0) = onnx::Flatten[axis=1](%1392) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1168:0\n",
      "  %output : Float(1, 2, strides=[2, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%1393, %head.classifier.weight, %head.classifier.bias) # /usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1847:0\n",
      "  return (%output)\n",
      "\n",
      "Pytorch  model was successfully converted: onnx/efficientnetV2_917.onnx\n"
     ]
    }
   ],
   "source": [
    "!python ConvertONNX.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f0060f-a7da-44cb-a090-76908182e838",
   "metadata": {},
   "source": [
    "# Load ONNX model in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff6268bc-c27d-4774-b53c-6cf190196e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'pt_model/'\n",
      "/home/feng/deeplearning/deeplearning/Projects/Classify/PyTorch/EfficientNetV2-pytorch/Glove_Class_Train/pt_model\n",
      "efficientnetv2_917_cpu3.pt  model.py      testPT-GPU.py\n",
      "Export_PT_CPU.py            \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%cd pt_model/\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40d41b89-9bfc-42a2-a464-d5429dc9ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python Export_PT_CPU.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "365fa601-1d28-47ae-9611-71e71ba2aff1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e00fc89b2a47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'efficientnetv2_917_cpu3.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.jit.load('efficientnetv2_917_cpu3.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea1004-b6e8-4732-8cf0-2a4edc862192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
